-- phpMyAdmin SQL Dump
-- version 4.7.2
-- https://www.phpmyadmin.net/
--
-- Host: localhost
-- Generation Time: Jul 31, 2017 at 09:25 PM
-- Server version: 5.7.19-0ubuntu0.16.04.1-log
-- PHP Version: 7.0.18-0ubuntu0.16.04.1

SET SQL_MODE = "NO_AUTO_VALUE_ON_ZERO";
SET AUTOCOMMIT = 0;
START TRANSACTION;
SET time_zone = "+00:00";


/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;
/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;
/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;
/*!40101 SET NAMES utf8mb4 */;

--
-- Database: `hofesh`
--

-- --------------------------------------------------------

--
-- Table structure for table `ariyaio`
--

CREATE TABLE `ariyaio` (
  `id` int(11) NOT NULL,
  `content` mediumtext COLLATE utf8mb4_bin NOT NULL,
  `url` varchar(225) COLLATE utf8mb4_bin NOT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin;

--
-- Dumping data for table `ariyaio`
--

INSERT INTO `ariyaio` (`id`, `content`, `url`) VALUES
(1, 'Static Site with Hugo and Firebase(`_|_`)\nAbout a year ago, I decided to abandon WordPress for this blog and switch to Hugo to generate the content and Firebase to host it. How did the authoring workflow change due to this switch?\n\nWordPress is a CMS (content management system) and hence all the authoring workflow happens in a web browser. With Hugo, the process is radically different. As a static site generator, Hugo will construct all the HTML files from every blog entry written in Markdown format, based on a certain template. The huge benefit: all those Markdown files can be stored conveniently in a version control system. The ubiquitous git is a natural choice for doing so.\n\n\n\nAs the blog author, I’m working on a blog draft at a time. The local git repository lives in my laptop and this is where I keep iterating and editing the said draft. I can use Hugo locally to test my changes until I am satisfied with the draft and ready to have it published. While this example illustrates the use of Hugo, other popular static site generators also use the same principle.\n\nWhile the content can be published to Firebase using its excellent CLI, a better approach is to have it fully automated. For doing this, first I set up a private repository on GitLab (other services such as GitHub or Bitbucket would work as well) and make it as the remote origin for my local working repository. Every once a while, particularly when I want to publish a new blog post, I run git push to ensure that the two repositories are in sync. Since GitLab offers web-based editing, if I’m on the road and I want to make a minor tweak to my blog content, I can also do that as long as I have some Internet access.\n\nIn addition to a remote repository, I also create an automated build job using GitLab CI. Since it is a built-in feature of GitLab, I don’t need to worry of setting up a CI task somewhere else, e.g. on Travis CI. My .gitlab-ci.yml looks like the following:\n\nimage: mhart/alpine-node:6.3\nbefore_script:\n  - apk update && apk add openssl\n  - wget https://github.com/spf13/hugo/releases/download/v0.16/hugo_0.16_linux-64bit.tgz\n  - echo \"37ee91ab3469afbf7602a091d466dfa5  hugo_0.16_linux-64bit.tgz\" | md5sum -c\n  - tar xf hugo_0.16_linux-64bit.tgz && cp ./hugo /usr/bin\nhugo_firebase:\n  stage: deploy\n  script:\n  - npm install --silent\n  - npm run build:site\n  - npm run firebase:deploy-ci\n\n\nGitLab CI uses an in-container build process, which I do like a lot. The first block in the above file basically sets up the environment in a container based on Alpine-based Node.js image and by downloading and installing Hugo on the fly. This step is actually quite bandwidth-efficient, consuming only about 17 MB in total download size. It is far easier than preparing a custom Hugo image to be placed in Docker Hub. As a bonus, it is also easy to upgrade to a newer Docker image and a newer Hugo.\n\nThe actual deployment is carried out using Firebase CLI. Since it is based on Node.js, it is also handy to use package.json:\n\n{\n  \"name\": \"ariya.io\",\n  \"version\": \"1.0.0\",\n  \"main\": \"index.js\",\n  \"dependencies\": {\n    \"firebase-tools\": \"~3.0.3\"\n  },\n  \"devDependencies\": {},\n  \"scripts\": {\n    \"build:site\": \"rm -rf public && hugo\",\n    \"firebase:deploy-ci\": \"firebase deploy --token ${FIREBASE_TOKEN}\"\n  }\n}\n\n\nThe environment variable FIREBASE_TOKEN stores the Firebase authentication token. It is saved as a secret variable.\n\nUsing this setup, every single time I push to GitLab, the deployment process is automatically triggered. Usually it takes about a minute for the deploy job to finish. Manual verification via Firebase Console is also rather easy.\n\nWith Firebase Hosting, I enjoy the benefit of HTTP/2, full SSL/TLS for custom domain, as well as CDN support for lightning-fast delivery. At the same time, the workflow is smooth and reliable. Since a static site is only a set of HTML pages, there is no need to worry about CMS vulnerabilities. Easy, secure, and fast!\n\n(`_|_`)May 31, 2017(`_|_`)ariya.io(`_|_`)static-site-with-hugo-and-firebase', 'static-site-with-hugo-and-firebase'),
(2, 'First Look: Kotlin Native(`_|_`)\nA big surprise in the Kotlin land was the technology preview of Kotlin/Native that can compile your Kotlin program into native executable, thereby completely eliminating the need for Java Virtual Machine.\n\nAs a relatively young language, Kotlin gained some popularity in the last few years. Kotlin presents a syntax relatively familiar to Java programmers. Since it came from JetBrains (the maker of IntelliJ, WebStorm, Android Studio, etc), the tooling support is excellent. Interoperability with Java is top notch, not merely an afterthought. And of course, Kotlin is a viable alternative for developing Android applications.\n\nRunning Kotlin programs requires a virtual machine (Java or JavaScript). This is however changing. Just yesterday, JetBrains announced the availability of the technical preview of Kotlin/Native. By leveraging LLVM, Kotlin/Native compiles a Kotlin program into a self-contained executable for iOS, macOS, and Linux (Windows support will be coming later).\n\nTo try Kotlin/Native, simply download it (illustrated here for Linux):\n\n$ curl -OL http://download.jetbrains.com/kotlin/native/kotlin-native-linux-0.1.tar.gz\n$ tar xf kotlin-native-linux-0.1.tar.gz\n$ cd kotlin-native-linux-0.1\n\n\nAlso, make sure you have Java 8 installed on the system. Often, it is as easy as installing OpenJDK 8, either via the package manager or a third-party distribution such as Zulu from Azul Systems.\n\nLet us try it with a simple program:\n\n$ cat << EOF > hola.kt\n> fun main(args : Array<String>) {\n>     println(\"Hello from Kotlin!\")\n> }\n> EOF\n$ bin/kotlinc hola.kt -o hola\n\n\nIf the Kotlin compiler, kotlinc, is invoked for the first time, it needs to grab some additional LLVM-related packages (which may take a while), giving the prompt such as:\n\nDownloading native dependencies (LLVM, sysroot etc).\nThis is a one-time action performed only on the first run of the compiler.\n...\n\n\nOnce the compilation is completed, the executable is ready:\n\n> ./hola\nHello from Kotlin\n\n\nTo my excitement, the size of the executable (after running strip) is rather small, around 163 KB. This is quite good for such an initial tech preview. As expected, the resulting executable does not have a lot of dependencies:\n\n$ ldd ./hola\n        linux-vdso.so.1 (0x00007ffc419e3000)\n        libdl.so.2 => /lib/x86_64-linux-gnu/libdl.so.2 (0x00007f4362b4c000)\n        libm.so.6 => /lib/x86_64-linux-gnu/libm.so.6 (0x00007f436284b000)\n        libpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f436262e000)\n        libgcc_s.so.1 => /lib/x86_64-linux-gnu/libgcc_s.so.1 (0x00007f4362418000)\n        libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007f436206d000)\n        /lib64/ld-linux-x86-64.so.2 (0x00007f4362d50000)\n\n\nIt is also fascinating that this tech preview already has the support for interfacing with C functions (often known as FFI, foreign function interface). The Kotlin/Native git repository at github.com/JetBrains/kotlin-native contains a few sample applications which demonstrate it, including an OpenGL teapot demo (via GLUT):\n\n\n\nDo you think 2017 will be an exciting year for Kotlin? I believe so!\n\n(`_|_`)Apr 5, 2017(`_|_`)ariya.io(`_|_`)first-look-kotlin-native', 'first-look-kotlin-native'),
(3, 'Squeezing JPEG Images with Guetzli(`_|_`)\nGuetzli, a new JPEG encoder from Google, is a promising solution to reduce the size of JPEG images without causing any perceptible degradation in quality.\n\nAs an image format, JPEG is extremely popular, particularly for photos. A JPEG encoder is responsible to take an input image and produce a corresponding a JPEG file, ideally of course with the size much much smaller than the original. A well-known flavor of a modernized JPEG encoder is MozJPEG, developed by Mozilla. Check my previous my blog post Using MozJPEG via Docker if you want to know more about MozJPEG.\n\nAs of lately, there is a new kid on the block, Guetzli from Google. Trying out Guetzli is easy, since the project page prepares prebuilt binaries for Linux, macOS, and Windows. Of course, if you fancy building it from source, that is also a possibility. Once the executable is available, running it is even easier:\n\nguetzli original.jpg optimized.jpg\n\n\nMy test on running Guetzli on a 10-megapixel photo (birds-of-paradise) yields the following result\n\n\n\nThe original image, almost 3 MB in size, is what Canon EOS 400D produced. Reencoding it with MozJPEG with quality of 95 brought it to around 1.3 MB. Finally, running Guetzli on this file saved another 326 KB, reducing the file size to barely 1 MB. When I compare the original photo with what Guetzli optimizes, frankly I can not notice any difference. For the practical purpose of sharing the photo in social media or projecting it to a big TV for the whole family to enjoy, the output of Guetzli is just as good as the original.\n\nThe trick employed by Guetzli is to search for a particular JPEG quantization that optimizes its pyschovisual model. This explains why Guetzli’s tagline is Perceptual JPEG Encoder. Practically speaking, the model is not new as it has been unveild by the Butteraugli project:\n\n\nButteraugli is a project that estimates the psychovisual similarity of two images. It gives a score for the images that is reliable in the domain of barely noticeable differences.\n\n\nThe drawback of this technique is that the search is computationally expensive. In the example I have given above, for that 10-megapixel photo, Guetzli ran for 28 minutes before it finished. On top of that, it was also very hungry, consuming 1 GB of memory during the optimization.\n\nHowever, for a much smaller image, the optimization is more reasonable. When I ran Guetzli on this simple banner, the width is just 600 pixels, the optimization was completed in just a few seconds, reducing the file size from 27,950 bytes to just 20,836 bytes. For such a simple step, saving 7 KB for everyone who needs to download the image is totally worth the effort.\n\nLet the Guetzlification begin!\n\n(`_|_`)Mar 21, 2017(`_|_`)ariya.io(`_|_`)squeezing-jpeg-images-with-guetzli', 'squeezing-jpeg-images-with-guetzli'),
(4, 'Debian on Windows via WSL(`_|_`)\nDebian is well known for its legendary stability. These days, with the help of Windows Subsytem for Linux (WSL), Debian’s rich sets of tools and utilities are also available to millions of Windows users.\n\n\nWhen you activate Windows 10 feature called Windows Subsystem for Linux (WSL), it will download and install Ubuntu Linux (as of now, version 12.0414.04). It will be made available as “Bash on Ubuntu on Windows”. But instead of Ubuntu, is it possible to use Debian? Fortunately, there is this WSL Distribution Switcher project that allows switching the baseline Linux OS for WSL.\n\nTo switch to Debian, first we need to clone the repository (assuming Git is installed and available from PowerShell):\n\n> git clone https://github.com/RoliSoft/WSL-Distribution-Switcher.git\n> cd WSL-Distribution-Switcher\n\n\nNext step is to grab Debian itself, for instance its latest stable version, Jessie (this requires Python):\n\n> python get-source.py debian:jessie\n> python install.py debian:jessie\n\n\nThe script grabs the root file system (from Docker image downloaded from Docker Hub) and unpacks it in the local AppData directory (e.g. C:\\Users\\ariya\\AppData\\Local\\lxss in my system).\n\nBefore we launch Debian, we need to fix the situation with sudo. This is done by switching the default user for WSL to root and launch bash:\n\n> lxrun /setdefaultuser root\n> bash\n\n\nAt this stage, we are already inside Debian. Now it is time to install sudo (as Docker image’s rootfs often does not have it) and to ensure that your user account is in the sudo group:\n\n$ apt-get update\n$ apt-get install sudo\n$ adduser ariya sudo\n$ exit\n\n\nBack to PowerShell, restore the default user for WSL and launch bash for real:\n\n> lxrun /setdefaultuser ariya\n> bash\n\n\nTo prove that is really Debian:\n\n$ cat /etc/debian_version\n8.7\n\n\nOr in a more detailed fashion:\n\n$ sudo apt-get install -y lsb-release\n$ lsb_release -da\nNo LSB modules are available.\nDistributor ID: Debian\nDescription:    Debian GNU/Linux 8.7 (jessie)\nRelease:        8.7\nCodename:       jessie\n\n\nSince this is just a regular Debian system, we can do many things. For instance, we shall be able to run Lua:\n\n$ sudo apt-get install -y lua5.2\n$ cat << EOF > hola.lua\n> print(\"Hello from Lua on Debian via Windows\")\n> EOF\n$ lua hola.lua\nHello from Lua on Debian via Windows\n\n\nBut hey, it’s so much fun to use LuaJIT. And perhaps we shall not install the prebuilt package but rather compile it from its source code. After grabbing the source tarball, e.g LuaJIT-2.0.4.tar.gz, what we need to do:\n\n$ sudo apt-get install -y build-essential\n$ tar zxf LuaJIT-2.0.4.tar.gz\n$ cd LuaJIT-2.0.4\n$ make\n$ src/luajit hola.lua\nHello from Lua on Debian via Windows\n\n\nThe above steps demonstrate that WSL running Debian can be a perfectly working environment for application development.\n\nNow, what do you plan to do with this new superpower?\n\n(`_|_`)Mar 11, 2017(`_|_`)ariya.io(`_|_`)debian-on-windows-via-wsl', 'debian-on-windows-via-wsl'),
(5, 'Windows for Web Development(`_|_`)\nMicrosoft Windows, a popular consumer operating system, can be a capable platform for web developments. There are three hidden tricks to make that happen: utilize a package manager, use a powerful code editor, and run Linux within Windows.\n\nDebian and Ubuntu users love apt-get, macOS fans swear by Homebrew (though Nix is gaining traction). What about the poor fellow who is using Windows? Fortunately, there is a Windows package manager called Chocolatey. Managing tools and applications on Windows become much much less painful with Chocolatey. Once it is installed, a lot of packages are available at your disposal. Want to install Chrome, Firefox, Node.js, OpenJDK, and Python in one go? Just run this:\n\nchoco install googlechrome firefox nodejs zulu python\n\n\n\n\nBrew a cup of tea, and once you are back, all of those are installed, ready to be used. There are thousand packages available for Chocolatey, most of them are quite fresh (for instance, Node.js v7.6 was available for Chocolatey a few hours after the release was officially announced). Keeping your installation up-to-date and secure is easy as choco upgrade all, no more hassle of hunting down the updates for each and every application. For more information on Chocolatey, please read its extensive documentation.\n\nDoing web development without a powerful code editor will be disastrous. Fortunately, there are many choices available for this, from a commercial IDE (e.g. WebStorm) to an open-source lightweight editor (e.g. Vim). Full-featured IDEs such as Eclipse or NetBeans can be configured to handle the usual tasks of web development. On the other hand, there is a growing number of non-IDE code editors suitable for the typical development activities: Sublime Text, Atom, Visual Studio Code, and many more.\n\nMy favorite these days is Visual Studio Code (of course, it is installable via Chocolatey). Beside being actively developed by Microsoft, this open-source code editor can be extended to support various development platforms, whether it is Python, Go, Ruby, PHP, C/C++. C#, F#, Nim, Elixir, and even Java.\n\nLast but not least, do not miss the opportunity of running Linux straight inside Windows, by using Windows Subsytem for Linux (WSL). For a detailed overview on WSL, read the blog post on its underlying technology. In a nutshell, this feature allows Windows to run unmodified Linux executables. In fact, when enabling WSL for the first time, you are installing and using Ubuntu with no modification whatsoever, exactly the same Ubuntu system if you would have installed on a blank machine. Don’t like Ubuntu? Use WSL-Distribution-Switcher to choose between a dozen other distributions, from the trusted OpenSUSE to the rock-solid Debian.\n\nWSL is extremely powerful because a whole new ecosystem of Linux libraries, tools, and utilities are now a few clicks away. Can’t find the Windows equivalent of a tool that you like? Don’t bother, just use the (original) Linux version thereof. Need to verify a server-centric setup? Just provision this Ubuntu-inside-Windows to replicate the environment. Again, no emulation and no recompilation are necessary.\n\nWhat is your own secret trick to make Windows work for you? Please share it with us!\n\n(`_|_`)Feb 28, 2017(`_|_`)ariya.io(`_|_`)windows-for-web-development', 'windows-for-web-development'),
(6, 'ChakraCore on Linux(`_|_`)\nThe latest version of ChakraCore, an open-source JavaScript engine from Microsoft, finally supports JIT compilation on platforms such as Linux and macOS.\n\nAbout a year ago, I played with the initial port of ChakraCore to Linux. Back then, nothing really compiled yet. Time flies and since a few months ago, it is finally possible to enjoy the full glory of ChakraCore on Linux.\n\nThe safest way to play with Linux ChakraCore is to do it an isolated environment (regardless whether the host machine is macOS or another Linux). My favorite is to use Vagrant:\n\nvagrant init ubuntu/xenial64\nvagrant up && vagrant ssh\n\n\nNote that ChakraCore is officially tested on Ubuntu 16.04, hence the above xenial64 box. If you are using an older version of Ubuntu, do not despair. ChakraCore will still compile, but you might need an updated version of CMake, e.g. for Ubuntu 12.04, follow the instructions in this Stack Overflow post.\n\n\n\nOnce inside the virtual machine, grab a few important packages:\n\nsudo apt-get -y update\nsudo apt-get install -y build-essential unzip cmake clang-3.8 libicu-dev libunwind8-dev\n\n\nNow, it is time get the source code and compile it from source!\n\ncurl -o ChakraCore-1.4.zip https://codeload.github.com/Microsoft/ChakraCore/zip/v1.4.0\nunzip ChakraCore-1.4.zip && cd ChakraCore-1.4.0\n./build.sh --cxx=/usr/bin/clang++-3.8 --cc=/usr/bin/clang-3.8\n\n\nIt will take some time for the build process to complete. Once it finishes, you can try out the simplistic JavaScript shell based on ChakraCore. Create a simple test file name math.js (note the use of the exponentiation operator, a feature of ES2016):\n\nconsole.log(3 ** 4);\n\n\nand then run it with ChakraCore shell:\n\n$ BuildLinux/Release/ch math.js\n81\n\n\nThere you have it: a completely functional JavaScript engine from Microsoft, running on Linux!\n\n(`_|_`)Jan 8, 2017(`_|_`)ariya.io(`_|_`)chakracore-on-linux', 'chakracore-on-linux'),
(7, 'On-the-fly JavaScript Syntax Node Inspection(`_|_`)\nA common approach to analyze JavaScript source statically is to parse the source into an abstract syntax tree (AST) and then to traverse the AST. An alternative approach that might work in a few cases is to inspect each syntax node as it is constructed.\n\nA powerful feature available in Esprima since version 3.0 is the ability to invoke a callback function after every syntax node in the abstract syntax tree is created, often referred as the syntax delegate. If you are familiar with map for arrays, then this concept is not strange to you. In the case of Esprima, the argument passed to the callback function is the corresponding syntax node.\n\nThe simplest illustration of this feature is the following script for Node.js:\n\nvar esprima = require(\'esprima\');\nesprima.parse(\'answer = 42\', {}, function(n) {\n  console.log(n.type);\n});\n\n\nAfter pulling Esprima module (npm install esprima), running the script gives the output:\n\nIdentifier\nLiteral\nAssignmentExpression\nExpressionStatement\nProgram\n\n\nOur callback function, which does nothing but to print the node’s type, was called five times. The first two calls were with the deepest nodes (which were also leaves), an Identifier node representing answer and a Literal node for 42. The next was an AssignmentExpression node that combines the previous two nodes (answer = 42). It was then followed by the only statement in the code fragment, an ExpressionStatement node. The last one was (always) the top-level Program node.\n\nIf you pay attention, this is essentially very similiar to the depth-first traversal algorithm. In this case however, we do not wait until the AST is completely constructed. Heck, we do not even save the result of parse at all.\n\nA practical use of the syntax delegate is to detect the presence of a particular node. Let us assume you want to ban the use of any ternary operator. In other words, if there is such a following file bad.js:\n\nvar hour = 9;\nvar msg = (hour < 12) ? \'morning\' : \'afternoon\';\nconsole.log(\'Good \' + msg + \'!\');\n\n\nyou want to be warned because the second line there utilizes the ternary operator.  In the AST produced by Esprima, a ternary operator is represented by a node of the type ConditionalExpression (try it yourself with the online parser demo). Thus, all we have to do is to construct a callback function that looks for such a node. Here is a possible implementation (yes, it is only 8 lines of code!):\n\nvar fs = require(\'fs\');\nvar esprima = require(\'esprima\');\nvar contents = fs.readFileSync(process.argv[2], \'utf-8\');\nesprima.parse(contents, {}, function (node, meta) {\n  if (node.type === \'ConditionalExpression\') {\n    console.log(\'Ternary at line\', meta.start.line);\n  }\n});\n\n\n\n\nIf the above script is named warn-ternary.js, it can be invoked with Node.js as follows:\n\n$ node warn-ternary.js bad.js\nTernary at line 2\n\n\nWhat is new here is the second argument to the callback function. It contains the metadata of the node. The most important metadata is the starting and end location of the node. Hence, it is possible to locate the line number that contains the ternary operator, using meta.start.line.\n\nThese are two simple examples to get you started. If you want to further explore this powerful feature of Esprima, I highly recommend launching your favorite Node.js debugger, follow the code execution, and inspect the way the callback function is invoked. Who knows, perhaps you will come up with a fantastic tool for our beloved JavaScript!\n\n(`_|_`)Dec 31, 2016(`_|_`)ariya.io(`_|_`)on-the-fly-javascript-syntax-node-inspection', 'on-the-fly-javascript-syntax-node-inspection'),
(8, 'Syntax Highlighting in the Terminal(`_|_`)\nSyntax higlighting provides some nice additional visual cues for a code fragment, especially when it is part of an article or a slide deck. But what about code examples in terminal? There is no reason why it should not be highlighted as well.\n\nAs part of a live coding session, often there is a need to quickly show the working snippets, either in the form of code, data (e.g. in JSON), or configuration (e.g. in YAML), in the terminal. A proven solution is to open the snippet in an IDE or an editor that supports syntax higlighting. However, it does not have to be that way. To reduce distractions (switching from and to a different application window), the snippet can be shown right there in the terminal in its full glory, with colors and such.\n\nAmong many different choices, highlight is quite popular. Because of that, it is easily installable using your favorite package manager (apt-get install highlight on Debian/Ubuntu, choco install highlight on Windows, etc). If you are on macOS and use Nix, it is nix-env -i highlight away.\n\nHighlight is very powerful. It can convert code written in many languages into various formats, from LaTeX to HTML. For the purpose of terminal output, the command looks like:\n\n$ highlight --out-format=xterm256 sourcefile\n\n\nas illustrated in the following screenshot:\n\n\n\nFor JavaScript-related code (that includes JSON), a good alternative is Cardinal, a tool made by @thlorenz. Once it is installed from npm with npm install -g cardinal, it is available as the command-line tool cdl.\n\n\n\nBeside a command-line tool, Cardinal is also a Node.js library. Hence, it can be utilized by another utility that needs to display some code or configuration to the user: a bootstrapper, a scaffolding tool, etc.\n\nCardinal supports a few different themes and also a custom theme, if you fancy making one (see its documentation for the details). By tweaking its configuration file, e.g. ~/.cardinalrc, you can also display the line number on the left side.\n\n\n\nUnder the hood, Cardinal relies on the tokenization of the source input. This is carried out using Esprima via redeyed (another library by @thlorenz). Because of that, Cardinal can cope with syntactically invalid code (shown above as broken.js, note the missing closing bracket) or even a slight variant of JavaScript such as TypeScript (ZipCodeValidator.ts in the screenshot).\n\nNext time you need to show some code in the terminal, think of Highlight or Cardinal!\n\n(`_|_`)Nov 27, 2016(`_|_`)ariya.io(`_|_`)syntax-highlighting-in-the-terminal', 'syntax-highlighting-in-the-terminal'),
(9, 'TypeScript 2.0 and Strict Null Checking(`_|_`)\n\n\nThe most recent TypeScript 2.0 includes the ability to treat every type as non-nullable. This is powerful, as ignoring null often leads to latent problems. This post enumerates common type errors related to strict null checking and how they can be remedied.\n\nIn the pull request that implements non-nullable types, Anders Hejlsberg (you may know him from Turbo Pascal, Delphi, and C# as well) explained that:\n\n\nIn strict null checking mode, the null and undefined values are not in the domain of every type and are only assignable to themselves and any.\n\n\nEven better, the type checking also takes into account the control flow, as elaborated in his other pull request.\n\nNow, you may already take care of the null problem by incorporating the checks manually at various places. By migrating to TypeScript 2.0, you will enjoy the additional null checking offered by its compiler. As the migration happens, the compiler will start to complain about many things, some of which are described here.\n\nNot assignable to parameter of type ‘never’\n\nThe most common reason for this error is because there is no more type widening. Here is an example code that triggers the issue. Imagine that there are two compartments in your lunch box and you have to fill them with your choice of food, with its name and calories:\n\nfunction bad() {\n    const lunchBox = [];\n    lunchBox.push(new Sandwich(\'Tuna\', 350));\n    lunchBox.push(new Fruit(\'Banana\', 105));\n}\n\n\nwhich results in something like:\n\nerror TS2345: Argument of type \'Fruit\' is not assignable to parameter of type \'never\'.\n\n\nThe array lunchBox does not have any type information, so it is set to never. As soon as you try to insert an item into the array, the type conflict occurs (never vs Fruit).\n\nOnce the problem like this is identified, the fix is rather straightforward: include the type information accordingly. The following snippet demonstrates the solution.\n\nfunction good() {\n    const lunchBox: Food[] = [];\n    lunchBox.push(new Sandwich(\'Tuna\', 350));\n    lunchBox.push(new Fruit(\'Banana\', 105));\n}\n\n\nArgument of type ‘null’ is not assignable to…\n\nThis error is very similar:\n\nerror TS2345: Argument of type \'null\' is not assignable to parameter of type \'Food\'.\n\n\nand it is the result of the following code:\n\nfunction bad() {\n    const lunchBox: Food[] = [];\n    // light lunch today\n    lunchBox.push(null);\n    lunchBox.push(new Fruit(\'Banana\', 105));\n}\n\n\nHere the values stored in the array lunchBox are supposed to be of the type Food. However, there is a piece of code that tries to insert a null instead (you skip the big meal).\n\nThe fix? There are many possibilities. One of them is to modify the type to allow null (as influenced by C# nullable type):\n\ntype Nullable<T> = T | null;\n\n\nwhich transform the code to look like:\n\nfunction good() {\n    const lunchBox: Nullable<Food>[] = [];\n    // light lunch today\n    lunchBox.push(null);\n    lunchBox.push(new Fruit(\'Banana\', 105));\n}\n\n\nPlease note that while the example code above is very clear and the null is spotted right away, it is not always the case with a large function with complex code paths.\n\nObject is possibly ‘null’\n\nHa, this is the whole point of strict null checks after all!\n\nerror TS2531: Object is possibly \'null\'\n\n\nThe above error is produced by the following code fragment. The TypeScript compiler conveniently warns us that accessing a property of a null value is not likely what we want. Fixing this issue is left as an exercise for the reader.\n\nfunction bad(lunchBox: Nullable<Food>[]) {\n    const total = lunchBox.reduce((cal, item) => cal + item.calories, 0);\n    console.log(\'Total calories:\', total);\n}\n\n\nHow do you like this new feature of TypeScript? Share your experience!\n\n(`_|_`)Oct 2, 2016(`_|_`)ariya.io(`_|_`)typescript-2-and-strict-null-checking', 'typescript-2-and-strict-null-checking'),
(10, 'Anatomy of a Bug Report(`_|_`)\nA report of an issue should always contain three parts: how to reproduce it, what is being currently observed, and what is the expectation.\n\nWhen a software engineer discusses a bug, usually what they mean is a fault or a defect. If we adopt the excellent definition offered in the book Practical Software Testing:\n\n\nA fault (defect) is introduced into the software as the result of an error. It is an anomaly in the software that may cause it to behave incorrectly, and not according to its specification.\n\n\nParaphrasing it, a defect is simply a behavior deviation between the specification and the implementation. A good defect report therefore needs to have three parts: steps to reproduce it, the expected outcome, and the actual outcome.\n\n\n\nThe first part is important to give a proper context to the reader. The process to reproduce the defect needs to be described in a step-by-step fashion. Each step must be clear to everyone who is familiar with the product but not necessarily aware of the problem yet. The complete set of the described steps needs to be minimal, it should only contain the absolute minimum of steps to demonstrate the defect.\n\nIt is relatively straightforward to verify that the steps to reproduce the defect is non-ambiguous and minimal. Grab another person, perhaps a co-worker, and ask them to follow the steps. If that person does not need to ask a question or request a clarification, then the steps can be considered good.\n\nWhen someone follows the steps described earlier, that person should observe an actual outcome. This is the result of the behavior of the current implementation. Since this report is about a defect, clearly the outcome is not what the reporter expects. Thus, it is mandatory to describe the expected outcome, the result of the behavior when the implementation follows the specification faithfully. Stated differently, once the defect is fixed, the observed outcome will match the expected one.\n\nLet us pick an example, a defect in JavaScriptCore (the JavaScript engine used in WebKit) originally filed as WebKit bug #162013. Using the above framework, we can rework the defect report to look like the following.\n\n\nTitle: Duplicate parameter names with default parameters should throw a SyntaxError exception\n\n\nA title should be a concise answer to the question, “What kind of problem do you have?”.\n\n\nSteps to reproduce:\n1. Launch WebKit Nightly\n2. Open the console of Web Inspector\n3. Run the following JavaScript code: function f(x=0, x){}\n\n\nAny web developer should be able to follow the above instructions without any difficulties.\n\n\nActual: The test code is executed without any error.\nExpected: A SyntaxError exception is thrown.\n\n\nThis contrast between actual vs expected emphasizes the difference between how JavaScriptCore currently runs the test code and how the specification treats the test code as syntactically invalid.\n\nWith this simple approach, anyone can understand a defect report without spending hours analyzing it.\n\nAs a final reminder, a good defect report should be as objective as possible. It should not contain any opinions, predictions, or guesses from the reporter. It is of course fine to comment on the report and share some subjective thoughts on the problem or the solution, but those need be clearly marked as such, separated from the undisputed facts discovered in the investigation.\n\nRemember, don’t code today what you can’t debug tomorrow!\n\n(`_|_`)Sep 16, 2016(`_|_`)ariya.io(`_|_`)anatomy-of-a-bug-report', 'anatomy-of-a-bug-report'),
(11, 'ChakraCore on macOS(`_|_`)\nMicrosoft open-sourced their JavaScript engine, ChakraCore, sometime ago. Since then, it has been ported to run on other platforms than Windows. This is fantastic, as now it is possible to use it on other Unices, including macOS.\n\nIt has been more than half a year ago I was playing with ChakraCore on Linux. Back then, the porting was not completed yet but now it is possible to have fun with ChakraCore on non-Windows platform. There are still some caveats, for instance JIT (just-in-time) compilation is not fully supported yet. Still, it should not prevent us from enjoying ChakraCore and start using it.\n\nFor macOS, the main build dependencies are Xcode and CMake. The first is necessary for all the development tools, while CMake (version 3.2 or later) is the chosen build tool. Since I am using Nix as my macOS package manager (see why it is awesome), it is a simple step for me:\n\n$ nix-env -i cmake\n$ cmake --version\ncmake version 3.6.0\n\n\nChakraCore also requires ICU library. This is fulfilled by installing the right package and setting up some environment variables:\n\nnix-env -i icu4c\nexport LIBICU_DEV=$(nix-env -q --xml --out-path icu4c | egrep -o \'(/nix[-/.0-9a-zA-Z]+)-dev\')\n\n\nNow it is time to grab ChakraCore from its repository. While the branch is called linux, it is actually for Linux, FreeBSD, and macOS ports.\nUpdate: There is no need to use that special branch anymore, just use master.\n\ngit clone https://github.com/Microsoft/ChakraCore.git\ncd ChakraCore\n\n\nThere are more than 430 C++ sources to compile, so grab a cup of coffee while waiting for ChakraCore to build!\n\n./build.sh --static --icu=$LIBICU_DEV/include\n\n\n\n\nOnce it is completed without any errors, we can run a simple JavaScript shell built with ChakraCore named ch (it stands for Chakra Host). It does not have a lot of features (i.e. it is not Node.js), but it is sufficient to experiment with. Assuming we have a JavaScript program called hello.js with the following content:\n\nprint(\"Hello world\");\n\n\nthen running it will give us:\n\n$ ./BuildLinux/Release/ch hello.js \nHello world\n\n\nThis example only invokes print, a built-in function (think of console.log) exposed to the JavaScript run-time inside that ch shell.\n\nOf course, ChakraCore knows all the standard JavaScript run-time objects:\n\n$ cat math.js\nprint(\"Sqrt of 2 is\", Math.sqrt(2));\n\n$ ./BuildLinux/Release/ch math.js\nSqrt of 2 is 1.4142135623730951\n\n\nWe can also play with ES2015 (formerly known as ES6):\n\n$ cat class.js \nclass Car {\n  constructor(maker, model, year) {\n    print(\'I am\', maker, model, year);\n  }\n}\nnew Car(\'Maserati\', \'Quattroporte\', 2020);\n\n$ ./BuildLinux/Release/ch class.js \nI am Maserati Quattroporte 2020\n\n\nWhile it is interesting to play with that simplistic shell, obviously ChakraCore is more than that. At the next installment, we will cover the use of ChakraCore to add a scripting feature to an existing application.\n\n(`_|_`)Aug 30, 2016(`_|_`)ariya.io(`_|_`)chakracore-on-macos', 'chakracore-on-macos'),
(12, 'Terminating SSL with Hitch(`_|_`)\nDo you have a web application and still not using SSL? No need to rearchitect your application, you can use a TLS/SSL proxy to front the traffic your application. Among many different choices, Hitch is lightweight, fast, and easy to setup.\n\nIf you used Stud in the past, Hitch (website: hitch-tls.org) is the modern version of it. Hitch is being actively developed by Varnish Software. You might be already familiar with Varnish, a very popular open-source caching proxy.\n\nSince it is a fairly recent revival, usually there is not a lot of prebuilt packages available. Fortunately, Hitch is a rather small project, just a couple of C source files. Building it from source takes only a few minutes.\n\nFirst, make sure you have the necessary tools.\n\nWith a recent Debian or Ubuntu system, it is a matter of installing a few packages:\n\nsudo apt-get install -y pkg-config build-essential libev-dev libssl-dev\n\n\nIf you are on macOS, install the equivalent packages to libev and OpenSSL. Since I’m using Nix (because it’s a wonderful package manager), I also need to set a couple of environment variables so that those packages will be properly discovered:\n\nnix-env -i libev openssl\nexport LIBEV_DIR=$(nix-env -q --xml --out-path libev| grep -Eo \"\\\"(/nix.+)\\\"\")\nexport LIBSSL_DIR=$(nix-env -q --xml --out-path openssl| grep dev| grep -Eo \"\\\"(/nix.+)\\\"\")\nexport SSL_CFLAGS=\"-I $LIBSSL_DIR/include -L $LIBSSL_DIR/lib\"\nexport SSL_LIBS=-lssl\nexport CRYPTO_CFLAGS=\"-I $LIBSSL_DIR/include -L $LIBSSL_DIR/lib\"\nexport CRYPTO_LIBS=-lcrypto\nexport CFLAGS=\"-I $LIBEV_DIR/include -L $LIBEV_DIR/lib $SSL_CFLAGS\"\n\n\nLet’s download the source tarball and compile the code:\n\ncurl https://hitch-tls.org/source/hitch-1.2.0.tar.gz -O\nopenssl md5 hitch-1.2.0.tar.gz | grep \"f2f19b6e92115c083d0fccf59b7bd856\"\ntar zxf hitch-1.2.0.tar.gz\ncd hitch-1.2.0\n./configure --with-rst2man=/bin/true\nmake\n\n\nCheck the executable to ensure that everything is built properly:\n\n$ src/hitch --version\nhitch 1.2.0\n\n\nYou can also verify that Hitch does not have a lot of dependencies (shown here on Ubuntu 14.04):\n\n$ ldd src/hitch\nlinux-vdso.so.1 =>  (0x00007ffd393e0000)\nlibssl.so.1.0.0 => /lib/x86_64-linux-gnu/libssl.so.1.0.0 (0x00007f39587fb000)\nlibcrypto.so.1.0.0 => /lib/x86_64-linux-gnu/libcrypto.so.1.0.0 (0x00007f395841f000)\nlibev.so.4 => /usr/lib/x86_64-linux-gnu/libev.so.4 (0x00007f3958210000)\nlibc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007f3957e4b000)\nlibdl.so.2 => /lib/x86_64-linux-gnu/libdl.so.2 (0x00007f3957c47000)\nlibm.so.6 => /lib/x86_64-linux-gnu/libm.so.6 (0x00007f3957940000)\n/lib64/ld-linux-x86-64.so.2 (0x00005600f800e000)\n\n\nFor a quick sanity check, we can create a test certificate:\n\nsudo apt-get install -y ssl-cert\nsudo make-ssl-cert /usr/share/ssl-cert/ssleay.cnf example.pem\nsudo chmod +r example.pem\n\n\nNow assuming there is an HTTP server running on port 8000, Hitch can be invoked as follows:\n\nsrc/hitch --frontend=[*]:8443 --backend=[localhost]:8000 example.pem \n\n\nOpen your favorite web browser and go to that URL on port 8443 (the browser might give a warning first, due to our test certificate). Hitch will receive that request, handle TLS, and pass the unencrypted connection to the backend running on port 8080:\n\n[ 7435] 10.0.2.2:62635 :0 8:9 proxy connect\n[ 7435] 10.0.2.2:62635 :0 8:9 ssl handshake start\n[ 7435] 10.0.2.2:62635 :0 8:9 ssl client handshake revents=1\n[ 7435] 10.0.2.2:62635 :0 8:9 ssl client handshake err=2\n[ 7435] 10.0.2.2:62635 :0 8:9 ssl client handshake revents=1\n[ 7435] 10.0.2.2:62635 :0 8:9 ssl end handshake\n[ 7435] 10.0.2.2:62635 :60641 8:9 backend connected\n[ 7435] 10.0.2.2:62635 :60641 8:9 Connection closed by backend\n[ 7435] 10.0.2.2:62635 :60641 8:9 proxy shutdown req=1\n[ 7435] 10.0.2.2:62635 :60641 8:9 proxy shutdown req=0\n\n\nObviously, I recommend that you configure Hitch properly (choosing a set of suitable ciphers, etc) depending on your need. Meanwhile, running CipherScan on the default settings will get you:\n\n\n\nHitch is not the only approach to terminate TLS/SSL. Yet, if you are still looking for a solution, give it a try and you have no more excuse not to enable HTTPS for everything!\n\n(`_|_`)Aug 10, 2016(`_|_`)ariya.io(`_|_`)terminating-ssl-with-hitch', 'terminating-ssl-with-hitch'),
(13, 'Shrinking PNG Images with Quantization(`_|_`)\nA screenshot is usually displayed from a PNG image. If the screenshot is mainly for the web consumption, often it is not important to have every pixel portraying the color faithfully. This is an opportunity to reduce the bandwidth consumption by delivering a reasonably good, quantized version of the screenshot in a smaller PNG image.\n\nA perfect reproduction of a screenshot is often necessary for cases such as computer graphics research, Photoshop tutorials, etc. However, when a screenshot exists as an illustration to an article or a blog post, the pixel-by-pixel correctness can be sacrificed. Color quantization is suitable for this purpose.  The trade-off: a minor loss in quality for a much smaller PNG file.\n\nThe following diagram compares an image in its original form and after being quantized to only 64 colors. See if you can spot enough perceptible differences.\n\n\n\nMeanwhile, the reduction in the file size looks promising. If this image is served on a popular web site, the total bandwidth saving could be significant. On top of that, your site visitors will enjoy the image appearing earlier on their web browser.\n\nA popular tool for PNG color quantization is pngquant. Installing it easy as the web site, pngquant.org, already offers ready-to-use binary for various operating systems. On macOS (formerly known as OS X), if you prefer to work with a graphical application instead of a command-line tool, try ImageAlpha or ImageOptim instead.\n\n$ pngquant\npngquant, 2.7.2 (June 2016), by Kornel Lesinski, Greg Roelofs.\n   Color profiles are supported via Cocoa. Using libpng 1.6.23.\n\n\nHere is an example of running pngquant on a file:\n\n$ pngquant --speed 1 --verbose screenshot.png\nscreenshot.png:\n  read 6KB file\n  made histogram...1144 colors found\n  selecting colors...2%\n  selecting colors...4%\n  selecting colors...6%\n  selecting colors...8%\n  selecting colors...21%\n  selecting colors...34%\n  selecting colors...46%\n  selecting colors...59%\n  selecting colors...72%\n  selecting colors...85%\n  selecting colors...97%\n  selecting colors...100%\n  moving colormap towards local minimum\n  eliminated opaque tRNS-chunk entries...0 entries transparent\n  mapped image to new colors...MSE=0.297 (Q=99)\n  writing 256-color image as screenshot-fs8.png\nNo errors detected while quantizing 1 image.\n\n\nThe option -s1 means the slowest speed, for the best result (do not worry, even with this option pngquant usually finishes in a fraction of a second). The output will be a new file named screenshot-fs8.png. As you can see from the log (thanks to --verbose), the original image has 1144 distinct colors but now it has been reduced to only 256 colors. This also demonstrates that pngquant is a lossy compression, it is inevitable that some color information will be the lost. The trick is to understand whether the loss is still acceptable or not.\n\nNow compare the original and the quantized versions to see if you are satisfied with the result. If it turns out that the quantized version still looks really good, it does not hurt to reduce the colors even further. For instance, running the following variant will limit the total number of colors to 64:\n\n$ pngquant 64 --speed 1 screenshot.png\n\n\nAlso, I highly recommend running zopflipng on the output. Zopfli is a lossless encoder so expect no further quality degradation by using it, yet the file size may continue to decrease. For further details, refer to my previous blog post on using Zopfli to optimize PNG.\n\nIn the comparison illustrated earlier, a simple step of running pngquant (followed by zopflipng) cuts the file size to half of the original. Of course, the saving becomes more significant if the image is larger. If your web site serves a lot of PNG images, consider adding this step in your transport optimization strategy and your site visitors will appreciate you!\n\n(`_|_`)Jul 12, 2016(`_|_`)ariya.io(`_|_`)shrinking-png-images-with-quantization', 'shrinking-png-images-with-quantization'),
(14, 'Migration: From WordPress to Hugo(`_|_`)\nAfter using Blogger and WordPress for  5 years each, it is time for something new. I am migrating this blog to a new space, https://ariya.io, with the primary objective of delivering it as fast as possible.\n\nIn the context of a fast transport of a web site, the use of a content delivery network (CDN) is inevitable. This is the reason I rely on Firebase Hosting to build and deploy this new blog. Thanks to its CDN integration (it seems that Firebase is using Fastly), most requests are served from the closest CDN edge servers. Often times, this results in an unbelievable, lightning-fast delivery (checked with Pingdom, excluding the time for SSL handshake).\n\n\n\nTo have a full control over the site, I decided to move away from a CMS (in this case, WordPress) to a static web site generated using Hugo, a blazing-fast static site generator. Each post is a Markdown file, exported from WordPress. Even with over 750 posts, the site poses no difficulties at all to Hugo as it can generate all HTML files in just 2 seconds.\n\nThere are two features lost in this migration: e-mail subscription and related posts. For the former, I am evaluating a third-party subscription service and I am confident that this feature will come back again soon. In the mean time, if you get notified of a new post in this blog via e-mail, please also check the site, ariya.io, from time to time. For displaying related posts, I am also convinced that a rather sophisticated Hugo template, once I know how to leverage its full potential, would be able to do the job as well.\n\nI have never been a fan of WordPress site search. With the migration, I have the chance to replace it with DuckDuckGo search box. You will spot the search box on the landing page and the custom 404 page.\n\nA selling point of WordPress is its web-based editing. Not wanting to lose this feature, I use a private git repository on GitLab to store the new content. That means, creating a new post using a web browser is still entirely possible thanks to GitLab web editor. To deploy the site, the build workflow with Firebase is implemented using GitLab CI pipeline. Overall, this new approach is more robust and still quite flexible.\n\nAn advantage of Firebase: it is trivial to enable SSL, both for practicing SSL everywhere and to prepare for HTTP/2.\nUpdate: After Firebase enabled it, this site is also supporting HTTP/2.\n\nEnjoy the all new https://ariya.io!\n\n(`_|_`)Jul 5, 2016(`_|_`)ariya.io(`_|_`)migration-from-wordpress-to-hugo', 'migration-from-wordpress-to-hugo'),
(15, 'Using Zopfli to Optimize PNG Images(`_|_`)\nPNG format is very useful because it preserve all the colors, making it suitable to depict a screenshot faithfully. Unfortunately, many graphics applications do not produce a PNG file with the smallest possible size. Fortunately, this situation can be remedied using an additional tool such as Zopfli from Google.\n\nZopfli is an encoder implementation of DEFLATE, a compression method commonly used in PNG format (among many other usages, e.g. ZIP, etc), designed to produce the likely smallest compressed output. Since it is a lossless transformation, a PNG file that is recompressed with Zopfli still retains all the pixels as expected.\n\n\n\nFor a web site that serves a lot of PNGs, it is beneficial to run Zopfli on all the PNG images. Making the files smaller (without losing any pixels) means that the web site visitor will enjoy an improved experience due to a faster transport. If the site is extremely popular, the total bandwidth saving could be significant.\n\nCompiling Zopfli on Linux or macOS (formerly known as OS X) is easy:\n\n$ git clone https://github.com/google/zopfli.git\n$ cd zopfli\n$ make zopflipng\n\n\nAfter this, usually I stash the zopflipng executable to my ~/bin:\n\n$ cp ./zopflipng ~/bin\n$ ./zopflipng\nZopfliPNG, a Portable Network Graphics (PNG) image optimizer.\n \nUsage: zopflipng [options]... infile.png outfile.png\n       zopflipng [options]... --prefix=[fileprefix] [files.png]...\n\n\nTo optimize a single image:\n\n$ zopflipng screenshot.png screenshot_small.png\n\n\nNote that since Zopfli’s compressor is a CPU-intensive operation, the process often takes a few seconds.\n\nFor a batch conversion, a simple script can be helpful. For instance, I have this png-press.sh:\n\n#!/usr/bin/env sh\n \ntmpfile=$(mktemp)\nzopflipng -m -y $1 $tmpfile\nmv $tmpfile $1\n\n\nNow go to a directory full of images and run:\n\n$ find . -iname *.png  | xargs -I % ./png-press.sh %\n\n\nAs an illustration, this blog site has over 280 PNG images (mostly screenshots), taking a total of 24.4 MB in space. After running the above step, the space consumption is reduced to only 19.1 MB. A good 5 MB saving!\n\nNow, what’s your excuse not to Zopflify your screenshots?\n\n(`_|_`)Jun 28, 2016(`_|_`)ariya.io(`_|_`)using-zopfli-to-optimize-png-images', 'using-zopfli-to-optimize-png-images');
INSERT INTO `ariyaio` (`id`, `content`, `url`) VALUES
(16, 'Isolated Development Environment using Nix(`_|_`)\nIn the earlier blog post, I mentioned the use of Nix as a package manager on OS X. In this follow-up, you will witness the power of Nix to create isolated development environments.\n\nLet us assume I just installed Nix and I don’t have any other packages installed yet:\n\n$ nix-env -qs\nIP-  nix-1.11.2\nIPS  nss-cacert-3.21\n\n\nI need to work on a project named Finch. This is a stable project, it is running in production, it relies on a set of solid and proven environments: Go 1.4, PUC-Lua 5.3, and Python 2.7.\n\nOn the other hand, I also have another unrelated project, Grove. With this project, I’m still experimenting and thus I want to use the latest cutting-edge technology. Its stack is based on the latest Python 3.5 and Go 1.6. For other reasons, I also needed a faster Lua and thereby I pick LuaJIT. As a version control, Fossil is chosen instead of Git.\n\nFor the first project, there is ~/projects/finch/default.nix with the following content:\n\nwith import <nixpkgs> {};\nstdenv.mkDerivation rec {\n  name = \"env\";\n  env = buildEnv { name = name; paths = buildInputs; };\n  buildInputs = [\n    python\n    python27Packages.virtualenv\n    python27Packages.pip\n    go_1_4\n    lua5_3\n  ];\n}\n\n\nWithout going into Nix expression (refer to the manual for the details), the above file tells Nix to build a new environment with the given list of packages specified by the package’s attribute path, listed as buildInputs. How do I know the attribute path for e.g. Go 1.4? One way is to list all available packages:\n\n$ nix-env -qaP | grep \'go-1.4\'\nnixpkgs.go_1_4             go-1.4.3\n\n\nIn the above example go_1_4 (or the fully qualified path nixpkgs.go_1_4) is the attribute path for our lovely go-1.4.3 package.\n\nOnce this Nix file is ready, every time I want to work on Finch, all I have to do is:\n\n$ cd ~/projects/finch/\n$ nix-shell\n[nix-shell:~/projects/finch]$\n\n\nThis will start a new shell with all the packages specified in default.nix. That is, I’m going to get the exact specified version of Python, Go, and Lua. If this is done for the first time, Nix needs to install or build those packages but subsequent call to nix-shell will be very fast since it is reusing what is in the cache.\n\nTo verify that this is working:\n\n[nix-shell:~/projects/finch]$ python --version\nPython 2.7.11\n[nix-shell:~/projects/finch]$ pip --version\npip 8.1.2 from /nix/store/3cag9i2pa52qjxq5yvjap6m7jvp6idqm-python2.7-pip-8.1.2/lib/python2.7/site-packages (python 2.7)\n[nix-shell:~/projects/finch]$ go version\ngo version go1.4.3 darwin/amd64\n[nix-shell:~/projects/finch]$ lua -v\nLua 5.3.0  Copyright (C) 1994-2015 Lua.org, PUC-Rio\n\n\nThis is a completely sealed development environment to work on the Finch project. I can use Python, including virtualenv and pip, as expected:\n\n[nix-shell:~/projects/finch]$ virtualenv env\nNew python executable in env/bin/python2.7\nAlso creating executable in env/bin/python\nInstalling setuptools, pip, wheel...done.\n[nix-shell:~/projects/finch]$ source env/bin/activate\n(env)\n[nix-shell:~/projects/finch]$ pip install simplejson\nCollecting simplejson\nInstalling collected packages: simplejson\nSuccessfully installed simplejson-3.8.2\n(env)\n[nix-shell:~/projects/finch]$ pip list\npip (8.1.2)\nsetuptools (19.4)\nsimplejson (3.8.2)\nvirtualenv (13.1.2)\nwheel (0.24.0)\n(env)\n\n\nIf I exit the shell, I’m back to the default environment which may not have all the specified packages at all.\n\n[nix-shell:~/projects/finch]$ exit\nariya:~/projects/finch $ go version\n-bash: go: command not found\nariya:~/projects/finch $ pip --version\n-bash: pip: command not found\n\n\n\n\nNow I am switching back to Grove. Its default.nix looks slightly different:\n\nwith import <nixpkgs> {};\nstdenv.mkDerivation rec {\n  name = \"env\";\n  env = buildEnv { name = name; paths = buildInputs; };\n  buildInputs = [\n    python35\n    python35Packages.virtualenv\n    python35Packages.pip\n    luajit\n    fossil\n  ];\n}\n\n\nMy initial step before working on Grove:\n\n$ cd ~/projects/grove/\n$ nix-shell\n[nix-shell:~/projects/grove]$\n\n\nAnd it’s easy to see what I get within this environment:\n\nnix-shell:~/projects/grove]$ fossil version\nThis is fossil version 1.33 [9c65b5432e] 2015-05-23 11:11:31 UTC\n[nix-shell:~/projects/grove]$ lua -v\nLuaJIT 2.1.0-beta1 -- Copyright (C) 2005-2015 Mike Pall. http://luajit.org/\n[nix-shell:~/projects/grove]$ virtualenv env\nNew python executable in env/bin/python3.5m\nAlso creating executable in env/bin/python\nInstalling setuptools, pip, wheel...done.\n[nix-shell:~/projects/grove]$ source env/bin/activate\n(env)\n[nix-shell:~/projects/grove]$ pip list\npip (7.1.2)\nsetuptools (19.4)\nvirtualenv (13.1.2)\nwheel (0.24.0)\n(env)\n\n\nAs you can see, I keep my global environment as clean as possible and at the same time, I have the flexible working environment for my two (or more) different projects. The necessary dependent packages of one project will not interfere or pollute other projects, even if it is the same package with different versions (Python 2.7 vs Python 3.5, Go 1.4 vs Go 1.6, PUC-Lua 5.3 vs Lua-JIT 2.1).\n\nEnjoy!\n\n(`_|_`)Jun 12, 2016(`_|_`)ariya.io(`_|_`)isolated-development-environment-using-nix', 'isolated-development-environment-using-nix'),
(17, 'Nix as OS X Package Manager(`_|_`)\nPower users on OS X are familiar with Homebrew or MacPorts for installing and managing software packages conveniently. Yet, those two well-known tools are not the exclusive players. There is a growing interest in Nix, particularly for its use on OS X.\n\nPackage management using Nix is quite simple and intuitive. It does work quite well to replace Homebrew and MacPorts. To get started, install Nix following the instructions:\n\ncurl https://nixos.org/nix/install | sh\n\n\nNix only needs access to /nix, it does not touch any other top-level directories (Nix will never pollute your /usr or /usr/local). Hence, removing Nix is a matter to nuking that /nix directory.\n\nOnce it is installed, the main command-line tool you will interact the most will be nix-env. Try installing a trivial package like this:\n\n$ nix-env -i hello\ninstalling ‘hello-2.10’\nthese paths will be fetched (0.02 MiB download, 0.07 MiB unpacked):\n  /nix/store/b6bxihaz9s5c79dsgbbxvjg8w44a036i-hello-2.10\nfetching path ‘/nix/store/b6bxihaz9s5c79dsgbbxvjg8w44a036i-hello-2.10’...\n$ hello --version\nhello (GNU Hello) 2.10\n\n\nNote the installation path, a peculiar subdirectory under /nix/store. The name contains the cryptographic hash of all inputs necessary to build the package, essentially capturing the complete build dependencies. This enables powerful Nix features such as easy handling of multiple package versions, atomic installation, and many more.\n\nNix also creates a profile for every user, which you once you search for an executable (the importance of Nix profile itself will be more obvious once you start to be more familiar with Nix).\n\n$ which hello\n/Users/ariya/.nix-profile/bin/hello\n\n\nRemoving a package is as easy as installing it:\n\n$ nix-env -e hello\nuninstalling ‘hello-2.10’\n\n\nIn many cases, Nix will install a package in its binary form (as built and cached by the Hydra-based build farm).\n\n\n\nWondering what you can install with Nix? Well, Nix’s collection of packages (especially on OS X, around seven thousands) is not as impressive as Homebrew and MacPorts. Yet, you may find the common packages already available, from Git to Vim (and its plugins). To list all available packages:\n\n$ nix-env -qa\n\n\nJust like every package manager, Nix is also useful to upgrade your arsenal of tools. For instance, OS X El Capitan is armed with Git 2.6 by default. But perhaps you want to use the most recent Git 2.8 instead. This is not a difficult endeavor:\n\n$ git --version\ngit version 2.6.4 (Apple Git-63)\n$ nix-env -i git\nwarning: there are multiple derivations named ‘git-2.8.0’; using the first one\ninstalling ‘git-2.8.0’\n$ which git\n/Users/ariya/.nix-profile/bin/git\n$ git --version\ngit version 2.8.0\n\n\nLater on, if you decide that you don’t like the latest version and you prefer to stick with the default one, the rollback leaves no meaningful left-over and it returns the state of the system exactly before you installed Git 2.8:\n\n$ nix-env -e git\nuninstalling ‘git-2.8.0’\n$ which git\n/usr/bin/git\n$ git --version\ngit version 2.6.4 (Apple Git-63)\n\n\nThese package management tasks are not unique to Nix. Wait for the sequel of this post, where we learn the power of Nix to comfortably handle multiple environments (e.g. Python 2.7 vs Python 3.5).\n\nUpdate: the follow-up blog post is now available, please read Isolated Development Environment with Nix.\n\n(`_|_`)May 25, 2016(`_|_`)ariya.io(`_|_`)nix-as-os-x-package-manager', 'nix-as-os-x-package-manager'),
(18, 'API Names and Begging the Negatives(`_|_`)\nWhen using a programming library, it is unfortunate that we often encounter the use of function and property names in its negative variant. Particularly when there is a choice of two values, using the positive variant would help reducing confusions and ambiguities.\n\n\n\nAs a non-native speaker, understanding a request for help sometimes troubles me a little bit, especially in the first few years of using the language regularly. With English, my biggest challenge was “Do you mind if I borrow your pen?” and other similar constructs. In the beginning, almost automatically my answer was always “Yes” (of course, what I meant was “Yes, you can use my pen”). Note how my answer was semantically not in agreement with my intention. If it was expanded into “Yes, I do mind”, that definitely indicated that I did not like that person to borrow my pen.\n\nIf you wake me up in the middle of the night because you need my help to figure out whether A equals a if caseInsensitive is false, I will be having a hard time. It would have been much easier for me when that special property carries the name caseSensitive.\n\nIn the web world, it is hard to avoid this form because disabled is a popular property name, especially for form elements. This also means that the use of disabled propagates to various library, from jQuery UI to AngularJS (ngDisabled).\n\nThe same problem applies to function names. Looking at any piece of code that invokes setHidden(false), I need to pause and think to ensure that I don’t get it wrong (“is that component visible or not”). Less likely of course if it is simply setVisible(true). A similar case is to be made for methods such as disallowThis() or disallowThat(). An alternative exists, simply use the allowThis(), allowThat() variants when it makes sense.\n\nIn real-world, we are practically more familiar with the existence of thing, and not the lack of thing. You feel that the coffee shop is warm because of the heat, not due to the lack of cold. As you are ready to request a refill, your barista notices that your cup is a quarter full, not a three quarter empty.\n\nNext time you would want to expose a property or a method in a public API, think about its positive vs negative form!\n\n(`_|_`)Apr 17, 2016(`_|_`)ariya.io(`_|_`)api-names-and-begging-the-negatives', 'api-names-and-begging-the-negatives'),
(19, 'Always-on VPN on Your Phone(`_|_`)\nWe often hear stories of harmful last-mile content tampering, from YouTube video downgrading to JavaScript-injected advertisement. This prompted me to run an experiment of always-on VPN on my phone (Nexus 5X running Android 6). Surprisingly, I come to the conclusion that it is definitely feasible to do so without affecting the battery life. Even if you are not a road warrior, it is still good to give it a try and see how it goes.\n\nThere are many ways to set up VPN, it varies from doing everything yourself to just using a commercial service. For Android or iOS devices, there exist numerous popular choices for a good VPN service. Comparing different VPN services is beyond the scope of this blog post, feel free to check out the popular ones such as Vypr, Express, Pure, and many more. One thing that I discovered while doing this exercise was that there is no truly “the best VPN” as the service you choose will depend on the trade-offs you are willing to make.\n\nOne service that I liked a lot and thus I ran it for a while for this experiment is Private Tunnel (works well for both Android and iOS). It is developed and offered by OpenVPN Technologies, the folks behind the OpenVPN project. Unsurprisingly of course, it uses OpenVPN under the hood. What makes Private Tunnel very attractive to me is the pricing model. Unlike other services that use the usual monthly subscription model, Private Tunnel usage is based on volume. This is typically known as pay-as-you-go, e.g. $20 gives you access to 100 GB traffic. Since I do not use my phone for high-bandwidth activities (such as media streaming), it is going to take me forever to hit that 100 GB quota. For all intents and purposes, it is very affordable.\n\nOne does not need to have any technical expertise on VPN or OpenVPN to use Private Tunnel.\n\nThe app itself is almost trivial: launch and press the Connect button. It could not be simpler than that. The only drawback is the lack of automatic reconnect. If your WiFi is flaky or your 3G/4G/LTE is spotty, occasionally you will be in a state of not using the tunneled connection. In a way, this is a good thing because it trains you to watch for the lock symbol on the status bar, hence building your natural sense of security.\n\nThere are advantages and disadvantages of using VPN. If you follow the school of thought of using VPN continuously, at least now you would be able to do it even as you consume the Internet from your wonderful smartphone.\n\nAt the next installment, we will take a look at some easy steps to set up an OpenVPN server manually and use OpenVPN client from your phone.\n\n(`_|_`)Mar 29, 2016(`_|_`)ariya.io(`_|_`)always-on-vpn-on-your-phone', 'always-on-vpn-on-your-phone'),
(20, 'Using MozJPEG via Docker(`_|_`)\nMozJPEG, a JPEG encoder project from Mozilla, is a fantastic way to optimize your JPEG files. Setting it up however might be quite a hassle. Fortunately, a virtualized environment such as Docker offers a much simplified way to use MozJPEG.\n\nThe important requirement is that you have Docker installed and ready to use. If you are on Linux, this should be easy. For OS X and Windows users, follow the steps in my previous blog post on Easy Docker on OS X.\n\nFirst, we will grab MozJPEG source code:\n\ngit clone git://github.com/mozilla/mozjpeg.git \ncd mozjpeg \ngit checkout v3.1\n\n\nIn the current directory, create a Dockerfile with the following content. As you can see, here we will base it on Alpine Linux since it is quite small (around 5 MB).\n\nFROM alpine:3.3 \nADD . /source \nRUN apk --update add autoconf automake build-base libtool nasm \nRUN cd /source && autoreconf -fiv && ./configure --prefix=/opt/mozjpeg && make install\n\n\nOnce this Dockerfile is ready, fire it up with:\n\ndocker build -t mozjpeg .\n\n\n\n\nYou can watch the progress as Docker grabs Alpine 3.3 base image and let Alpine’s package manager, apk, install a number of dependent packages. After that, MozJPEG is being compiled and built from source. Once this is completed (it may take a while), we are ready to utilize this new image for optimizing JPEGs. Also, there is no need to stay in the current directory.\n\nFor the basics on using MozJPEG, I recommend reading the article Using mozjpeg to Create Efficient JPEGs. Let’s say we have a picture we want to optimize, e.g. photo.jpg. We can start a new Docker container containing the above compiled MozJPEG and use it as follows:\n\ncd ~/Documents \ndocker run -v $PWD:/img mozjpeg sh -c \"/opt/mozjpeg/bin/cjpeg -quality 80\n  /img/photo.jpg > /img/photo_small.jpg\"\n\n\nThe command-line option –v $PWD:/img maps the current directory on your host machine to /img as seen from within the container. After that, a shell is invoked with the full command to start MozJPEG’s cjpeg at quality level 80. When I tried this on a simple photo, I was very happy with the optimized version while I got a massive decrease in file size (from 158 KB to 45 KB). Of course, your mileage may vary and make sure you read Kornel’s excellent article on fair image comparison.\n\nStill not optimizing your JPEG files? Now you have no more excuse!\n\n(`_|_`)Mar 14, 2016(`_|_`)ariya.io(`_|_`)using-mozjpeg-via-docker', 'using-mozjpeg-via-docker'),
(21, 'Easy Docker on OS X(`_|_`)\n Using Docker on OS X is getting easier. Previously, it involved setting up boot2docker by hand. With the new Docker Toolbox (which wraps boot2docker and Kitematic, among others), installing Docker is almost trivial.\n\nThe first step is to download and install Docker Toolbox. In case it encounters a problem during the initial run, I recommend reinstalling or updating your VirtualBox first. The major component of Docker Toolbox is Kitematic, which serves a gateway to a catalog of Docker images. You can launch a container based on a particular image. The first image, hello-world-nginx, is always a good start. It contains an instance of Nginx, a popular web server. Click on the CREATE button and wait for a moment while the image is being downloaded from Docker Hub. The progress can be monitored from the container logs.\n\n\n\nOnce the container is running, we can test it. Go to the Settings tab and then Ports. It will show the IP address and port on the OS X system where Nginx is serving the page. Now all you need to do is to open your favorite web browser to go to that address and you will see the HTML content served by Nginx inside the container.\n\nTo change the content of HTML file, go to the Volumes setting and click on /website_files. Kitematic will map it to a directory on your OS X. This is the fun part: edit the HTML file, save it, and refresh your web browser. It is fun to see this round-trip of bits and bytes, a file from the OS X system goes into the container, served via Nginx running in Linux, and then appears as a web content through a web browser.\n\n\n\nIf you want to play with Docker client command line, simply click the DOCKER CLI button on the bottom left corner of Kitematic. This will open the terminal app with access to the docker executable. Try it by running:\n\n$ docker --version \nDocker version 1.9.1, build a34a1d5\n\n\nor by running this minimalistic Node.js image (obviously, it is a complicated way to compute the square root of a number):\n\n$ docker run iron/node node -e \"console.log(Math.sqrt(2))\" \n1.4142135623730951\n\n\nStill afraid of Docker hassle? Hopefully this post shows that the fear is not justified.\n\n(`_|_`)Feb 22, 2016(`_|_`)ariya.io(`_|_`)easy-docker-on-os-x', 'easy-docker-on-os-x'),
(22, 'Playing with ChakraCore on Linux(`_|_`)\nChakraCore, the JavaScript engine that powers the new Edge browser, has been open-sourced by Microsoft. While currently it only runs on Windows, support for other operating systems is in the roadmap. It is fun to follow the progress of the Linux version of ChakraCore.\n\nObviously, nothing works on Linux yet since the porting is still in its early stage. For a start, ChakraCore Windows is built using Visual Studio. For other platforms, the build process needs to use CMake.\n\nOn top of that, Windows-specific API needs to be abstracted. The ChakraCore team decides to bring the important bits and pieces from CoreCLR, another open-source .NET core runtime from Microsoft. CoreCLR already contains the so-called PAL, Platform Adaptation Layer, that deals with file handling, memory management, thread, etc. It does make sense to leverage PAL since it already works quite well for multi-OS support in CoreCLR.\n\n\n\nHow to play with ChakraCore Linux? The easiest is using a virtual machine so that you can do it if your host machine is OS X. In fact, even on Linux host, it is quite beneficial to isolate the setup from your main working environment. I use Vagrant since this is the fastest to prepare. Since ChakraCore Linux requires Clang version 3.5, the easiest is to base your system on Ubuntu 15.10 (Wily Werewolf):\n\nvagrant init ubuntu/wily64\nvagrant up && vagrant ssh\n\n\nYou need a couple of good packages:\n\nsudo apt-get -y update\nsudo apt-get install -y build-essential git cmake clang\n\n\nSwitch from GCC to Clang:\n\nexport CC=\"$(which clang)\"\nexport CXX=\"$(which clang)\"\n\n\nNow the party begins. Clone the repository of ChakraCore, switch to the Linux branch, and have fun!\n\ngit clone https://github.com/Microsoft/ChakraCore.git\ncd ChakraCore\ngit branch linux origin/linux\ngit checkout linux\ncmake . && make\n\n\n(`_|_`)Jan 19, 2016(`_|_`)ariya.io(`_|_`)playing-with-chakracore-on-linux', 'playing-with-chakracore-on-linux'),
(23, 'The Four Fish: Story and Visual(`_|_`)\nAn important step in improving your public speaking skills is to learn from the master. These days, there are a lot of very fascinating talks that can become the source of inspiration. One of them is the most recent TED talk titled, “The four fish we’re overeating”.\n\n\n\nThis talk from Paul Greenberg, as in the usual TED tradition, is not very long. However, in just about 15 minutes, the talk beautifully demonstrates several attributes of a well thought and carefully crafted presentation. If you haven’t watched it, you are welcomed to watch the talk first and then come back again later. Go on, I can wait.\n\nEverytime you attend a presentation training, the importance of the main story is emphasized again and again. The story needs to be narrated in such a way that it can answer the most important thing that the audience care about: What’s in it for me?. Of course, not everybody in the audience needs to draw the same conclusion after Paul finished the talk. Some of them will adjust their seafood consumption, some others will do a follow-up research, and maybe a few won’t care much since they are not a big fan of seafood anyway. Yet, such a talk is considered a success if nobody forgets the story right away the minute they are leaving.\n\nRelated to the story, the opening and the closing of the talk need to be as attractive. A very common way to do this is by narrating a mesmerizing personal story and this is what Paul did in the talk. The closing part is usually more difficult to handle since it needs to address two things. First, it should be related to the opening story to symbolize the wrap up. Second, it must end the talk on a high note.\n\nLast but not least, the slides used by Paul solely served the role of supporting materials. Hence, there is no need to fill the decks with bullet points and long-winded text. The slides can be purely visual, filled with maps, charts, and comparisons. A few analogies here and there help making the point, whether it’s the four fish vs chickens-geese-ducks-turkeys or 80 ton metrics vs human weight. Still, if you would have listened to him while chatting over coffee, the story will not be less profound even where there is no slide involved.\n\nWhat do you like about Paul’s talk? Which techniques do you plan to adopt for your own talk?\n\n(`_|_`)Dec 26, 2015(`_|_`)ariya.io(`_|_`)the-four-fish-story-and-visual', 'the-four-fish-story-and-visual'),
(24, 'Continuous Tests of Downstream Projects(`_|_`)\nIf your library is being used by many other applications, it is often a good idea to run their test suites. Since those downstream applications may break because of your library, this helps catching those cases before you officially release a new public version of the library.\n\nThis is the extra cautious step that we have been practicing for the Esprima project. Since Esprima is the dependency of a few dozens projects out there and its npm package is downloaded at a rate of 10 millions/month, we want to be aware if anything will fall apart before we update it. Thus, those projects become a sort of animal sentinel (“canary in a coal mine”).\n\nEvery time there is a new pull request, there is a number of downstream projects (e.g. Istanbul, JSCS, jsfmt, etc) which will be tested against the modified Esprima in that pull request. The logic is rather simple and the implementation itself weighs just around 100 lines of code.\n\n\n\nFirst, a new temporary directory is created (since we don’t want to clobber the current working directory). In that directory, the downstream project, e.g. Istanbul, will be check out using git clone. For Esprima, we choose to track the master branch of every downstream project and live with the risk of instability. However, for your own project, you may consider tracking a stable branch instead.\n\nAfter that, the project dependencies are installed via npm i. Obviously, among many different packages, this will install the stable, published version of Esprima. This is where the fun begins. That Esprima module will be replaced by dropping in the current development version of Esprima (i.e. of the feature branch associated with the pull request). Following this step, the project tests are executed by running npm test. If any of the tests failed, there is a possibility that it is caused by the pull request. Whether it is a success or a failure, the information will be posted to the pull request to help making the informed decision.\n\nNote that in some cases, the downstream project itself could fail its own test suite. The solution is to track its more stable branch, rather than its development branch. Of course, if the project is too fragile and it does not keep the good hygiene, then it is not terribly suitable as a canary and you have to pick another project.\n\nAs with many other FOSS projects, Esprima is relying on Travis CI to run its tests. For this particular downstream test however, we decided to run it on a different hosted CI system, Circle CI. The reason is simple, we want to have the downstream tests running in parallel to the other usual battery of unit tests and regression tests. For Esprima, the entire downstream test could take some time to finish, about 14 minutes give or take. Running both in parallel means that every pull request can be reviewed after the Travis CI job is completed, while waiting for the longer downstream tests.\n\nMaintaining a library? Be responsible and test your downstream projects!\n\n(`_|_`)Nov 30, 2015(`_|_`)ariya.io(`_|_`)continuous-tests-of-downstream-projects', 'continuous-tests-of-downstream-projects'),
(25, 'Twenty Thousands Leagues Inside the Optical Fiber(`_|_`)\nThese days, we can reach anyone on this planet, anywhere they are located, anytime we like. However, we often never realize that it is only possible because there is a high-bandwidth Internet backbone running on modern and sophisticated fiber optic transmission systems.\n\nAt the most recent O’Reilly Velocity conferences, in Santa Clara and another one in New York, I gave a keynote titled 20,000 Leagues Inside the Optical Fiber. In that talk, I summarized a few important technological milestones in our communication system, up to where we enjoy the luxury of being interconnected with a pipeline with humongous capacity. I won’t spoil it for you as you can watch this 9-minute talk on YouTube:\n\nI believe that keeping this perspective is very important for us. When we engage in various activities and we think that we are noble folks who achieve some earth-shattering objectives, let us pause for a second and recall the series of scientific journeys that transformed our civilization.\n\nIf you know someone who is a scientist, give them a hug. They are the reasons that we could be passionate about what we are doing today.\n\n(`_|_`)Oct 21, 2015(`_|_`)ariya.io(`_|_`)twenty-thousands-leagues-inside-the-optical-fiber', 'twenty-thousands-leagues-inside-the-optical-fiber'),
(26, 'JavaScript Testing with Latest Firefox and Chrome on AppVeyor(`_|_`)\nBuilding a web application without testing it on the major consumer browsers will be crazy. Fortunately, we have a few cross-browser testing services such as Sauce Labs, BrowserStack, and many more. Still, for a quick sanity check on the latest stable version of Google Chrome and Mozilla Firefox, nothing beats the fantastic service provided by AppVeyor.\n\nAs a hosted continuous integration service, AppVeyor runs your application (and its tests) on Windows, more precisely Microsoft Windows Server 2012 R2. This means, we have access to the widely used web browsers: Internet Explorer, Firefox, and Chrome. Due to the platform integration, IE 11 is always available. Often times, Firefox and Chrome are a few versions behind. To solve this issue, we can always install the latest stable version of these two browser right before running thet tests.\n\nIf you want to follow along, I have prepared a simple project github.com/ariya/karma-appveyor. Clone the repository to get the feeling of what it is doing. Since it is designed to be very simple, it consists of only one test, written using Mocha unit test library and executed using Karma test runner:\n\ndescribe(\"sqrt\", function() {\n  it(\"should compute the square root of 4 as 2\", function() {\n    assert.equal(Math.sqrt(4), 2);\n  });\n});\n\n\nThe test itself can be executed by running npm test. It will launch Karma to run the test in the following browsers available on your system: Chrome, Firefox, Safari, and IE. The available browsers are detected using a very nice Karma plugin called karma-detect-browsers. If you are on OS X, what you got is something like this:\n\n\n\nTo run it on AppVeyor, first we need to craft the configuration file that looks like:\n\nversion: \"{build}\"\n\nenvironment:\n  nodejs_version: \"0.12\"\n\ninstall:\n  - ps: Install-Product node $env:nodejs_version\n  - node --version\n  - npm --version\n  - npm install\n\ntest_script:\n  - npm test\n\n\nNow go to appveyor.com, sign in using your GitHub account, create a new project and choose your repository. Explicitly ask for a new build and after a while, AppVeyor is brewing the build as follows:\n\n\n\nIt is running the tests with IE 11, Firefox 30, and Chrome 41. The last two browsers are quite outdated. How do we force an upgrade?\n\nChocolatey to the rescue! Built on top of Nuget, Chocolatey facilitates a silent install of many Windows applications (hence why it is known as the “apt-get of Windows”). We need to tweak our appveyor.yml so that Chocolatey installs firefox and googlechrome package. Of course, if you are living on the edge, feel free to include Firefox Beta and Chrome Beta to the mixture.\n\ninstall:\n  - choco install firefox\n  - choco install googlechrome\n  - ps: Install-Product node $env:nodejs_version\n  - node --version\n  - npm --version\n  - npm install\n\ntest_script:\n  - npm test\n\n\nRun the build on AppVeyor and this time, the build log will be different:\n\n\n\nThere you go: we have IE 11, Firefox 40, and Chrome 45 running our test!\n\n(`_|_`)Sep 16, 2015(`_|_`)ariya.io(`_|_`)javascript-testing-with-latest-firefox-and-chrome-on-appveyor', 'javascript-testing-with-latest-firefox-and-chrome-on-appveyor'),
(27, 'JavaScript Code Coverage Dashboard with Codecov.io(`_|_`)\nIt is a truth universally acknowledged, that a single function critical to the success of the application, must be in want of a unit test. A practical way to prevent the lack of a unit test is to ensure that the overall code coverage does not regress. Fortunately, for applications written in JavaScript, there are a few code coverage services which can help with the task.\n\n\n\nThanks to a variety of language tooling available these days, it is not hard to measure and track code coverage of a JavaScript application. My go-to solution is involving Istanbul as the coverage tool, combined with either Karma or Venus.js as the test runner. This setup works with various popular unit test libraries out there. If you are new to this, I recommend checking out my past blog posts on this subject:\n\n\nKarma and Istanbul with Mocha\nKarma and Istanbul with Jasmine\nKarma and Istanbul with QUnit\nIstanbul and Venus.js (Mocha, Jasmine, QUnit)\n\n\nAnd yet, the work does not stop there. Would it be fantastic if the code coverage report becomes another feedback information for a contributor? Is it possible to track down every single pull request and check if the changes associated with that pull request would regress the coverage? The answer is yes. The key to that is utilizing a hosted code coverage service. There are many out there and in this post I will cover (pun intended) my current favorite, Codecov.io.\n\nThank for a set of its rich features, integrating Codecov.io to your open-source project is very easy. For a start, you do not need to create a dedicated account as you can just authenticate using Github. Furthermore, Codecov.io has a built-in support for Github (as well as other hosted Git such as Bitbucket), choosing a project to be added to your dashboard is trivial.\n\nKeep in mind that Codecov.io displays the coverage information of your project. Your build process still need to produces that coverage information. Also, it is assumed that you have a continuous integration system that runs the build process every time there is a new check-in or when someone has a feature branch in a pull request. For many FOSS project, Travis CI is the most common solution although there are a few other hosted CI services out there.\n\nTo following a long, check out this simple repository that I have created: github.com/ariya/coverage-mocha-istanbul-karma. This repo contains a simple JavaScript project along with its equally simple test suite designed for Mocha. The tests will be executed by Karma.\n\nTo start using Codecov.io, first we need to enable the coverage information in Cobertura format. I have played with different coverage formats and I discovered that Cobertura is the most suitable (your mileage may vary and things can change from time to time). If you use Istanbul directly, you can use its report command to generate the coverage information in the right format (refer to the documentation for more details). With our setup, I modified a section in the Karma configuration file, karma.conf.js, from:\n\ncoverageReporter: {\n    dir : \'coverage/\',\n    reporters: [\n        { type: \'html\', subdir: \'html\' },\n        { type: \'lcov\', subdir: \'lcov\' },\n    ]\n}\n\n\nto:\n\ncoverageReporter: {\n    dir : \'coverage/\',\n    reporters: [\n        { type: \'html\', subdir: \'html\' },\n        { type: \'lcovonly\', subdir: \'lcov\' },\n        { type: \'cobertura\', subdir: \'cobertura\' }\n    ]\n}\n\n\nThis ensures that Karma tells Istanbul to produce another coverage information, in addition to the default lcov, in the format that we want, Cobertura. You can test this, simply execute npm test and after a while, you will spot the file coverage/cobertura/cobertura-coverage.xml that contains the coverage information. This is what we need to send to Codecov.io. There are multiple ways to do that, the easiest is to use codecov.io package. You can use this package by running:\n\nnpm install --save-dev codecov.io.\n\n\nIn this example, package.json is modified to look like this:\n\n\"scripts\": {\n    \"test\": \"grunt karma:test\",\n    \"ci\": \"npm test && codecov < coverage/cobertura/cobertura-coverage.xml\"\n}\n\n\nThus, everytime you invoke npm run ci on your Travis CI job, the tests will be executed and the coverage information will be sent to Codecov.io.\n\n\n\nTo setup the dashboard, login to Codecov.io and add the repository as a new project. Codecov.io maintains a nice mapping of project URL. For example, the coverage dashboard for this example repo github.com/ariya/coverage-mocha-istanbul-karma is codecov.io/github/ariya/coverage-mocha-istanbul-karma. The next time you kick a build on the project, the dashboard will display the coverage information as sent from the build process.\n\nIf that works flawlessly, now you want to enable its pull request integration. Go to the project page and choose Integration and Setup, Pull Request Comment. Now you can determine various ways Codecov.io will comment on every pull request. For a start, you may want to enable Header and Compare Diff.\n\nIn the example repo, I have created a pull request, github.com/ariya/coverage-mocha-istanbul-karma/pull/3, that demonstrated a coverage regression. In that pull request, there is a commit that aims to optimize the code but that optimization does not include an additional unit test. This triggers the following response from Codecov.io, a feedback that is rather obvious:\n\n\n\nWith the build process that produces the coverage information, combined with a service such as Codecov.io, it is easy to keep untested code away from your project!\n\n(`_|_`)Aug 25, 2015(`_|_`)ariya.io(`_|_`)javascript-code-coverage-dashboard-with-codecov-io', 'javascript-code-coverage-dashboard-with-codecov-io'),
(28, 'Presenting without a Self-Introduction(`_|_`)\nIn many tech conferences and other events, we see a trend where the speaker rarely introduces themselves or even when they do, it is rather short (and sweet). Why does this happen? Is that a good trend or a bad one?\n\n\n\nThe argument against doing a self-introduction is pretty simple. Today, we live in a different age. Information is always available at our fingertips. Before going to a talk, we can do a lot of research on the speaker. Right before the talk, there is always an opportunity to check their Twitter, LinkedIn, and other social media. Even better, we can do that with a given context, whether it is related to the current topics of the day or with other speakers that we have known.\n\nA minor variant of this approach is a very quick introduction, ideally in just a few seconds or less. It is thus important to come up with an introduction that is relevant to the audience. Something like “My name is Joe Sixpack, I work for Acme Corp” is less optimal as it does not give the audience any information as to why you are the best person to deliver the talk. It makes sense to switch to the style of “I’m Joe and I created Project Atlantis” if your talk is all about Project Atlantis. In the same spirit, it adds nothing if you ramble for minutes and minutes, enumerating your various achivements and other open-source projects, if those are remotely relevant to the presentation.\n\nOf course, what would help is to establish a good online presence. Some people in the audience look you up on Twitter (and perhaps start following you). Others will Google/Bing/DuckDuckGo your name and take a quick look at your personal homepage. A few will probably want to know what you have posted on your Instagram. In all cases, it is very helpful for your audience if those sites give a faithful representative of who you are, what you like, and other informations related to the subject.\n\nObviously, this is all moot point if there is a moderator who is introducing you. In that case, I have seen that many presenters skip their self-introduction since usually the introduction from the moderator is already flattering and you do not want to spoil that.\n\nWhat about telling the audience about your employer? I believe flashing the company logo or mentioning it quickly in passing is sufficient. If your talk is fantastic, there will be a lot of follow-up discussions and this is usually the best moment to tell more in-depth stories about your company or your start-up.\n\nIt is common nowadays to be in a conference where the talk is only 20 minutes, give or take. Therefore, every minute spent introducing yourself is a minute worth of another good material for your audience.\n\n(`_|_`)Jul 16, 2015(`_|_`)ariya.io(`_|_`)presenting-without-a-self-introduction', 'presenting-without-a-self-introduction'),
(29, 'Detecting and Automatically Fixing JavaScript Code Style(`_|_`)\nAt the most recent jQuerySF conference, Mike Sherov and I did a joint talk on the topic of JavaScript Syntax Tree: Demystified. The highlight of the talk was the demo from Mike as he showed how to fix coding style violations automatically.\n\nThe trick is to use JSCS and its latest features. If you want to follow a long, here is a step-by-step recipe.\n\nFirst, you need to have JSCS installed. This is as easy as:\n\nnpm install -g jscs\n\n\nLet’s pick an example project, for this illustration I use my kinetic scrolling demo:\n\ngit clone https://github.com/ariya/kinetic.git\ncd kinetic\n\n\nNow you want to let JSCS analyze all the JavaScript files in the project and deduce the most suitable code style:\n\njscs --auto-configure .\n\n\n\n\nGive it a few seconds and after a while, JSCS will present the list of code style presets along with its associated number of errors, computed from your JavaScript code. If you already have a preset in my mind, you can choose one. An alternative would be to pick one that has the least amount of violations, as it indicates that your code already gravitates towards that preset.\n\nOnce you choose a preset, JSCS will ask you a couple of self-explained questions. At the end of this step, the configuration file .jscsrc will be created for you. With the configuration, the real magic happens. You just to invoke JSCS this way:\n\njscs -x .\n\n\nthen it will automatically reformat your JavaScript. Double check by looking at the changes and you will see that your code style now follows the specified preset.\n\nWith JSCS, you can comfortably ensure code style consistency throughout your project!\n\n(`_|_`)Jun 28, 2015(`_|_`)ariya.io(`_|_`)detecting-and-automatically-fixing-javascript-code-style', 'detecting-and-automatically-fixing-javascript-code-style'),
(30, 'C++ Multiple Return Values(`_|_`)\n With a complex application, it is often convenient to have a function that returns not just one value. There are many different ways to achieve this in C++, from using a structure to taking advantage of the latest C++ 11 tuple class template.\n\nThe obvious choice, returning an object, seems a bit overkill in many cases. First, you need to declare the structure. It is not seldom that the structure needs to be available for the consumer, hence you have to expose it to the outside world. The construction of the instance is also another ceremonial activity nobody likes to carry out unnecessarily.\n\nFortunately, if the function is supposed to return only two values, std::pair is to the rescue. Most likely, make_pair will be used to construct the pair. Each element of the pair can be accessed using first and second, respectively. This is illustrated in the following example:\n\nstd::pair<std::string , int> findPerson() {\n    return std::make_pair(\"Joe Sixpack\", 42);\n}\n \nint main(int, char**) {\n    std::pair< std::string, int> person = findPerson();\n    std::cout < < \"Name: \" << person.first << std::endl;\n    std::cout << \"Age: \" << person.second << std::endl;\n    return ;\n}\n\n\nWhat if you need more than just two values? Well, obviously std::pair is not fit for the job. In this case, we can leverage boost:tuple from Boost Tuple library. If you are already using std::pair, it is very easy to get familiar with boost::tuple. A tuple can be created using make_tuple, its element is accessed using get<n>, where n denotes the element index.\n\n#include <boost /tuple/tuple.hpp>\n \nboost::tuple<std::string , std::string, int> findPerson() {\n    return boost::make_tuple(\"Joe\", \"Sixpack\", 42);\n}\n \nint main(int, char**) {\n    boost::tuple< std::string , std::string, int> person = findPerson();\n    std::cout < < \"Name: \" << person.get< >() < < \" \"\n        << person.get< 1>() < < std::endl;\n    std::cout << \"Age: \" << person.get< 2>() < < std::endl;\n    return ;\n}\n\n\nWith the latest C++ 11, there is no need to rely on a third party library anymore since std::tuple is already available. With minor tweaks, the previous Boost example will look this in C++. Note also the use auto that saves us from unnecessary verbosity. The compiler knows the return type of findPerson and there is no need for a lengthy type declaration anymore.\n\n#include <tuple>\n \nstd::tuple<std::string , std::string, int> findPerson() {\n    return std::make_tuple(\"Joe\", \"Sixpack\", 42);\n}\n \nint main(int, char**) {\n    auto person = findPerson();\n    std::cout < < \"Name: \" << std::get< >(person) < < \" \" <<\n        std::get< 1>(person) < < std::endl;\n    std::cout << \"Age: \" << std::get< 2>(person) < < std::endl;\n    return ;\n}\n\n\nWhile we are at it, might as well mention std::tie, useful to easily unpack a tuple (similar to ES6 destructuring). It is convenient alternative to the element access using get. The code fragment below demonstrates its usage.\n\nint main(int, char**) {\n    std::string first_name, last_name;\n    int age;\n    std::tie(first_name, last_name, age) = findPerson();\n    std::cout < < \"Name: \" << first_name << std::endl;\n    return ;\n}\n\n\nFrom your own experience, which of these techniques do you like and why do you favor it?\n\n(`_|_`)Apr 30, 2015(`_|_`)ariya.io(`_|_`)c-multiple-return-values', 'c-multiple-return-values'),
(31, 'Continuous Integration for Node.js Projects with TeamCity(`_|_`)\nThere are various hosted continuous integration services out there that you can use for your Node.js projects, from Travis CI to drone.io and many others. If you feel adventurous or you are always fascinated by a DIY solution (for whatever reasons), it is apparently quite easy to setup your own CI system quickly using Docker and TeamCity.\n\nAs an easy-to-use continuous integration system, TeamCity offers two free solutions for you: Professional Server license for up to 20 build configurations or Open Source license for your open-source projects. This is usually sufficient to get you started. Also, per the usual server agent architecture, we will run TeamCity server and agent in two separate containers. This is very similar to my previous blog post on TeamCity installation using Docker, with a minor tweak.\n\nFirst, you need a machine for the server. This could be a physical machine, a virtual machine, or even a VPS. For a hassle-free setup, sign up for either Vultr or Digital Ocean (note: my affiliate links). Make sure you evaluate the system requirements to run the server (e.g. 2 cores and 2 GB RAM will be ideal).\n\nOn this machine, Docker must be installed properly. A useful quick test:\n\nsudo docker run -it ariya/centos7-oracle-jre7 cat /etc/redhat-release\n\n\nshould show something like:\n\nCentOS Linux release 7.0.1406 (Core)\n\n\nOnce Docker is there, starting TeamCity server is as easy as:\n\nsudo docker run -dt --name teamcity_server -p 8111:8111 \\\n  ariya/centos7-teamcity-server\n\n\nThis is using a prepared container I have created called ariya/centos7-teamcity-server. Note that the container supports volume mapping of /data/teamcity. You definitely need to do this if you want to persist your TeamCity projects and other settings. Here is a fancier way to invoke the server where the data is stored on the host system under /var/data/teamcity and with automatic restart in case the server dies.\n\nsudo docker run -dt --name teamcity_server --restart=always -p 8111:8111\n  -v /var/data/teamcity:/data/teamcity\n  ariya/centos7-teamcity-server\n\n\nAlso, if you are using a firewall, make sure to accept connections on port 8111. With iptables:\n\nsudo iptables -A INPUT -p tcp --dport 8111 -j ACCEPT\nsudo service iptables save\n\n\nOnce the server is running, visit the site (on port 8111) using your web browser. This allows you to initialize and configure TeamCity server. In a minute or two, it should be ready to use.\n\n\n\nYou can start creating your CI project, refer to the excellent TeamCity documentation for details. For the build process itself, it is quite common to invoke npm twice, first to install the dependencies and then to run the tests. This is illustrated in the following screenshot.\n\n\n\nWhile it is sufficient to use the command-line runner to invoke e.g. npm test, if you want to be a bit more sophisticated, you can use a customized runner such TeamCity.Node.\n\nOf course, the project can not be executed right now because the server does not have any connecting build agents yet. Starting an agent is also extremely straightforward as I already prepared another container for that, ariya/centos7-teamcity-agent-nodejs. This container is already equipped with Node.js 0.10 and npm 1.3.\n\nsudo docker run -e TEAMCITY_SERVER=http://$TEAMCITY_HOST:8111 -dt -p 9090:9090 \\\n  ariya/centos7-teamcity-agent-nodejs\n\n\nIn the above example, you need to supply the IP address of your server with the environment variable TEAMCITY_HOST. Again, the firewall needs to accept connections on port 9090.\n\n\n\nIt is of course possible to run this agent on the same host as the server, particularly if you have a beefy machine. In this case, you need to use Docker IP address:\n\nexport TEAMCITY_HOST=$(sudo docker inspect --format \\\n  \'{{ .NetworkSettings.IPAddress }}\' teamcity_server)\n\n\nIt takes a while for the agent to register itself with the server. However, it does not mean that the agent is immediately available. First, you need to authorize it so that the server will trust the agent and start dispatching the build tasks to the said agent. After that, you can start running your project.\n\n\n\nThanks to Docker, everything could be done in 10 minutes or less. Have fun with all the tests!\n\n(`_|_`)Mar 31, 2015(`_|_`)ariya.io(`_|_`)continuous-integration-for-node-js-projects-with-teamcity', 'continuous-integration-for-node-js-projects-with-teamcity');
INSERT INTO `ariyaio` (`id`, `content`, `url`) VALUES
(32, 'Towards ECMAScript 6 with Esprima 2(`_|_`)\n\n\nLittle did I know that the start of my adventure with Esprima three years ago will result in something beyond my expectation. While the syntax tree format used by Esprima is not original (see SpiderMonkey Parser API), this de-facto format gains a lot of traction since it provokes a Cambrian explosion of composable JavaScript language tooling, everything from a code coverage tool, a style checker, a delta debugger, a syntax autocompleter, a complexity visualizer, and many more. Mind you, this AST format is far from perfect and hence why some of us at Shape Security are taking a journey to figure out a better format.\n\nThroughout the development, Esprima is also being used as a playground for a rigorious workflow. For example, performance is always important and hence why a benchmark system was implemented early on. There were numerous optimized JavaScript tricks (fixed object shape, profile-guided code shuffling, object-in-a-set) which I discovered via a few interesting investigations. Esprima also enforces a hard threshold of certain metrics, such as cyclomatic complexity and test coverage. Speaking of tests, I consider Esprima’s test suite (~ 800 unit tests) as its crown jewel. It is not uncommon to hear that this collection of tests is being utilized to assist the development of another similar parser, whether it is written in JavaScript or other languages.\n\nAfter being in the wild for a while, Esprima started to attract more contributions, not only in term of adding new features but also for troubleshooting defects, solving performance challenges, and other less glamorous tasks. The growth, 600 dependent packages and 3 millions/month download on npmjs, needs to be anticipated as well. This was why after talking to Dave Methvin some time ago, I felt confident that jQuery Foundation would be a good new umbrella for the project. And that was how the adoption was initiated and finally completed a few weeks ago.\n\nAt the same time, JavaScript continues to evolve. The next edition, ECMAScript 6 (will be called ECMAScript 2015 officially) has its specification frozen, with some JavaScript engines (SpiderMonkey, V8, Chakra, JavaScriptCore) already start to support a few selected features. This has been anticipated by creating the special harmony branch in early 2012. In fact, it has served as the basis of a transpiler called (now defunct) Harmonizr, back when writing a transpiler was not considered cool yet. Meanwhile, more folks (particularly Facebook engineers and some others) continue to enhance this branch. It is being used to drive Facebook JavaScript infrastructure (see JSTransform, Recast, Regenerator, JSX), among others for its ES6 adoption. Still, this harmony branch (despite some unofficial third-party releases) is considered experimental and it should not be used in production.\n\nThis brings us to the most recent 2.0 release. Among others, this release starts to include carefully selected ES6 features (e.g. arrow function, default parameter, method definition). This is to facilitate the migration of downstream language tools, per the original plan outlined several months ago in the mailing-list:\n\n\nThe new master, which bears the version 2.x, will start to introduce ECMAScript 6 features. We will do it peacemeal, taking features which are known to be more or less stabilized in the most recent draft spec. In a few cases, this is a matter of bringing in the existing implementation from the experimental harmony branch.\n\n\nThanks to the wonderful community, these three years have been fantastic. Let’s continue to build amazing tools!\n\n(`_|_`)Feb 9, 2015(`_|_`)ariya.io(`_|_`)towards-ecmascript-6-with-esprima-2', 'towards-ecmascript-6-with-esprima-2'),
(33, 'SMTP Bar Joke and EHLO(`_|_`)\nSome time ago, I came up with a bar joke involving SMTP. Since I need to explain it a couple of times, I thought I just write it down as a blog post for future reference.\n\nThe joke goes like this (as a tweet):\n\n\n  \n    A man walks into an SMTP bar. He says, \"EHLO guys!\".\n  \n  \n  \n    — Ariya Hidayat (@AriyaHidayat) March 13, 2014\n  \n\n\nThe key thing here is the EHLO part. To explain this, let me show you a typical chatting between an SMTP server (e.g. from your mail provider) and an SMTP client (e.g. your email application). If you want to follow along, there is a nice trick. Sign up at Mailtrap for a test account (you can authenticate using your Github credential) and you will have a test server to play with.\n\nStart by connecting to the server using telnet:\n\ntelnet mailtrap.io 2525\nTrying 54.85.222.127...\nConnected to mailtrap.io.\nEscape character is \'^]\'.\n220 mailtrap.io ESMTP ready\n\n\nAt this moment, you are supposed to greet the server (see RFC 821, Section 3.5 on Opening and Closing) using the HELO command:\n\nHELO mailtrap.io\n250 mailtrap.io\n\n\nIf you carefully read the above RFC 821, it is obvious that SMTP commands are 4-letter words. Thus, MAIL is for initiating a transaction, NOOP is to do nothing, HELP for showing up some instructions, and so on.\n\nAs SMTP grows in functionality, an extension mechanism is established so that the client recognizes certain extra features of the server and perhaps would like to leverage them. Rather than inventing a completely different opening command, EHLO is introduced (see RFC 5321, Section 3.2 on Client Initialization). This new command let the client and server know about each other’s privileged status. For example, running EHLO on Mailtrap gives us:\n\nEHLO mailtrap.io\n250-mailtrap.io\n250-SIZE 5242880\n250-PIPELINING\n250-ENHANCEDSTATUSCODES\n250-8BITMIME\n250-DSN\n250-AUTH PLAIN LOGIN CRAM-MD5\n250 STARTTLS\n\n\nwhich basically lists some service extensions supported by Mailtrap’s SMTP server.\n\nPractically all modern email clients prefer to use EHLO instead. It is quite widespread and hence, the bar joke and the EHLO style of greeting. That was fun, right?\n\nQUIT\n\n(`_|_`)Jan 28, 2015(`_|_`)ariya.io(`_|_`)smtp-bar-joke-and-ehlo', 'smtp-bar-joke-and-ehlo'),
(34, 'C++ Class and Preventing Object Copy(`_|_`)\n\n\nIn some cases, an instance of a C++ class should not be copied at all. There are three ways to prevent such an object copy: keeping the copy constructor and assignment operator private, using a special non-copyable mixin, or deleting those special member functions.\n\nA class that represents a wrapper stream of a file should not have its instance copied around. It will cause a confusion in the handling of the actual I/O system. In a similar spirit, if an instance holds a unique private object, copying the pointer does not make sense. A somehow related problem but not necessarily similar is the issue of object slicing.\n\nThe following illustration demonstrates a simple class Vehicle that is supposed to have a unique owner, an instance of Person.\n\nclass Car {\npublic:\n  Car(): owner() {}\n  void setOwner(Person *o) { owner = o; }\n  Person *getOwner() const { return owner; }\n  void info() const;\nprivate:\n  Person *owner;\n};\n\n\nFor this purpose, the implementation of Person is as simple as:\n\nstruct Person {\n  std::string name;\n};\n\n\nTo show the issue, a helper function info() is implement as follows:\n\nvoid Car::info() const\n{\n  if (owner) {\n    std::cout < < \"Owner is \" << owner->name < < std::endl;\n  } else {\n    std::cout << \"This car has no owner.\" << std::endl;\n}\n\n\nFrom this example, it is obvious that an instance of Car must not be copied. In particular, another clone of a similar car should not automatically belong to the same owner. In fact, running the subsequent code:\n\nPerson joe;\n  joe.name = \"Joe Sixpack\";\n \n  Car sedan;\n  sedan.setOwner(&joe);\n  sedan.info();\n  Car anotherSedan = sedan;\n  anotherSedan.info();\n\n\nwill give the output:\n\nOwner is Joe Sixpack\nOwner is Joe Sixpack\n\n\nHow can we prevent this accidental object copy?\n\nMethod 1: Private copy constructor and copy assignment operator\n\nA very common technique is to declare both the copy constructor and copy assignment operator to be private. We do not even need to implement them. The idea is so that any attempt to perform a copy or an assignment will provoke a compile error.\n\nIn the above example, Car will be modified to look like the following. Take a look closely at two additional private members of the class.\n\nclass Car {\npublic:\n  Car(): owner() {}\n  void setOwner(Person *o) { owner = o; }\n  Person *getOwner() const { return owner; }\n  void info() const;\nprivate:\n  Car(const Car&);\n  Car& operator=(const Car&);\n  Person *owner;\n};\n\n\nNow if we try again to assign an instance of Car to a new one, the compiler will complain loudly:\n\nexample.cpp:35:22: error: calling a private constructor of class \'Car\'\n  Car anotherSedan = sedan;\n                     ^\nexample.cpp:22:3: note: declared private here\n  Car(const Car&);\n  ^\n1 error generated.\n\n\nIf writing two additional lines containing repetitive names is too cumbersome, a macro could be utilized instead. This is the approach used by WebKit, see its WTF_MAKE_NONCOPYABLE macro from wtf/Noncopyable.h (do not be alarmed, in the context of WebKit source code, WTF here stands for Web Template Framework). Chromium code, as shown in the file base/macros.h, distinguishes between copy constructor and assignment, denoted as DISALLOW_COPY and DISALLOW_ASSIGN macros, respectively.\n\nMethod 2: Non-copyable mixin\n\nThe idea above can be extended to create a dedicated class which has the sole purpose to prevent object copying. It is often called as Noncopyable and typically used as a mixin. In our example, the Car class can then be derived from this Noncopyable.\n\nBoost users may be already familiar with boost::noncopyable, the Boost flavor of the said mixin. A conceptual, self-contained implementation of that mixin will resemble something like the following:\n\nclass NonCopyable\n{\n  protected:\n    NonCopyable() {}\n    ~NonCopyable() {}\n  private: \n    NonCopyable(const NonCopyable &);\n    NonCopyable& operator=(const NonCopyable &);\n};\n\n\nOur lovely Car class can be written as:\n\nclass Car: private NonCopyable {\npublic:\n  Car(): owner() {}\n  void setOwner(Person *o) { owner = o; }\n  Person *getOwner() const { return owner; }\n  }\nprivate:\n  Person *owner;\n};\n\n\nCompared to the first method, using Noncopyable has the benefit of making the intention very clear. A quick glance at the class, right on its first line, and you know right away that its instance is not supposed to be copied.\n\nMethod 3: Deleted copy constructor and copy assignment operator\n\nFor modern applications, there is less and less reason to get stuck with the above workaround. Thanks to C++11, the solution becomes magically simple: just delete the copy constructor and assignment operator. Our class will look like this instead:\n\nclass Car {\npublic:\n  Car(const Car&) = delete;\n  void operator=(const Car&) = delete;\n  Car(): owner() {}\n  void setOwner(Person *o) { owner = o; }\n  Person *getOwner() const { return owner; }\nprivate:\n  Person *owner;\n};\n\n\nNote that if you use boost::noncopyable mixin with a compiler supporting C++11, the implementation of boost::noncopyable also automatically deletes the said member functions.\n\nWith this approach, any accidental copy will result in a quite friendlier error message:\n\nexample.cpp:34:7: error: call to deleted constructor of \'Car\'\n  Car anotherSedan = sedan;\n      ^              ~~~~~\nexample.cpp:10:3: note: \'Car\' has been explicitly marked deleted here\n  Car(const Car&) = delete;\n  ^\n\n\nSo, which of the above three methods is your favorite?\n\n(`_|_`)Jan 10, 2015(`_|_`)ariya.io(`_|_`)c-class-and-preventing-object-copy', 'c-class-and-preventing-object-copy'),
(35, 'Docker and Phoenix: How to Make Your Continuous Integration More Awesome(`_|_`)\n\n\nWhile a build system is always critical to the success of a software project, maintaining such a system is not always fun. Hence, we tend to investigate many different ways to reduce the maintenance effort. Thanks to Docker, there is a possibility to have the build agent itself very simple because it does nothing but to spin and run a Docker container.\n\nImagine if you are a Python shop and suddenly you have an engineer trying to experiment with Go for the new REST API server. It is certainly possible to retrofit your build infrastructure to include Go development tools and dependencies. But what if another environment and other frameworks are also needed? It is not scalable (process-wise) to always bug your build/release engineers and bug them with these (continuous) requirements.\n\nIn a configuration that involves a server-agent setup (or in Jenkins lingo, master-slave), the agent is the one that does the backbreaking work. In the previous blog post, Build Agent: Template vs Provisioning, I already outlined the most common techniques to eliminate the need to babysit a build agent. I am myself is a big fan of the automatic provisioning approach. Like what Martin Fowler wrote about Phoenix Server:\n\n\nA server should be like a phoenix, regularly rising from the ashes.\n\n\nWhen a build agent misbehaves due to a configuration drift, we shall not bother to troubleshoot it. We simply terminate that troublesome phoenix and let it regenerate (thanks to the provisioning mechanism). For another rather philosophical aspect on this approach, read also my other blog post on A Maturity Model for Build Automation.\n\nThe Container is the Phoenix\n\nIf many of your build agents share the same trait, e.g. they are mostly a Linux system (often in its virtualized form, e.g. an EC2 instance) with assorted different tools (compilers, libraries, frameworks, test systems), then the scenario can be further simplified. What if the build agent is not the actual Phoenix? What if the build agent is only the realm where the phoenix lives (and dies)?\n\nIn this situation, a Docker container becomes the real phoenix. Every project will need to supply some additional information (imperative: in the form of a script, declarative: common configuration understood by the build tool) necessary for the build agent: which container to be used and how to initiate that in-container build.\n\nLet’s take a simple project and setup a build using this Docker and Phoenix approach. For this example, we will build a CPU feature detection tool (implemented using C++). If you want to follow along, simply clone its git repository gitlab.com/ariya/cpu-detect and pay attention to the phoenix subdirectory.\n\nThere are two shell scripts inside the phoenix subdirectory: init.sh and build.sh.\n\nThe first one, init.sh, is the one to be executed by the build agent. It pulls the container used to execute the actual build step. Since this is a C++ project, we will leverage the gcc container. After that, it runs the container with a volume mapping so that /source inside the container is mapped to the git checkout directory. When the container is launched, it also executes the other script build.sh (referred as /source/phoenix/build.sh since we are now inside the container).\n\nIf we simplify it, the whole content of init.sh can be summarized as:\n\ndocker run -v $SOURCE_PATH:/source gcc:4.9 sh - c \"/source/phoenix/build.sh\"\n\n\nThe second script, build.sh, is not executed by the build agent directly. It will run inside the specified container, as described above. The main part of build.sh is to run the actual build step. For this project, it only needs to invoke make (in a real-world project, a battery of tests must be part of this). Before that, the script needs to prepare a build directory and copy the original source (remember, /source inside the container corresponds to the git checkout). Once the build is completed, the build artifact has to be transferred back. In this case, we just copy the generated cpu-detect executable.\n\nIf any step during this process fails, including make itself, then the whole process will be marked as a failure. This automatic propagation of status eliminates the need for a custom error handling.\n\nTo test this setup, have a box with Docker ready to use and then launch phoenix/init.sh. If everything works correctly, you will see an output like the following screenshot.\n\n\n\nIf you experience some Inception moment trying to follow the steps, please use the following diagram. It is also a useful exercise to adopt those two phoenix scripts to your own personal project.\n\n\n\nAgent of Democracy\n\nIn the above example, we pull and run a ready-to-use gcc container. In practice, you may want to come up with a set of customized containers to suit your need. Hence, it is highly recommended that you setup your own Docker registry to be used internally. This becomes a private registry and it should not be accessible by anyone outside your organization. Here is how your init.sh might look like incorporating the technique:\n\nREGISTRY=\"docker.mycompany.com\"\nIMAGE=\"golang\"\nTAG=\"1.4\"\nCONTAINER=\"${REGISTRY}/${IMAGE}:${TAG}\"\n \necho \"Container to be used: $CONTAINER.\"\ndocker pull $CONTAINER\necho\n\n\nNow that the build process only happens inside the container, you can trim down the build agent. For example, it does not need to have packages for all development environment, from Perl to Haskell. All it needs is Docker (and of course the client software to run as a build agent) and thereby massively reducing the provisioning and maintenance effort.\n\nLet’s go back to the illustrative use case mentioned earlier. If an engineer in your team is inspired to evaluate Go, you do not need to modify your build infrastructure. Just ask them to provide a suitable Go development container (or reuse an existing once such as google/golang) and prepare that phoenix-like bootstrapper scripts. The same goes for the new intern who prefers to tinker with Rust instead. No change in the build agent is necessary! Everyone, regardless the project requirements, can utilize the same infrastructure.\n\nIn fact, if you think through this carefully, you will realize that all those Linux build agents are not unique at all. They all have the same installed packages and no agent is better or worse than the others. There is no second-class citizen. This is democracy at its best.\n\nParametrization and Resilience\n\nKnowing the build number and other related build information is often essential to the build process. Fortunately, many continuous integration systems (Bamboo, TeamCity, Jenkins, etc) can pass that information via environment variables. This is quite powerful since all we need to do is to continue to pass that to Docker. For example, if you use Bamboo, then the invocation of docker needs to be modified to look like (notice the use of -e option to denote an environment variable).\n\ndocker run -v $SOURCE_PATH:/source \\\n  -e bamboo_buildNumber=${bamboo_buildNumber}\\\n  $CONTAINER sh - c \"/source/phoenix/build.sh\"\n\n\nAnother side effect of this Docker-based build is the built-in error recovery. In many cases, a build may fail or it gets stuck in some process. Ideally, you want to terminate the build in this situation since it warrants a more thorough investigation. Armed with the useful Unix timeout command, we just need to modify our Docker invocation:\n\nTIMEOUT=2m\necho \"Triggering the build (with ${TIMEOUT} timeout)...\"\ntimeout --signal=SIGKILL ${TIMEOUT} \\\n  docker run -v $SOURCE_PATH:/source \\\n  $CONTAINER sh - c \"/source/phoenix/build.sh\"\n\n\nBy the way, this is the reason why there is an explicit docker pull in init.sh. Technically it’s not needed, but we use it a mechanism to warm up the container cache. This way, the time it takes to initially pull the container will not be included in that 2-minute timeout.\n\nWith the use of timeout, if the Docker process would not complete in 2 minutes, it will be terminated with SIGKILL, effectively aborting the whole step at once. Since the offending application is isolated inside a container, this kind of clean-up also results in a really clean termination. There is no more server hanging out doing nothing because it was not killed properly. There is no stray zombie process eating the resources in the background.\n\nSummary: Use Docker to modify the build agent to be a realm where your phoenix lives and dies. After that, turn every build process into a short-lived phoenix.\n\n(`_|_`)Dec 25, 2014(`_|_`)ariya.io(`_|_`)docker-and-phoenix-how-to-make-your-continuous-integration-more-awesome', 'docker-and-phoenix-how-to-make-your-continuous-integration-more-awesome'),
(36, 'Shells: bash, dash, and fish(`_|_`)\nThe most recent Shellshock, a vulnerability in the popular shell bash, got me to evaluate again the unique setup on Ubuntu/Debian. In this setup, script execution is not handled by bash, this job is carred out by dash, the Debian Almquist Shell. Meanwhile, bash is still used for the interactive shell since dash does not have autocomplete and history support.\n\nOne advantage of this setup is that you start to write your script taking into account that it will not be executed by bash only. This makes sense, it requires just a little effort to avoid certain bashisms and stay compatible to the POSIX syntax. I myself was pretty ignorant of this, assuming that bash is ubiquitous. After using dash for a while, I learn a couple of new tricks and I am happier than my scripts follow this standard best practice. While dash is more efficient in its execution, in most cases the difference is negligible and that was not my primary concern.\n\nLinux users can get dash easily, it is one apt-get or yum install away. For OS X, it is easy enough to build it from its source, e.g.:\n\nDASH_VERSION=0.5.8\nDASH_FULLNAME=dash-${DASH_VERSION}\nDASH_TARBALL=dash_${DASH_VERSION}.orig.tar.gz\nDASH_DOWNLOAD=https://mirrors.kernel.org/debian/pool/main/d/dash/${DASH_TARBALL}\nrm -rf ${DASH_TARBALL} ${DASH_FULLNAME}\ncurl -L ${DASH_DOWNLOAD} -o ${DASH_TARBALL}\ntar xzf ${DASH_TARBALL}\ncd ${DASH_FULLNAME}\n./configure && make\nsudo make install\n\n\nUpdate: On OS X (these days known as macOS), it is advised to use a package manager to install and keep dash up-to-date. For example, Nix works well and installing dash is a matter of running nix-env -i dash. Read also why Nix is awesome.\n\n\n\nAs for the interactive shell, my favorite these days is fish. It does not support every single feature of bash but it works very well. If you are desperate, you can still workaround what you miss from bash. And make sure you check out Oh My Fish! as well.\n\nWhether you prefer bash or dash or fish, Unix shells are always fun to explore!\n\n(`_|_`)Sep 29, 2014(`_|_`)ariya.io(`_|_`)shells-bash-dash-and-fish', 'shells-bash-dash-and-fish'),
(37, 'Chicago, jQuery, and Web Revolution(`_|_`)\nLast week I was in Chicago for the most recent jQuery Conference, part of my autumn tour. It was a fantastic opportunity to have some face-to-face conversations as well as to get to know different folks in the jQuery community. Most importantly, I feel the urge to recall the revolution of the web, in which the state Illinois played an extremely important role.\n\nThe talk I must deliver for jQuery Conference is on a 10,000-foot overview of JavaScript execution in a web browser (check the slide deck, expect the video in a few weeks. Update: watch the video). Since the browser is an essential topic in this case, I could not resist to interject a story, a short detour on the browser history. You might have read a different variant of this, when I wrote about the back-story of various names of popular browsers out there. In particular, pay attention to the exploratory theme (in bold) in the following diagram.\n\n\n\nThe said revolution was started by Mosaic, well-known as the first popular web browser which dramatically boosted the popularity of world wide web. Mosaic was developed at NCSA, part of University of Illinois. Some Mosaic team members later went to create Netscape and develop Netscape Navigator. One of them is Marc Andreessen (@pmarca), a graduate of University of Illinois, who is known these days as a prominent investor at Andreessen Horowitz (a16z) VC firm.\n\nMosaic was later born again in the form of Internet Explorer. Spyglass, an official licensee of NCSA Mosaic project, licensed their browser technology (unrelated to the original Mosaic code) to Microsoft and it became the genesis of a new browser contender to Netscape Navigator. The rise of Internet Explorer also led to the first Browser War.\n\nDuring this time, Netscape was in trouble and the browser code was released as an open-source project Mozilla. After a few years, Firefox emerged and this time became the browser that challenged Internet Explorer. One of the co-creator of Firefox is Dave Hyatt, he was involved with Netscape and it is hardly a surprise that he also finished his graduate from University of Illinois. Later on, Dave Hyatt was one of the influential figures behind WebKit, the rendering engine that powers Safari.\n\nSomething that is not mentioned in the above browser diagram is of course JavaScript. Are you going to be surprised if I now mention that Brendan Eich (@BrendanEich), the father of JavaScript, finished his master also at the University of Illinois?\n\nBeside being close to the seed of such a revolution, I did really enjoy my first trip to Chicago. It seems that Chicago easily makes it into the list of future travel I want to plan. Meanwhile, my next stop will be San Francisco for the upcoming HTML5 Developer Conference.\n\n(`_|_`)Sep 17, 2014(`_|_`)ariya.io(`_|_`)chicago-jquery-and-web-revolution', 'chicago-jquery-and-web-revolution'),
(38, 'CPU Feature Detection(`_|_`)\nWith so many great cross-platform libraries out there, there is hardly any need to reinvent the wheel. In many cases, it is even possible to extract a portion of a sophisticated multi-platform application code to be reused in a different application. In this example, a basic CPU detection class from Chromium C++ code is built into a simple command-line tool.\n\nThe challenge in such an extraction process is figuring out the dependencies. Chromium src/base directory contains a lot of useful basic classes for application development. They are however targeted primarily to be used when building Chromium alltogether. Often times, it means it is not easy to use only one class without pulling a series of other dependent classes. In the worse case, you will go down the rabbit hole.\n\nFor this exercise, we will be using the base::CPU class found in base/cpu.h. As expected, this class depends on some other classes. Fortunately for us, it does not go that far. The dependency graph looks like the following:\n\n\n\nThus, what we need to do is to grab all those files from Chromium source code. So that you can follow along, I have prepared a Git repository gitlab.com/ariya/cpu-detect. Once this base::CPU class is ready, using it is trivial:\n\nbase::CPU cpu;\nstd::cout < < \"Vendor: \" << cpu.vendor_name() << std::endl;\n\n\nFor the complete demo app, here is the full output when running on my Chromebook Pixel:\n\n\n\nSince this is just an example, we omit a rather important thing. The class implementation actually needs to use StringPiece. In our flavor above, string_piece.h is an empty file (to satify the include). We don’t need any code because StringPiece is only necessary for ARM architecture. If we stick with Unix on x86, then we can live with that dummy header file. Obviously, in real life and with other possible classes, you may not be that lucky.\n\nIsn’t it true that we don’t code today what we can’t reuse tomorrow?\n\n(`_|_`)Sep 7, 2014(`_|_`)ariya.io(`_|_`)cpu-feature-detection', 'cpu-feature-detection'),
(39, 'Autumn 2014 Conferences(`_|_`)\n\n\nAfter a short pause, I’ll be giving tech talks again in a few weeks. The first one will be for jQuery Conference in Chicago, the other one is for the autumn edition of HTML5 Developer Conference in San Francisco.\n\nFor the jQuery folks, I’d like to share my understanding as to how web browsers execute JavaScript code. The official title of the talk is JavaScript and the Browser: Under the Hood and the abstract looks like the following:\n\n\nA browser’s JavaScript engine can seem like a magical black box. During this session, we’ll show you how it works from 10,000 feet and give you the understanding of the main building blocks of a JavaScript engine: the parser, the virtual machine, and the run-time libraries. In addition, the complicated relationship with the web browser with a JavaScript environment will be exposed. If you are curious as to what happens under the hood when the browser modifies the DOM, handles scripted user interaction, or executes a piece of jQuery code, don’t miss this session!\n\n\nIn San Francisco, I will use the opportunity to demystify the secrets behind smooth animated user interface. The talk itself is basically a walkthrough of some bite-size examples, demonstrating among others Cover Flow in JavaScript and CSS 3-D.\n\n\nWith the support for buttery-smooth GPU-accelerated 3-d effect with CSS, modern browsers allow an implementation of a stunning fluid and dynamic user interface. To ensure that the performance is still at the 60 fps level, certain best practices needs to be followed: fast JavaScript code, usage of requestAnimationFrame, and optimized GPU compositing. This talk aims to show a step-by-step guide to implement the infamous Cover Flow effect with JavaScript and CSS 3-D. We will start with the basic principle of custom touch-based scrolling technique, the math & physics behind momentum effect, and the use of perspective transformation to build a slick interface. Don’t worry, the final code is barely 200 lines!\n\n\nIf you will be around in Chicago or San Francisco, don’t miss these talks!\n\n(`_|_`)Sep 1, 2014(`_|_`)ariya.io(`_|_`)autumn-2014-conferences', 'autumn-2014-conferences'),
(40, 'PhantomJS 2 and JavaScript Goodies(`_|_`)\nAs I mentioned in my earlier blog post, we are now working torward stabilizing the development version of PhantomJS. One thing I would like to elaborate here with respect to the features of this forthcoming PhantomJS 2 is its improved JavaScript support.\n\nWith the fresher WebKit (thanks to Qt 5.3’s QtWebKit module), PhantomJS 2 also benefits from a lot of JavaScript improvement in JavaScriptCore, the JavaScript engine of WebKit. This brings PhantomJS to the more-or-less expectation of features which are supposed to be supported by a modern web browser.\n\n\n\nIn fact, if we run the official test suite for ECMA-262, the ECMAScript Language Specification version 5.1, at test262.ecmascript.org, then we will see that PhantomJS (just like Safari 7) only fails 2 tests. If you compare it with other browsers, Chrome 36 has 4 failures and Firefox 31 has 42 failing tests. In a way, we can say that (by leveraging JavaScriptCore), PhantomJS is pretty much as standard compliant as it could get.\n\n\n\nAmong others, many will rejoice for the availability of Function.prototype.bind (bug 10522), something that is missing from the old QtWebKit in Qt 4.8. There were various attempts to solve this in the past, see my previous post to the mailing-list. However, as I wrote there, sometimes our collective effort was not enough to move the mountain.\n\nAnother related improvement is the handling of the special object arguments. Just like other modern browsers, now you can JSON.stringify this object (bug 11845), use in a for-in loop (bug 11558, bug 10315), and call Object.keys on it (bug 11746).\n\nPhantomJS 2 will be released whenever it is ready (monitor the mailing-list if you want to get notified). Meanwhile, if you want to compile it yourself and play with this bleeding-edge version, follow the step-by-step instructions. If you are on Linux or OS X (like typical geeks these days), building it yourself should take just 30 minutes on a fairly decent machine.\n\nGood things come to those who wait!\n\n(`_|_`)Aug 16, 2014(`_|_`)ariya.io(`_|_`)phantomjs-2-and-javascript-goodies', 'phantomjs-2-and-javascript-goodies'),
(41, 'Easy Debugging with cgdb(`_|_`)\n\n\nMastering GNU Debugger (gdb) is an essential skill for many programmers these days. In many cases, debugging using gdb is carried out straight from your favorite editor or IDE. For a quick stand-alone debugging session, a nice alternative is to use a visual, terminal-based wrapper for GDB called cgdb.\n\nThe usage of cgdb is designed to appeal vim users. When you launch cgdb, it shows a split-screen arrangement. The bottom half is the usual gdb console while the top half shows the content of the file where the program currently stops. The size of the window can be easily adjusted, I often shrink the gdb console to a minimum since I like to see more file content.\n\nEverytime gdb does the single-stepping or moving to the next source line, the corresponding line in the source view will be highlighted. It is even customizable, either with an arrow indicator on the gutter or by highlighting the entire line. The source view window is always synchronized, if gdb jumps to another file then you will immediately see the content of that file.\n\nOpening another source is also easy, thanks to its vim-like incremental filename search. Once a particular file is open, setting a breakpoint on a certain line is as simple as specifying the line number in the gdb console.\n\nThere are many different things you can do with cgdb, refer to its documentation for the details. If you are stuck with plain vanilla gdb hitherto, I highly recommend using cgdb for fun and profit!\n\n(`_|_`)Aug 10, 2014(`_|_`)ariya.io(`_|_`)easy-debugging-with-cgdb', 'easy-debugging-with-cgdb'),
(42, 'JavaScript and V8 TurboFan(`_|_`)\nRecently, Google engineers landed a new optimizing JavaScript compiler for V8, codenamed TurboFan. As the name implies, this is supposed to further improve JavaScript execution speed, likely to be better than its predecessor, Crankshaft. While TurboFan is still in its early stage, that doesn’t mean we can’t take a look at it.\n\nPlaying with this TurboFan flavor of V8 is not difficult. First you need to build the bleeding-edge branch, where this 70,000-lines of code currently resides. After the new V8 shell is freshly baked, we can have some fun and inspecting TurboFan’s work.\n\nI did not have the time to dig really deep yet, so for now we just take a peek at the initial stage of the new optimizing compiler’s pipeline.\n\nLet’s have a simple test program:\n\nfunction answer() {\n  return 42;\n}\nprint(answer());\n\n\nIf this is test.js, then we can play with TurboFan by running:\n\n/path/to/v8/shell --always-opt \\\n  --trace-turbo \\\n  --turbo-types \\\n  --turbo-filter=answer \\\n  test.js\n\n\nWe use the --always-opt option so that the code is optimized immediately (otherwise, only e.g. hot loops will be optimized). In order to inspect TurboFan, --trace-turbo and --turbo-types options are necessary. Last but not least, we are only interested in our own function answer() to be examined, hence the use of --turbo-filter option. If we pass * instead, V8 will dump too much information, mostly on other internals slightly irrelevant for this discussion.\n\nWe can see that TurboFan is doing its magic by looking at the first few lines of the output:\n\n---------------------------------------------------\nBegin compiling method answer using Turbofan\n\n\nFor further investigation, it is better to redirect the output to a log file. The log file will contain the data for 4 different graphs: initial untyped graph, context specialized graph, lowered typed graph, and lowered generic graph. This is the result of the Turbofan compiling pipeline. Every graph is easy to visualize since it is printed in the de-facto dot format.\n\nFirst, we need to separate each individual graph:\n\ncsplit -s -f graph log \"/--/\" {4}\n\n\nAssuming GraphViz is installed, we can see the first graph, the initial untyped, by running:\n\ntail -n +2 graph01 | dot -T png > untyped.png\n\n\nwhich is shown in the following screenshot:\n\n\n\nThis is the intermediate representation (IR) directed graph. You may recognize some nodes in the graph resembling the original JavaScript code such as the NumberConstant[42] and Return nodes. Each node has an operator and its associated IR opcode. This is very similar to the Sea of Nodes IR approach from Cliff Click (see Combining analyses, combining optimizations and A Simple Graph-Based Intermediate Representation) used by Java HotSpot compiler.\n\nThe above graph is built as the first compiler pipeline stage by traversing the abstract syntax tree. There is hardly a surprise here. The edges Start (node #0) and End (node #10) are self explanatory. For every function, the information on its Parameter (node #4) is always mandatory. Checking the stack is an inherent part of V8 internals, hence the need for JSCallRuntime (node #5).\n\nInside the function body, every statement will be visited by the AST builder. In our example, there is only one, a return statement. For this, the builder also needs to visit the argument, which happens to be a numeric literal. The final outcome is a node which represents the opcode Return (node #7) which also refers to the constant (node #6).\n\nThe node in gray (Return, node #9) indicates that it is “dead”, i.e. unused. This is actually a special return statement (returning undefined) which plays a role only if the function does not have an explicit return. Since it is not the case here, the node is not being used or referred anywhere, hence its dead status.\n\nAfter this initial graph is obtained, the next stage are context specialization, type analysis, and IR lowering. These three topics are outside the scope (pun intended) of what I want to cover right now so we will have to discuss them some other time. However, note that our test.js is very simple, there is no assignment or any complicated operations and hence the subsequent compiler stages do not enhance the IR graph in any meaningful way. In fact, If you plot graph02 (using the similar dot command as before), you will see that the resulting image is exactly the same as in the previous screenshot.\n\nUltimately, TurboFan needs to generate some machine code. Predictably, it has its own code generator (currently for x86 and ARM, both 32-bit and 64-bit), it does not reuse the existing Hydrogen and Lithium code generators from Crankshaft. The machine code is emitted from the instruction sequence. If you take a look at the log file, the relevant part of the sequence is:\n\n14: ArchRet v6(=rax)\n\n\nIf you find out what v6 is, it refers to the constant 42. On x86-64, this instruction thus can be turned into a MOVQ RAX, 0x2A00000000 followed by RET 8. Straightforward, isn’t it?\n\nTurboFan is still very young and I’m sure there is still lots of room to grow. In most recent episode of JavaScript engine optimization, WebKit enjoys a speed boost thanks to the new FTL (fourth-tier JIT compiler based on LLVM) while Firefox continues to refine its whole-method JIT compiler IonMonkey. Will TurboFan become the V8’s answer to them?\n\nWelcome to the world, TurboFan!\n\n(`_|_`)Aug 3, 2014(`_|_`)ariya.io(`_|_`)javascript-and-v8-turbofan', 'javascript-and-v8-turbofan'),
(43, 'Towards PhantomJS 2(`_|_`)\nIt is been a while since PhantomJS received a facelift. This is about to change, the current master branch is now running the unstable version of PhantomJS 2. Among others, thing brings the fresher Qt 5.3 and its updated QtWebKit module.\n\nThanks to the hard work of many contributors, in particular @Vitallium and KDAB, PhantomJS 2 is getting close to its final stage. There are still many things to do, from fixing the failing unit tests to running a thorough integration test, but at least the current master branch can be built on Linux, OS X, and Windows already.\n\nA typical user will want to wait until the final release to get the official binaries. However, those who are brave enough to experiment with this bleeding-edge version are welcome to build it from source.\n\nWe still do not know when it is going to be ready for the final release, stay tuned and monitor the mailing-list.\n\nWith this new major version, we also have an opportunity to review and improve the development workflow. Several topics are already being discussed (feel free to participate, your feedback will be appreciated): removing CoffeeScript support, revamping the test system, searching for a better issue tracker, building a continuous integration system, and last but not least, modularization approach for future distribution. These tasks are far from trivial, any kind of help is always welcomed.\n\nA journey of a thousand miles begins with a single step. And expect more rolling updates in the next few weeks!\n\n(`_|_`)Jul 29, 2014(`_|_`)ariya.io(`_|_`)towards-phantomjs-2', 'towards-phantomjs-2'),
(44, 'Easy TeamCity Installation with Docker(`_|_`)\nTeamCity from JetBrains is an easy-to-use and powerful continuous integration system. It is a commercial product, but there is a special zero-cost license for small projects and FOSS applications. While installing TeamCity is relatively easy, its setup is further simplified via the use of Docker.\n\nLike many other state-of-art continuous integration systems, TeamCity adopts the concept of build server and build agent. The server is responsible for the adminstration and build configurations. The actual build itself (compilation, packaging, deployment, etc) is carried out by one or more build agents. With this approach, it is also easy to provision the agent automatically so that the entire setup requires very little manual tweaks.\n\nTeamCity Server only requires Java. The installation is rather straightforward. With Docker, this is even easier. I have prepared a special container for this, ariya/centos6-teamcity-server. The base system for the container is ariya/centos6-oracle-jre7, a CentOS 6.5 system running the official Oracle Java 7 (to be more precise, JRE 1.7.0_65-b17 at the time of this writing).\n\nAssuming you have a system (VPS such as Linode or DigitalOcean, Amazon EC2 instance, a virtual machine, a real box) that already has Docker installed, setting up a TeamCity Server is as easy as running the following commands. Note that if you are on OS X, use boot2docker if you just want to experiment with this setup (see my previous blog post Docker on OS X for more details).\n\ndocker run -dt -name teamcity_server -p 8111:8111 ariya/centos6-teamcity-server\n\n\nGive it a few minutes or so, now open the box’s address at port 8111 to start the web configuration of TeamCity Server (read the official TeamCity documentation for more details), as shown in the following screenshot. If your host system is using iptables, make sure to accept connections on port 8111. Note that TeamCity data will be stored in the special location /data/teamcity. This is a standard Docker volume, it is useful to allow easy mounting, back-up, or future upgrade.\n\n\n\nOnce the server is configured, it is time assign a build agent to this server (otherwise, nothing can be built). Again, we will spawn a build agent easily using Docker by running the container named ariya/centos6-teamcity-agent. For the agent to work, we need to specify the server. Here is how you would run it:\n\ndocker run -e TEAMCITY_SERVER=http://buildserver:8111 \\\n    -dt -p 9090:9090 ariya/centos6-teamcity-agent\n\n\nIf you run this in the same host which is running the server container, you need to link them together:\n\ndocker run -e TEAMCITY_SERVER=http://teamcity_server:8111 \\\n    --link teamcity_server:teamcity_server -dt ariya/centos6-teamcity-agent\n\n\nUpdate: the above link does not work, due to the lack of bidirectional connection between two containers. You need to obtain the internal IP address instead, refer to the latest blog post on TeamCity for details.\n\nThe environment variable TEAMCITY_SERVER is mandatory, it needs to point to the location of the instance of TeamCity server you started in the previous step. Once you run the container, it will contact the specified server, download the agent ZIP file, and set it up. Wait a few minutes since the build agent usually updates itself after the first contact to the server. If everything works correctly, you should see a new agent appearing on the Agents tab on your TeamCity server web interface. Authorize the agent and now it should be ready to take any build job!\n\nIf there is a problem launching the agent (docker ps) does not show the container running, try to run it again but this time with the option -it (interactive terminal) instead of -dt. This will dump some additional debugging message which can be helpful to assist troubleshooting.\n\nNote that this agent container is also based on CentOS 6 with Java 7. Usually this is not enough as you may need other dependencies (different SDKs, compilers, libraries, etc). Ideally those dependencies should be resolved automatically, either by basing the container on a different system or by setting up the right automatic provisiniong. Refer to my previous blog post Build Agent: Template vs Provisioning for a more detailed overview.\n\nStill have an excuse not to do continuous integration? I don’t think so!\n\n(`_|_`)Jul 24, 2014(`_|_`)ariya.io(`_|_`)easy-teamcity-installation-with-docker', 'easy-teamcity-installation-with-docker'),
(45, 'Build Agent: Template vs Provisioning(`_|_`)\nFor an automated build system, a typical configuration involves the separation between the build server and the build agents (some systems call it master-slave or coordinator-runner). Such a configuration allows any addition or removal of new build agents, perhaps to improve the build performance, without causing too much disruption. When it is time to spawn a new build agent, there are at least two possible techniques: recreate it from the template or provision it from scratch.\n\nExcept for various corner cases, build agents nowadays often run in a virtualized environment. This makes it easy to install, upgrade, and manage the agent. An important benefit of having it virtualized is the ability to take the snapshot of the state of the build agent. When there is a problem, it is possible to revert it to the last good known snapshot. In addition, that snapshot could serve as the agent template. If there is a need to have more build agents, maybe because the build jobs are getting larger and larger, then a new agent can be created by cloning it from the template.\n\nWith today’s technologies, template-based build agent is not difficult to handle. Vagrant permits a simplified workflow for managing virtual machines with VirtualBox, VMware, etc. Continuous integration system like TeamCity and Bamboo has a built-in support for Amazon EC2, a new instance from a specified AMI can be started and stopped automatically. And of course, running a new Linux system in a container is a child’s play with Docker.\n\nThis template-based approach, while convenient, has a major drawback. If the software to be built has an updated set of dependencies (patched libraries, different compiler, new OS), then all the build agents become outdated. It is of course enough to create a fresh agent from scratch based on the new dependencies and spawning a bunch of new agents from this template. Yet, this process is often not automated and error-prone, an accident waiting to happen.\n\nIn the previous blog post A Maturity Model for Build Automation, I did already outline the loose mapping of capability maturity model to the state of common automated build system. With this, it is easy to see how we can level up the above template-based approach. Instead of relying on a predefined configuration, a build agent should be able to create a working environment for the build from a provisioning script. The litmus test is rather simple: given a fresh virtual machine, the build agent must figure out all the dependencies, find out what’s missing and solve it, and then be in a state where it is ready to take any build job.\n\nAgain, today’s technologies make such those provisioning actions as easy as 1-2-3. We already have all kinds of powerful configuration management tools (CFEngine, Chef, Puppet, Ansible, etc). In many cases, relying on the OS package managers (apt-get, rpm, yum, Chocolatey, etc) or even framework-specific packaging solution (pip, npm, gem, etc) is more than enough. There is hardly any excuse not to adopt this provisioning solution.\n\nLast but not least, it’s possible to combine these two to form a hybrid, optimized approach. Given a plain vanilla machine, the provisioning script can always upgrade it to the intended state. That should also still hold even if the machine is already polluted with some old dependencies. This opens an opportunity for doing both. In the context of Docker, it means that the base image needs to be refreshed with all the dependencies, e.g. different compiler and system libraries. At this point, the existing agents can still continue to function, perhaps installing missing stuff as necessary. However, once the base image is fully upgraded, the agent container can be rebuilt and it will bypass any redundant installation.\n\nCare to share which approach do you use/experience/prefer?\n\n(`_|_`)Jul 15, 2014(`_|_`)ariya.io(`_|_`)build-agent-template-vs-provisioning', 'build-agent-template-vs-provisioning');
INSERT INTO `ariyaio` (`id`, `content`, `url`) VALUES
(46, 'Extracting Parts of Git Repository and Keeping the History(`_|_`)\nAt some point, a software project will grow beyond its original scope. In many cases, some portions of the project become their own mini world. For maintenance purposes, it is often benefical to separate them into their own projects. Furthermore, the commit history for the extracted project should not be lost. With Git, this can be achieved using git-subtree.\n\nWhile git-subtree is quite powerful, the feature that we need for this task is its splitting capability. The documentation says the following regarding this split feature:\n\n\nExtract a new, synthetic project history from the history of the prefix subtree. The new history includes only the commits (including merges) that affected prefix, and each of those commits now has the contents of prefix at the root of the project instead of in a subdirectory. Thus, the newly created history is suitable for export as a separate git repository.\n\n\nThis turns out to be quite simple. In fact, there is already a Stack Overflow answer which describes the necessary step-by-step instructions. The illustration below, also dealing with a real-world repo, hopefully serves as an additional example of this use case.\n\nFirst of all, make sure you have a fresh version of Git:\n\ngit --version\n\n\nIf it says 1.8.3, then get a newer version since there is a bug (fixed in 1.8.4) which will pollute your commit logs badly, i.e. by adding “-n” everywhere.\n\nFor this example, let’s say we want to extract the funny automatic name generator (for a container) from the Docker project into its own Git repository. We start by cloning the main Docker repository:\n\ngit clone https://github.com/dotcloud/docker.git\ncd docker\n\n\nWe then split the name generator, which lives under pkg/namesgenerator, and place it into a separate branch. Here the branch is called namesgen but feel free to name it anything you like.\n\ngit-subtree split --prefix=pkg/namesgenerator/ --branch=namesgen\n\n\nThe above process is going to take a while, depending on the size of the repository. When it is completed, we can verify it by inspecting the commit history:\n\ngit log namesgen\n\n\nThe next step is to prepare a place for the new repository (choose any directory you prefer). From there, all we need to do is to pull the namesgen branch which was splitted before:\n\ncd ~\nmkdir namesgen\ncd namesgen\ngit init\ngit pull /path/to/docker/checkout namesgen\n\n\nThat’s it! Of course, normally you want to push this to some remote, e.g. a repository on GitHub or Bitbucket or your own Git endpoint:\n\ngit remote add origin git@github.com:joesixpack/namesgen.git\ngit push -u origin --all\n\n\nThe new repository will only contain the files from pkg/namesgenerator/ directory from Docker repository. And obviously, every commit that touch that directory still appears in the history.\n\nMission accomplished!\n\n(`_|_`)Jul 6, 2014(`_|_`)ariya.io(`_|_`)extracting-parts-of-git-repository-and-keeping-the-history', 'extracting-parts-of-git-repository-and-keeping-the-history'),
(47, 'Velocity, Kinematics, and Cover Flow(`_|_`)\nLast week, one of my favorites conferences, Velocity Conference, took place in Santa Clara. Beside the joy of meeting old friends and making new acquaintances, Velocity was exciting for me due to its crazy amount of excellent materials to digested post-conference. In addition to that, this was also for the fourth time I gave a talk there and this time I presented the topic of Smooth Animation on Mobile Web.\n\n\n\nUpdate: the 30-minute video is available, watch it on YouTube!\n\nThe objective of the talk (see the slide deck) is to demonstrate some examples which implement some common best-practices for client-side high-performance web apps: optimized JavaScript, requestAnimationFrame, event throttling, and GPU acceleration. Rather than simple examples, demos which represent real-world applications were shown instead. This covers things like kinetic scrolling for implementing a flick list, parallax effect in a photo viewer, and last but not least, a clone of Cover Flow with a deadly combination of CSS 3-D and JavaScript.\n\nFollowers of this blog corner may realize that this is now a new topic as I have covered this extensively in the past (on kinetic scrolling, parallax effect, and Cover Flow). This is the first time however that I delivered the subject in a tech talk (and I won’t fool myself, there is certainly room for improvement). It is certainly a challenge, complicated written articles can be consumed and analyzed one step at a time while a presentation forces everyone to be on the same pace. I still plan to experiment with various different deliveries of the content.\n\nOn a related note, it is also fascinating to notice how sophisticated user interface takes a lot of ideas of everyday physics, whether it’s about geometry or kinematics. Even on many modern mobile platform, the hardware is more than capable to produce all fancy effects that we want. The limit will be our own creativity: would we learn more about physics and leverage it to build amazing interface for mobile web?\n\n(`_|_`)Jun 29, 2014(`_|_`)ariya.io(`_|_`)velocity-kinematics-and-cover-flow', 'velocity-kinematics-and-cover-flow'),
(48, 'Great Teams Make History(`_|_`)\nThe Spurs just recently won the 2014 NBA Finals with a series of convincing games. Most importantly however, they demonstrated the amazing traits of unselfishness and teamwork. It is not about getting the individual fame and glory, it is all about working together towards the common goal.\n\nTime and time again we witnessed the excellent execution of team effort, both in the defense and offense (if you missed it, watch the following 1-minute clip). Every player, superstar or not, is a key element to the orchestrated attack. Some players will get the assist and field goal points in their stats, but nobody would care if the team loses. On other hand, when the team wins, everyone deserves the credit.\n\n\n\nIf you are an engineer, the adventure of the Spurs towards the championship provides an extremely valuable lesson. As I have written in details in the previous blog post Impact Factor, once you are past the initial stage of proving yourself, the real journey begins. Your career immediately reaches saturation if you can not escape from the checklist mentality. It is not about being a lone wolf anymore, it is all about collaboration and playmaking.\n\nThe tagline of a magazine ad (it was for Visual Studio) that I spotted 6 years ago said it best:\n\n\nGood coders solve problem. Great teams make history.\n\n\nBe a source of inspiration for your team mates and you’ll ultimately shape the future!\n\n(`_|_`)Jun 18, 2014(`_|_`)ariya.io(`_|_`)great-teams-make-history', 'great-teams-make-history'),
(49, 'White Trolling(`_|_`)\nWhen dealing with annoying people, there are at least two possible choices: ignore them or contain them. The former is a popular advice for combatting Internet trolls. The question is, shall we start to move slowly towards the containment tactic?\n\nImagine a group of people wandering in your neighborhood. They are not criminals, they are not dangerous at all. They just tend to waste everyone’s time. They are the ultimate masters of time sinks. Of course, we can (and we should) continue to ignore them (“don’t feed the Troll” mantra) until they are going away.\n\nAn alternative will be to invite all of them to a basement, get some pizza and other communal food, and ask a very smart robot (with top-of-the-line artifical intelligence) to keep them busy for as long as they care. The idea is very simple, the more time they spend in that contained environment, the less time they have to waste someone’s else time.\n\nWhile such a robot is not available yet, the strategies can be still developed and validated in a smaller scope, perhaps as an online bot. In many cases, we need to borrow the elements from the trolls themselves. What follows is a random collection of some ideas, I’m sure these can be improved further.\n\nTiming is always important. Tracking past responses makes it possible to deduce the likely schedule of the trolls. The bot needs to keep the trolls busy at their peak time.\n\nAsymmetric effort ensures the effectiveness. Our bot should spend 5 seconds writing a reponse that keeps the trolls busy for half a day.\n\nProvocation should be a recurring theme, the bot should ignore any baits from the trolls (wouldn’t it be easy?) and try to always get under their skin.\n\nIn our tech world, we have witnessed computers capable of understanding complex web pages, playing chess, winning a quiz show, and serving as a personal assistant. Will we see human trolls vs troll bots anytime soon?\n\n(`_|_`)Jun 8, 2014(`_|_`)ariya.io(`_|_`)white-trolling', 'white-trolling'),
(50, 'Docker on OS X(`_|_`)\n In the world of virtualization nowadays, Docker is the new kid on the block. It is almost trivial to set up and play with it when you are running Linux. What if, like many geeks out there, you are using OS X as your primary development system? Two possible solutions are discussed here, using boot2docker or running it via a Linux virtual machine.\n\nLet’s take a simple Go-based HTTP server and run it in a container. I have prepared a demo at gitlab.com/ariya/docker-hellogo that you can follow along. To initiate, start with:\n\ngit clone https://gitlab.com/ariya/docker-hellogo.git\ncd docker-hellogo\n\n\nThe content of the Dockerfile in that repo is as follows (simplifed):\n\nFROM centos:centos6\nADD . /src\nRUN yum -y install golang\nEXPOSE  8200\nCMD [\"go\", \"run\", \"/src/serve.go\"]\n\n\nIt sets CentOS 6 as the base image, installs Go, and finally exposes port 8200 (where the HTTP server will run). The final CMD line specifies what to do when the container is executed, which is to run the said HTTP server.\n\nAssuming that Docker is available (e.g. properly installed on Ubuntu), we can build the container:\n\nsudo docker build -t hellogo .\n\n\nThe dot . refers to the current directory (i.e. the Git checkout) and the built image will be called hellogo. Note that this will pull the base image for CentOS 6, if it is not yet available locally.\n\nOnce the build process is completed, running the image is as easy as:\n\nsudo docker run -p 8200:8200 -t hellogo\n\n\nThe argument -p 8200:8200 specifies the port forwarding. Open your browser and go to http://localhost:8200 and you should see the famous Hello world! message.\n\nFor those who are using OS X, fortunately there are at least two possible ways to realize the above steps without creating a Linux VM manually and running it there.\n\nThe first choice is to use boot2docker, a superlightweight Linux distro just to run Docker. Once boot2docker is installed, the setup is like this (note that we need the second line to ensure the correct port forwarding):\n\nboot2docker init\nvboxmanage modifyvm boot2docker-vm --natpf1 \"http,tcp,127.0.0.1,8200,,8200\"\nboot2docker up\nexport DOCKER_HOST=tcp://localhost:4243\n\n\nAnd that’s it! Now you can run docker build and docker run as described earlier (skip the sudo part). Rather straighforward, isn’t it?\n\nThe second choice is to have a virtual machine running Linux and use Docker from there. It is indeed an additional layer and some extra overhead, but in many cases it still works quite well. Obviously, create a virtual machine manually is not something you normally do these days. We can leverage Vagrant and VirtualBox for that.\n\nTo illustrate this, there is a Vagrantfile in the Git repo:\n\nVAGRANTFILE_API_VERSION = \"2\"\nVagrant.configure(VAGRANTFILE_API_VERSION) do |config|\n  config.vm.box = \"ubuntu/trusty64\"\n  config.vm.network \"forwarded_port\", guest: 8200, host: 8200\n  config.vm.provision \"shell\",\n    inline: \"apt-get -y update && apt-get -y install docker.io\"\nend\n\n\nIt is based on the recent Ubuntu 14.04 (Trusty). The provisioning script is very simple, its job is to install Docker. Note also the forwarding of port 8200. Initialize this virtual machine by running:\n\nvagrant up\n\n\nGive it a minute or two and now the virtual machine should be ready. You can verify this by running VirtualBox Manager. If there is no problem whatsoever, we can connect to that virtual machine:\n\nvagrant ssh\n\n\nIn this ssh session, you can run docker build and docker run as previously described. Since port 8200 is correctly forwarded, you could also visit http://localhost:8200 using e.g. Safari running on OS X (the host system).\n\nFor this setup, you can witness the power of virtualization. Your OS X machine is running Ubuntu 14.04 system in a VirtualBox-based virtual machine. Now, within that Ubuntu system, there is another CentOS 6.5 system running in a container. The simple Go-based HTTP server is being executed in that container. Fun, isn’t it?\n\nLast but not least, the fresh Vagrant 1.6 release has an official support for Docker as a new provider. I haven’t tried this but if you found that this official Docker provider streamlines the workflow ever further, please do share it with us.\n\nContain all the things!\n\n(`_|_`)May 28, 2014(`_|_`)ariya.io(`_|_`)docker-on-os-x', 'docker-on-os-x'),
(51, 'The Curious Case of JavaScript NaN(`_|_`)\nNaN, not a number, is a special type value used to denote an unrepresentable value. With JavaScript, NaN can cause some confusion, starting from its typeof and all to the way the comparison is handled.\n\nSeveral operations can lead to NaN as the result. Here are some examples (follow along on JSBin: jsbin.com/yulef):\n\nMath.sqrt(-2)\nMath.log(-1)\n0/0\nparseFloat(\'foo\')\n\n\nThe first trap for many JavaScript beginners is usually the unexpected result of calling typeof:\n\nconsole.log(typeof NaN);   // \'number\'\n\n\nIn a way, while NaN isn’t supposed to be a number, its type is number. Got it?\n\nStay calm, as this will continue to lead to many confusing paths. Let’s compare two NaNs:\n\nvar x = Math.sqrt(-2);\nvar y = Math.log(-1);\nconsole.log(x == y);      // false\n\n\nMaybe that’s because we’re supposed to use strict equal (===) operator instead? Apparently not.\n\nvar x = Math.sqrt(-2);\nvar y = Math.log(-1);\nconsole.log(x === y);      // false\n\n\nArrgh! Could it be because they are NaNs from two different operations? What about…\n\nvar x = Math.sqrt(-2);\nvar y = Math.sqrt(-2);\nconsole.log(x == y);      // false\n\n\nEven crazier:\n\nvar x = Math.sqrt(-2);\nconsole.log(x == x);      // false\n\n\nWhat about comparing two real NaNs?\n\nconsole.log(NaN === NaN); // false\n\n\nBecause there are many ways to represent a NaN, it makes sense that one NaN will not be equal to another NaN. Still, this is the reason why I sometimes tweet:\n\n\n  \n    This is your annual reminder that NaN stands for \"Not a NaN\".\n  \n  \n  \n    — Ariya Hidayat (@AriyaHidayat) October 23, 2013\n  \n\n\nTo solve this, originally I intended to submit this proposal for ECMAScript 7:\n\n\n\nBut of course, solutions (and workarounds) already exist today.\n\nLet’s get to know the global function isNaN:\n\nconsole.log(isNaN(NaN));      // true\n\n\nAlas, isNan() has its own well-known flaws:\n\nconsole.log(isNaN(\'hello\'));  // true\nconsole.log(isNaN([\'x\']));    // true\nconsole.log(isNaN({}));       // true\n\n\nThis often leads to a number of different workarounds. One example is to exploit the non-reflective nature of NaN (see e.g. Kit Cambridge’s note):\n\nvar My = {\n  isNaN: function (x) { return x !== x; }\n}\n\n\nAnother example is to check for the value’s type first (to prevent coercion):\n\nMy.isNaN = function(x) { return typeof x === \'number\' && isNaN(x); };\n\n\nNote: The coercion that is being blocked here is related to isNaN. As an exercise, compare the result of isNaN(2), isNaN(\'2\') and isNaN(\'two\').\n\nFortunately, for the upcoming ECMAScript 6, there is Number.isNaN() which provides a true NaN detection (BTW, you can already use this function in the latest version of Chrome and Firefox). In the latest draft from April 2014 (Rev 24), this is specified in Section 20.1.2.4:\n\n\nWhen the Number.isNaN is called with one argument number, the following steps are taken:\n\n\nIf Type(number) is not Number, return false.\n\nIf number is NaN, return true.\n\nOtherwise, return false.\n\n\n\nIn other words, it returns true only if the argument is really NaN:\n\nconsole.log(Number.isNaN(NaN));            // true\nconsole.log(Number.isNaN(Math.sqrt(-2)));  // true\n \nconsole.log(Number.isNaN(\'hello\'));        // false\nconsole.log(Number.isNaN([\'x\']));          // false\nconsole.log(Number.isNaN({}));             // false\n\n\nNext time you need to deal with NaN, be extremely careful!\n\n(`_|_`)May 18, 2014(`_|_`)ariya.io(`_|_`)the-curious-case-of-javascript-nan', 'the-curious-case-of-javascript-nan'),
(52, 'Cloud Storage, Identity, and Web Application Platform(`_|_`)\nThere is a definite convergence of solution duality in services like Dropbox, Box, Apple iCloud, and Google Drive. The first two started from being a content synchronization/storage and then moved towards an identity solution, the other two are known to have existing users lured into the cloud storage story. Should they continue to march forward, could this be the strategic delivery platform for HTML5 applications?\n\nImagine you own a small business and it uses Box for content sharing and collaboration. At one point, every employee has an account there (even easier with a variety of single sign-on services out there). Before you know, Box will be your company-wide document management hub, in particular since it integrates with other business applications (CRM, marketing and sales tools, etc). The explosion of smartphones and tablets, mobile native and web apps, along with BYOD propels this even further. Being productive does not mean being in the office cubicle anymore.\n\nYour data is stored in that secure, remote storage. Your identity is an integral part of the service. Your business applications already access the data and use that identity information. At this rate, the next logical step is to build your own applications on top of the application platform. Many organizations have the need for a set of customized applications, from a straighforward book-a-meeting-room mini application to something as complicated as HR-finance-engineering integration for new hires. Only the code to build the application is to be constructed, the back-end data storage and user authentication problems are already solved for you.\n\nSpeaking about code, this is where an application written using web technologies (HTML, CSS, JavaScript) can have a slight advantage. Granted, we can already enjoy native mobile apps from the vendor such as Dropbox Carousel, Box OneCloud Text Editor. Still, for applications specific to your business needs, there is seldom a reason to go that far. Functional is the keyword here. Obviously, you want the fastest deployment time possible, with the opportunity for further incremental improvements as the business needs change over the time.\n\nThe ultimate key here is when Box, Dropbox, and other similar solutions start to provide a hybrid application container. You can write your app in JavaScript and then get it smoothly deployed and managed via that container. Data access is easy with the existing back-end SDK, security and access control is there with the existing user management SDK.\n\nIt will be hard to expect that Google and Apple will provide such an integrated web application and delivery platform, consider each of them has a significant interest in pushing Android and iOS (to be fair, we may see another attempt from Google via the Chrome Apps approach). For Box and Dropbox however, they are in the perfect position to offer a platform which can easily attract a lot of experienced web developers out there.\n\nCould it give the birth of a true integration of HTML5 and cloud technologies?\n\n(`_|_`)May 10, 2014(`_|_`)ariya.io(`_|_`)cloud-storage-identity-and-web-application-platform', 'cloud-storage-identity-and-web-application-platform'),
(53, 'Autodetect JavaScript TDD/BDD Library(`_|_`)\n A unique feature of Venus.js, a JavaScript test runner from LinkedIn, is that the test configuration can be in the form of source annotation. This is useful, e.g. to choose which test library (Mocha, Jasmine, QUnit) should be used to execute the tests. Now, wouldn’t it be fantastic if the test runner can deduce the said library automatically?\n\nDuring a chat over coffee, I proposed that kind of best-effort detection idea to my fellow Shape Security engineer, Seth (who is involved with Venus.js). Obviously, this type of detection might not be 100% accurate. However, I postulate that it should be good enough in most cases, particularly in the case where the annotation is not present.\n\nAs a proof of concept, I have implemented detect-testlib.js (see the Git repository at gitlab.com/ariya/detect-testlib). It uses Esprima to parse the test code, collect the important verbs (more about this later), and then use the gathered information to decide whether the test is written in Jasmine or qUnit, or if it is completely unknown. To follow along, clone the repo, run npm install first, and the try the following:\n\nnode detect-testlib.js test/jquery-attributes.js\n\n\nThat jquery-attributes.js is taken from the actual jQuery unit tests. As expected, detect-testlib will confidently say that those tests are using qUnit. For another attempt, check test/yeoman-env.js (again, taken from Jasmine-based Yeoman unit tests).\n\nHow does the detection work? There are many different ways to implement it. For this proof-of-concept, I opt for something simple. The tool will scan the names of the function (aka, the verbs) used in the top-level and the secondary level. In other words, given the following code:\n\ndescribe(\"sqrt\", function() {\n    it(\'computes the square root of 9 as 3\', function() {\n        expect(My.sqrt(9)).toBeCloseTo(3, 10);\n    });\n}\n\n\nthen it will collect describe in the top-level group and it in the test-level group. After a while, we will have these two arrays populated (without any duplicates). For example, running it on test/jquery-attributes.js will give the arrays as:\n\n{ topLevel:\n   [\'module\', \'test\' ],\n  testLevel: \n   [ \'expect\',\n     \'deepEqual\',\n     \'equal\',\n     \'ok\',\n     \'strictEqual\',\n     \'testVal\',\n     \'testAddClass\',\n     \'testRemoveClass\',\n     \'testToggleClass\' ] }\n\n\nOnce the array is obtained, the special decide() function will use a simple heuristic to figure out the library being used in the test code. As an illustration, for the above example, it will conclude that the test is using Jasmine (based on the existence of describe and it). For a different test code like the following:\n\ntest(\"sqrt\", function() {\n  equal(My.sqrt(4), \"2\", \"Check for square root of 4\" );\n});\n\n\nthen decode() will go for QUnit as its solution.\n\nObviously, in some corner cases this simple decision rule will fail. However, that is expected since it is rather minimalistic. You are encouraged to develop a more sophisticated classification implementation in case a more faithful decision is needed for your application.\n\nHow about Mocha? Since Mocha can support both TDD and BDD style, the decision factor is more complicated. A possible solution is to detect the assertion mechanism and cross-correlate it with the typical pattern of assertions (expect.js, Chai, etc) used with Mocha.\n\nHave fun with autodetection!\n\n(`_|_`)May 1, 2014(`_|_`)ariya.io(`_|_`)autodetect-javascript-tddbdd-library', 'autodetect-javascript-tddbdd-library'),
(54, 'JavaScript Unit Tests and Code Coverage Tracking using Venus.js(`_|_`)\nThese days, having enough unit tests for a JavaScript-based web application/library is the bare minimum. Ideally, the code coverage of those tests is also monitored in a day-to-day development situation. Fortunately, this is easy to do with a modern test runner such as Venus.js.\n\nNamed after the famous Venus flytrap, Venus.js was originated at LinkedIn Engineering group to facilitate its JavaScript testing activities. Venus.js is pretty comprehensive, it supports unit tests written for a number of test libraries: Mocha (default), Jasmine, and QUnit. Venus.js is easy to install and to use, I recommend reading its excellent Getting Started tutorial.\n\nFor the demonstration of code coverage, I prepare a Git repository gitlab.com/ariya/coverage-istanbul-venus. If you want to follow along, just clone it and check its contents.\n\nFirst, let’s take a look at the code we want to test. This is just a DIY implementation of the square root function, it can’t be simpler than:\n\nvar My = {\n    sqrt: function(x) {\n        if (x < ) throw new Error(\"sqrt can\'t work on negative number\");\n        return Math.exp(Math.log(x)/2);\n    }\n};\n\n\nIn order to maximize the test coverage, the unit tests for the above My.sqrt() function needs to check for normal square root operation and also when it is supposed to throw an exception. This is available in the test/test.sqrt.js file (based on Mocha) which looks like the following:\n\n/**\n * @venus-library mocha\n * @venus-code ../sqrt.js\n */\ndescribe(\"sqrt\", function() {\n  it(\"should compute the square root of 4 as 2\", function() {\n    expect(My.sqrt(4)).to.equal(2);\n  });\n});\n\n\nOne notable feature of Venus.js is its zero-configuration design. In the above example, we don’t need to write any HTML to serve the code and the test. Venus.js uses an annotation approach. You can see the use of @venus-code to specify the file containing the code we want to test (i.e. the implementation of My.sqrt) and @venus-library to choose the testing library (i.e. Mocha). Everything else will be taken care of automatically.\n\nIf Venus.js is properly installed, executing the test is a matter of running:\n\nvenus test/test.sqrt.js -e ghost\n\n\nwhich gives the following result:\n\n\n\nIn the test invocation, the option -e ghost indicates that the tests are to be executed headlessly using PhantomJS (again, another nice built-in feature of Venus.js). Of course, Venus.js supports other testing environments and it can run the tests on real web browsers or even via Selenium Grid or Sauce Labs.\n\nHow to show the code coverage of the tests? It is a matter of adding another option:\n\nvenus test/test.sqrt.js -e ghost --coverage\n\n\nBehind the scene, Venus.js uses Istanbul, an excellent JavaScript instrumentation and code coverage tool. Running the test with coverage tracking will add a few more lines of report. Thanks to Istanbul, all three types of code coverage (statements, functions, branches) will be tracked accordingly.\n\n\n\nAnother very useful feature of Venus.js is the ability to mix-and-match tests written using a different library. This is illustrated in the example repo. Instead of only test/test.sqrt.js, you also spot two additional files with their own set of unit tests: test/test.extensive.js and test/test.error.js. The former adds more checks on the square root functionality (probably excessive, but you got the point) while the latter detects some more corner cases. What is interesting here is that test.extensive.js relies on Jasmine while test.error.js is written using QUnit.\n\nIf you check the package manifest, what npm test actually runs is:\n\nvenus test --coverage -e ghost\n\n\nIn other words, Venus.js will locate all the test files in the test/ directory and execute them. In this case, we have three (3) test files using different test libraries and Venus.js will handle them just fine. Isn’t it nice?\n\nIn the past, I have explained the use of Karma and Istanbul to track code coverage of JavaScript unit tests written using Jasmine, QUnit, and Mocha. However, if Karma is not your cup of tea or if your different subteams would like to use different test libraries, then perhaps Venus.js can be the solution for you.\n\nHave fun trapping those bugs!\n\n(`_|_`)Apr 20, 2014(`_|_`)ariya.io(`_|_`)javascript-unit-tests-and-code-coverage-tracking-using-venus-js', 'javascript-unit-tests-and-code-coverage-tracking-using-venus-js'),
(55, 'Supersonic JavaScript(`_|_`)\n A few days ago, I gave a talk at the most recent Web Tech Talk meetup hosted by Samsung. The title is Supersonic JavaScript (forgive my little marketing stunt there) and the topic is on changing the way we think about optimizing JavaScript code.\n\nNone of the tricks presented there will make your code break the sound barrier. Nevertheless, some of them can serve as the food for thought to provoke our brain to look at the problem in a few different ways. If you want to follow along, check or download the slide deck (before you ask: it was not video recorded).\n\nI discussed four different ideas during the talk.\n\nShort Function. Back in the old days, function calls were expensive. These days, modern JavaScript engines are smart enough and can do self-optimization. For some details on this optimization, read my previous blog post Automatic Inlining in JavaScript Engines and Lazy Parsing in JavaScript Engines. There is no need to outsmart the engine and therefore stick with a concise and readable code.\n\nFixed Object Shape. This swings in the other direction. How can we help the engine so that it can take the fast path most of the time? For more information, refer to my blog post JavaScript object structure: speed matters.\n\nProfile Guided. Related to the previous point, can we control our own code so that it takes the fast path whenever possible but will still fall back to the slow path everynow and then? What we need is a set of representative data for the benchmark and the profile can be used to tweak the implementation. More details are available in my two other blog posts Profile Guided JavaScript Optimization and Determining Objects in a Set.\n\nGarbage Handling. Producing a lot of object often places a burden on the garbage collector. As an illustration, check out a short video from Jake Archibald describing the situation of using +new Date.\n\nThere is no silver bullet to any performance problem. However, like I already mentioned in my Performance Calendar’s article JavaScript Performance Analysis: Keeping the Big Picture, it is important to keep in mind: are we always seeing the big picture or are we trapped into optimizing to the local extreme only?\n\nNow, where’s that TOPGUN application form again…\n\n(`_|_`)Apr 13, 2014(`_|_`)ariya.io(`_|_`)supersonic-javascript', 'supersonic-javascript'),
(56, 'Tracking JavaScript Annotations(`_|_`)\n\n\nOne of the interesting features of Esprima is to retrieve every comment inside a JavaScript source. Even better, each comment can be linked to the related syntax node. This is very helpful (like in the case of JSDoc) since any additional information regarding the program can be provided via the comment serving as a form of annotation.\n\nLet’s take a look at the simple code below:\n\n// Give the ultimate answer\nfunction answer() { return 42 }\n\n\nIf we let Esprima consume the above code (as a string) like this (mind the attachComment option):\n\nvar tree = esprima.parse(code, { attachComment: true });\n\n\nthen the object tree will contain an array called leadingComments which is part of the function declaration. Portions of that tree is visualized in the following diagram. Note that the leadingComments array has only one element, because there exists only one single-line comment before the function.\n\n\n\nMany documentation tools rely on a specially-formatted comment to derive additional information. For example, since JavaScript does not specify the type of every function parameter, that piece of information can be encoded in the annotation. This is very familiar for those who use JSDoc, Closure Compiler, or other similar tools. The following fragment demonstrates the usage:\n\n/**\n * Compute the square root.\n *\n * @param {number} x number.\n * @return {number} The square root of x.\n */\n \nfunction SquareRoot(x) {\n    return Math.exp(Math.log(x)/2);\n}\n\n\nHere is another example:\n\n/**\n * Adds three numbers.\n *\n * @param {number} x First number.\n * @param {number} y Second number.\n */\n \nfunction Add(x, y, z) {\n    return x + y + z;\n}\n\n\nUnfortunately, the annotation in the above example is missing the tag for the third parameter. It often happens, in some cases due to some refactoring which may result in out-of-sync comment. Since such a mistake is not caught during unit testing, it may go undetected for a while.\n\nIt is however possible to use Esprima to extract the comment and then process it with a JSDoc annotation parser such as Doctrine. This way, if a function parameter is not undocumented, we can warn the developer as early as possible. The proof-of-concept of such a tool exists in the repository gitlab.com/ariya/missing-doc/. The gist is in its analyze function (missing-doc.js):\n\ndata = doctrine.parse(comment.value, {unwrap: true});\n    params = [];\n    data.tags.forEach(function (tag) {\n        if (tag.title === \'param\') {\n            params.push(tag.name);\n        }\n    });\n\n\nOnce we got the comment associated with a syntax node (that represents a function declaration), it got parsed by Doctrine and we just iterate through all the found tags. The next step is quite logical:\n\nmissing = [];\n    node.params.forEach(function (param) {\n        if (params.indexOf(param.name) < ) {\n            missing.push(param.name);\n        }\n    });\n\n\nHere we compare what is being documented (x and y) in the annotation tags with the actual function parameters (x, y, and z). When something is not listed in the annotation, it will go into our missing array for the subsequent reporting.\n\nRunning the tool with Node.js like this:\n\nnpm install\nnode missing-doc.js test/sample2.js\n\n\ngives the following result:\n\nIn function Add (Line 8):\n Parameter z is not documented.\n\n\nEasy enough! All in all, this microtool weighs less than 70 lines of JavaScript.\n\nHow do you plan to use Esprima’s comment attachment feature?\n\n(`_|_`)Apr 6, 2014(`_|_`)ariya.io(`_|_`)tracking-javascript-annotations', 'tracking-javascript-annotations'),
(57, 'Nashorn: The New Rhino on the Block(`_|_`)\n The most recent Java 8 release came with lots of new features, one of them is the brand-new JavaScript engine to replace the aging Rhino. This new engine, called Nashorn (German for rhinoceros), is high-performant and specification compliant. It is definitely useful whenever you want to mix-and-match your Java and JavaScript code.\n\nTo check the performance of Nashorn, I use it to run Esprima and let it parse some large code base (unminified jQuery, 268 KB). This quick, rather non-scientific test exercises two aspects of JavaScript run-time environment: continuous memory allocation (for the syntax nodes) and non-linear code execution (recursive-descent parsing).\n\nIf you want to follow along, check the repository gitlab.com/ariya/nashorn-speedtest. Assuming you have JDK 8 installed properly, run the following:\n\njavac -cp rhino.jar speedtest.java\njava -cp .:rhino.jar speedtest\n\n\nThis test app will execute Esprima parser and tokenizer on the content of the test file. Rhino gets the first chance, Nashorn follows right after (each engine gets 30 runs). In the beginning, Rhino’s first run is 2607 ms and slowly it speeds up and finally this parsing is completed in just 824 ms. Nashorn timings have a different characteristic. When it is cold, Nashorn initially takes 5328 ms to carry out the operation but it quickly picks up the pace and before you know, it starts moving full steam ahead, reaching 208 ms per run.\n\nBehind the scene, Nashorn compiles your JavaScript code into Java bytecodes and run them on the JVM itself. On top of that, Nashorn is taking advantage of invokedynamic instruction (from the Da Vinci Machine Project, part of Java 7) to permit “efficient and flexible execution” in a dynamic environment such as JavaScript. Other JVM languages, notably here JRuby, also benefit from this new invokedynamic feature.\n\n\n\nWhat about Nashorn vs V8? It is not terribly fair to compare both, V8 is designed specifically for JavaScript while Nashorn leverages the battle-hardened, multi-language JVM. But for the fun of it, the Git repo also includes a JavaScript implementation of the test app which can be executed with V8 shell. On the same machine, V8 can complete the task in about 110 ms. Nashorn is not as mature as V8 yet, it is quite an achievement that it is only twice as slow as V8 for this specific test.\n\nAs a high-performance JavaScript on the JVM, Nashorn has many possible applications. It serves as a nice platform to play and experiment with JavaFX. Yet, it is powerful enough to be part of a web service stack (Vert.x, Project Avatar). On a less ambitious level, having another fast implementation of JavaScript is always good so that there is an alternative to run various JavaScript tools in an environment where Node.js is not available or not supported. As an illustration, check my previous blog post on a simple Ant task to validate JavaScript code.\n\nNext time you have the urge to herd some rhinos, consider Nashorn!\n\n(`_|_`)Mar 31, 2014(`_|_`)ariya.io(`_|_`)nashorn-the-new-rhino-on-the-block', 'nashorn-the-new-rhino-on-the-block'),
(58, 'Exploring Eclipse Orion 5(`_|_`)\nEclipse Orion released its latest version 5, right before the most recent EclipseCon. This new version packs several exciting features, everything from stylistic change in the appearance to an streamlined cloud deployment. My favorite is the easy-to-use Node.js bundle.\n\nWith Orion 5, it is supertrivial to try out Orion (assuming you have Node.js and npm):\n\nnpm install orion\n\n\nThen you can launch it by running:\n\nnode node_modules/orion/server.js /path/to/your/project\n\n\nand then open your favorite web browser and point it to localhost:8081. Now you will be able to edit existing files and create new files and folder. This works even if you don’t have any Internet connection.\n\nAlternatively open the configuration file node_modules/orion/orion.conf and change workspace variable to the location of your JavaScript project you want to edit (if you are crazy, just set it to your home directory). Then, start Orion server by running npm start orion.\n\nLet’s take a look at a quick Express example.\n\n\n\nThe above screenshot also demonstrates new Orion’s ability to provide autocomplete (or in Eclipse world, it’s called Content Asisst) for Express-based JavaScript code. It’s not limited to Express, there is also support for other frameworks such as Postgres, MySQL, MongoDB, and a few more.\n\nOnce this simple application is written, we can launch it without leaving Orion, thanks to its shell feature. Switch to the Shell tab, run npm install followed by node start hello.js, and our simple Express app is up and running.\n\n\n\nOrion now supports ESLint to validate your JavaScript code. Various rules for ESLint can be set visually.\n\n\n\nSpeaking of customization, obviously you can choose a number of different theme or even create your own:\n\n\n\nIt is also possible to try Orion via its online demos. If you would like to check the capabilities of Orion editing component only, there is the pure editor example. For testing its complete features, it is recommended to go to OrionHub, create an account, and enjoy the test drive.\n\nWhether you are online or offline, web-based tools are just fun!\n\n(`_|_`)Mar 22, 2014(`_|_`)ariya.io(`_|_`)exploring-eclipse-orion-5', 'exploring-eclipse-orion-5'),
(59, 'The Phenomenal Fluent 2014(`_|_`)\n\n\nThis week it’s all about the most recent Fluent Conference 2014 in San Francisco. It’s the third Fluent and boy, it’s getting more phenomenal than ever.\n\nFor my part, I presented a talk on the topic of Design Strategies for JavaScript API (slide deck, 2.2 MB PDF download). If you are a regular reader of this blog, you may be familiar with the topic. A few past blog posts which discuss the subject in more details are:\n\n\nStatic polymorphism and consistency\nBoolean traps\nNon-descriptive property names\nArray slice vs splice\nString substr, substring, and slice\n\n\nObviously there were tons of very very interesting presentations. To get the taste, you can watch the keynotes video (check this YouTube playlist). From Brendan’s session, bleeding-edge JavaScript features such as SIMD support and asm.js-esque Unreal 4 engine demo will make you very excited.\n\nThe full video compilation will be sold once it is out in a few weeks. You may also wait for those speakers who will upload their own video once it is available.\n\nKudos to the organizers and everyone involved for such a memorable event. See you next year!\n\nUpdate: You can watch my presentation on YouTube (28 minutes).\n\n(`_|_`)Mar 15, 2014(`_|_`)ariya.io(`_|_`)the-phenomenal-fluent-2014', 'the-phenomenal-fluent-2014'),
(60, 'API Names and Static Polymorphism(`_|_`)\nWhile static polymorphism is often discussed in the context of C++ (in particular, related to CRTP and method overloading), we can generalize the concept to help us choosing the most optimal function and property names of a public interface. This also applies to JavaScript API, of which some examples and illustrations are given in this blog post.\n\n\n\nIn his article Designing Qt-Style C++ API from 2005, Matthias Ettrich argued that the very major benefit of static polymorphism is to make it easier to memorize APIs and programming patterns. This can not be emphasized enough. Our memory has a limited capacity, related functionalities can be understood better when they demonstrate enough similarity. In other words, but static polymorphism is the answer to the (ultimate) search of consistency.\n\nTake a look at the screenshot. It shows a user interface created by a hypothetical framework: some radio buttons, a check box, and a push button. Now imagine if setting the text which represents the label for each individual component involves a code fragment that accesses the framework like this:\n\nX1.value = \'Rare\';\nX2.value = \'Medium\';\nX3.value = \'Well done\';\nY.option = \'Fries\';\nZ.caption = \'Order\';\n\n\nBecause the code is aligned that way, it is easy to see why this is confusing. A radio button relies on value property, a check box needs a property called option, and finally the text for the push button comes from caption. This demonstrates inconsistency. Once the problem is spotted, the fix is easy:\n\nX1.value = \'Rare\';\nX2.value = \'Medium\';\nX3.value = \'Well done\';\nY.value = \'Fries\';\nZ.value = \'Order\';\n\n\nThis of course does not apply only to these UI elements. For example, a slider and a progress bar can have similar names for some of their properties since each needs a set of values to to define the range (maximum and minimum) and the current value. An example of incosistency is if one calles it maximum and the other prefers maxValue. Check your favorite UI framework’s API documentation for a progress bar and a slider and see if those properties demonstrate the principle of static polymorphism.\n\nOf course, this also applies to function names. Imagine if moving a point involves calling translate whereas moving a rectangle means calling translateBy. Such a case could simply be an honest mistake, yet this indicates that it falls through the crack as it managed to escape any possible code review.\n\nStatic polymorphism does not stop at the practice of choosing function names. Imagine that we have a way to define a rectangular shape by its corner (top left position) and its dimension (width and height).\n\ncorner = new Point(10, 10);\ndim = new Size(70, 50);\nR = new Rect(corner, dim);\n\n\n\n\nSince it is tedious to always create two objects for the constructor, we can have another shortcut constructor that takes four values. In this variant, the parameters of the constructor represents x1, y1, x2, y2 coordinates of that rectangle.\n\nQ = new Rect(10, 10, 80, 60);\n\n\nIt is likely that the second constructor was designed in isolation. The set of numbers in the above line of code has a major difference compared to that of the previous code fragment. In fact, if someone converts the Point Size version to the shortcut version, they need to use different values. The spirit of the first constructor is a pair of (x, y) and (width, height), the second constructor however expects a pair of (x1, y1) and (x2, y2). Worse, if you are familiar with the first constructor and suddenly found a code that uses the second form, you might not be alarmed that the meaning of the last two numbers is not what you have in mind.\n\nIt does not matter if you are a library author or an application developer. Next time you want to introduce a new property/function/object, scour your existing code and look for patterns that have been used again and again. Those are good data points and should not be ignored.\n\nNow, aren’t you hungry after looking at the first example? BRB.\n\n(`_|_`)Mar 9, 2014(`_|_`)ariya.io(`_|_`)api-names-and-static-polymorphism', 'api-names-and-static-polymorphism'),
(61, 'JavaScript String: substring, substr, slice(`_|_`)\n Extracting a portion of a string is a fairly well understood practice. With JavaScript, there are three different built-in functions which can perform that operation. Because of this, often it is very confusing for beginners as to which function should be used. Even worse, sometimes it is easy to fall into the trap and choose the wrong function.\n\nString’s substring (ECMAScript 5.1 Specification Section 15.5.4.15) is the first logical choice to retrieve a part of the string. This substring function can accept two numbers, the start and the end (exclusive) character position, respectively. In case the end value is smaller than the start, substring is smart enough to swap the values before doing the string extraction. An example of substring is illustrated in this code snippet:\n\nvar a = \'The Three Musketeers\';\na.substring(4, 9);     \'Three\'\na.substring(9, 4);     \'Three\'\n\n\nMany JavaScript environments (including most modern web browsers) also implement a variant of substring called substr (Section B.2.3). However, the parameters for substr are the start character position and the numbers of characters to be extracted, respectively. This is shown in the following fragment:\n\nvar b = \'The Three Musketeers\';\nb.substr(4, 9);     \'Three Mus\'\nb.substr(9, 4);     \' Mus\'\n\n\nThis pair of functions, when they are both available, can be really confusing. It is so easy to mistake one for another and thereby leading to an unexpected outcome. It also does not help that the names, substring and substr, are too similar. Without looking at the documentation or the specification, there is a chance of picking a wrong one.\n\nTo add more confusion to this mixture, a String object also supports slice (Section 15.5.4.13), just like in Array’s slice. For all intents and purposes, slice has a behavior very close to substring (accepting start and end position). However, there is a minor difference. If the end value is smaller than the start, slice will not internally swap the values. In other words, it follows what is expected for Array’s slice in the same situation and thus it returns an empty string instead.\n\nvar c = \'The Three Musketeers\';\nc.slice(4, 9);       \'Three\'\nc.slice(9, 4);       \'\'\n\n\nEach of these three function can accept two parameters and perform the string extraction based on those parameter values. The result however can be different. Again, it is just like in the confusing case of Array methods (see my previous blog post on JavaScript Array: slice vs splice)\n\nWhen we write our own JavaScript library, how can we minimize such a confusion? The solution is of course to avoid an API which leads to this situation at the first place. Whenever a new public function needs to be introduced, search for existing ones to ensure that there will not be a similar confusion. Of course, it is even better if such a step is enlisted in the API review checklist.\n\nPrevention is the best cure. Be advised of your function name!\n\n(`_|_`)Feb 27, 2014(`_|_`)ariya.io(`_|_`)javascript-string-substring-substr-slice', 'javascript-string-substring-substr-slice');
INSERT INTO `ariyaio` (`id`, `content`, `url`) VALUES
(62, 'The Remarkable DevNexus 2014(`_|_`)\n In the last two days I have been busy with DevNexus 2014, the largest tech conference held in Atlanta. DevNexus has been going on for a while and this year it’s getting really big with over 1,000 attendees and tons of speakers.\n\n In the last two days I have been busy with DevNexus 2014, the largest tech conference held in Atlanta. DevNexus has been going on for a while and this year it’s getting really big with over 1,000 attendees and tons of speakers.\n\nFor this edition of DevNexus, I delivered two talks:](http://lanyrd.com/2014/devnexus/scxgbg/) (slide deck, PDF download of 4.2 MB) and JavaScript API Design Principles (slide deck, PDF download of 2.1 MB). I got a lot of good discussion and feedback after each talk. The sessions were recorded, expect to see the audio/video in the near future. Of course, I also enjoyed the good opportunity to meet folks I’ve known only from our online interactions, as well as to make new friends in this space.\n\nThe conference itself has been fantastic, professionally organized without any glitch at all. WiFi worked flawlessly, the snack and the food were amazing (obviously, there was Coca Cola everywhere). Kudos to the sponsors and the organizers for such a memorably event!\n\nThis is my first visit to Atlanta and it is been quite impressive. I definitely do not mind coming back in the near future. Meanwhile, I have two more events to visit, Fluent and EclipseCon, to complete my winter/spring conference tour. Next stop: San Francisco.\n\n(`_|_`)Feb 25, 2014(`_|_`)ariya.io(`_|_`)the-remarkable-devnexus-2014', 'the-remarkable-devnexus-2014'),
(63, 'Tricks for GPU Composited CSS(`_|_`)\n The use of graphics processing unit (GPU) in modern browsers, particularly for page rendering, means that there is no more excuse for laggy animation. In some cases, when the intended animation is not necessarily GPU friendly, some tricks need to be employed so that the graphics operations do not cause a potential performance problem.\n\nThe fundamental principles of exploiting GPU for popular CSS features have been described in my previous blog post on Optimizing CSS3 for GPU Compositing. The key here is the compositing process where the browser uploads portions of the page as GPU textures and subsequent animation frames involve only a small set of operations on those textures. The current modern browser rendering engines allow a few different operations to delegated to its GPU-compositor: opacity, transformation, and filter.\n\nStill, for a buttery smooth 60 fps interface, web developers need to ensure that certain rendering operations are GPU friendly. As mentioned in my previous blog post, an easy way to verify that is by using Safari’s Show Compositing Border feature. The number on the top left corner for each rectangle represents more or less every content update operation which necessites a texture upload to the GPU. Efficient compositing is indicated by having that number unchanged during the course of the animation.\n\nWhat about animations that are not easily handled by the compositor? Let’s take a look at the following example (also check the live demo at codepen.io/ariya/full/xuwgy):\n\n@keyframes box {\n    0% { background-color: green; }\n    100% { background-color: blue; }\n}\n\n\n\n\nFor clarity, the box is also moving horizontally back and forth. When it is on the left, the color is green and as it moves to the right, the color also changes to blue. Safari (with its compositing border indicator enabled) reveals that there is a continuous rendering of the box onto a GPU texture. With more boxes, while viewing it on a mobile device, the animation will cause frame-dropping or even an application crash.\n\nTo overcome this issue, we need to find a trick where a continous texture update is avoided. In the simple color transition example above, we are lucky since we can opt to use CSS filter instead. However, if assume we can’t or won’t be using it, what would be a more generalized approach? Apparently, for such an animation with a short duration and thus the accuracy is not a big concern, we can always approximate it by superimposing two states, each represents the initial and the final state, and tween the opacity accordingly. To get the feeling of it, check out the demo at codepen.io/ariya/full/ofDIh.\n\nIn this arrangement, the user has the illusion that the box changes color. What actually happens is that the green box starts to disappear when the blue one slowly appears. Since changing the opacity is a very cheap operation for the GPU, the animation will be smooth. The following diagram shows the magic behind the scene. Viewed from a user facing north west, it is as if there is only one opaque box with a gradual color transition.\n\n\n\nThis technique can be applied to other properties as well. For example, take a look at this glowing effect: codepen.io/ariya/full/nFADe. While glowing can be achieved by varying the blur radius of the shadow, tweening between the glowing version and non-glowing version is our kind of cheat with this trick. Less accurate, more shortcut.\n\nAs with any other types of workaround, the opacity tweening trick has some drawbacks. Most important is that it requires more memory since we trade it for a fast animation frame. Thus, be judious in employing the trick since you can’t blindly consume all the available GPU textures for user interface animations.\n\nLast but not least, if you prefer to watch a video on this subject, take a look my past presentation on Fluid User Interface with Hardware Acceleration (28-min video, slide deck).\n\n(`_|_`)Feb 18, 2014(`_|_`)ariya.io(`_|_`)tricks-for-gpu-composited-css', 'tricks-for-gpu-composited-css'),
(64, 'The Majestic jQuery Conference San Diego 2014(`_|_`)\n The amazing weather in San Diego became the witness of the awesome jQuery Conference held this week. The keynotes were entertaining, the talks were inspiring (the videos will be available in the near future), and of course nothing beats meeting folks from this vibrant jQuery community.\n\nFor my part, I presented a talk titled Dynamic Code Analysis for JavaScript (check the slide deck, or download as PDF 3.3 MB) as the first one in the Code for Thought track. Those who follow this blog corner might be already familiar with the assorted topics I’ve covered, particularly from these past blog posts:\n\n\nSyntax tree visualization\nSource transformation: non-destructive vs regenerative\nQUnit code coverage with Istanbul and Karma\nPerformance analysis: sampling, tracing, timing\nScalability and run-time complexity\nQuality code via multiple layers of defense\nHard thresholds on JavaScript code coverage\n\n\nBeside that, of course meeting old acquitances and making new friends are fun! It’s also nice to have a face-to-face meeting with folks I’ve known only from hitherto online interactions.\n\nThe conference itself was professionally organized and it’s simply fantastic (check out some pictures by @gseguin on Flickr). Kudos to the sponsors, organizers, and everyone involved in making such a memorable event!\n\nThis jQuery Conference is the start of my winter/spring conference tour. My next stop will be a bit farther: DevNexus in Atlanta.\n\n(`_|_`)Feb 13, 2014(`_|_`)ariya.io(`_|_`)the-majestic-jquery-conference-san-diego-2014', 'the-majestic-jquery-conference-san-diego-2014'),
(65, 'JavaScript Array: slice vs splice(`_|_`)\n In JavaScript, mistaking slice for splice (or vice versa) is a common mistake among rookies and even experts. These two functions, although they have similar names, are doing two completely different things. In practice, such a confusion can be avoided by choosing an API that telegraphs the const-correctness of the function.\n\nArray’s slice (ECMAScript 5.1 Specification Section 15.4.4.10) is quite similar to String’s slice. According to the specification, slice needs to accept two arguments, start and end. It will return a new array containing the elements from the given start index up the one right before the specified end index. It’s not very difficult to understand what slice does:\n\n\'abc\'.slice(1,2)           // \"b\"\n[14, 3, 77].slice(1, 2)    //  [3]\n\n\nAn important aspect of slice is that it does not change the array which invokes it. The following code fragment illustrates the behavior. As you can see, x keeps its elements and y gets the sliced version thereof.\n\nvar x = [14, 3, 77];\nvar y = x.slice(1, 2);\nconsole.log(x);          // [14, 3, 77]\nconsole.log(y);          // [3]\n\n\nAlthough splice (Section 15.4.4.12) also takes two arguments (at minimum), the meaning is very different:\n\n[14, 3, 77].slice(1, 2)     //  [3]\n[14, 3, 77].splice(1, 2)    //  [3, 77]\n\n\nOn top of that, splice also mutates the array that calls it. This is not supposed to be a surprise, after all the name splice implies it.\n\nvar x = [14, 3, 77]\nvar y = x.splice(1, 2)\nconsole.log(x)           // [14]\nconsole.log(y)           // [3, 77]\n\n\nWhen you build your own module, it is important to choose an API which minimizes this slice vs splice confusion. Ideally, the user of your module should not always read the documentation to figure out which one they really want. What kind of naming convention shall we follow?\n\nA convention I’m familiar with (from my past time involvement with Qt) is by choosing the right form of the verb: present to indicate a possibly modifying action and past participle to return a new version without mutating the object. If possible, provide a pair of those methods. The following example illustrates the concept.\n\nvar p = new Point(100, 75);\np.translate(25, 25);\nconsole.log(p);       // { x: 125, y: 100 }\n \nvar q = new Point(200, 100);\nvar s = q.translated(10, 50);\nconsole.log(q);       // { x: 200, y: 100 }\nconsole.log(s);       // { x: 210, y: 150 }\n\n\nNote the difference between translate() that moves the point (in 2-D Cartesian coordinate system) and translated() which only creates a translated version. The point object p changed because it calls translate. Meanwhile, the object q stays the same since translated() does not modify it and it only returns a fresh copy as the new object s.\n\nIf this convention is used consistently throughout your application, that kind of confusion will be massively reduced. And one day, you can let your users sing I Can See Clearly Now happily!\n\n(`_|_`)Feb 4, 2014(`_|_`)ariya.io(`_|_`)javascript-array-slice-vs-splice', 'javascript-array-slice-vs-splice'),
(66, 'Searching and Sorting Without Loops(`_|_`)\nAt the recent San Francisco JavaScript meetup, I gave a talk on the subject of Searching and Sorting without Loops as part of its Functional Monthly series. In that talk, I explained various higher-order functions of JavaScript Array and their usage to replace explicit loops (for or while) in several different code patterns.\n\n\n\nI have published the slide deck for the talk (as PDF, 1.4 MB). The talk started with a quick refresh of five Array’s functions: map, filter, reduce, some, and every. Those functions will be used in the subsequent three parts of the talk: sequences, searching, and finally sorting. The first one, building sequences without any explicit loop, sets the stage for the rest of the discussion.\n\nIf you are following this blog corner, you may notice that this is not a new topic. This talk is basically a detailed walkthrough of some posts I have written in the past:\n\n\nSequences using JavaScript Array\nPrime Numbers, Factorial, and Fibonacci Series\nSearching: Array.prototype.some vs Array.prototype.reduce\nSorting Networks using Higher-Order Functions\n\n\nIt seems that you will need a lot of effort to understand all this complicate stuff. Nevertheless, think about the reward. Being able to understand this code fragment (fits in a single tweet) that constructs the first n numbers in the Fibonacci series is quite satisfying:\n\nfunction fibo(n) {\n  return Array.apply(, Array(n)).\n    reduce(function(x, y, z){ return x.concat((z < 2) ? z : x[z-1] + x[z-2]); }, []);\n}\n\n\nThe age of exploration is just beginning.\n\n(`_|_`)Jan 29, 2014(`_|_`)ariya.io(`_|_`)searching-and-sorting-without-loops', 'searching-and-sorting-without-loops'),
(67, 'The Flying Car Problem(`_|_`)\nMany free/open-source projects often suffer from a very specific feedback where it is assumed that a certain feature will not be implemented because of a philosophical reason. It is what I called as the “flying car” problem.\n\n\n\nAs an illustration, with a lot of users and very few contributors, PhantomJS was bound to have that problem. In fact, it does already and it will continue to have it. I don’t have a clear idea why it happens, however I suspect that it is caused by the practical impedance mismatch between the fundamental core implementation and its users. As you can imagine, most PhantomJS users are web developers who are not always exposed to the intricacies and the challenges of what happens behind the scene. This is pretty much like an automatic gearbox, my car mechanic and I might have a completely different idea of how such a gearbox should operate.\n\nIn a mailing-list thread over a year, I summarize the situation as:\n\n\nAny “why PhantomJS can’t do this” situation should be (at first) treated the same way as\n\n“why my car can’t fly” question. A car designer loves to have it, but the technology might not be there yet.\n\n\nAnother example is this remark on Hacker News (I don’t regularly follow HN, but from time to time certain comments were brought to my attention):\n\n\nI believe phantom made a fundamental mistake of not being nodejs based in the first place.\n\n\nThis is despite the subject itself is mentioned in the FAQ and has been discussed in the mailing-list (several times). I won’t go into the technical details (not the point here), but surely you can’t help but to notice a similar pattern here.\n\nAn engineering project is always handicapped by a certain engineering constraints. Many times the developers want to be pragmatic, there is nothing opinionated or philosophical about it. The recent Cambrian explosion of social media forums highlights the loudest noises and provokes heated flame wars to a different level. It is easy to fall into the trap whereby we assume (by means of extrapolation) that every project owner is hotheaded and opinionated. The calm and reasonable ones fade into the background.\n\nEvery sport team will welcome useful and constructive feedback. An emotional knee-jerk reaction from a trigger-happy armchair quarterback however hardly makes it to the prioritized items. As I have often expressed, we are not in the kindergarten anymore, screaming does not make the solution appear faster. While it is an opportunity to polish the art of self-restraint, any kind of flying car problem unnecessarily drains the energy of every project maintainer. The optimal win-win compromise is for both sides to always practice the principle of Audi alteram partem. The very least, give it five minutes.\n\nEnough rambling already, I need to go back to my garage to fix that damn hoverboard…\n\n(`_|_`)Jan 27, 2014(`_|_`)ariya.io(`_|_`)the-flying-car-problem', 'the-flying-car-problem'),
(68, 'Third Time\'s a Charm(`_|_`)\n Three years ago, the first version of PhantomJS was announced to the public. It is still a toddler, but hey, it is growing up and getting some traction at an unprecedented rate.\n\nLooking at the number of downloads over the last few years, the trend is obviously “up to the right”, a total of over 3 millions downloads. This can be explained easily. Many web applications and projects are using a various different test frameworks, most of them rely on PhantomJS to run the tests headlessly. Thus, those crazy downloads are mostly automatic as PhantomJS is being pulled as one of the dependencies, typically in a CI system.\n\n\n\nThe community also keeps growing. Our mailing-list grows from just over a thousand members to 1,600 members. The code repository github.com/ariya/phantomjs doubles its stargazers to more than 9,100 to date. There are countless new projects using PhantomJS directly or indirectly, it is harder and harder to keep track of them all.\n\nJust like any other toddlers of its age, PhantomJS is not perfect. It screams and makes a lot of noises. It does things you don’t expect it to do. And yet it keeps walking, running around, playing with friends, and brings a lot of happiness to those around it.\n\nIt gives us an ideal to strive towards. In time, it will help us accomplish wonders.\n\nHere is to another amazing year!\n\n(`_|_`)Jan 23, 2014(`_|_`)ariya.io(`_|_`)third-times-a-charm', 'third-times-a-charm'),
(69, 'A Maturity Model for Build Automation(`_|_`)\n\n\nHow does your engineering organization build and deliver products to its customers? Similar to the well-known capability maturity model, the maturity level of a build automation system falls into one of the following: chaotic, repeatable, defined, managed, or optimized.\n\nLet’s take a look at the differences in these levels for a popular project, PhantomJS. At the start of the project, it was tricky to build PhantomJS unless you were a seasoned C++ developer. But over time, more things were automated, and eventually engineers without C++ backgrounds could run the build as well. At some point, a Vagrant-based setup was introduced and building deployable binaries became trivial. The virtualized build workflow is both predictable and consistent.\n\nThe first level, chaotic, is familiar to all new hires in a growing organization. You arrive in the new office and on that first day, an IT guy hands you a laptop. Now it is up to you to figure out all the necessary bits and pieces to start becoming productive. Commonly it takes several days to set up your environment – that’s several days before you can get any work done. Of course, it is still a disaster if the build process itself can be initiated in one step.\n\nThis process is painful and eventually someone will step up and write documentation on how to do it. Sometimes it is a grassroots, organic activity in the best interest of all. Effectively, this makes the process much more repeatable; the chance of going down the wrong path is reduced.\n\nJust like any other type of document, build setup documentation can be out of sync without people realizing it. A new module may be added last week, which suddenly implies a new dependency. An important configuration file has changed and therefore simply following the outdated wiki leads to a mysterious failure.\n\nTo overcome this problem, consistency must be mandated by a defined process. In many cases, this is as simple as a standardized bootstrap script which resolves and pulls the dependency automatically (make deps, bundle install, npm install, etc). Any differences in the initial environment are normalized by that script. You do not need to remember all the yum-based setup when running CentOS and recall the apt-get counterparts when handling an Ubuntu box. At this level, product delivery via continuous deployment and integration becomes possible. No human interaction is necessary to prepare the build machine to start producing the artifacts.\n\nIn this wonderful and heterogenous environment it is unfortunately challenging to track delivery consistency. Upgrading the OS can trigger a completely different build. A test which fails on a RHEL-based is not reproducible on the engineer’s MacBook. We are lucky that virtualization (VirtualBox) or containment (Docker) can be leveraged to ensure a managed build environment. There is no need to install, provision, and babysit a virtualized build machine (even on Windows, thanks to PowerShell and especially Chocolatey). Anyone in the world can get a brand-new computer running a fresh operating system, get the bootstrap script, and start kicking the build right away.\n\nThere are two more benefits of this managed automation level. Firstly, a multi-platform application is easier to build since the process of creating and provisioning the virtual machine happens automatically. Secondly, it enables every engineer to check the testing/staging environment in isolation, i.e. without changing their own development setup. Point of fact, tools like Vagrant are quickly becoming popular because they give engineers and devops such power.\n\nThe last level is the continuous optimizing state. As the name implies, this step refers to ongoing workflow refinements. For example, this could involve speeding up the overall build process which is pretty important in a large software project. Other types of polishes concern the environment itself, whether creating the virtual machine from the .ISO image (Packer) or distributing the build jobs to a cloud-based array of EC2/GCE boxes.\n\nMy experience with automated build refinement may be described like this:\n\n\nChaotic: hunt the build dependencies by hand\nRepeatable: follow the step-by-step instructions from a wiki page\nDefined: have the environment differences normalized by a bootstrapping script\nManaged: use Vagrant to create and provision a consistent virtualized environment\nOptimizing: let Packer prepare the VM from scratch\n\n\nHow is your personal experience through these different maturity levels?\n\nNote: Special thanks to Ann Robson for reviewing and proofreading the draft of this blog post.\n\n(`_|_`)Jan 17, 2014(`_|_`)ariya.io(`_|_`)a-maturity-model-for-build-automation', 'a-maturity-model-for-build-automation'),
(70, 'JavaScript Kinetic Scrolling: Part 5 (Cover Flow Effect)(`_|_`)\nIn the fifth part of this JavaScript kinetic scrolling tutorial, a demo of the attractive Cover Flow effect (commonly found in some Apple products) using the deadly combination of kinetic scrolling and CSS 3-D will be shown. The entire logic is implemented in ~200 lines of JavaScript code.\n\nThe cool factor of Cover Flow is in its fluid animation of the covers in the 3-D space. If you haven’t seen it before, you miss a lot! To get the feeling of the effect, use your browser (preferably on a smartphone or a tablet) to visit ariya.github.io/kinetic/5. Swipe left and right to scroll through the cover images of some audiobooks.\n\n\n\nMy first encounter to this Cover Flow effect was 6 years ago as I implemented this with pure software in C/C++. It ran quite well even on a lowly hardware (such as this 200 MHz HTC Touch). Of course, with GPU-accelerated CSS animation, there is no need to write an optimized special renderer for this. For this example, we manipulate the transformation matrix directly using CSS Transform feature. To follow along, check the main code in coverflow.js.\n\nThere are several key elements in this demo. First, we will need a smooth scrolling with the right acceleration and deceleration using the exponential decay technique which was covered in Part 2. Also, stopping the scrolling at the right position is necessary (Part 3, see the snap-to-grid code) as we need to have all the cover images in the perfect arrangement, not halfway and not being stuck somewhere.\n\nWhen you look at the code, the scrolling via mouse or touch events impacts the value of the variable offset. In fact, the code for doing that is line-by-line equivalent to what has been covered in the previous parts. On a normal circumstances, this offset is always an integer multiply of 200 (the cover image size, in pixels). When the user makes a touch gesture to drag the cover or when it is decelerating by itself, then the value could be anything. This is where we need to apply tweening to give the right transformation matrix for each cover image.\n\nSuch a decoupling results in a modular implementation. All the events (touch, mouse, keyboard, timer) only deal with the change in offset, it has no knowledge as to how the value will be useful. The main renderer, which is the scroll() function, knows nothing on how that offset value is computed. Its responsibility is very limited: given the offset, compute the right matrix for every single cover. This is carried out by going a loop through the stack of the covers, from the front-most image to the ones in the far background, as illustrated in this diagram. Note how the loop also serves to set the proper z-index so that the center image becomes the front cover and so on.\n\nEvery image is initially centered on the screen. After that, the right translation is in the X axis is computed based on the relative position of the image. For a depth perception, there will be an additional translation in the Z axis, making the cover going farther from the screen. Finally the image is rotated (in the Y axis) with a positive angle and a negative angle for the left and right side, respectively. The 3-D visual comes from the perspective of the main div element which is the parent of every single image element.\n\n\n\nThe entire scroll() is about 40 lines. If the explanation above is still confusing, it is always fun to step through the code and watch the variables as it goes through one cover to another. The code is not crazily optimized, it is deliberately chosen to be as clear as possible without revealing too much. Having said that, with the most recent iOS or Android phones, the effect should be pretty smooth and there is not any problem achieving over 30 fps most of the time. You will get some minor extra frames (particularly useful for older devices) if the reflection effect is removed.\n\nSince this demo is intended to be educational, I left a few exercises for the brave readers. For example, the tweening causes only one cover to move at a time. If you are up for a challenge, see if you can move two covers, one that is going to the front and one that is going to the back. In addition, the perspective here is rather a cheat since it applies on the parent DOM element (as you can witness, these transformed images have the same vanishing point). Applying an individual perspective and Y-rotation requires wrapping every img element with its container. Of course, the 3-D effect does not have to be like Cover Flow as you could always tweak the matrix logic so that it resembles e.g. MontageJS Popcorn instead.\n\nOnce you leave the flatland, there is no turning back!\n\n(`_|_`)Jan 14, 2014(`_|_`)ariya.io(`_|_`)javascript-kinetic-scrolling-part-5-cover-flow-effect', 'javascript-kinetic-scrolling-part-5-cover-flow-effect'),
(71, 'PageSpeed Proxy: Part 2(`_|_`)\nIn the first part, I showed you an easy way to test PageSpeed Module by running it as a proxy, thanks to nginx and ngx_pagespeed. Instead of a prebuilt binary of PSOL (PageSpeed Optimization Library), this second part demonstrates how to build it from source.\n\nWe will continue using the same Vagrant-based setup from the same Git repository, gitlab.com/ariya/pagespeed-proxy. In fact, the modifications I have applied to the provisioning script setup-proxy.sh serves as the self-documented step-by-step of what needs to be done.\n\nJust like many other Google projects, mod_pagespeed is using Gyp for its build process. Thus, there is the need to grab the latest depot_tools (pretty straightforward). Also, care must be taken to ensure the availability of Git version 1.8 as the previous version does not work with Gyp on mod_pagespeed. This is also the reason why the script setup-proxy.sh needs to build Git 1.8 from source if the system-wide installed Git is not up-to-date.\n\nThe build process itself does not have any gotchas, as long as you stick with the given instructions in the Build PSOL from Source wiki page. Just make sure you explicitly choose the same versions for mod_pagespeed and ngx_pagespeed (1.7.30.1 in this example), otherwise any API differences would cause the compilation to fail. Also, since mod_pagespeed relies on a lot of third party code (check its DEPS file), everything from JsonCpp, Apache Serf, libjpeg-turbo, and many others, including some bits from Chromium, the process is going to take some time, both for fetching those libraries and building them.\n\nOnce everything is completed, the end result is still the same like the previous part. You will have an HTTP forward proxy running on port 8000 which uses PageSpeed optimization library to compress the web pages passing through it. Verification is simple, run these two commands\n\ncurl http://ariya.github.io/js/random/index.html\ncurl -x localhost:8000 http://ariya.github.io/js/random/index.html\n\n\nand you should the difference in the output as depicted in the screenshot. Notice the removal of the single HTML comment and the minification of JavaScript. In this simple example, the compressed HTML is reduced to only 87% of its original size.\n\n\n\nSee you in Part 3!\n\n(`_|_`)Dec 31, 2013(`_|_`)ariya.io(`_|_`)pagespeed-proxy-part-2', 'pagespeed-proxy-part-2'),
(72, 'JavaScript Kinetic Scrolling: Part 4(`_|_`)\n The fourth part of this JavaScript kinetic scrolling series shows an implementation of horizontal swipe to browse a gallery of photo. In addition to that, a simple parallax effect will be demonstrated as well.\n\nScrolling sideways is a common pattern in many application. The ubiquitous example is the home screen of many mobile tablets and phones, where the user needs to swipe left and right to scroll through the choices of many application icons. A typical photo application, even since the very first iPhone, allows the user to view the next and previous picture by a quick swipe. Tabbed view in many Android applications also feature the possibility of flicking to switch tabs (instead of tapping on the tab directly).\n\nA clever tweak to a horizontal swipe interface is the extra parallax effect. It is easier to explain this if you see the Android home screen. As you swipe left/right, you can watch how the icons are moving at a different distance compared to the wallpaper. This gives the impression that the icons are floating in the air, as supposed to stick right on top of the wallpaper.\n\nAnother popular application leveraging the parallax effect is the native weather application (iOS and Android) from Yahoo!, as illustrated in the following diagram. In the right screenshot, I am dragging the screen to the right halfway. However, you can see that the black-and-white building does not disappear from the screen. If you look carefully at the left screenshot, that building is in the right-half of the screen. Without any parallax effect, if I push the background halfway, the right-half (and thus also the building) should not be visible anymore.\n\n\n\nWhat does it take to implement this horizontal scrolling using vanilla JavaScript? Apparently, we already have the foundation in place. Dragging to the left/right is not foreign, this basic handling is in the Part 1 of this series. The flick gesture is already covered in Part 2. The fact that the screen needs to snap to the left or the right is simply the snap-to-grid feature, already explained in details in Part 3. What we need to change is the direction of the gesture detection as now we have to move horizontally.\n\nTo get the feeling of the implementation, open your browser and navigate to ariya.github.io/kinetic/4. Swipe left and right to scroll through the (wonderful) photos.\n\nThe core of the implementation is the three-card system, each represents the left, center, and right photo. Under normal circumstances, the center card occupies the entire view and both the left and right are out of the view. If the user swipes to the right, then we pulls the left card to the view (the center card is behind the left one). In addition to that, we also moves the center card at half the distance for the parallax effect.\n\n\n\nThe same scenario happens (in the reverse direction) if the user swipes to the left instead. Once the flick gesture is fully completed, we tweak all the three cards so that they all represents the final arrangement. All this logic takes only about 180 lines of JavaScript code (see scroll.js for details).\n\nAs an exercise for the reader, try to adjust the parallax implementation so that it faithfully resembles what Yahoo! Weather application does. With that application, you will notice that the new image (from the left or right) which got pulled as you swipe the center image has a peculiar parallax-ness as well. To implement something like this, you can’t use the img element directly as you need to wrap the image in another container, e.g. a div element, and adjust the offset of the image relative to its container. That seems challenging, but it is not too complicated to implement.\n\nI hope this parallax effect is fascinating. See you in Part 5!\n\n(`_|_`)Dec 18, 2013(`_|_`)ariya.io(`_|_`)javascript-kinetic-scrolling-part-4', 'javascript-kinetic-scrolling-part-4'),
(73, 'Code Coverage of Mocha Tests using Istanbul and Karma(`_|_`)\nMany JavaScript projects are using Mocha to run the unit tests. Combining Mocha with Istanbul and Karma, it is easy to track the code coverage of the application code when running the tests.\n\nWhile Mocha has a built-in support for running the tests from the command-line via Node.js, in some cases you still want to verify your code with the real web browsers. The easiest way to do that with by using Karma to automatically launch the browsers, control them, and execute the tests. The repository github.com/ariya/coverage-mocha-istanbul-karma shows a simple example on how to do this. To experiment with it, simply clone the repository and then run\n\nnpm install\nnpm test\n\nYou should get something like:\n\nRunning \"karma:test\" (karma) task\nINFO [karma]: Karma v0.10.8 server started at http://localhost:9876/\nINFO [launcher]: Starting browser PhantomJS\nINFO [launcher]: Starting browser Firefox\nINFO [PhantomJS 1.9.2 (Linux)]: Connected on socket ASrZI0wwAgPFSaxNmDHI\nINFO [Firefox 25.0.0 (Ubuntu)]: Connected on socket sBSK-fR9V5s-8pWWmDHJ\nPhantomJS 1.9.2 (Linux): Executed 2 of 2 SUCCESS (0.327 secs / 0.023 secs)\nFirefox 26.0.0 (Ubuntu): Executed 2 of 2 SUCCESS (0.446 secs / 0.002 secs)\nTOTAL: 4 SUCCESS\nDone, without errors.\n\n\nThe configuration file for Karma, shown below, specifies that the tests should run on PhantomJS and Firefox. Of course, it is also easy to add other browsers.\n\nmodule.exports = function(config) {\n  config.set({\n    basePath: \'\', \n    autoWatch: true,\n    frameworks: [\'mocha\'],\n    files: [\n      \'sqrt.js\',\n      \'test/*.js\'\n    ],  \n    browsers: [\'PhantomJS\', \'Firefox\'],\n \n    reporters: [\'progress\', \'coverage\'],\n    preprocessors: { \'*.js\': [\'coverage\'] },\n \n    singleRun: true\n  }); \n};\n\n\nnpm test will run the tests by executing the right Karma task as mentioned inside Gruntfile.js. Note that Grunt is not mandatory here, running Karma directly is as easy as:\n\nnode_modules/.bin/karma start karma.conf.js\n\n\nJust like in the previous coverage examples (using QUnit and Jasmine), the code we want to test is the following simple implementation of the square root function:\n\nvar My = {\n    sqrt: function(x) {\n        if (x < ) throw new Error(\"sqrt can\'t work on negative number\");\n        return Math.exp(Math.log(x)/2);\n    }\n};\n\n\nThe tests for that function are in test/test.sqrt.js. In fact, it is also possible to run the tests manually with a web browser, simply open test/index.html file and you will see the report:\n\n\n\nAs an exercise, try to remove one test and see what happens as you run the test again. In fact, open the coverage report (look under coverage directory) and you will find the glaring warning from Istanbul, indicating the worrying level of coverage confidence.\n\n\n\nJust like a good code coverage tool, Istanbul reports missing branch coverage. This is very important as looking only at the statement coverage may hide some latent bugs.\n\nNow, if make it this far, you are very close to implement full enforcement of coverage threshold.\n\n(`_|_`)Dec 12, 2013(`_|_`)ariya.io(`_|_`)code-coverage-of-mocha-tests-using-istanbul-and-karma', 'code-coverage-of-mocha-tests-using-istanbul-and-karma'),
(74, 'PageSpeed Proxy: Part 1(`_|_`)\nPageSpeed Module from Google, available for Apache and nginx, is a quick solution to improve web application network performance. As a bonus, if we configure nginx as a proxy server, then it can also serve as a web acceleration solution.\n\nThere is a growing number of PageSpeed optimization filters, anything from a straightforward CSS minification to a sophisticated images recompression. If you are already using Apache or nginx, PageSpeed module is relatively easy to use.\n\nA different use case for PageSpeed is as a proxy server which you use for your daily browsing, e.g. what @jedisct1 has implemented via Apache proxy module. In this blog post, I show an alternative setup by using nginx instead, mainly by following the steps described in the ngx_pagespeed project.\n\nRather that doing things manually, you can just use the automated setup using Vagrant with VirtualBox. Simply clone pagespeed-proxy Git repository and then you only need to run:\n\nvagrant up\n\nFor this experiment, the virtual machine is based on Ubuntu 12.04 LTS (Precise Pangolin) 64-bit. If you tweak the configuration inside Vagrantfile to a CentOS-based Vagrant box, e.g. from Opscode Bento collection, it should also work just fine. Should you rather trust your own virtual machine, you can create a Vagrant box from scratch automatically, check out my previous blog post on Using Packer to Create Vagrant Boxes.\n\nThe provisioning script of the box takes care the step of downloading the latest nginx and compile it with Google’s PageSpeed module. When it is ready, the script will also launch nginx as a forward proxy at port 8000 (this port is also forwarded and hence the proxy is available for the host machine as well). The proxy will run two optimizations filters (as a starting point): HTML comment removal and JavaScript minification, this can be proved by looking at the provided configuration file nginx.conf:\n\nhttp {\n    server {\n        listen 8000;\n        server_name localhost;\n        location / {\n            resolver 8.8.8.8;\n            proxy_pass http://$http_host$uri$is_args$args;\n        }\n        pagespeed on;\n        pagespeed RewriteLevel PassThrough;\n        pagespeed EnableFilters remove_comments,rewrite_javascript;\n        pagespeed FileCachePath /home/vagrant/cache;\n    }\n}\n\n\nTo verify the operation of the optimizing proxy, run these two commands (on the host machine) and observe the different outcomes:\n\ncurl http://ariya.github.io/js/random/index.html\ncurl -x localhost:8000 http://ariya.github.io/js/random/index.html\n\n\nThe second one pipes the original HTML content through the enabled optimization filters, comment removal and script rewrite, and thereby it will result in a smaller page. This is definitely just an illustration, feel free to play with a number of other PageSpeed filters and observe the impacts.\n\nObviously, it is also possible to setup your web browser to use the proxy at localhost:8000. When looking at the same URL given above, it will result in something like the following screenshot. Again, compare it with the case where you view the page without using the proxy.\n\n\n\nFor a more practical usage of the proxy, stay tuned!\n\n(`_|_`)Dec 10, 2013(`_|_`)ariya.io(`_|_`)pagespeed-proxy-part-1', 'pagespeed-proxy-part-1'),
(75, 'JavaScript Kinetic Scrolling: Part 3(`_|_`)\nIn the third part of this JavaScript kinetic scrolling series, the so-called snap to grid feature is demonstrated. The implementation is rather straightforward, it is a matter of figuring out where the scrolling should stop and then adjusting that target position to the intended location.\n\n\n\nThe second part of the series discussed the scrolling deceleration technique by using an exponential decay concept. With a flick list, this means that the list will slow down and stop at some point, depending on the launch velocity at the moment the user releases the grip. It turns out that this also becomes the important key to implement snap to grid.\n\nNote that the exponential decay curve permits us to know about two things (1) when the scrolling will stop (2) where it will stop. As soon as the launch velocity is known, these two values can be computed analytically. This is very powerful, in particular since the final stop position can be adjusted right away. For a quick live demo, go to ariya.github.io/kinetic/3 (preferably using your smartphone browser), flick the list, and see how it always stops to align the color entry to the overlaid slot.\n\nThe following diagram illustrates the concept. Without any snap to grid, the curve of the scrolling position as a function of time is depicted in the gray line. Let us assume that the final position will be at 110 px. If we know that the snapping grid is every 25 px, then that final position needs to be adjusted either to 100 px or 125 px. Since the former is the closest, that will be the ultimate final position and the deceleration will follow the curve colored in blue.\n\n\n\nThe relevant code for this feature can be seen in the repository github.com/ariya/kinetic. Really, it is not much different than the code shown already in the previous second part. The new addition is this following fragment:\n\ntarget = Math.round(target / snap) * snap;\n\n\nThe variable snap here stores the row height of each item (it is computed once during the initialization). If you already familiarize yourself with the exponential decay implementation, target contains the final scrolling position when the deceleration finishes. Without snapping feature, we don’t tweak this value. When we want to adjust the final scrolling position to be magnetically anchored to nearest snapping location, then we simply change this value.\n\nAlso, observe that there is no requirement that snap has to be a constant. A list with non-uniform row height can still enjoy snap to grid feature. All we need is an array of possible values for the final position and every deceleration target must be modified to the closest value. In case you study physics, this is quite similar to the idea of discrete packets of electromagnetic energy in quantum mechanics.\n\nIn some libraries which implement kinetic scrolling, snap to grid is implemented by continuously tracking the scrolling position. When it is about to stop, then the position is adjusted to move to the closest possible position based on the grid distance. Not only this results in a more complicated code, such an approach has a major drawback. In some cases, the list can overshoot before it bounces back and therefore it does not demonstrate a smooth scrolling effect at all. With the analytical technique described here, this awkward effect will not happen at all. As always, a proper solution often comes with the cleanest implementation!\n\nWhat will be shown in the fourth part? Let’s keep it as a surprise!\n\n(`_|_`)Dec 5, 2013(`_|_`)ariya.io(`_|_`)javascript-kinetic-scrolling-part-3', 'javascript-kinetic-scrolling-part-3'),
(76, 'Winter 2013 Conferences(`_|_`)\n\n\nIt is getting colder, it starts to feel like winter. Right when it will be warmer again slowly, it is time for me to give another round of tech talks.\n\nMy first stop is Atlanta, for DevNexus 2014, February 24-25 (follow @devnexus to get all updates). It is not in California, so I expect a true end-of-winter experience. For DevNexus, I’ll have two talks on Tweaking CSS3 for Hardware Acceleration and JavaScript API Design Principles.\n\nIf you can’t be in Atlanta, I plan to give another Design Strategies for JavaScript API presentation for the evergrowing Fluent 2014 in San Francisco, March 11-13. I spoke at this wonderful conference twice already, every year was wonderful. Follow @fluentconf for more information on this 2014 edition. If you decide to attend it, it is also packed with other awesome talks.\n\nLast but not least, EclipseCon NA 2014 will be held in Burlingame, March 17-20 (make sure to track @eclipsecon). This time, I will use the opportunity to continue my campaign for a better development experience with the talk titled Next-generation JavaScript Language Tooling. There is a healthy growing front-end developers using Eclipse and expect to see more talks related to JavaScript at this conference.\n\nIf you plan to be in Atlanta, San Francisco, or Burlingame, let’s have a chat!\n\n\n\nUpdate: I will be also at jQuery Conference 2014 in San Diego, Feb 12-13. At this conference, my presentation will be about Dynamic Code Analysis for JavaScript. This will be my first jQuery event and I’m pretty excited about that.\n\n(`_|_`)Nov 29, 2013(`_|_`)ariya.io(`_|_`)winter-2013-conferences', 'winter-2013-conferences');
INSERT INTO `ariyaio` (`id`, `content`, `url`) VALUES
(77, 'JavaScript Kinetic Scrolling: Part 2(`_|_`)\nIn the second part of this series of JavaScript kinetic scrolling example, the inertial effect is implemented. This is done by tracking the movement while the user is still dragging the view and then automatically scroll the view until it stops at some point.\n\nThe first part already covered the basic drag-and-scroll technique (if you have not read it yet, please do so because the concept will be reused here). Before we add the kinetic effect, let us see first what happens to the scroll offset of a list view as the user taps, drags, and releases his finger.\n\n\n\nThe shaded area in the above diagram is when the user still manually controls the list, he scrolls up and then down and then up again. Right when this user finally releases his finger, the list starts to enter the automatic scrolling mode. During this mode, the list starts moving at a certain speed but then it slows down and then eventually it comes to a halt. To carry out the automatic scrolling, it is important to figure out the initial velocity right at that release moment. This is done by tracking the finger position and computes the velocity, this happens between the tap and release.\n\n\n\nIf this kinetic scrolling is implemented properly, what we would get is something depicted in the following animation (GIF, forgive the quality). Should you want to play with the live demo, go to ariya.github.io/kinetic/2 with your favorite modern smartphone. Pay attention to the smooth scrolling as you flick the list. Note that it does not have edge bouncing feature yet, we will cover this in some future episode.\n\nHow to track the velocity while the user is still dragging and scrolling the list? A simple approach, among a billion possibilities, is to use a periodic timer. When the timer fires, retrieve the current position and use it to compute the velocity. Empirically, tracking the position 10 times per second (a timer interval of 100 ms) proves to be sufficient.\n\nThis tracking activity shall start as soon as the user initiates the tap, hence we modify our tap() function implementation to look like the following. The key here is that the function track() which will be invoked repeatedly as long as we still want to track the velocity.\n\nfunction tap(e) {\n    pressed = true;\n    reference = ypos(e);\n \n    velocity = amplitude = ;\n    frame = offset;\n    timestamp = Date.now();\n    clearInterval(ticker);\n    ticker = setInterval(track, 100);\n \n    e.preventDefault();\n    e.stopPropagation();\n    return false;\n}\n\n\nThe code for track() is quite short. The idea is to compare the current position and time to the previous recorded position and time, frame and timestamp, respectively. From this delta, the instantaneous velocity v is easily obtained. The last line acts as a simple moving average filter, this protects us from any wild variation, either from the user’s own erratic movement or from other input noise.\n\nfunction track() {\n    var now, elapsed, delta, v;\n \n    now = Date.now();\n    elapsed = now - timestamp;\n    timestamp = now;\n    delta = offset - frame;\n    frame = offset;\n \n    v = 1000 * delta / (1 + elapsed);\n    velocity = 0.8 * v + 0.2 * velocity;\n}\n\n\nThe track() function plays its role during the manual dragging (the shaded part in the previous diagram). Once the user releases his finger from the touch device, the situations changes dramatically. Now we have to use the computed launch velocity to decide the next move, as evidenced from the implementation of the following function.\n\nfunction release(e) {\n    pressed = false;\n \n    clearInterval(ticker);\n    if (velocity > 10 || velocity < -10) {\n        amplitude = 0.8 * velocity;\n        target = Math.round(offset + amplitude);\n        timestamp = Date.now();\n        requestAnimationFrame(autoScroll);\n    }\n \n    e.preventDefault();\n    e.stopPropagation();\n    return false;\n}\n\n\nCompared to the original code (in Part 1), there is additional block to trigger the automatic scrolling, autoScroll function. The threshold speed of 10 pixels/second is used to prevent any automatic scrolling if the velocity is too low. The launch velocity is used to compute where the scrolling needs to stop, this is the purpose of the amplitude variable. The factor 0.8 is tweakable. If you want to make the list feel “heavy” reduce the number. Consequently, a higher factor will give the illusion of a smooth and frictionless list. Updating the scroll offset is the responsibility of autoScroll() function. Note how this is trigger using requestAnimationFrame for a jankfree animation.\n\n\n\nA typical flick list has a deceleration that is a form of exponential decay. In other words, the deceleration system is just an overdamped spring-mass system. Fortunately, it is a standard differential equation and its solution is rather straightforward (ŷ is the target position, A is the amplitude, t is the current time, τ is the time constant).\n\nThe math may look scary but the actual code is not that complicated. As long as this autoScroll() function still needs to move the list by more than 0.5 pixel, it will be repeatedly invoked. In fact, the following lines of code (it is indeed quite short, isn’t it?) is the heart of this well-known deceleration effect.\n\nfunction autoScroll() {\n    var elapsed, delta;\n    if (amplitude) {\n        elapsed = Date.now() - timestamp;\n        delta = -amplitude * Math.exp(-elapsed / timeConstant);\n        if (delta > 0.5 || delta < -0.5) {\n            scroll(target + delta);\n            requestAnimationFrame(autoScroll);\n        } else {\n            scroll(target);\n        }\n    }\n}\n\n\nThe value of timeConstant here is quite important. If you want to really mimic iOS (in its UIWebView, decelerationRate normal), the suggested value is 325. This corresponds to a time constant of 325 ms. Math geeks may also realize that with the animation interval of 16.7 ms (from 60 fps), this automatic scrolling effectively reduces the scrolling velocity by a factor of 0.95, which is Math.exp(-16.7 / 325), until it barely moves and therefore the scrolling is stopped completely.\n\nJust to emphasize again, the chart of position as a function of time for this deceleration is depicted below, created using Google plot 150*(1-exp(-t/325)). You may have seen the tail (last part) of the first diagram showing this kind of exponential decay curve.\n\n\n\nNote that this kind of automatic scrolling also means that the scrolling will stop, regardless of the initial velocity computed earlier, after approximately 1.95 seconds (6 * 325). System theory tells us that after the duration of 6x the time constant, the position will be within 0.25% of the target position (mathematically, you can get that from calculating Math.exp(-6)). Thus, by choosing the time constant, you can make the list feel light or heavy, depending on your need.\n\nHow about the rest of the code? It is, surprisingly, still the same as the one presented in first part. There is no need to modify drag() function because the behavior is still the same. Also the helper functions need not change at all. Recycling always feels good!\n\n\n\nTo see the full JavaScript code (roughly 130 lines), check the repository github.com/ariya/kinetic/. It has been tested on Android 4.3 or later (Chrome, Firefox), Android 2.3 (Kindle Fire), and iOS 6 or later (Mobile Safari). Also, as I mentioned in the beginning of this series, treat this example code as an example, nothing more and nothing less (it is optimized for readability and less on performance). Use the basic knowledge to inspire you to write, implement, and tweak your own variant of kinetic scrolling. That said, it doesn’t mean that this particular code is really slow. With Nexus 4 and Nexus 7, there is no problem of hitting 60 fps most of the time. This can also be verified by looking at the detailed frame statistics (using Chrome Developer Tools). Obviously, the painting time HUD is also very useful in this analysis.\n\nThe physics effect has fascinated many developers since iPhone popularized the concept. In fact, the web-oriented implementation of this concept exists in various forms (virtually in all mobile-focused libraries), from the early PastryKit edition to a dedicated microlibrary such as FTScroller. If you are always curious about the math and the physics behind it, I hope my explanation above shows that there is nothing really mystical about it.\n\nIn the third part, an important feature will be shown: snap to grid.\n\nUpdate: It is published, please enjoy Part 3.\n\n(`_|_`)Nov 25, 2013(`_|_`)ariya.io(`_|_`)javascript-kinetic-scrolling-part-2', 'javascript-kinetic-scrolling-part-2'),
(78, 'Nexus 5 Web Performance Quick Check(`_|_`)\nNexus 5 is the most recent high-end smartphone with the authentic Google experience. With its amazing performance at the given price, Nexus 5 enjoys favorable reviews from The Verge, Ars Technica, ZDNet, Engadget, ComputerWorld, and many others. In term of web browsing experience, how does it compare to its older sibling Nexus 4?\n\nThe following basic performance analysis confirms the qualitative observation that Nexus 5 feels much much snappier then its predecessor. Obviously, the main reason behind this is the upgraded hardware subsystems. While Nexus 4 is armed with Snapdragon S4 Pro (quad core, 1.5 GHz), LG and Google boosted the fire power even further with the use of Snapdragon 800 in Nexus 5 (still quad core, 2.3 GHz). The memory system remains at 2 GB of RAM, but the graphics processor enjoys some minor speed bump as well, presumably to handle twice the amount of pixels (1280×768 px to 1920×1080 px). Speaking about pixels, Nexus 5 display (at 445 ppi) is simply gorgeous.\n\nRunning the default browser, which is Google Chrome, on Nexus 5 reveals the user agent:\n\n\nMozilla/5.0 (Linux; Android 4.4; Nexus 5 Build/KRT16M) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/31.0.1650.59 Mobile Safari/537.36\n\n\nFor day-to-day web browsing activities, DOM performance plays a very important role. Site interactivity and content handling rely on a smooth DOM access and modification. The following graph (longer is better) shows the difference between Nexus 4 (Chrome 30, Jelly Bean) and Nexus 5 (Chrome 30, KitKat) when running the DOM core tests from Dromaeo (full result).\n\n\n\nBecause iPhone 5S is currently the hottest non-Android competitor to Nexus 5, I also included its result for this particular test. Unsurprisingly, this flagship smartphone from Apple (running Mobile Safari on iOS 7.0) is still miles ahead, presumably due to its powerful 64-bit ARM-based Apple A7 processor.\n\nIf we want to focus only on JavaScript performance, a good candidate is the fresh-from-the-over Octane 2.0 benchmark suite. The outcome of running this suite is depicted in this bar chart (again, longer is better). There is hardly a surprise there (I leave it to your imagination as to where iPhone 5S will be positioned there), it pretty much echoes the previous comparison.\n\n\n\nNeed more evidence? Here is Kraken 1.1 benchmark result (shorter is better). If you are not familiar with Kraken, it is a set of benchmarks from Mozilla designed to account for future types of web applications. Again, the numbers won’t lie about the performance differences.\n\n\n\nLast time I reviewed Nexus 4 performance, it did not show a refinement compared to Galaxy Nexus. This time however, LG and Google demonstrated a commitment to build a significantly faster browsing performance. And of course, there are other major improvements such as LTE support, high-resolution display, better camera, and many others. If you are currently using Nexus 4, don’t think twice and upgrade right away to Nexus 5!\n\n(`_|_`)Nov 19, 2013(`_|_`)ariya.io(`_|_`)nexus-5-web-performance-quick-check', 'nexus-5-web-performance-quick-check'),
(79, 'Using Packer to Create Vagrant Boxes(`_|_`)\nThe process of managing a virtual machine is heavily simplifed via the use of Vagrant. However, there is still a manual or a semi-automatic process involved for creating the base box itself. There are many tools designed to solve to this problem, the most recent one is Packer from @mitchellh, the very same man behind Vagrant.\n\nPacker allows you to create a personal Vagrant base box easily. This means that you don’t need to rely anymore on some random ready-made boxes from the Internet. With Packer, you know what is being installed into your base box and hence the box can be more trustworthy. While Packer supports Vagrant, it can also be used to prepare a system for Amazon EC2, VMware, and many others.\n\nUsing Packer to create CentOS and Ubuntu boxes is not difficult. If you want to follow along, I have prepared a Git repository ariya/packer-vagrant-linux which contains all the necessary bits to create CentOS 5.4 and/or Ubuntu 12.04 LTS 64-bit boxes. Make sure you have the latest version of VirtualBox, Vagrant, and Packer installed properly in your machine before you follow these step-by-step instructions.\n\nPacker works with a template file. In the repository mentioned above, there are two templates, each for CentOS and Ubuntu. As an example, if you want to build the base CentOS box, you need to invoke the command:\n\npacker build centos-6.4-x86_64.json\n\nThis triggers the download of VirtualBox Guest Additions image and the actual CentOS 5.4 installation image. These two images will be cached, see the subdirectory packer_cache, so that any subsequent build does not trigger a full download again. Obviously, if you rather create a Ubuntu box, just replace the specified file with the one for Ubuntu.\n\nUsing the installation image, Packer will prepare a blank temporary virtual machine (clearly visible if you have VirtualBox Manager running as the machine is called packer-virtualbox) and install CentOS into that machine. Unless you are running it in a headless mode, a window will show up the actual installation process:\n\n\n\nFor many sysadmins, unattended Linux installation may sound familiar: CentOS uses kickstart while Ubuntu uses preseeding. The configuration files for this automated installation are in the http subdirectory (served via HTTP to the installer). You can open the template file, centos-6.4-x86_64.json in the above example, to get the understanding of this unattended installation configuration.\n\nOnce the intended Linux distribution is installed, the template file tells Packer to do some basic provisioning by running several shell scripts (check the subdirectory scripts). After this provisioning step is completed, Packer will export the temporary virtual machine and create a Vagrant base box out of it. In this example, it will be stored in the build subdirectory. At this point you are ready to use your base box, it is a matter of using vagrant init with the path to the box in that build directory.\n\nNow, who said packing can’t be fun?\n\n(`_|_`)Nov 14, 2013(`_|_`)ariya.io(`_|_`)using-packer-to-create-vagrant-boxes', 'using-packer-to-create-vagrant-boxes'),
(80, 'Getting in Shape(`_|_`)\n\n\nLast week I started a new chapter in my professional career. I am now working for Shape Security, a cool startup in Mountain View focusing on the next-generation web content security.\n\nI am pretty excited about the product, the team, and the technology. With a serious funding, along with an impressive array of investors, the journey has just started. Personally, I can’t wait to share with you some of the cutting-edge security systems we are working on!\n\nStay hungry, stay secure.\n\n(`_|_`)Nov 4, 2013(`_|_`)ariya.io(`_|_`)getting-in-shape', 'getting-in-shape'),
(81, 'JavaScript Insights(`_|_`)\n With my new partner-in-crime Ann Robson, we had a presentation JavaScript Insights at the most recent HTML5 Developer Conference in San Francisco. In this talk, we discussed several important JavaScript code quality tools.\n\nYou might have seen my previous renditions of this theme (Fluent, Velocity, and a few others), yet those variants were quite jam-packed and too condensed. As Ann has written in her blog post, one primary objective of this new attempt is to make it “more palatable and practical”.\n\nThe biggest challenge we experienced during the brewing process of the presentation is figuring out the right composition. We have enough materials to talk all day long about JavaScript language tooling, but we need to pack it in such a way that it can be thought-provoking enough and yet not too cliché. We covered topics such as multi-layer defense, pre-commit hook, code coverage, and cyclomatic complexity. There were also further discussion on tools to catch things like stray logging, Boolean traps, strict mode violations, polluting and unused variables, and nested conditionals.\n\nIf you missed this talk, enjoy the slide deck (download as PDF, 1.5 MB).\n\nUpdate: Check also the 40-minute video.\n\nOf course, feel free to send us your feedback, just hit @arobson and/or @ariyahidayat on Twitter!\n\n(`_|_`)Oct 23, 2013(`_|_`)ariya.io(`_|_`)javascript-insights', 'javascript-insights'),
(82, 'Sorting Networks using Higher-Order Functions of JavaScript Array(`_|_`)\nAn implementation of a sorting algorithm usually uses one or more iterating loops in the form of for/while statement. With JavaScript and its powerful Array object, these loops can be avoided since Array’s higher-order functions are enough for iterating the array. One candidate for this technique is the implementation of sorting networks.\n\nBefore we start, let us do a quick refresh on some higher-order functions. In my previous blog post Searching using Array.prototype.reduce, there is an implementation of insertion sort without any loop statements at all. If we change the problem into sorting an array of numbers, the complete code will be:\n\nfunction sort(entries) {\n  return Array.apply(, Array(entries.length)).map(function () {\n    return entries.splice(entries.reduce(function (max, e, i) {\n      return e > max.value ? { index: i, value: e } : max;\n    }, { value: null }).index, 1).pop();\n  }); \n}\n \nconsole.log(sort([14, 3, 77])); // [ 77, 14, 3 ]\n\n\nLike a typical insertion sort, the outer loop picks the largest value one at a time while the inner loop searches for the largest number in the working array. For the outer loop, Array.apply(0, Array(N)) is the trick to generate a usable empty array, see my other blog post on Sequence using JavaScript Array. In the inner loop, reduce is used to locate the largest number as well as its index. The index is needed to yank that number out of the array. At the same time, the number is being stashed into the sorting result.\n\nIf you are still confused, try to deconstruct and debug the above code. When necessary, write the imperative version, possibly using the classical for loop, and compare both versions. It is quite useful to understand this properly to make it easier to follow the next part.\n\nFor the sorting network, the process involves two steps. The first step is to build the comparator network, the second is the actual sorting process via comparison and swap according to the constructed network. For the second step, the core operation is the following function (that acts like a comparator unit):\n\nfunction compareswap(array, p, q) {\n  if (array[p] < array[q]) {\n    var temp = array[q];\n    array[q] = array[p];\n    array[p] = temp;\n  }\n}\n\n\nAs an illustration, if the array to be sorted has 3 numbers only, practically the sorting will be a series of the following steps:\n\ncompareswap(entries, , 1); \ncompareswap(entries, 1, 2); \ncompareswap(entries, , 1);\n\n\nFor 4-number array, it will be like:\n\ncompareswap(entries, , 1); \ncompareswap(entries, 1, 2); \ncompareswap(entries, 2, 3); \ncompareswap(entries, , 1); \ncompareswap(entries, 1, 2); \ncompareswap(entries, , 1);\n\n\nIf we draw the sequence, the sorting network annotation look like the following diagram. You probably can already see the pattern here, in particular if you relate it to the previous implementation of insertion sort. There is a few alternatives to this configuration of sorting networks such as odd-even mergesort, Bitonic, and many others.\n\n\n\nThe comparator network simply formalizes this so that we can put every compare-and-swap action in a single loop. As long as we have the right network for the given array size, sorting is a matter of running:\n\nfunction sort(network, entries) {\n  for (var i = ; i < network.length; ++i)\n    compareswap(entries, network[i], network[i] + 1)\n}\n\n\nQuiz: what kind of sorting algorithm is that?\n\nHow to create the network? A quick way is shown below. Note that the network will be always the same for the given array size (N), thus it may make sense to memoize it in some scenarios.\n\nfunction createNetwork(N) {\n  var network = [];\n  for (var i = N - 1; i >= ; --i)\n    for (var j = ; j < i; ++j)\n      network.push(j);\n  return network;\n}\n\n\nObviously, why use for loop if we can leverage Array object? Here is the version, out of a gazillions other possibilities, which uses only Array’s higher-order functions. Like what I have discussed in the Fibonacci series construction, reduce can be (ab)used to accumulate elements into an array and this serves as the outer loop. The inner loop is way simpler, it only needs to create a sequence of numbers from 0 to the current limit.\n\nfunction createNetwork(N) {\n  return Array.apply(, Array(N)).reduce(function (network, _, y) {\n    return network.concat(Array.apply(, Array(N - y - 1)).map(function(_, x) {\n      return x;\n    }));\n  }, []);\n}\n\n\nCombining both these two steps give us the final code as follows (notice the same code pattern for reduce). See if you recognize the construct for each step and if you can analyze what it is doing there.\n\nfunction sort(input) {\n  var array = input.slice();\n  Array.apply(, Array(array.length)).reduce(function (network, _, y) {\n    return network.concat(Array.apply(, Array(array.length - y - 1))\n      .map(function(_, x) { return x; }));\n  }, []).reduce(function(result, p) {\n    if (array[p] < array[p + 1]) {\n      var temp = array[p + 1];\n      array[p + 1] = array[p];\n      array[p] = temp;\n    }\n    return array;\n  }, array);\n  return array;\n}\n\n\nWhile sorting network is supposed to be well suited for parallelized comparison, it does not give us a lot of benefit in the context above. However, I hope these two different ways to implement sorting in JavaScript will inspire you to further explore the wonderful world of sorting networks.\n\nNote: Special thanks to Bei Zhang for his initial implementation of sorting network and for reviewing this blog post. \n\n(`_|_`)Oct 16, 2013(`_|_`)ariya.io(`_|_`)sorting-networks-using-higher-order-functions-of-javascript-array', 'sorting-networks-using-higher-order-functions-of-javascript-array'),
(83, 'Code Coverage of QUnit Tests using Istanbul and Karma(`_|_`)\nQUnit, used by projects like jQuery and jQuery Mobile, is a rather popular JavaScript testing framework. For tests written using QUnit, how do we measure its code coverage? A possible solution which is quite easy to setup is to leverage the deadly combination of Karma and Istanbul.\n\nJust like our previous adventure with Jasmine code coverage, let us take a look at a simple code we need to test. This function My.sqrt is a reimplementation of Math.sqrt which may throw an exception if the input is invalid.\n\nvar My = {\n  sqrt: function(x) {\n    if (x < ) throw new Error(\"sqrt can\'t work on negative number\");\n      return Math.exp(Math.log(x)/2);\n  }\n};\n\n\nA very simple QUnit-based test for the above code is as follows. \n\ntest(\"sqrt\", function() {\n  deepEqual(My.sqrt(4), 2, \"square root of 4 is 2\");\n});\n\n\nManually running the test is easy as opening the test runner in a web browser:\n\n\n\nFor a smoothed development workflow, an automated way to run the tests will be much preferred. This is where Karma becomes very useful. Karma also has the ability to launch a predetermined collection of browsers, or even to use PhantomJS for a pure headless execution (suitable for smoke testing and/or continuous delivery).\n\nBefore we can use Karma, installation is necessary:\n\nnpm install karma karma-qunit karma-coverage\n\n\nKarma requires a configuration file. For this purpose, the config file is very simple. As an illustration, the execution is done by PhantomJS but it is easy to include other browsers as well.\n\nmodule.exports = function(config) {\n  config.set({\n    basePath: \'\',\n    frameworks: [\'qunit\'],\n    files: [\n      \'*.js\',\n      \'test/spec/*.js\'\n    ],\n    browsers: [\'PhantomJS\'],\n    singleRun: true,\n    reporters: [\'progress\', \'coverage\'],\n    preprocessors: { \'*.js\': [\'coverage\'] }\n  });\n};\n\n\nNow you can start Karma with the above configuration, it would say that the test passes just fine. Should you encounter some problems, you can look at an example repository I have setup github.com/ariya/coverage-qunit-istanbul-karma, it may be useful as a starting point or a reference for your own project. As a convenience, the test in that repository can be executed via npm test.\n\nWhat is more interesting here is that Karma runs its coverage processor, as indicated by preprocessors in the above configuration. Karma will run Istanbul, a full-featured instrumenter and coverage tracker. Essentially, Istanbul grabs the original JavaScript source and injects extra instrumentation code so that it can gather the execution metrics once the process finishes (read also my previous blog post on JavaScript Code Coverage with Istanbul). In this Karma and Istanbul combo, the generated coverage report is available in the under the subdirectory coverage.\n\n\n\nThe above report indicates that the single test for My.sqrt is still missing the test for an invalid input, thanks to branch coverage feature of Istanbul. The I indicator next to the conditional statement tells us that the if branch was never taken. Of course, once the issue is known, adding another test which will cover that branch is easy (left as an exercise for the reader).\n\nNow that code coverage is tracker, perhaps you are ready for the next level? It is about setting the hard threshold so that future coverage regression will never happen. Protect yourself and your team from carelessness, overconfidence, or honest mistakes!\n\n(`_|_`)Oct 9, 2013(`_|_`)ariya.io(`_|_`)code-coverage-of-qunit-tests-using-istanbul-and-karma', 'code-coverage-of-qunit-tests-using-istanbul-and-karma'),
(84, 'Searching using Array.prototype.reduce(`_|_`)\nSearching for a particular element in a JavaScript array is often carried out using a typical iteration. In some cases, forEach and some can be used as well. What is often overlooked is the potential use of Array.prototype.reduce to perform such an operation.\n\nECMAScript 5.1 specification, in Section 15.4.4.21, describes the callback function to reduce as:\n\n\ncallbackfn is called with four arguments: the previousValue (or value from the previous call to callbackfn), the currentValue (value of the current element), the currentIndex, and the object being traversed.\n\n\nAn illustration of reduce can be seen in the following snippet. Thanks to the addition x + y, the code computes the sum of all numbers in the array, with an optional offset in the second example.\n\n[1, 2, 3, 4, 5].reduce(function (x, y) { return x + y });       //  15\n[1, 2, 3, 4, 5].reduce(function (x, y) { return x + y }, 100);  // 115\n\n\nAs a matter of fact, I already covered a rather complicated construct using reduce to produce the Fibonnaci series. To perform a search using reduce, fortunately it does not need to be complicated.\n\nLet’s take a look at the following problem (part of JavaScript Under Pressure): find the longest string in an array of strings. An imperative solution looks something like the following code (using forEach may simplify the loop but the idea remains the same):\n\nfunction findLongest(entries) {\n  for (var i = , longest = \'\'; i < entries.length; ++i) \n    if (entries[i].length > longest.length) longest = entries[i];\n  return longest;\n}\n\n\nA version which relies on reduce is a single statement:\n\nfunction findLongest(entries) {\n  return entries.reduce(function (longest, entry) {\n    return entry.length > longest.length ? entry : longest;\n  }, \'\');\n}\n\n\n\n\nWe set the initial value for longest as an empty string. The callback function for reduce ensures that longest will be kept updated because we always choose, via the convenient ternary operator, the longest string for its return value.\n\nNow imagine that the problem is expanded, not only we need to obtain the longest string but we also need to get the index of that longest string in the array. While it sounds more complex, the solution is still as compact as before:\n\nfunction findLongest(entries) {\n  return entries.reduce(function (longest, entry, index) {\n    return entry.length > longest.value.length ?\n      { index: index, value: entry } : longest;\n  }, { index: -1, value: \'\' });\n}\n\n\nThe callback function takes advantage of the third parameter, i.e. the index of the current element. The rest is pretty much the same, except now we need to store a richer object contained both the index and the string, as opposed to just a simple string.\n\nAt this point, the problem is made even more challenging: sort the array based on the length of the string. Fortunately, this is again not as crazy as you might think. In fact, we are halfway there since we already have the ability to find the longest string in an array. This is a perfect chance to implement something like insertion sort. For every run, find the longest string, pluck it from our array, and then the push it to the result.\n\nWe can realize quickly that the loop needs to run as many as the available array elements. If you read my previous blog post on Sequence with JavaScript Array, it is obvious that we can simply use Array.apply and map for the iteration. The code will look like the following fragment. See if you can figure out the reason behind the use of splice and pop there.\n\nentries = Array.apply(, Array(entries.length)).map(function () {\n  return entries.splice(findLongest(entries).index, 1).pop();\n});\n\n\nPushing a bit to the extreme, what if the solution can only use reduce? In this case, we need to revive the trick already employed in that Fibonacci series adventure. The use of reduce is reduced (pun intended) to an accumulating iteration, we simply start with an empty array as the initial value and fill this array as we go. Inlining the longest-string-search and shortening a few variables for some additional air of mystery, the complete incantation will be as fascinating as the code below:\n\nentries = Array.apply(, Array(entries.length)).reduce(function (r) {\n  return r.concat(entries.splice(\n    entries.reduce(function (longest, e, i) {\n      return e.length >= longest.e.length ?  { i: i, e: e } : longest;\n    }, { e: \'\' }).i, 1\n  ));\n}, []);\n\n\nInsertion sort is rather impractical in real-world scenarios and the above cascaded construct is not always readable. However, hopefully this can still show that Array.prototype.reduce can be quite charming at times!\n\n(`_|_`)Oct 7, 2013(`_|_`)ariya.io(`_|_`)searching-using-array-prototype-reduce', 'searching-using-array-prototype-reduce'),
(85, 'Code Coverage of Jasmine Tests using Istanbul and Karma(`_|_`)\nFor modern web application development, having dozens of unit tests is not enough anymore. The actual code coverage of those tests would reveal if the application is thoroughly stressed or not. For tests written using the famous Jasmine test library, an easy way to have the coverage report is via Istanbul and Karma.\n\nFor this example, let’s assume that we have a simple library sqrt.js which contains an alternative implementation of Math.sqrt. Note also how it will throw an exception instead of returning NaN for an invalid input.\n\nvar My = {\n  sqrt: function(x) {\n    if (x < ) throw new Error(\"sqrt can\'t work on negative number\");\n      return Math.exp(Math.log(x)/2);\n  }\n};\n\n\nUsing Jasmine placed under test/lib/jasmine-1.3.1, we can craft a test runner that includes the following spec:\n\ndescribe(\"sqrt\", function() {\n  it(\"should compute the square root of 4 as 2\", function() {\n    expect(My.sqrt(4)).toEqual(2);\n  });\n});\n\n\nOpening the spec runner in a web browser will give the expected outcome:\n\n\n\nSo far so good. Now let’s see how the code coverage of our test setup can be measured.\n\nThe first order of business is to install Karma. If you are not familiar with Karma, it is basically a test runner which can launch and connect to a specific set of web browsers, run your tests, and then gather the report. Using Node.js, what we need to do is:\n\nnpm install karma karma-coverage\n\n\nBefore launching Karma, we need to specify its configuration. It could be as simple as the following my.conf.js (most entries are self-explained). Note that the tests are executed using PhantomJS for simplicity, it is however quite trivial to add other web browsers such as Chrome and Firefox.\n\nmodule.exports = function(config) {\n  config.set({\n    basePath: \'\',\n    frameworks: [\'jasmine\'],\n    files: [\n      \'*.js\',\n      \'test/spec/*.js\'\n    ],\n    browsers: [\'PhantomJS\'],\n    singleRun: true,\n    reporters: [\'progress\', \'coverage\'],\n    preprocessors: { \'*.js\': [\'coverage\'] }\n  });\n};\n\n\nRunning the tests, as well as performing code coverage at the same time, can be triggered via:\n\nnode_modules/.bin/karma start my.conf.js\n\n\nwhich will dump the output like:\n\nINFO [karma]: Karma v0.10.2 server started at http://localhost:9876/\nINFO [launcher]: Starting browser PhantomJS\nINFO [PhantomJS 1.9.2 (Linux)]: Connected on socket N9nDnhJ0Np92NTSPGx-X\nPhantomJS 1.9.2 (Linux): Executed 1 of 1 SUCCESS (0.029 secs / 0.003 secs)\n\n\nAs expected (from the previous manual invocation of the spec runner), the test passed just fine. However, the most particular interesting piece here is the code coverage report, it is stored (in the default location) under the subdirectory coverage. Open the report in your favorite browser and there you’ll find the coverage analysis report.\n\n\n\nBehind the scene, Karma is using Istanbul, a comprehensive JavaScript code coverage tool (read also my previous blog post on JavaScript Code Coverage with Istanbul). Istanbul parses the source file, in this example sqrt.js, using Esprima and then adds some extra instrumentation which will be used to gather the execution statistics. The above report that you see is one of the possible outputs, Istanbul can also generate LCOV report which is suitable for many continuous integration systems (Jenkins, TeamCity, etc). An extensive analysis of the coverage data should also prevent any future coverage regression, check out my other post Hard Thresholds on JavaScript Code Coverage.\n\nOne important thing about code coverage is branch coverage. If you pay attention carefully, our test above is still not exercising the situation where the input to My.sqrt is negative. There is a big “I” marking in the third-line of the code, this is Istanbul telling us that the if branch is not taken at all (for the else branch, it will be an “E” marker). Once this missing branch is noticed, improving the situation is as easy as adding one more test to the spec:\n\nit(\"should throw an exception if given a negative number\", function() {\n  expect(function(){ My.sqrt(-1); }).\n    toThrow(new Error(\"sqrt can\'t work on negative number\"));\n});\n\n\nOnce the test is executed again, the code coverage report looks way better and everyone is happy.\n\n\n\nIf you have some difficulties following the above step-by-step instructions, take a look at a Git repository I have prepared: github.com/ariya/coverage-jasmine-istanbul-karma. Feel free to play with it and customize it to suit your workflow!\n\n(`_|_`)Oct 3, 2013(`_|_`)ariya.io(`_|_`)code-coverage-of-jasmine-tests-using-istanbul-and-karma', 'code-coverage-of-jasmine-tests-using-istanbul-and-karma'),
(86, 'The Fabulous Edge New York 2013(`_|_`)\nAs part of my little tour this season, last Monday I was in Manhattan to participate at Edge Conference 2013, New York City edition. Organized by FT Labs and Google, Edge (always) featured a fascinating set of panels and high-quality discussions.\n\nThe videos of every panel (total duration: 7 hours) are already available:\n\n\nResponsive Images\nRendering Performance\nThird Party Scripts\nReal-Time Data\nOffline\nLegacy Clients\nPayments\n\n\nOn a side note, this also became my second visit to New York City, the first was for EmpireJS last year. Manhattan was still as charming as my first encounter. I really need to be careful, at this rate I would start to fall in love seriously with NYC.\n\nIf you missed this conference, watch the videos and keep an eye on its 2014 edition!\n\n(`_|_`)Sep 26, 2013(`_|_`)ariya.io(`_|_`)the-fabulous-edge-new-york-2013', 'the-fabulous-edge-new-york-2013'),
(87, 'Fast-Forward Git Merge(`_|_`)\nMerging a branch is a pretty common operation when using Git. In some circumstances, Git by default will try to merge a branch in a fast-forward mode. How is this different with a merge without fast-forwarding?\n\nLet us assume that I created a topic branch named speedup from the current master. After working on this branch for a while (three commits, those white circles), I finally decided that I am done and then I pushed it to my own remote. Meanwhile, nothing else happened in the master branch, it remained in the same state right before I branched off. The situation is depicted in the following diagram.\n\nOnce the project maintainer got notified that my branch is ready to be integrated, she might use the usual steps of git fetch followed by git merge and thus, my work is landed in the source tree. Because master has not been changed since the commit (gray circle) which serves as the base for the said topic branch, Git will perform the merge using fast-forward. The whole series of the commits will be linear. The history will look like the diagram below (left side).\n\n\n\nAnother variant of the merge is to use -no-ff option (it stands for no fast-forward). In this case, the history looks slightly different (right side), there is an additional commit (dotted circle) emphasizing the merge. This commit even has the right message informing us about the merged branch.\n\nThe default behavior of Git is to use fast-forwarding whenever possible. This can be changed, the no fast-forward mode can be easily set as the default merge using the right proper configuration.\n\nPerhaps the typical encounter of non fast-forward merge is via the use of the green Merge button on GitHub, as part of its pull request workflow. When someone creates a pull request, there is a choice to merge the change (whenever GitHub thinks it is possible to do it) just pressing this button on the project page.\n\n\n\nUnfortunately, at least as of now, GitHub’s web interface will perform the merge as if you would specify -no-ff. In other words, even if there is a possibility of fast-forwarding, GitHub will not do that. One possible explanation is so that the pull request could be identified. For example, the few recent commits of a project (I picked ESLint as an example, nothing particular about the project) can look like this:\n\n\n\nLooking at the graph, it is clear that those few patches can be merged using fast-forward mode. Alas, GitHub style of merge turned the commit history from a linear progression to something that resembling a railroad diagram.\n\nIn short, non fast-forward merge keeps the notion of explicit branches . It may complicate the commit history with its non-linear outcome at the price of preserving the source of the branches (pull requests, when using GitHub). On the other hand, fast-forward merge keeps the changesets in a linear history, making it easier to use other tools (log, blame, bisect). The source of each branch will not be obvious, although this is not a big deal if the project mandates the strict cross-reference between the commit message and its issue tracker.\n\nWhich one is your merging preference, with or without fast-forwarding?\n\n(`_|_`)Sep 20, 2013(`_|_`)ariya.io(`_|_`)fast-forward-git-merge', 'fast-forward-git-merge'),
(88, 'Scope Analysis for JavaScript Code(`_|_`)\nWalking the syntax tree of a JavaScript code is often the first step towards building a specialized static analyzer. In some cases however, when the analysis involves variables and functions within the code, an additional scope analysis is necessary. This permits a more thorough examination of those variables and functions, including to check if some identifiers accidentally leak to the global scope.\n\nOf course, such a simple leak detector is not new. In my previous blog post Polluting and Unused JavaScript Variables, I’ve covered two simple JavaScript utilities for catching this sloppy practice. In addition to that, I also reviewed the concept of identifier highlighting and rename refactoring in an editor. As a bonus of this highlighting feature, it is easy to spot the missing declaration which leads to the global leak (unless we’re in strict mode), as shown in the following screenshot of the online highlighting demo.\n\n\n\nIn the above code, widht is where the cursor is (hence, the yellow highlight). Due to the typo, it is not a match for the local variable declared as width. The problem is caught at run-time if the code is running in strict mode. However, obviously it is fantastic to get noticed of the mistake ahead of time. This is where a static analysis of the scope of every variable and function will be tremendously useful.\n\nFortunately, these days you can use a microlibrary called Escope (GitHub: Constellation/escope) which can analyze the scope of the entire code. This adds another useful library to the existing family of Esprima (for parsing), Estraverse (syntax traversal tool), and Escodegen (code regeneration). This arsenal of tools can be quite deadly.\n\nThe detailed operation and usage of Escope is beyond the scope (pun intended) of this blog post. Instead, let me just show you one built-in feature of the library, implicit declaration at the global scope. In other words, this is a collection of all variables which leak unintentionally, as in the previous highlighting example. It is as easy as this function:\n\nfunction find_leak(code) {\n  var leaks, syntax, globalScope;\n \n  leaks = [];\n  syntax = esprima.parse(code, { loc: true });\n  globalScope = escope.analyze(syntax).scopes[];\n  globalScope.implicit.variables.forEach(function (v) {\n      var id = v.identifiers[];\n      leaks.push({\n          name: id.name,\n          line: id.loc.start.line\n      });\n  });\n \n  return leaks;\n}\n\n\nFirst we need to parse the code and store its abstract syntax tree in syntax. Note that location tracking is enabled because we want to locate the line number of every leaking variable. After that, scope analysis is being invoked and we grab the first one, its global scope. Now it is a matter of iterating variables within its implicit declaration and collecting the necessary information, i.e. the name and the location. This is the return value of the function and you can easily process it.\n\nReal-world analysis will involve more processing than just a simple global leak collection (you can even visualize the scopes). Hopefully, this simple example will spark your interest in leveraging the scope information of any piece of JavaScript code.\n\n(`_|_`)Sep 17, 2013(`_|_`)ariya.io(`_|_`)scope-analysis-for-javascript-code', 'scope-analysis-for-javascript-code'),
(89, 'Autumn 2013 Conferences(`_|_`)\n\n\nSummer is almost over, fall is around the corner. I’ll hit the road again, this time I plan to be in New York, Los Altos, and San Jose.\n\nIn just a few days (Sep 23), there is Edge NYC 2013 where I join the Rendering Performance panel. Edge is a quite popular high-quality web conference (in fact, this one is sold out already), the videos from the previous installments have been always my favorites. Thus, I am quite honored to be able to participate as the panelist. If you already registered, you can start lodging your questions for the panels.\n\nA big fan of community events? Silicon Valley Code Camp is a perfect fit for you. Since this code camp is hosted in the weekend (Oct 5-6), it is a perfect opportunity to learn something new even though you are still busy with work. Plus, the venue itself, Foothill College, is quite a nice place. This time, my session will be about The Future of JavaScript Language Tooling.\n\n\n\nUpdate: I will be also at the HTML5 Developer Conference (Oct 22-23) in San Francisco. This time, the topic will be about JavaScript Insights and I’ll be joined by a new partner-in-crime, Ann Robson.\n\nLast but not least, another favorite event of mine: YUIConf 2013 (Nov 6-7). This event is still being prepared and it is likely too early to finalize the materials. However, most likely I plan to speak on the topic of Next-Generation JavaScript Language Tooling and JavaScript API Design Principles.\n\nThe last summer conferences were simply marvelous and I still plan to continue the experience!\n\n(`_|_`)Sep 6, 2013(`_|_`)ariya.io(`_|_`)autumn-2013-conferences', 'autumn-2013-conferences'),
(90, '2013 Nexus 7 JavaScript Performance Quick Check(`_|_`)\n\n\nThe second generation Nexus 7, revealed a few weeks ago, is a good refresh of this popular Android tablet. Beside the much improved display density (going to 323 ppi from 216 ppi), this All-New Nexus 7 also has a different SoC. If this tablet is used mainly for browsing the web, how does it perform compared to its older sibling?\n\nLet us take a look at the hardware specification differences which may contribute to the performance. The memory has been bumped from 1 GB to 2 GB, this brings much more room to breath for the applications (notably the web browser). The SoC is still a quad-core system, Nexus 7 2012 is using 1.2 GHz Nvidia Tegra 3 while the 2013 edition is based on 1.51 GHz Qualcomm Snapdragon S4 Pro (APQ8064). The latter is a little confusing (probably just a branding issue) since it is more like an underclocked Snapdragon 600, with Krait 300 CPU.\n\nComparing these two SoCs, this battle can probably be viewed as a match between the implementations of ARM Cortex-A9 MPCore (Tegra 3) vs ARM Cortex-A15 MPCore (APQ8064). It would be interesting to see how APQ8064 competes with some new Tegra4-based tablets.\n\nNow it is time to see some colorful bar charts. Note that every test is carried out on the respective device running Jelly Bean (Android 4.3) and with Chrome 28.\n\nThe first test is DOM performance. A fast implementation of DOM modification and access will significantly impact many web pages which sprinkle some interactivity. Using the collection of DOM core tests from Dromaeo, here is the result (longer is better). The new Nexus 7 definitely shows approximately 20% improvement compared to the older generation.\n\n\n\nThere is a similar consistency if we check for pure JavaScript performance via the Octane benchmark (longer is better). The margin is not that big, most likely because the tests do not involve as much memory access as the previous DOM analysis.\n\n\n\nWith another benchmark from Mozilla, Kraken, the outcome looks pretty similar (shorter is better). Kraken itself aims to resemble more of future generation web apps. In this category, Snapdragon S4 Pro demonstrates a major win (more than 50%) over the poor Tegra3 system.\n\n\n\nWhile it is not covered here, there is also a GPU difference which can make an impact. The new Nexus 7 is equipped with Adreno 200. According to the various graphics benchmarks done by AnandTech, this easily kicks Tegra’s ULP GeForce to the curb. Faster, better GPU is always a good thing for web browsers, particularly for rendering-heavy web applications which can use a lot of GPU compositing benefits.\n\nFrom our previous quick check of the 2012 edition of Nexus 7, its web performance is more or less comparable to iPad 3. It is good to know that Google raises the bar again and pushes for a more performant, affordable Android tablets for all of us!\n\nVerdict: Using Nexus 7 mainly for web browsing and the cost is not a problem? Upgrade.\n\nNote: Special thanks to Donald Carr for a short loan of his Nexus 7.\n\nRelevant Reviews:\n\n\nThe Verge: Google Nexus 7 review (2013)\nArs Technica: Cheaper than most, better than all\nAnandTech: Nexus 7 (2013) – Mini Review\nEngadget: Nexus 7 review (2013)\nCNet: The best small tablet gets even better\n\n\n(`_|_`)Aug 21, 2013(`_|_`)ariya.io(`_|_`)2013-nexus-7-javascript-performance-quick-check', '2013-nexus-7-javascript-performance-quick-check');
INSERT INTO `ariyaio` (`id`, `content`, `url`) VALUES
(91, 'Searching with Array.prototype.some(`_|_`)\n Iterating over an array to search for an item is a pretty common task. With JavaScript, Array.prototype.forEach is often the popular choice. In some cases however, Array.prototype.some can be a better fit for the job if there is no need to search the entire array once a condition is fulfilled.\n\nThere are at least three different ways to iterate over arrays and objects in JavaScript: for loops, array methods, listing property keys. If the iteration is being carried out to perform a search operation, it may lead to the following example:\n\nfunction findEmployee(id) {\n  for (var i in employees)\n    if (employees[i].id === id)\n      return employees[i];\n}\n\n\nWithout any guards and error checks, the code above is rather self-explanatory. Now, since JavaScript Array has some powerful higher-order functions, one certainly can tweak the above code to look like this:\n\nfunction findEmployee(id) {\n    var employee;\n    employees.forEach(function (e) {\n        if (e.id === id) employee = e;\n    });\n    return employee;\n}\n\n\nLet us review what the specification says about Array.prototype.forEach (Section 15.4.4.18):\n\n\ncallbackfn should be a function that accepts three arguments. forEach calls callbackfn once for each element present in the array, in ascending order.\n\n\nIn our example problem, supposed that the employee’s id is unique (ideally of course this would be an associative container, see also the blog post Determining Objects in a Set, but that is a different story). The search via forEach is rather inefficient, it will continue even though there is already a hit. It is mandated by the above specification, invoking the callback once for each element present.\n\nAn improvement to the search would be to stop right away once the condition is fulfilled. Note that the condition needs not be only a single match. There are problems like searching the first 3 free spaces, locating enough suitable rooms, etc. Fortunately, there are Array methods which can do that: every and some. I have covered the use of every to implement a primality test (see the previous blog post on Prime Numbers, Factorial, and Fibonacci Series with JavaScript Array) so let us take a look at its sibling.\n\nSection 15.4.4.17 of ECMAScript 5.1 specification reveals that for Array.prototype.some:\n\n\ncallbackfn should be a function that accepts three arguments and returns a value that is coercible to the Boolean value true or false. some calls callbackfn once for each element present in the array, in ascending order, until it finds one where callbackfn returns true.\n\n\nThis is exactly what we need! Rewriting the previous code fragment gives the following version. The iteration will not continue if there is a match.\n\nfunction findEmployee(id) {\n    var employee;\n    employees.some(function (e) {\n        if (e.id === id) {\n            employee = e;\n            return true;\n        }\n    });\n    return employee;\n}\n\n\nDid you ever encounter a situation where some can be used instead of forEach? Tell us!\n\n(`_|_`)Aug 15, 2013(`_|_`)ariya.io(`_|_`)searching-with-array-prototype-some', 'searching-with-array-prototype-some'),
(92, 'JavaScript Kinetic Scrolling: Part 1(`_|_`)\nFlick list, with its momentum effect and elastic edge, becomes a common user-interface pattern since it was made popular by Apple iPhone a few years ago. Implementing this pattern using HTML and JavaScript seems to be a daunting task for many web developers. In this series, I will uncover the mystery of kinetic scrolling via several easy-to-digest code examples.\n\nBefore we go crazy and apply those fancy effects, it is important to set a solid foundation. Hence, the first part will deal only with an exemplary implementation of a basic drag-to-scroll technique (no momentum, no edge bouncing). The concept and also some parts of the code will be reused in the rest of the series. If you want to follow along and get the full code, check out the repository github.com/ariya/kinetic.\n\n\n\nHere is the game plan. Let us assume that the view (a DOM element) we want to scroll is quite large. Being viewed on the limited device screen, it is as if the screen acts as a viewport window. Scrolling the content is a matter of translating the view while keeping the viewport fixed. In order to translate the view correctly (using CSS3 transform), we need to capture the user interaction with the view. As the user taps and then drags up/down the view, we need to control the offset accordingly to give the illusion that the view follows his finger’s movement.\n\nFor this tutorial, the view contains the common Lorem ipsum text (generated via lipsum.com). Also notice that the scrolling is only in the vertical direction. To give an idea, try to load the demo ariya.github.io/kinetic/1 on your modern smartphone. It has been tested on Android 4.3 (Chrome, Firefox), Android 2.3 (Kindle Fire), and iOS 6 (Mobile Safari).\n\n\n\nSince we do not want the browser to handle and interpret user gesture natively, we need to hijack it. This is achieved by installing the right event listeners (for both mouse and touch events), as illustrated below. The handlers tap, drag, and release have the most important role in the implementation of this scrolling technique.\n\nview = document.getElementById(\'view\');\nif (typeof window.ontouchstart !== \'undefined\') {\n    view.addEventListener(\'touchstart\', tap);\n    view.addEventListener(\'touchmove\', drag);\n    view.addEventListener(\'touchend\', release);\n}\nview.addEventListener(\'mousedown\', tap);\nview.addEventListener(\'mousemove\', drag);\nview.addEventListener(\'mouseup\', release);\n\n\nInitializing some state variables is also an important step. In particular, we need to find the right bounds (max and min) for the view’s scrolling offset. Because our view will occupy the whole screen, innerHeight is used here. In a real-world application, you might want to use the computed (style) height of the view’s parent element instead. As you will see shortly, pressed state is necessary to know when the user drags the list.\n\nmax = parseInt(getComputedStyle(view).height, 10) - innerHeight;\noffset = min = ;\npressed = false;\n\n\nIf you try the demo, you will notice a subtle scroll indicator. Intentionally, this is placed on the left side of the view. This way, you will notice immediately that this is not the browser’s native scrollbar. That indicator needs to be placed anywhere between the topmost and bottommost of the screen, hence the need for a relative factor (will be used later). Bonus point: where does that hardcoded value 30 comes from?\n\nindicator = document.getElementById(\'indicator\');\nrelative = (innerHeight - 30) / max;\n\n\nSince we want to adjust the view’s position using CSS3 transform, we need to figure out the right style property to use. A comprehensive detection can be employed, but the following simple approach already works quite reliably.\n\nxform = \'transform\';\n[\'webkit\', \'Moz\', \'O\', \'ms\'].every(function (prefix) {\n    var e = prefix + \'Transform\';\n    if (typeof view.style[e] !== \'undefined\') {\n        xform = e;\n        return false;\n    }\n    return true;\n});\n\n\nBefore we see the actual event handlers, let us take a look at two important helper functions.\n\nSince both mouse and touch events need to be supported, the following ypos function abstracts the retrieval of the vertical position associated with the event.\n\nfunction ypos(e) {\n    // touch event\n    if (e.targetTouches && (e.targetTouches.length >= 1)) {\n        return e.targetTouches[].clientY;\n    }\n \n    // mouse event\n    return e.clientY;\n}\n\n\nAnother important function is scroll, it moves the view and the scroll indicator to the right place. Note that we need to clamp the scroll offset so that it does not go outside the computed bounds.\n\nfunction scroll(y) {\n    offset = (y > max) ? max : (y < min) ? min : y;\n    view.style[xform] = \'translateY(\' + (-offset) + \'px)\';\n    indicator.style[xform] = \'translateY(\' + (offset * relative) + \'px)\';\n}\n\n\nAll good things come in three. The functions tap, release, and drag are essential to the core logic of the scrolling. Surprisingly, they are all simple and concise!\n\nThe first one, tap, is triggered when the user touches the list for the first. This is where we need to mark it as pressed.\n\nfunction tap(e) {\n    pressed = true;\n    reference = ypos(e);\n    e.preventDefault();\n    e.stopPropagation();\n    return false;\n}\n\n\nLater on, when the user releases his grip, we need to undo the marking via release.\n\nfunction release(e) {\n    pressed = false;\n    e.preventDefault();\n    e.stopPropagation();\n    return false;\n}\n\n\nEvery time the user moves his finger, we know exactly how many pixels it has moved (since we always track the last point). This way, the view’s offset also receives the same amount of relative scrolling movement. A simple threshold of 2 pixels is used to prevent jittering due to some micromovements.\n\nfunction drag(e) {\n    var y, delta;\n    if (pressed) {\n        y = ypos(e);\n        delta = reference - y;\n        if (delta > 2 || delta < -2) {\n            reference = y;\n            scroll(offset + delta);\n        }\n    }\n    e.preventDefault();\n    e.stopPropagation();\n    return false;\n}\n\n\nAnd that’s all the scrolling code! Overall, it weighs just around 80 lines.\n\nFeel brave and want an exercise? Tweak the scroll indicator so that it fades in and fades out at the right time (synchronized with the pressed state). Its opacity can be animated with CSS3 transition.\n\nAlso, keep in mind that the code presented here serves mostly as an inspiration. It is optimized for readability and not for performance (extreme JavaScript optimizations, GPU compositing, etc). Your real-world implementation needs to be more structured, robust, and well-tested.\n\n\n\nHow about the performance? Well, at this stage, there is hardly anything computationally expensive. The scrolling speed can be checked either using Chrome’s frame rate HUD or painting time. More detailed timeline is also available via Chrome Developer Tools. The above capture shows the frame statistics on a Nexus 4 running Chrome 28. We are well within the limit of 60 fps!\n\nIn the next installment, watch how the momentum effect gets implemented. Stay tuned.\nUpdate: I already published the second part, covering the physics behind the inertial deceleration.\n\n(`_|_`)Aug 6, 2013(`_|_`)ariya.io(`_|_`)javascript-kinetic-scrolling-part-1', 'javascript-kinetic-scrolling-part-1'),
(93, 'Continuous Painting Mode in Chrome(`_|_`)\nGetting a consistent 60 fps experience on mobile web means that we need to monitor the performance criteria. One important metric is the painting time, particularly important on a resource-constraint device. Fortunately, with Chrome’s continuous painting mode, it is easy to check whether the performance budget is fulfilled or not.\n\nTo set this up on an Android phone, remote debugging must be enabled (follow the detailed steps). On the desktop side, install ADB Plugin from Chrome Web Store. If everything works well, remote debugging is just one click away. Once the session starts, look for Settings icon (right bottom corner) which will open the Settings pane. From this pane, Enable continuous page repainting is easy to locate.\n\n\n\n\n\nOnce it is activated, there will be a simple, greenish head-up display (HUD) which displays the painting time rate chart (as a function of time), as well as the GPU memory consumption. The chart has a threshold line, this is the 16.7 ms painting time corresponding with the target frame rate of 60 fps.\n\nThe following screenshot demonstrates the HUD for a simple web page, ariya.github.io/css/glowingtext/. This page was designed to simulate an animated glowing text by varying the blur radius of the text shadow.\n\nFor this example, we can see how the painting time gets modulated. This is because the glow effect increases and decreases the blur radius, and hence it varies the amount of pixels processed for every frame. That explains why the painting time chart has those periodic peaks and valleys.\n\nOverall, this HUD is quite similar to the FPS counter (see my previous blog post Frame Rate HUD on Chrome for Android). However, since what is being displayed here is the painting time, it is more convenient to spot the spikes indicating “too slow” painting.\n\n\n\nArguably, while you are there, you might as well use the full performance analysis via the Timeline feature (shown above). In particular, some detailed rendering and painting records can be easily obtained, refer to Chrome Developer Tools documentation for more info.\n\nTo the glory of 60 fps!\n\n(`_|_`)Aug 5, 2013(`_|_`)ariya.io(`_|_`)continuous-painting-mode-in-chrome', 'continuous-painting-mode-in-chrome'),
(94, 'Encouraging Shorter Tech Talk(`_|_`)\n\n\nAttending technical events, from the local after-hours meetups to the high-caliber and well-known conferences, becomes the usual part of a developer’s life. Generally, those events are packed with 45-minute talks, often also to the full one hour. I argue that there are more benefits of limiting such tech talks to a shorter duration, say 20 minutes (or even 18 minutes, in the style of TED talks). The most important is that it will lead to a more thoughtful, lean, and balanced content.\n\nFirst of all, the presenter needs to cut to the chase. Long-winded introduction is out of the question. In the last few years, we have seen some tremendous improvement in the way the self-introduction was conducted. There is no more wasted minutes of credentials flashing (meticulous list of projects, certificates, affiliates), irrelevant funny story about someone’s Twitter handle, or any other conversational icebreakers longer than necessary. But of course it is even better if there is simply no room for those. After all, the audience can use their favorite search engine to look for more information about the speaker.\n\nAs a corollary, the speaker also needs to filter the content and condense it. During the preparation, careful thought needs to be exercised to pick the most relevant topics only, given the time constraint. It will be less of “How do I fill this 40 minutes” and more of “What will be the three important take aways for the audience”. Remember that the speech is for the benefit of the audience, it is not a vehicle to show off various domain expertise of the presenter.\n\nA shorter allocated time naturally promotes to a more balanced composition. If the presentation is in the format of problem-solving (typical for a lot of tech talks), the speaker will not ramble too much on the initial sales pitch. How many times have you witnessed talks about web performance in which the first 15 minutes were spent only on explaining the benefit of performant web sites? Let’s get straight down to business, no need to convince us that we are in the right room.\n\nLast but not least, packing different talks into an hour means more diversity and variety for the attendees. One hour is not enough anyway to make someone become really competent in a particular field. That time is better spent on giving the audience some use-cases, inspirations and pointers for further self-exploration. Even one convincing story will be more memorable than a long checklist of tips and tricks. Now, imagine getting three inspirational and memorable stories in one hour!\n\nWhat if the topic can not be packed into a 20-minute session? Well, there is always a choice of splitting them into two parts, conveniently mapped (among others) into beginner vs intermediate level. Those who are not novice anymore but still want to enrich their knowledge can choose to only participate in the second part. Other curious minds who just want to get the taste of the field could focus on the first part, possibly even skipping the sequel. It is a better value for everyone.\n\nThere will be always the need for longer talks. However, those in-depth coverage are better handled in the form of workshops. Many conferences have this extra one-day, usually before the usual technical sessions start, dedicated for those long, lecture-style of tutorials.\n\nThese days, conference organizers often offers some extras to the standard technical sessions, usually in the form of lighting talks, unconference, Ignite, and other similar variants. In some cases, like JSConf, many talks finished in 30 minutes of less. At the last O’Reilly Fluent, we have seen two 20-minute talks packed into one usual slot. In the near future, hopefully more and more organizers will consider and give priorities to those short, high-quality talks.\n\nRemember Pericles, Time is the wisest counselor of all.\n\n(`_|_`)Jul 30, 2013(`_|_`)ariya.io(`_|_`)encouraging-shorter-tech-talk', 'encouraging-shorter-tech-talk'),
(95, 'Profile-Guided JavaScript Optimization(`_|_`)\nProfile-guided optimization (PGO) is a known compiler technique to produce an optimized code. The generated code is biased towards the common data set which will be fed to the code. It is definitely possible to apply the same technique to web applications written in JavaScript.\n\nVarious compilers, from Microsoft Visual C++ to Intel Fortran, leverage the profile data to make judgements on how to hit the right compromise. For example, small functions which get executed quite often should be in the close proximity so that the locality helps the CPU cache. The execution statistics can also help deciding which functions should be inlined, which branches should be pushed to top, and many other different trade-offs.\n\nA key to a successful profile-guided optimization is a set of representative data. It could be a sample which is obtained during the test run. However, we need to ensure that the data really resembles, to a certain extent, the actual real-world distribution. For example, a JSON parser should be tested with a set of valid (albeit synthetic) stringified objects, and not just a stream of random characters.\n\nLet us take a look at the following example. Supported the JSON parser mentioned above (or any other kind of parsing function) needs to check whether a character represents a decimal digit (0-9) or not. A possible implementation, among a billion possible variants, is as simple as:\n\nfunction isDigit(ch) {\n  return \'0123456789\'.indexOf(ch) >= ;\n}\n\n\n\n\nThe next question is, how the input data distribution look like? For this discussion, let us assume that apparently the characters fed into this function are mostly whitespaces, letters, and the real digits as depicted in the pie chart.\n\nIf 65% of the time, isDigit will receive a space, should we tackle that first? We may save some time since there is no need to check for those 10 different possibilities of the digits if it turns out to be a simple whitespace. With this in mind, we can tweak the implementation to become:\n\nfunction isDigit(ch) {\n  return (ch !== \' \') && \'0123456789\'.indexOf(ch) >= ;\n}\n\n\nThanks to the short-circuit behavior of logical AND expression (see Section 11.11 Binary Logical Operators), everytime ch is a space, the function will bail out immediately. This form the special fast path for the code. If this condition is not fulfilled, we fall back again to the slow path.\n\nGeneralizing this approach, a pair of slow vs fast path is illustrated as follows:\n\n\n\nGiven the right profile data, it should not be too difficult to estimate the performance benefit. For the given example isDigit, it likely does not matter much since the function is so simple and it gets executed in a split second. When measuring the time, make sure you pay attention to both its accuracy and precision.\n\nIn a general situation where you can avoid the slow path under certain circumstances, the extra performance should be noticeable. For example, if the generic slow path takes 2 ms to process the data and you have 100 items in the data set, the total processing will be 200 ms. Now, assume that the fast path is twice as fast, i.e. 1 ms. According to the given distribution, the fast path is executed only on 65 items of that data set. Also, because the slow path is now in the fall back and not executed immediately, there will be an extra 20% overhead. This means, the total processing will become 142 ms (65 * 1 ms + 35 * 2.2 ms). That is roughly 40% speed-up.\n\nLast but not least, there are two things you need to consider before doing a profile-guided optimization. First, make sure that this is where the bottleneck is. Nothing is more disastrous than a premature optimization as it is not worth any engineer’s time to speed up something which does not matter much. Second, pay attention to the data set for the test runs as it must resemble the real-world data which will be faced by your application. Having a wrong profile will cause an incorrect optimization and may lead to a performance penalty. Also, keep in mind that the data set may evolve. After all, optimization is a journey and not a destination.\n\nLike they used to say: profile responsibly.\n\n(`_|_`)Jul 26, 2013(`_|_`)ariya.io(`_|_`)profile-guided-javascript-optimization', 'profile-guided-javascript-optimization'),
(96, 'Prime Numbers, Factorial, and Fibonacci Series with JavaScript Array(`_|_`)\n\n\n\n\nInstead of using loops, JavaScript Array object is quite powerful to create sequences. What about some more complex series and not just a list of consecutive numbers or letters? Fortunately, we still have other Array’s functions such filter, map, every, and reduce at our disposal. Those can be used to generate a list of prime numbers, compute the factorial, and produce the Fibonacci series.\n\nPrime Numbers\n\nPrime numbers are fascinating, in particular because the concept is so simple and yet there are multiple ways dealing with them so that the tasks are often employed in problem-solving interviews. Every JavaScript programmer worth her salt should be able to come up with a simple way to check whether a given integer i is a prime number or not. One possible loop-based solution, for i >= 2, is given as follows:\n\nfunction isPrime(i) {\n  for (var c = 2; c < = Math.sqrt(i); ++c)\n    if (i % c === ) return false;\n  return true;\n}\n\n\nThe above primality test implementation is probably not the most optimal one, it is enough to illustrate the concept.\n\nFrom this function, the next task is to print all prime numbers between 0 and N:\n\nfunction primeList(N) {\n  var list = [];\n   for (var i = 2; i != N; ++i)\n     if (isPrime(i)) list.push(i);\n  return list;\n}\n\n\nWe already learned that some loop-based iterations can be turned into Array one-liners. Can we apply the same technique to the above problem?\n\nLet us tackle isPrime() first. The suitable solution here is to use Array.prototype.every. In Section 15.4.4.16, the ECMAScript 5.1 specification says:\n\n\nevery calls callbackfn once for each element present in the array, in ascending order, until it finds one where callbackfn returns false. If such an element is found, every immediately returns false. Otherwise, if callbackfn returned true for all elements, every will return true.\n\n\nIn other words, we can use every to check for every potential divisor and see if one of them is the divisor for the candidate. If yes, obviously the candidate is not a prime number and we just need to bail out immediately. If there is a suitable divisor after the exhaustive search, it means we find our prime number.\n\nSurprisingly, the code is shorter that the above explanation. Also, ~~ trick is being used instead of Math.floor, for some additional mystery.\n\nfunction isPrime(i) {\n  return (i > 1) && Array.apply(, Array(1 + ~~Math.sqrt(i))).\n    every(function (x, y) { return (y < 2) || (i % y !== ) });\n}\n\n\nThe other function, primeList(), is rather easy to refactor. Recall again the approach of using the combination of Array constructor, apply, and map, we end up with the following final solution. Note that the primality test is now inlined via the use of Array.prototype.filter.\n\nfunction primeList(N) {\n  return Array.apply(, Array(N)).map(function (x, y) { return y }).\n    filter(function (i) {\n      return (i > 1) && Array.apply(, Array(1 + ~~Math.sqrt(i))).\n        every(function (x, y) { return (y < 2) || (i % y !== ) });\n    });\n}\n\n\nThe (deadly) combination of map, filter, and every is apparently enough to avoid the loops!\n\nIf you care about the upcoming ECMAScript 6, the use of arrow function and array comprehension permits the above construct to be written as:\n\nfunction primeList(N) {\n  return [for (i of Array.apply(, Array(N)).map((x, y) => y))\n    if ((i > 1) && Array.apply(, Array(1 + ~~Math.sqrt(i))).\n      every((x, y) => (y < 2) || (i % y !== ) ))\n    i];\n}\n\n\nFactorial\n\nComputing factorial is another math-related intriguing activity. In fact, due to its nature, this becomes the usual exercise for recursive programming introduction. For now, let us rather focus on the non-recursive implementation, something along the line of:\n\nfunction factorial(n) {\n  var f = 1;\n  for (var c = 1; c < = n; ++c) f *= c;\n  return f;\n}\n\n\nHere, if we want to avoid the imperative style of using a loop, the strategy will be different. Because computing the factorial of n depends on all the previous values, we can not simply use map or even every like in the previous example. For this, we need the help of Array.prototype.reduce. The specification, in Section 15.4.4.21, has something to say about this higher-order function :\n\n\ncallbackfn is called with four arguments: the previousValue (or value from the previous call to callbackfn), the currentValue (value of the current element), the currentIndex, and the object being traversed.\n\n\nIt is likely easier to understand reduce from the following simple illustration:\n\n[1, 2, 3, 4, 5].reduce(function (x, y) { return x + y });       //  15\n[1, 2, 3, 4, 5].reduce(function (x, y) { return x + y }, 100);  // 115\n\n\nBecause of x + y, the above code essentially produces the sum of every number in the array. Here x corresponds to the previous value and y is the current value (which will go from 1 to 5). In this context, imagine x acts like an accumulator. Note also that reduce can accept an optional second argument which will become the initial value. In the above example, 100, this will offset the computed total.\n\nWe can also do things like the following. Not only the array element (current value, y) is being used, the callback also uses the element index, passed as the third argument z.\n\n[14, 3, 77].reduce(function(x, y, z) { return x + y * z }, );   // 0*14 + 1*3 + 2*77\n\n\nIf you make it this far, you probably already come up with a solution to the factorial problem. Here is an exemplary implementation. Note the return value from the callback, it is not straightforward because the element index z starts from 0, not from 1.\n\nfunction factorial(n) {\n  return Array.apply(, Array(n)).reduce(function(x, y, z) { return x + x * z; }, 1);\n}\n\n\nAs usual, here is the ECMAScript 6 version with an arrow function:\n\nfunction factorial(n) {\n  return Array.apply(, Array(n)).reduce((x, y, z) => x + x * z, 1);\n}\n\n\nFinally, for a comparison see also this tweet from Angus Croll (@angustweets). For a different take, check out the version from Jed Schmidt (@jedschmidt) where the function itself is also reused as the callback for reduce.\n\nFibonacci Series\n\nThis short treatise is incomplete without Fibonacci series, often associated with the growth of rabbit population. The idea behind Fibonacci numbers is relatively simple and yet there can be dozens of puzzling programming tasks associated with it.\n\nIf one is asked to show the first n Fibonacci numbers, her implementation can look like:\n\nfunction fibo(n) {\n  var f = [];\n  for (var c = ; c < n; ++c) {\n    f.push((c < 2) ? c : f[c-1] + f[c-2]);\n  }\n  return f;\n}\n\n\nIf we want to switch the implementation to leverage JavaScript Array object, the situation with the two previous values becomes a real problem. Relying on reduce would be tricky since its callback only receives one previous value. Also, we can peek at the last two values from the callback’s last argument, the array being traversed, because that array is immutable (this is functional programming after all).\n\nFortunately, the programming world is full of magic tricks and secret passages. Among other possibilities, one trick where we can keep using reduce is to use an (empty) array as the initial value. In fact, this array will contain the final Fibonacci series. Since we continue to stash more numbers in that array, looking at the two previous numbers becomes very easy. In fact, the full code for that is not long-winded at all.\n\nfunction fibo(n) {\n  return Array.apply(, Array(n)).\n    reduce(function(x, y, z){ return x.concat((z < 2) ? z : x[z-1] + x[z-2]); }, []);\n}\n\n\nUpdate: The original version contains map but Jed Schmidt (@jedschmidt) kindly pointed out that it is not necessary because we just want to use the element index and we do not care about the element value itself.\n\nRewriting the above function to use ECMAScript 6‘s array comprehension and arrow function is left as an exercise for the reader.\n\nFinally, if you still cast doubt on the power of JavaScript Array object, think about it again. Among mortals second thoughts are the wisest.\n\n(`_|_`)Jul 24, 2013(`_|_`)ariya.io(`_|_`)prime-numbers-factorial-and-fibonacci-series-with-javascript-array', 'prime-numbers-factorial-and-fibonacci-series-with-javascript-array'),
(97, 'Sequences using JavaScript Array(`_|_`)\n\n\n\n\nGenerating a sequence is a common programming task. This is rather easy to achieve using a straightforward loop. With JavaScript however, there exists a more functional variant using the powerful Array object. This permits the generation of all kind of sequences, from A..Z to a list of prime numbers, without any loops at all.\n\nSupposed you are about to create a list of numbers 1, 2, 3 and place it in an array, one possible loop-based implementation is:\n\nvar result = [];\nfor (var i = 1; i != 4; ++i) result.push(i)\nconsole.log(result);  // [1, 2, 3]\n\n\nObviously, tweaking the code can yield a different kind of sequence. For example, a sequence of Latin alphabets is a matter of converting each number into the right letter:\n\nvar list = \'\';\nfor (var i = ; i != 26; ++i) list += String.fromCharCode(i + 65);\nconsole.log(list);   // \'ABCDEFGHIJKLMNOPQRSTUVWXYZ\'\n\n\nUsing loops is nice, but can we get the same result sans loops? Fortunately, JavaScript is quite capable of doing it. We just need to rely on its built-in object Array. In the following explanation, all the sections mentioned refer to the Standard ECMA-262, the official ECMAScript Language Specification edition 5.1.\n\nEarth\n\nFirst of all, we need to create an array which has the specified amount of elements. For that 1,2,3 example, we need a 3-element array. Fortunately, this is trivial:\n\nArray(3);\n\n\nNote that there is no need to use new for object construction, this is explained in Section 15.4.1:\n\n\nWhen Array is called as a function rather than as a constructor, it creates and initialises a new Array object.\n\n\nArray(3) creates an array with the length of 3, it is the same as [,,,]. The resulting array however has holes in it. In fact, although it has 3 elements, those elements do not exist. Holes like this are not so obvious if you try to peek at the array contents. Compare the two lines:\n\nArray(3).join(\'-\');                // \"--\"\n[null,undefined,null].join(\'-\');   // \"--\"\n\n\nWe can verify the existence of an array element just like checking for a property in a generic JavaScript object, using the in operator (Section 11.8.7):\n\nin Array(3);   // false\n1 in Array(3);   // false\n2 in Array(3);   // false\n2 in [,,9];      // true\n\n\nAs pointed by Axel Rauschmayer, holes inside an array are also detected with forEach.\n\nWater\n\nHow to fill those holes? A trick discovered by many seasoned JavaScript developers (see e.g. Brandon Benvie’s post on es-discuss) is to use Array.apply. Instead of some empty elements, now we have undefined to replace them:\n\nArray(3);                  // [,,,]\nArray.apply(, Array(3));  // [undefined, undefined, undefined]\n\n\nTo really understand this trick, recall how Function.prototype.apply works (Section 15.3.4.3), particularly in the Step 8, transforming an array into an argument list for the function, called spreading. No wonder this approach is quite often used to find the minimum or maximum value in an array. In the following fragment, the two lines are identical:\n\nMath.max(14, 3, 77);                 // 77\nMath.max.apply(Math, [14, 3, 77]);   // 77\n\n\nWhen apply receives an array with an empty element, it gets converted into undefined and thereby eliminates any holes in the array. If we combined it with Array construction, the end effect is constructing a new array with the spread.\n\nArray.apply(, [1,,3]);  // is the same as\nArray(1, undefined, 3);\n\n\nAir\n\nNow that we have an array with the right number of elements, how do fill it with the right sequence? Array.prototype.map to the rescue! Section 15.4.4.19 shows that:\n\n\nmap calls callbackfn once for each element in the array, in ascending order, and constructs a new Array from the results.\n\n\nFurther down, we also observe that:\n\n\ncallbackfn should be a function that accepts three arguments. callbackfn is called with three arguments: the value of the element, the index of the element, and the object being traversed.\n\n\nThe second argument, the index of the element, is the key to our solution:\n\nArray.apply(, Array(3)).map(function (x, y) { return y + 1; });  // [1, 2, 3]\n\n\nAnd if the sequence is about the squares of the first few integers:\n\nArray.apply(, Array(3)).map(function (x, y) { return (y + 1) * (y + 1); });\n\n\nFinally, for the English alphabets ‘ABCDEFGHIJKLMNOPQRSTUVWXYZ’:\n\nArray.apply(, Array(26)).map(function(x,y) {\n  return String.fromCharCode(y + 65);\n}).join(\'\');\n\n\nFor alternatives to using map, see also Brandon Benvie’s usage of Function.call with Number or Ben Alman’s solution with Object.keys.\n\nFire\n\nWith the new array comprehension feature of the forthcoming ECMASCript 6, the above one-liners can be slightly tweaked. For example, the alphabets sequence might be written as (note the use of arrow function):\n\n[for (i of Array.apply(, Array(26)).map((x, y) => y))\nString.fromCharCode(65 + i)].join(\'\');\n\n\nHere the conversion from each number to the corresponding letter is carried out outside the map callback. This makes the code easier to digest, it resembles a proper composition: generate the sequence first and do another step to transform the sequence. For details, check out my previous blog post (with tons of examples) on ECMAScript 6 and Array Comprehension.\n\nLoops are overrated, aren’t they?\n\nAddendum: As a follow-up, see also how you can use the same approach to generate a list of prime numbers, compute the factorial, and produce the Fibonacci series in the new blog post: Prime Numbers, Factorial, and Fibonacci Series with JavaScript Array.\n\n(`_|_`)Jul 20, 2013(`_|_`)ariya.io(`_|_`)sequences-using-javascript-array', 'sequences-using-javascript-array'),
(98, 'Detecting JavaScript Libraries and Versions(`_|_`)\nIn the spirit of making our web browsing activities more secure, often times we need to be aware of all the resources and assets being loaded by our important web sites (Internet banking, HR portal, and the likes). Fortunately, it is rather easy to programmatically inspect which JavaScript libraries are used by those sites.\n\nUsing PhantomJS, the headless browser based on WebKit, we just need a simple script which loads a web page and then check its content. PhantomJS has the ability of executing any JavaScript code within the web page context, this permits a simple check of the existence of a particular library. Here is a 30-line script which demonstrates this approach:\n\nvar page = require(\'webpage\').create(),\n    system = require(\'system\'),\n    address;\n \nif (system.args.length === 1) {\n    console.log(\'Usage: libdetect.js url\');\n    phantom.exit(1);\n}\n \npage.settings.loadImages = false;\naddress = system.args[1];\nconsole.log(\'Loading\', address, \'...\');\n \npage.open(address, function (status) {\n  if (status !== \'success\') {\n    console.log(\'ERROR: Unable to load\', address);\n    phantom.exit();\n  } else {\n    setTimeout(function () {\n      var jQueryVersion;\n      jQueryVersion = page.evaluate(function () {\n        return (typeof jQuery === \'function\') ? jQuery.fn.jquery : undefined;\n      });\n      if (jQueryVersion) {\n        console.log(\'jQuery\', jQueryVersion);\n      } else {\n        console.log(\'This site does not use jQuery.\');\n      }\n      phantom.exit();\n    }, 2000);\n  }\n});\n\n\nThe principle is quite straighforward: set up the right page object, load the requested URL, and then evaluate a piece of code which extract the jQuery version via jQuery.fn.jquery. For more details, PhantomJS documentation can be quite handy to understand what the script does at every step.\n\nIf you run the script on a site like CNN, the outcome will be:\n\nphantomjs libdetect.js http://www.cnn.com\nLoading http://www.cnn.com ...\njQuery 1.7.2\n\n\nFor sites which do not use jQuery, we got a prompt like:\n\nphantomjs libdetect.js http://news.bbc.co.uk\nLoading http://news.bbc.co.uk ...\nThis site does not use jQuery.\n\n\nTo keep it simple, the script only checks for the popular jQuery but it should be easy to extend it to detect all other well-known libraries and frameworks out there. Now imagine using the script to crawl thousands popular web sites out there, we can come up with a distribution chart of various JavaScript libraries and versions. Any volunteers?\n\n(`_|_`)Jul 17, 2013(`_|_`)ariya.io(`_|_`)detecting-js-libraries-versions', 'detecting-js-libraries-versions'),
(99, 'ECMAScript 6 and Proxy(`_|_`)\nBeing able to intercept a certain operation to an object can be really useful, in particular during a troubleshooting session. With ECMAScript 6, this is possible via its new feature, proxy. Creating a proxy on a particular object allows a predefined handler to get notified when something happens.\n\nIn the latest draft specification (Rev 15, May 14, 2013), section 15.18 on Proxy Objects is still empty. It is safe to assume that more information will be available later, when the specification starts to stabilize. Meanwhile, there is some useful information on the Direct Proxies wiki page. At the time of this writing, proxy support is already available on the latest stable version of Firefox and Chrome (experimental flag needs to be enabled).\n\nThe best way to illustrate a proxy is by a simple example (note: the code fragment is updated to use the new syntax, Proxy(target, handler), and not the deprecated Proxy.create):\n\nvar engineer = { name: \'Joe Sixpack\', salary: 50 };\n \nvar interceptor = {\n  set: function (receiver, property, value) {\n    console.log(property, \'is changed to\', value);\n    receiver[property] = value;\n  }\n};\n \nengineer = Proxy(engineer, interceptor);\n\n\nIn the above code, we create a simple object engineer. This object will be replaced by another one as the result of installing a proxy via Proxy(). The second parameter for this function is denoting a handler, interceptor in our case. A handler can have many different functions, for this simple example we have only one, set.\n\nLet’s see what happens if we executed the following code:\n\nengineer.salary = 60;\n\n\nThe handler will be called and its set function will be invoked. Thus, we will get:\n\nsalary is changed to 60\n\n\nEvery time a property of engineer is set, our interceptor will know about it. Obviously, there are various other operations which can be detected a proxy handler, such as property getter, keys(), iterator, and many others. Refer to the Direct Proxies wiki page for more details. Note: you might be also interested in tvcutsem/harmony-reflect which contains the polyfills so that you can use the new Proxy API on top of the deprecated one.\n\nBeside for debugging purposes, proxy can be helpful for libraries which implement data binding. Because a handler can be hooked to the data model, there is no need to use an alternative syntax (e.g. explicit set to change a value) or to continuously track the change (e.g. dirty state) to modify the model.\n\nHow would you plan to use proxy?\n\n(`_|_`)Jul 11, 2013(`_|_`)ariya.io(`_|_`)es6-and-proxy', 'es6-and-proxy'),
(100, 'Geolocation and Interactive Maps(`_|_`)\nGeolocation feature in a web browser is the key to improve the location-awareness of a web app. The following simple geolocation demo combines the information given by the browser with a textual geocoded address and a visual marker in a map.\n\n\n\nGetting the approximate address is not difficult to achieved using Google Maps Reverse Geocoding API. In fact, this was exactly how I have done it in my previous geolocation example. Now, displaying the location itself is also not a difficult matter, one can simple use the ubiquitous Google Maps or the alternatives such as OpenStreetMap.\n\nWith the recent release of Leaflet 0.6, I finally found some extra motivation to show how to use it in this context. For the tile data itself, I decided to give CloudMade a try (you need to sign up to get the API key and enjoy 500,000 free tiles every month). It took only a few minutes to implement this feature, combining Leaflet and CloudMade, especially if you follow Leaflet’s Getting Started guide. Some relevant code fragment:\n\nmap = L.map(\'map\').setView([coords.latitude, coords.longitude], 11);\nmap.zoomControl.setPosition(\'bottomright\');\nL.tileLayer(\'http://{s}.tile.cloudmade.com/apikey/997/256/{z}/{x}/{y}.png\', {\n  attribution: \'Map data © ...\', maxZoom: 18\n}).addTo(map);\ngeocoder.geocode({\'latLng\': pos}, function (results, status) {\n  var addr;\n  if (status == google.maps.GeocoderStatus.OK) {\n    addr = results[].formatted_address;\n    geocode.textContent = addr;\n    L.marker([coords.latitude, coords.longitude]).addTo(map).bindPopup(addr);\n});\n\n\nUsing Leaftlet, the map also works well on a variety of mobile platforms, everything from Android smartphones to Chromebook Pixel. And yes, it understands touch API for smooth panning and zooming. It feels good when pinch-to-zoom just works!\n\nTo give it a try, hit ariya.github.io/html/geolocation with your modern browser.\n\n(`_|_`)Jul 8, 2013(`_|_`)ariya.io(`_|_`)geolocation-and-interactive-maps', 'geolocation-and-interactive-maps'),
(101, 'The Awesome E4E 2013(`_|_`)\n\n\nLast week I had the honor of attending Engineers4Engineers, a small developer-oriented event organized by Constant Contact in Waltham (MA). This conference was attended by over 250 people, it was an amazing experience.\n\nDespite being the first in the series, the organizer did an awesome job (kudos to Anthony and friends who spent an enormous effort to ensure its success). The sessions were high-quality, featuring well-known speakers like Dharmesh Shah (HubSpot) for the opening keynote, as well as Mitchell Hashimoto (Vagrant), Charles Nutter (JRuby), and many others. The live streaming (of all 3 parallel tracks) went without a glitch, quite an achievement I would say.\n\nConstant Contact was a great host, I had some conversations with very very nice people. The food and make-your-own-trail-mix snack were satisfying, the social event held in downtown Waltham closed the event wonderfully.\n\nIf you live in the area, keep an eye (or two). You don’t want to miss next year’s E4E!\n\nAnd now, I’m getting ready for the final part of my summer tour.\n\n(`_|_`)Jul 3, 2013(`_|_`)ariya.io(`_|_`)the-awesome-e4e-2013', 'the-awesome-e4e-2013'),
(102, 'Optimizing CSS3 for GPU Compositing(`_|_`)\n\n\nModern web browsers can leverage the ubiquitous graphics processing unit (GPU), both in mobile and desktop, to accelerate page rendering. This is particularly suitable for popular CSS features such as animation, transition, opacity, transformation, and many others. Web developers however need to ensure that all the bits and pieces work well to achieve the ideal 60 frames per second.\n\nLet us take a look at the following Spinning Cube example, it combines 3-D transformation with keyframed animation. You can try the live demo, which will give something like the following (animated GIF, pardon the quality):\n\n\n\nThis example is a perfect case for the browser to perform GPU compositing. The browser will capture the DOM elements associated with every side of the cube and map them as textures residing on the GPU (you can think of a texture as a rectangular area containing the pixel values). Each side will get its own texture, thus in this demo we will have four textures. This process of capturing the pixels and sending them as textures only needs to be carried out once, i.e. at the very beginning right before any animation starts.\n\nWhat happens in each animation frame? There is no need for an expensive rendering, drawing those texts in a 3-D perspective. The browser will compute the necessary 3-D matrix to transform the existing textures so that each of them gets projected in the right way. The process repeats in a series of infinitesimal steps, hence the user gets the impression that the cube is rotating.\n\nIn the old days, when the possibility of GPU compositing did not exist, this entire animation will be quite costly. For every tick, the browser (via the underlying graphics stack) needs to continuously draw the text on each side with a different projection matrix, hardly a trivial task especially on platforms with limited speed and power.\n\nOne important key aspect of a successful GPU compositing is the optimal amount of texture upload. In our example above, the text never changes and hence the browser needs to do the capturing and texture mapping only once. How do we debug it? It is quite easy if you use Safari on OS X. First, run this command in a terminal:\n\ndefaults write com.apple.Safari IncludeInternalDebugMenu 1\n\n\nand then relaunch Safari. You’ll have an extra menu Debug. Pull that menu to go to Drawing/Compositing Flags menu item and then ensure that Show Compositing Borders is checked. Restart Safari. Now if you visit the spinning cube demo again, Safari (via WebKit) will display some extra information. You will get a colored border for every DOM element which gets its own layer and thus mapped as a GPU texture. However, the most important thing here is the number displayed in the corner. It indicates how many time the content of the layer has been updated. Each update is a possibly expensive operation since it involves the transport of pixels to the GPU.\n\n\n\nTo minimize the amount of texture uploads, you can only animate or transition the following properties: opacity, transform, and filter. Anything else may trigger a layer update. For example, check the example codepen.io/ariya/full/xuwgy that changes the background color of a box gradually between green and blue. You can add more and more boxes, at one point the whole animation feels really really sluggish. If this is running on a smartphone or a tablet, the browser will stop responding, in some cases eventually it will crash. Viewing this example from Safari:\n\n\n\nAs you can witness, the high numbers on the corner of every box are scary. The browser is busy recreating the content for that layer because the color has changed. For every step, this results in tons of pixels being pushed to the GPU. This exhausts both the memory bus to the GPU and the video memory of the GPU. It is a classic case of non-optimal GPU compositing and no amount of translate 3-D can solve this problem.\n\nWhile the choices of animated properties seem to be quite limited, this doesn’t mean the end of the world. In fact, if it is done carefully, the combination of opacity and transformation is sufficient to create some impressive effects. For some inspiration, check out demos like three.js Periodic Table, Photon CSS Lighting, FPS View, Montage MovieShow (shown below), and many others.\n\nTaking advantage of GPU acceleration is more than just blindly applying the “translate 3-D” incantation. Remember, a sport car does not give you a guarantee that you reach your destination faster than someone else, you are still at the mercy of the traffic situation. Making sure that the traffic between the CPU and the GPU is not congested is the key to help the browser hits the optimal balance.\n\n\n\nAddendum\n\nFor a more comprehensive take on this subject, refer to my previous talk Fluid User Interface with Hardware Acceleration (read the slide deck, watch the 28-min video on YouTube). There I also explained the workaround (read: hack) if you still insist on background color animation. Some other related articles you might want to read:\n\n\nNetflix: WebKit in Your Living Room\nGPU Accelerated Compositing in Chrome\nOn Translate3D and Layer Creation Hacks\nFirefox 4: hardware acceleration\nOff Main Thread Compositing (OMTC) and why it matters\nOptimizing Web Content in UIWebViews and Websites on iOS\n\n\n(`_|_`)Jun 26, 2013(`_|_`)ariya.io(`_|_`)optimizing-css3-for-gpu-compositing', 'optimizing-css3-for-gpu-compositing');
INSERT INTO `ariyaio` (`id`, `content`, `url`) VALUES
(103, 'Web Page Without External Resources(`_|_`)\nThese days, a typical web page is quite heavy. Even for a simple blogging site, there are many third-party scripts and resources involved, whether for Facebook Like button or Disqus-based commenting system. How do we know the impact of those extra bits?\n\nA quick tool I am currently playing with is rather simple. It utilizes PhantomJS, in particular its new request canceling feature (I have recently demonstrated the use of this feature to de-CSS-ify an entire page). Obviously, we also rely on its network monitoring ability to capture those requests and response. The latter is already quite popular, you can see how it is used as one possible backend for YSlow.\n\nJust like the previous example, the trick here is to add a simple filtering on the network request. For testing, I log all the network resources of my recent blog post using the included PhantomJS example, netsniff.js. The said post contains external scripts and styles for social media integration, Disqus, and also Speaker Deck (for the embedded slide deck). Those are blocked as I injected the following extra lines:\n\nself = \'http://ariya.ofilabs.com\';\n \npage.onResourceRequested = function (req, controller) {\n  if (req.url.indexOf(self) !== ) {\n    controller.abort();\n    return;\n  }\n  page.resources[req.id] = {\n    request: req,\n    startReply: null,\n    endReply: null\n  };\n};\n\n\nOnce I get the network traffic in HAR format, it can be visualized using the HAR viewer to get the waterfall diagram. Here I can see that by excluding those third-party resources, my site loads way faster (1.15 sec vs 7.5 sec). In addition to that, the thumbnail previews of the slides (from Speaker Deck) were gone, that trims the weight from 2.4 MB to 300 KB. This is of course to be expected, I do not have any plan to ditch Disqus, embedded slide deck, and other mash-up. However, it is good to keep a perspective on the speed and weight differences.\n\n\n\nWarning: This toy script lacks a thorough timing analysis, as well as other combinations of various scenarios (cold vs warm cache, 3G vs WiFi, responsive version, etc). For more serious web performance analysis, I recommend using other comprehensive tools out there (YSlow, FrontendTest, FluxUI, SiteSpeed.io, and many others).\n\nSince I am big fan of multiple layers of defense, some metrics obtained from the above script can be definitely used as the additional guards (possibly within a Git pre-commit hook). For example, if the total page weight excluding those third-party resources exceeds a certain threshold, then an alarm should be triggered. Also, PhantomJS permits programmatic page capture, another further enhancement is to render the web page with and without third-party resources for comparison (see also Depicted for perceptual diff). If the page looks completely awful with its own scripts and assets, the users might not be very happy if there is loading problem with external resources.\n\nWe should appreciate the extra rich interactivity enabled by these third-party goodies. Yet we also need to ensure that we keep our house clean!\n\n(`_|_`)Jun 25, 2013(`_|_`)ariya.io(`_|_`)web-page-without-external-resources', 'web-page-without-external-resources'),
(104, 'The Amazing Velocity 2013(`_|_`)\nLast week I was at Velocity 2013, a conference focusing on web performance and operations. The schedule was packed with high-quality sessions, the event was also attended by many luminaries and experts in the field. This was my third Velocity and it keeps getting better.\n\nOf course, another amazing aspect of such a conference is being able to talk to people, meet old acquaintances, make new friends, and have some fruitful discussions. Rest assured, I’m going to use some ideas from those discussions to shape the direction of my upcoming activities.\n\nI presented a topic on JavaScript language tooling (BTW, this was also the first time I used my Chromebook Pixel for running the slides and doing the live demo, it worked like a charm!). Regular readers of this blog have probably seen some of the tools explained in the talk, I have covered in the past in the following posts (for more articles on the similar topic, check the Highlights section):\n\n\nCode complexity analysis, visualization and monitoring\nCustom linting for e.g. stray logging and Boolean trap\nNon-destructive source transformation: quotes conversion, rename refactoring, block scope\nExecution tracing for run-time complexity analysis\nCode coverage analysis and guards\n\n\nYou can also check the slide deck (download as PDF, 6.1 MB).\n\nThere was live streaming of the keynote sessions, they are also available for offline viewing. If you want to enjoy the recorded video of every single talk, you need to buy the Complete Video Compilation.\n\nUpdate: You can also watch the recorded video on YouTube (39 minutes).\n\nVelocity initiated my summer tour (next stop: Waltham for Engineers4Engineers and Orlando for SenchaCon) with an amazing start. See you next year at Velocity 2014!\n\n(`_|_`)Jun 23, 2013(`_|_`)ariya.io(`_|_`)the-amazing-velocity-2013', 'the-amazing-velocity-2013'),
(105, 'JavaScript Source Transformation: Non-Destructive vs Regenerative(`_|_`)\nTransforming JavaScript source code is essential to build various JavaScript tools, from minifier to transpiler. There are two different techniques for doing the transformation: non-destructive change of the original source or full regeneration from the syntax tree. They serve different purposes and tend to complement each other.\n\nWith both strategies, the original source needs to be parsed first. This can be easily carried out using a parser. After that, what happens to the produced syntax tree depends on the chosen approach, as summarized by the following diagram.\n\n\n\nIn the case of non-destructive modification, we use the location information of the syntax nodes and/or tokens to find out what needs to be tweaked. An obvious example is when we want to change string literal quotes, from single quotes to double quotes (or the other way around). By locating every string literal, we know where the quotes are and thus we can just perform in-place replacement for the quotes (note that additional escaping might be necessary, since this is about strings).\n\nSimple syntax transpilation is also another typical use case. For example, if we want to use ECMASCript 6 block scope feature today, we need to transform the code (e.g. using defs.js) to run in an ECMAScript 5 environment. This is about converting let to var (taken into account the proper scoping of course).\n\nThe advantage of non-destructive transformation is that we do not lose many important parts of the original source which do not affect the syntax and execution. For example, converting double quotes to single quotes means that the existing indentation, comments, etc are not touched at all. The modification tool only changes stuff it is interested in, it should ignore everything else.\n\nIf we are building a tool which does not care about the original source, the obviously it is easier to just regenerate the source from the syntax tree. For example, a minifier reproduces a new source which is semantically equivalent to the syntax tree, but without the extra white spaces. In many cases, the minifier may also shorten variables names, remove unused code, and many other tweaks to the syntax nodes. This way, the code becomes shorter (in term of bytes) but it does not affect its execution. Such a minifier will not care about the original indentation and comments.\n\nFor the purpose of code coverage analysis, instrumentation is the first necessary step. A coverage tool like Istanbul will sprinkle its instrumentation code surrounding the syntax nodes, this way it can keep track of all statements and branches hit by the JavaScript interpreter. The instrumenter is another perfect use case of code regeneration. After it adds some more extra instrumentation syntax nodes, the newly generated code is the one which is going to be executed. At this stage, nobody cares about the formatting, indentation, and other cosmetic appearance.\n\nOf course, nothing stops us from composing two or more tools using these two different techniques!\n\n(`_|_`)Jun 18, 2013(`_|_`)ariya.io(`_|_`)javascript-source-transformation-non-destructive-vs-regenerative', 'javascript-source-transformation-non-destructive-vs-regenerative'),
(106, 'Cross-Reference: Commit Message and Issue Tracker(`_|_`)\nMaintainable software projects usually take the issue tracker seriously. More often, it is used not only to monitor bugs and defects, but also to serve as a task tracker. This practice permits the cross-reference between the commit message and the associated entry in the issue tracker, thereby allowing anyone to find the in-depth reasoning or discussion behind a particular commit.\n\nIf a project is hosted on GitHub, a cross-reference between the issue tracker and the commit log is handled automatically. As an example, the relevant commit log of PhantomJS revision 3edcabef is:\n\n\nFix compilation with MSVC 2010\n\nIssue #10158: https://github.com/ariya/phantomjs/issues/10158\n\n\nBecause of the reference Issue #10158, GitHub will link this commit with the said issue. If we go and take a look at issue #10158, the above commit will be mentioned, interleaved with other comments. Very handy!\n\n\n\nSince this cross-reference is quite useful, some projects mandate it as part of its contribution guide (house rules). Other extra advantages:\n\n\nCommit log is “frozen”, issue entry can always be updated\nIssues can be categorized/tagged/organized easily\n\n\nFor various reasons, many software projects are not hosted on GitHub. How do those projects, particularly the large ones, implement the cross-reference?\n\nFirst, let us take a look at Mozilla project. In its Mercurial repository, Mozilla contributors typically use a short, one-line commit message. As an example, have a look at revision d71234d65e90:\n\n\nBug 678037 – Add (disabled) ability to parse script bytecode lazily, r=luke\n\n\nThe message is broken down into 3 (three) parts: the bug id, the short description, and the reviewer name. Such a short description often does not tell anything, especially to those who are not familiar with the project. In order to find out more, we need to look at the linked issue, bug #678037. Here we can enjoy a lengthy and detailed discussion, reviews, and analysis on Mozilla implementation (for its JavaScript engine) of an optimization trick known as lazy parsing.\n\nAlso, we notice that there are some links back from the bug entry to the related revisions, pointing to the said check-ins. This is quite important as we can trace the changesets in the source repository which are part of the development of this bug. Often, changes need to be tweaked, staged, reverted, and rewritten. By keeping such a cross-reference, it is easy to follow the whole process.\n\nAnother large software project, WebKit, also has a similar contribution workflow, particularly with its tiered committer-reviewer level. WebKit commit message is however more verbose, it is more than just a very brief one-liner. If we pick revision 147858, it looks like:\n\n\nUnify the many and varied stack trace mechanisms, and make the result sane.\n\n​https://bugs.webkit.org/show_bug.cgi?id=114072\n\nReviewed by Filip Pizlo.\n\nSource/JavaScriptCore:\n\nMakes JSC::StackFrame record the bytecode offset and other necessary data\n\nrather than requiring us to perform eager evaluation of the line number, etc.\n\n\nNote the same pattern of bug link, reviewer, and the changeset explanation (both in the short form and the more verbose version). Again, if we visit bug #114072, there is a link pointing back to that particular revision.\n\n\n\nLast but not least, how does Chromium handle this? It is actually pretty similar (surprise), its contribution guide describes the details. Here is an example check-in, revision 191268:\n\n\nTextureLayer: clear texture id when clearing client.\n\nThis is to avoid having the impl side accessing a texture that’s been deleted.\n\nBUG=224308\n\nReview URL: https://chromiumcodereview.appspot.com/13126002\n\n\nThe commit message lists the bug id and the review URL. The latter, issue 13126002, is where the discussions and code reviews take place (the web interface works on an instance of Rietveld). The actual problem is still kept in the issue tracker, i.e. bug #224308 in this case. This forms an interesting connected triangle, whether you start from the bug entry, the code review, or the commit message, you can easily find the other two.\n\nIt seems tedious to open or reserve a bug every time you want to work on something. However, considering the benefits, it will be time well spent. Many projects usually give the contributors a set of helper scripts which can conveniently create the bug entry and also handle the rest of the workflow with the purpose of streamlining the entire process. As an example, Chromium uses depot_tools which (among others) permits the interaction with the code review tool just from the command-line.\n\nDo you also practice such a cross-reference in your project? Share your story!\n\n(`_|_`)Jun 13, 2013(`_|_`)ariya.io(`_|_`)cross-reference-commit-message-and-issue-tracker', 'cross-reference-commit-message-and-issue-tracker'),
(107, 'Capturing Web Page Without Stylesheets(`_|_`)\nIt is amazing to live in an environment where the Internet connection is ubiquitous and fast. But in case the tube is having a problem and the bits from the web server are broken into random pieces, how does the web site look like? If the content degrades gracefully, the lack of style sheets may reduce the attractiveness of the page but it should not significantly hamper the experience. Fortunately, there is a way to automatically check the appearance of a web page under that circumstance.\n\nSome time ago, I have demonstrated the use of PhantomJS, headless WebKit, to capture web pages programmatically. The example was also extended to capture just a particular portion of the page via clipping. For CSS-less capture, we just need to extend it with the new feature in PhantomJS 1.9 (as implemented by Vitaliy Slobodin): the ability to abort network requests.\n\nThere is a example loadurlwithoutcss.js which demonstrates this feature. In fact, combining this idea with the previous BBC News site capture, we can come up with the following screenshots. The left side shows the normal page (see my previous blog post on web clipping) while the right side demonstrates what happens when all the CSS files are not loaded at all.\n\n\n\nThe script which produces the above image is as follows:\n\nvar page = require(\'webpage\').create();\npage.settings.userAgent = \'WebKit/534.46 Mobile/9A405 Safari/7534.48.3\';\npage.settings.viewportSize = { width: 400, height: 600 };\n \npage.onResourceRequested = function(requestData, request) {\n    if ((/http:\\/\\/.+?\\.css$/gi).test(requestData[\'url\'])) {\n        console.log(\'Skipping\', requestData[\'url\']);\n        request.abort();\n    }   \n};\n \npage.open(\'http://m.bbc.co.uk/news/health\', function (status) {\n    if (status !== \'success\') {\n        console.log(\'Unable to load BBC!\');\n        phantom.exit();\n    } else {\n        window.setTimeout(function () {\n            page.clipRect = { left: , top: , width: 400, height: 600 };\n            page.render(\'bbc_unstyled.png\');\n            phantom.exit();\n        }, 1000);\n    }   \n});\n\n\nIt is pretty similar to its previous version. The new addition is a handler for onResourceRequested where we detect the URL for a style sheet and abort its loading. If the script is executed, it will display the message:\n\nSkipping http://static.bbci.co.uk/frameworks/barlesque/2.45.9/mobile/3.5/style/main.css\nSkipping http://static.bbci.co.uk/bbcdotcom/0.3.184/style/mobile/bbccom.css\nSkipping http://static.bbci.co.uk/news/1.7.1-259/stylesheets/core.css\nSkipping http://static.bbci.co.uk/news/1.7.1-259/stylesheets/compact.css\n\n\nwhich indicates that these 4 (four) style sheets won’t be part of the rendered output.\n\nThe entire process is rather straightforward. Because PhantomJS is cloud-ready, you can even have it running on an instance of Amazon EC2. It should not be too difficult to include this type of spartan rendering of your web site as another layer in the defensive development workflow.\n\nWhat do you plan to de-CSS-ify today?\n\n(`_|_`)Jun 10, 2013(`_|_`)ariya.io(`_|_`)capturing-web-page-without-stylesheets', 'capturing-web-page-without-stylesheets'),
(108, 'JavaScript Timing: Accuracy vs Precision(`_|_`)\nWhen analyzing the performance of a JavaScript-based application, stopwatch is often a convenient tool. Just like any other timing measurements in real life, it is important to ensure that this produces a valid and confident result. Thus, we need to avoid some factors which may reduce its accuracy and precision.\n\nImagine you are running on a track and you have five stopwatches giving wildly varying timing measurements of your performance. In this scenario, it is difficult to put a lot of confidence in the numbers. This is why many JavaScript-related benchmarks often come with a warning that the tested application should be the only one running. The goal is to minimize any random side activities which may cause some variations.\n\nIn the wikipedia page on Accuracy and precision, we find:\n\n\n..the accuracy of a measurement system is the degree of closeness of measurements of a quantity to that quantity’s actual (true) value.\n\n\nand also\n\n\nThe precision of a measurement system, also called reproducibility or repeatability, is the degree to which repeated measurements under unchanged conditions show the same results.\n\n\nIn addition, the target analogy is usually quite effective to demonstrate the concept. In the context of JavaScript world, you can also think of a dartboard (after all, no JavaScript discussion is complete until Dart is mentioned).\n\n\n\nIn order to get high-quality benchmark results, it is important to look at several factors: accuracy, errors, running time. This is why if you write tests for JSPerf, each measurement is displayed in ops/sec and relative margin of error. Should you directly use Benchmark.js (which powers JSPerf), this is also easy to retrieved using Benchmark.prototype.stats.rme. This is just one of the crucial considerations to ensure that your benchmark is bulletproof.\n\nEven if we finally obtain a result with a low margin of error, we still need to ensure that it is an accurate one. In a few cases, particularly with microbenchmarks, what is being measured may not reflect the reality. Modern JavaScript engine can perform various optimizations which falsify the measurement (among others) loop-invariant code motion, constant propagation, dead code elimination.\n\nAs a quick illustration, consider the following loop you want to time:\n\nfor (var i = ; i < 100; ++i) {\n  sum += Math.sqrt(2) * i;\n}\n\n\nIf a JavaScript engine (with loop-invariant code motion support) detects that this loop should be optimized, it may see that the Math.sqrt(2) can be computed once and placed outside the loop. In other words, the actual loop looks like as if you would have written it as the following fragment. This may or may not be what you want, hence it is important to carefully review such a loop.\n\nvar temp = Math.sqrt(2);\nfor (var i = ; i < 100; ++i) {\n  sum += temp * i;\n}\n\n\nDead code elimination is also known to offset timing analysis. Early published results of Internet Explorer 9 performance showed near-instant completion of some SunSpider tests, it turned out that this is attributed to its ability to eliminate dead code.\n\nNext time you throw some benchmark numbers, think carefully about its accuracy and precision!\n\n(`_|_`)Jun 7, 2013(`_|_`)ariya.io(`_|_`)javascript-timing-accuracy-vs-precision', 'javascript-timing-accuracy-vs-precision'),
(109, 'The Exciting Fluent 2013(`_|_`)\nToday is the final day of Fluent 2013, another conference focusing on JavaScript. There were tons of fascinating talks, everything from ECMAScript 6 to Web Components, organized in several parallel tracks. Overall, the event was very exciting.\n\nThe talks from the plenary sessions are already available on YouTube. For other sessions, you’ll need to purchase the All-Access Pass. Meanwhile, many slide decks have been posted to sites like SlideShare and Speaker Deck. Of course, attending the talks was not everything, I had some fun meeting and catching up with old friends as well making new acquaintances.\n\nI did a presentation on Improving JavaScript Code Quality to a crowded audience. If you follow this blog, what I have shown there is likely familiar to you. I did cover topics like syntax validation,\n\npolluting/unused variables, code coverage, complexity analysis and visualization, Boolean traps, ternary conditionals, scalability issue, programmatic rename refactoring, as well as various defensive strategies like coverage thresholds, complexity monitoring, Git precommit hook, and many others. If you missed it, you can enjoy the slide deck (PDF, 6.8 MB). Update: You can also watch the 42-minute video.\n\nFluent 2013 completed my spring conference activities. Now I need to get ready for the upcoming summer tour. See you next year at Fluent 2014!\n\n(`_|_`)May 30, 2013(`_|_`)ariya.io(`_|_`)the-exciting-fluent-2013', 'the-exciting-fluent-2013'),
(110, 'Chromebook Pixel for Web Development(`_|_`)\nThe latest high-end gadget from Google, Chromebook Pixel, is a fantastic laptop. With a high-density 239 pixels/inch display, Intel Core i5 processor, and 4 GB RAM, it won’t disappoint many users. On its software side, Pixel runs ChromeOS, a consumer-oriented stack for day-to-day computing usage. It turns out that tweaking the Pixel to make it suitable for doing real development is not a rocket science.\n\nDepending on how much effort you want to invest, there are different strategies which you can try. We start with the least intrusive one and close it with the most powerful, flexible solution.\n\nThe obvious plan is by using the built-in connectivity features of ChromeOS. For example, many web-based IDEs will run just fine under Chrome and thus you can use those services right away. System administrators can connect to a remote box (e.g. Amazon EC2 instances), either via the built-in crosh (Ctrl+Alt+T) or the installable Secure Shell. We can say that, borrowing the popular buzzword, Pixel is already convenient for doing cloud-based development.\n\nAnother alternative is to use the Pixel as a remote viewer for another machine. This is rather easy to prepare using Chrome Remote Desktop. Combined with file synchronization via Google Drive, this approach allows you to access and use existing Windows and OS X applications.\n\n\n\nOf course, real hackers would like to leverage the Pixel as a stand-alone system. After all, what’s the purpose of having a powerful and shiny laptop if we are at the mercy of another machine? In this case, the full freedom can be (re)claimed by installing a secondary Linux system. The easiest way to do that is by using Crouton (GitHub: github.com/dnschneid/crouton). It requires switching to the developer mode (be advised of the security implication), a small price to pay until a better solution emerges.\n\nThe foolproof setup is described in Crouton’s README. I followed the steps almost blindly and in no time I have Ubuntu (running under chroot) at my disposal. Note that this is not dual-boot, you essentially run ChromeOS and Ubuntu at the same time, side-by-side. Since it is a real, full-blown Ubuntu installation, you can do whatever you want with it: run a web server, install Ruby, use Python, compile C/C++ apps, play with V8, and many more. You also have the choice of using a desktop environment (e.g. Xfce, with resolution adjustments) or just staying with the command-line (illustrated in the next screenshot).\n\nWhile I always enjoy using my MacBook Air as the primary development machine, these days I tend to stick with the gorgeous Pixel. I guess, I am now officially Pixel-ed.\n\n\n\n(`_|_`)May 25, 2013(`_|_`)ariya.io(`_|_`)chromebook-pixel-for-web-development', 'chromebook-pixel-for-web-development'),
(111, 'ECMAScript 6 and Block Scope(`_|_`)\nUntil today, JavaScript comes with a function-level scope for variables and functions. This quirk often trips beginners who are already familiar with other curly braces language. With ECMAScript 6, the situation will change with the availability of the well-understood block scope.\n\nFunction-level scope leads to a situation called hoisting. For example, for this code:\n\nfunction f() {\n  doSomething();\n  var a = 1;\n}\n\n\nwhat really happens is something like:\n\nfunction f() {\n  var a;\n  doSomething();\n  a = 1;\n}\n\n\nOften, the knowledge about hoisting (or lexical environment in general) is used in a quiz or an interview question. In the following fragment, those who don’t possess the understanding will be left puzzled:\n\nconsole.log(\'foo\' in window); // true\nvar foo;\n\n\nFor programmers familiar with C/C++/Java, the use of var in a wrong place can trigger many pitfalls, among others variable leaking. Whether this is intentional or not is often not cleared from the code itself. Ambiguity like that may lead to a bug and other hard-to-trace annoyances:\n\nfor (var i = ; i < 3; i++) {\n  var j = i * i;\n  console.log(j);\n}\nconsole.log(j); //  4\n\n\nWith the upcoming ECMAScript 6, we can solve the issue by using Let and Const Declarations, see Section 12.2.1 of the latest specification draft. If we rewrite the above example to use let, it will look like the following:\n\nfor (var i = ; i < 3; i++) {\n  let j = i * i;\n  console.log(j);\n}\nconsole.log(j); // will throw\n\n\nthen running it will give an error instead:\n\n\nReferenceError: j is not defined\n\n\nThis is the typical programmer’s expectation, j is confined to that particular curly-braced block.\n\nIts partner-in-crime, const, behaves pretty much the same except it must be initialized and only once. This is perfect to store an immutable object. With both let and const, an optimistic static code analyzer can work much smarter to detect patterns which may cause problems and warn the user ahead of time.\n\nWhen can we can start using let and const? Fortunately, we can already use it today. Firefox already has implemented some supports for ECMAScript 6, including this block scope. With Chrome, you can enable V8 experimental features by toggling the switch via chrome://flags.\n\nNote: with V8, at least for the time being, you can use let with strict mode only, otherwise it will complain SyntaxError: Illegal let declaration outside extended mode.\n\nWhat about other browsers? Until they start supporting this block scope feature, you need to fall back to the solution of converting the code (also known as transpiling) into some construct which can be executed by today’s browsers. Using a generic transpiler such as Google Traceur is often the recommended way.\n\nAn alternative solution is by using defs.js from Olov Lassus. The idea is to transform block scoped declarations into normal variable statements, obviously taking into account the scope of each declaration. Given the code, defs.js will use Esprima to parse the code, walk the syntax tree, and apply the transformation whenever necessary. As an example, this code fragment:\n\nfunction f() {\n  let j = data.length;\n  console.log(j, \'items\');\n  for (let i = ; i < j; ++i) {\n    let j = data[i] * data[i];\n    console.log(j); // squares\n  }\n}\n\n\nwill be transformed into:\n\nfunction f() {\n  var j = data.length;\n  console.log(j, \'items\');\n  for (var i = ; i < j; ++i) {\n    var j$0 = data[i] * data[i];\n    console.log(j$0); // squares\n  }\n}\n\n\nLook how defs.js recognizes the right scope for j and therefore masquerade the innermost j with another name, j$0. The transformation itself is non-destructive, defs.js does not bother with anything other than let and const declaration. You can see how a comment is left untouched and the coding style is still exactly the same.\n\nObviously, there’s much more to defs.js than my simple example above, refer to Olov’s blog post for more details.\n\nHow do you plan to use let and const?\n\n(`_|_`)May 23, 2013(`_|_`)ariya.io(`_|_`)es6-and-block-scope', 'es6-and-block-scope'),
(112, 'Summer 2013 Conferences(`_|_`)\n\n\nJust like last year, summer means I’ll hit the road and do some evangelism work.\n\nFirst, I’m scheduled for O’Reilly VelocityConf 2013, June 20 in Santa Clara. This will be my third time speaking at Velocity and I’m quite thrilled about that. This time, my talk (Thursday, 1:15pm) is about Emerging Language Tools to Track JavaScript Quality and Performance.\n\nNext, Waltham, MA should be my next visit. Engineers4Engineers (June 28) will be pretty exciting, I pick the topic of Next-Generation JavaScript Language Tooling for my 45-minute talk. This conference is also top-notch, you’ll see a few amazing rockstars, including Charles Nutter (JRuby) and Mitchell Hashimoto (Vagrant). I’m a big fan of them and can’t wait to learn some magic tricks from their sessions.\n\nMid July, I’ll be doing several talks at SenchaCon 2013 in Orlando, FL (disclosure: Sencha is my employer). One of them is ECMAScript 6: JavaScript of the Future. If you are an avid follower of this blog, you probably can guess what this is all about just by reading my past posts on ECMAScript 6.\n\nIf you will be around in any of these places, let’s chat!\n\n(`_|_`)May 15, 2013(`_|_`)ariya.io(`_|_`)summer-2013-conferences', 'summer-2013-conferences'),
(113, 'Lumia 920 Web Performance Quick Check(`_|_`)\nLumia 920 is Nokia’s smartphone running Windows Phone 8 that is getting quite popular these days. When using this phone for browsing the web and running web applications, how does it stack up against its competitors?\n\nFirst of all, let’s check its browser user agent:\n\n\nMozilla/5.0 (compatible; MSIE 10.0; Windows Phone 8.0; Trident/6.0; IEMobile/10.0; ARM; Touch; NOKIA; Lumia 920)\n\n\nHardly a surprise, it is running the mobile version of Internet Explorer 10. This is good news since it is expected that many web pages out there will be supported just fine. With respect to the new HTML5 features however, it doesn’t seem that many of them are support yet since HTML5Test gives the score of 320, quite behind other competing mobile platforms.\n\nOne thing that I did quickly check is the browser’s ability to process lots of data by running a simple pixel crossfader using HTML5 canvas. This simple test exercises the CPU and its collaboration with the rest of the graphic stack. For this test and other subsequent ones, Lumia 920 will be compared against Nexus 4 running Chrome 26 on Android 4.2 and iPhone 5 with iOS 6’s Mobile Safari.\n\n\n\nFrom the outcome, it seems that iPhone 5 is still the king here. While both Lumia 920 and Nexus 4 are powered by Krait (dual-core and quad-core, respectively), there must be another factor in iPhone 5 which makes it extremely fast. Could be the high-performance A6 SoC, or maybe it’s just the tight software hardware integration.\n\nSpeaking about performance, what about running JavaScript-intensive applications? We turn to Octane benchmark to find the answer:\n\n\n\nAgain, the CPU differences certainly contributes to the varying score. It seems however that IE 10’s JavaScript engine (often known as Chakra) is still behind its competitor particularly for this ARM platform.\n\nLast but not least, DOM performance has been always my favorite (check the past performance checks with Nexus 4, Nexus 7, Kindle Fire). I do believe that high-performance DOM access has a profound (positive) impact on the browsing experience. Armed with the collection of DOM core tests from Dromaeo, here is what we got:\n\n\n\nUnfortunately, this combination of Lumia 920, Windows Phone 8, and IE 10 doesn’t really deliver the same cutting-edge DOM performance as its immediate market competitors. This might be related to the rather abysmal DOM speed of its desktop cousin, Internet Explorer 10.\n\nWhat to expect with IE 11 on the next Windows Phone? Better web performance!\n\n(`_|_`)May 12, 2013(`_|_`)ariya.io(`_|_`)lumia-920-web-performance-quick-check', 'lumia-920-web-performance-quick-check'),
(114, 'Continuous Monitoring of JavaScript Code Complexity(`_|_`)\nComplicated code is difficult to digest and hard to maintain. The best way to avoid it is by not having it at the first place. For web applications written in JavaScript, fortunately we have enough tooling machinery to detect complex code and block it from the source repository.\n\nAnalyzing code complexity is rather easy these days with the project like JSComplexity. Even better, the complexity metrics can be visualized in a good-looking and interactive report showing different metrics from McCabes cyclomatic complexity to Halstead complexity measures. Both these tools are easy to setup, they run quite well on the command-line (using Node.js).\n\nA preventive approach to force a complexity threshold on a new code is by using complexity comparison. With JSComplexity, this can be done via its --maxcc argument (there are other useful options as well, refer to its README for more details). If the package complexity-report is installed globally, this checking is easy as:\n\ncr --maxcc 15 index.js\n\n\nTo inject this in the multilayer defense workflow, simply include that check as part of e.g. Git precommit hook. If your project relies on Node.js for the test (i.e. via npm test), it is also useful to integrate this check. First of all, ensure that complexity-report package is within the devDependencies section of your package.json and then add a new entry for the scripts section, such as:\n\n\"complex\": \"node node_modules/complexity-report/src/cli.js --maxcc 15 index.js\"\n\n\nwhich permits running the check by npm run-script complex. Now it is a matter of inserting this step in the main test of the scripts section. If there is a function in index.js which has a cyclomatic complexity more than 15, that tool will complain and therefore cause the entire test to fail.\n\nWhile this already serves as a good complexity filter, we can bring it to the next level. For a start, it would be better if we have a clear understanding of the most complex functions. That way, it is easier to spot the worse offenders and have them fixed first. Again, this just requires a quite simple script, as illustrated from Esprima’s implementation of tools/list-complexity.js.\n\nvar cr = require(\'complexity-report\'),\n    content = require(\'fs\').readFileSync(\'index.js\', \'utf-8\'),\n    list = [];\n \ncr.run(content).functions.forEach(function (entry) {\n    list.push({ name: entry.name, value: entry.complexity.cyclomatic });\n});\n \nlist.sort(function (x, y) {\n    return y.value - x.value;\n});\n \nconsole.log(\'Most cyclomatic-complex functions:\');\nlist.slice(, 6).forEach(function (entry) {\n    console.log(\' \', entry.name, entry.value);\n});\n\n\nRunning the above script will list 6 functions which have the highest cyclomatic complexity. An example output is illustrated in the following screenshot, taken verbatim from Travis CI build report of Esprima.\n\n\n\nBecause Travis CI can run the tests on every GitHub pull request, such a report becomes very valuable when doing code review. If someone introduces a complex piece of code, it will be blatantly obvious. This preemptive defensive layer avoids unintentional merge of unreadable handiwork.\n\nComplexity analysis costs almost nothing. Why not always doing it where it makes sense?\n\n(`_|_`)May 8, 2013(`_|_`)ariya.io(`_|_`)continuous-monitoring-of-javascript-code-complexity', 'continuous-monitoring-of-javascript-code-complexity'),
(115, 'Hard Thresholds on JavaScript Code Coverage(`_|_`)\nWith the popularity of test-driven development (TDD), running a project which does not include an automated test workflow is often frown upon. The recent trend pushes it further: if the code coverage is not measured and monitored during that testing, the confidence level will not be very high. For JavaScript projects, how do we keep track of the coverage and prevent any regressions?\n\nIf the project is using Istanbul, the comprehensive code coverage tool for JavaScript, tracking is almost trivial. This holds even for a simple project. As an illustration, let’s have a quick look at esrefactor, a microlibrary which I created for assisting semi-automatic JavaScript refactoring, and its test suite. Running the unit tests (via Node.js) is a simple as node test/run.js (the tests are so simple, no external test framework is being used). Should we want to see the code coverage (and its report), istanbul is our best friend:\n\nistanbul cover test/run.js\n\n\nOnce the coverage metrics are obtained, we can compare them against our predefined thresholds, serving as the baseline coverage limits. For example, the following line means that the statement coverage should be 90% or more. If it is less than the specified limit, Istanbul will complain aloud.\n\nistanbul check-coverage --statement 90\n\n\nWhile this is already very nice, this percentage threshold is often not what you want. In another scenario, we know the unit tests cover 45 statements and miss just 5 statements. How do we ensure that any future modification to this project does not degrade that coverage further to 6 or more uncovered statements? This is where Istanbul’s negative threshold feature becomes really handy. All we need to do is to tweak the coverage check like the following:\n\nistanbul check-coverage --statement -5\n\n\nNext time someone checks in a new piece of code which doesn’t come with a set of suitable unit tests, the above Istanbul invocation will warn that poor fellow that a coverage regression happens. Even better, enlarge the safety net by including the thresholds for function coverage and branch coverage (read also my past blog post on the significance of branch coverage):\n\nistanbul check-coverage --statement -5 --branch -3 --function 100\n\n\nObligatory screenshot showing the situation where the threshold wasn’t hit:\n\n\n\nAs described in my multiple-layer defense approach, running coverage check manually is not the most optimal protection. We can bump up the coolness factor by using the powerful Git precommit hook feature. Now, don’t even try to sneak in untested code!\n\nFor many projects which rely on Node.js and npm, coverage check can be injected in the test ritual as well. First, add istanbul package into devDependencies section in package.json. To complete the typical npm install && npm test workflow, we need to involve coverage threshold check in the last step. The simplest way is by taking advantage of scripts section, illustrated here:\n\n\"scripts\": {\n\"test\": \"node test/run.js && npm run-script coverage\",\n\"coverage\": \"npm run-script analyze-coverage && npm run-script check-coverage\",\n\"analyze-coverage\": \"node node_modules/istanbul/lib/cli.js cover test/run.js\",\n\"check-coverage\": \"node node_modules/istanbul/lib/cli.js check-coverage --branch -2\"\n}\n\n\nFor a more serious project, using additional tools such as Grunt.js is highly recommended, particularly if some testing framework and/or test runner are also involved. There are already packages out there which integrates Istanbul with e.g. Mocha and QUnit. Thanks to this composibility technique, you can also find helper packages for test runners like Karma (née Testacular) and BusterJS, or even for CoffeeScript (via ibrik). Skipping coverage analysis should not be an excuse anymore!\n\nI’d like to close this blog post with a brilliant statement from @davglass:\n\n\n“If you think JSLint hurts your feelings, wait until you use Istanbul”\n\n\nProtect yourself against code coverage regression, you’ll sleep better every night.\n\n(`_|_`)May 2, 2013(`_|_`)ariya.io(`_|_`)hard-thresholds-on-javascript-code-coverage', 'hard-thresholds-on-javascript-code-coverage'),
(116, 'UI Patterns of Android News Applications(`_|_`)\nModern Android applications tend to follow certain user interface patterns, primarily as described in the official Android UI Guidelines. However, not every application is designed equally. Here we see how three news applications have the overall same look, yet the significant detailed differences are immediately obvious.\n\nBBC News application feels like the most polished. The top navigation bar looks and behaves as expected. Horizontal swipe works perfectly. The landing screen offers high-resolution photos, perfect for the new class of high-end Android smartphones. In my opinion, if someone uses many popular Android applications, BBC News application gives the least amount of surprises.\n\n\n\nOn the other hand, CNN application only adopts some of the best practices. Surprisingly it feels more like many Facebook-y applications, with the side bar which slides in and out. Tapping on its big “CNN Headlines” also does not bring you back to the landing screen. The news list shows the individual list items with this glaring dark gradient, quite hard on the eyes. There is no possible tweak to disable news update or even choose the update frequency. Last but not least, the “This is CNN” audio message when starting the application is fancy and welcoming, but it is kind of annoying (fortunately you can disable it, which you should do right away).\n\nHow about NBC News? Its application does not support horizontal swipe, there are only left and right arrows you can tap to move to the previous or next story. The landing screen is not special at all, many down arrows just add the clutter with no immediate benefit. Also, in the story list, you tend to see ad banners inserted here and there, another noisy elements. Finally, choosing the news section involves the use of this colorful rotary menu, complete with some animation and sound effect. This menu looks interesting at first, but the novelty wears off pretty quickly.\n\nThe above three applications were random samples, I picked them from the recommended ones in the Play Store. I also deliberately tested channel-specific applications and not the aggregator ones (maybe for some other time).\n\nWhat is your favorite news application? How is the user interface?\n\n(`_|_`)Apr 30, 2013(`_|_`)ariya.io(`_|_`)ui-patterns-of-android-news-applications', 'ui-patterns-of-android-news-applications'),
(117, 'Rename Refactoring for JavaScript Code(`_|_`)\nOne of the common refactoring activities is variable renaming. Many respectable IDEs have such a language-aware renaming feature. In some other cases, this is carried out via a simple search and replace. Manual search replace is error-prone and hence why a syntactically-correct rename refactoring tool can be useful.\n\nWe have seen how identifier highlighting is implemented in a simple Orion-based code editor. Renaming is the obvious next step, instead of just highlighting now we need to monitor any possible change to the code and appropriately rename the other identical references as well. For this purpose, there is a live rename refactoring demo you can try yourself at esprima.org/demo/rename.html.\n\nAssume we have the following function. It is extremely simple, the function returns true if the specified character is a hexadecimal digit.\n\n\n\nLater on, somebody decides that the name of the function parameter needs to change. All he needs to do is to place the cursor on any occurrence of that parameter (note the yellow highlight in two places) and start typing in the new name. Voila! Now both references get the new name. This renaming also works for normal declared variable as well as function name.\n\n\n\nBecause this demo uses escope (GitHub: github.com/Constellation/escope) from Yusuke Suzuki, the scope analysis follows the ECMAScript 5.1 specification faithfully. If there are other variables with the same name, if they are out of scope, those won’t be touched and got renamed. This is something that a blind search and replace will not recognize.\n\nIn a real-world application, functions are very likely more than just one-liner. Doing a renaming via an automated tool will save a lot of time, no need to hunt every single reference and to ensure that the scope is correct. The latter is practically quite tedious, especially for a deeply nested code polluted with some callbacks.\n\nBe advised that JavaScript is a flexible and dynamic language. Because of that, automagic application-wide renaming is often not always possible, in particular because resolving of an identifier can’t be correctly carried out until the code is executed. Many strategies have been developed to mitigate the issues, from a comprehensive type analysis to a convention-based approach. This will push the renaming refactoring further to the best-effort level.\n\nFor programmatic renaming (perhaps you want to replace all obj into the more descriptive object or something more logical than that), you can use a convenient microlibrary called esrefactor (GitHub: github.com/ariya/esrefactor). This library internally uses escope to analyze the scope after the syntax tree is obtained via Esprima. For Node.js users, there is the new esrefactor package ready to use.\n\nOnce it is set up, the real renaming action is usually just taking just a few lines of code:\n\nvar ctx = new esrefactor.Context(\'var x; x = 42\');\nvar id = ctx.identify(4);\nvar code = ctx.rename(id, \'answer\');\n\n\nIn the above code fragment, we first locate the identifier (in this case, it is a variable) at the index position of 4 (right before x in var x). After that, we use the rename() function to have it renamed to the new name. Predictably, what you get from code is var answer; answer = 42.\n\nNext time you plan a semi-automatic renaming refactoring to your code, you know what to do!\n\n(`_|_`)Apr 24, 2013(`_|_`)ariya.io(`_|_`)rename-refactoring-for-javascript-code', 'rename-refactoring-for-javascript-code'),
(118, 'JavaScript Variable Scope and Highlight(`_|_`)\nAn interesting feature of many programmer’s editors is identifier highlighting. It makes easy to spot where a particular variable or function is used. With JavaScript as the language, highlighting is also useful since some JavaScript beginners are often confused by JavaScript function-level scope and its related effect of variable hoisting.\n\nImplementing such a highlighting feature is usually far from trivial. Fortunately, we have many libraries which can resolve identifier scoping according to the language specification. One of them is escope (GitHub: github.com/Constellation/escope) from Yusuke Suzuki. While escope already implements a faithful scope analysis, it is often not very easy to use, hence I create a special microlibrary esrefactor (GitHub: github.com/ariya/esrefactor) which uses escope (after getting the syntax tree from Esprima) to locate occurrences of a given identifier.\n\nCombining some language-related libraries like this (another demonstration of tools composition) gives a simple demo which can be tried live at esprima.org/demo/highlight.html. In the following screenshot, the cursor was placed in the last occurence of shuffled, where the word is enclosed with a subtle red border. All other references are highlighted as well. A special reference, marked with the ! symbol on the left gutter, denotes the location where the variable is declared. This also works well for function parameters.\n\n\n\nThanks to Orion editor, there is also a small indicator (it is even clickable) on the right scroll bar which gives the approximate location of the references relative to entire code. This is handy if the code is very large so you don’t need to scroll endlessly to go to a particular reference.\n\nSince the demo uses escope, the scope analysis follows the ECMAScript 5.1 specification faithfully. For example, look at this rather convoluted code fragment and see how the highlight skips some variables even though they share the same name with the one under the cursor.\n\n\n\nNext week, we will see the logical next step of this feature: rename refactoring. Stay tuned!\n\n(`_|_`)Apr 18, 2013(`_|_`)ariya.io(`_|_`)javascript-variable-scope-and-highlight', 'javascript-variable-scope-and-highlight');
INSERT INTO `ariyaio` (`id`, `content`, `url`) VALUES
(119, 'Web Page Clipping with PhantomJS(`_|_`)\nOne of the major usages of PhantomJS is to capture web pages and render them as image. There are many rendering aspects which can be tweaked, the most popular one is the zoom factor, particularly useful to create thumbnails. A rather not-so-known parameter is the clipping rectangle which is very handy to limit the capture to a selected area only.\n\nA common use of the clipping rectangle is when you need to track the position and the size of a particular element (likely via getBoundingClientRect) and render only that element. This is also what CasperJS offers in its convenient function captureSelector.\n\nAnother variant is to produce the semi-paginated version of a web page. Mostly on mobile, the user needs to scroll up and down (typically) and getting the feeling of the continuity of the contents is quite important. For example, the very first “page” needs to show a complete intro. If an important central image is cut into half, that does not give a good impression.\n\nThe following images shows the approximate rendering of BBC web site on mobile which looks really good: a full intro followed by a bunch of story summaries.\n\n\n\nThe script used to generated the two images above is shown here.\n\nvar page = require(\'webpage\').create();\npage.settings.userAgent = \'WebKit/534.46 Mobile/9A405 Safari/7534.48.3\';\npage.settings.viewportSize = { width: 400, height: 600 };\npage.open(\'http://m.bbc.co.uk/news/business\', function (status) {\n    if (status !== \'success\') {\n        console.log(\'Unable to load BBC!\');\n        phantom.exit();\n    } else {\n        window.setTimeout(function () {\n            page.clipRect = { left: , top: , width: 400, height: 600 };\n            page.render(\'bbc-page1.png\');\n            page.clipRect = { left: , top: 600, width: 400, height: 600 };\n            page.render(\'bbc-page2.png\');\n            phantom.exit();\n        }, 2000);\n    }\n});\n\n\nIt is rather simple, especially if you understand the screen capture use case of PhantomJS. The user agent tweak is necessary to ensure that the delivered page is the mobile version. Two images are produced, each corresponds to the first and second “page” the user is going to see. This is achieved by adjusting the top value to offset that page. Pretty straightforward!\n\nWhat do you want to webclip today?\n\n(`_|_`)Apr 17, 2013(`_|_`)ariya.io(`_|_`)web-page-clipping-with-phantomjs', 'web-page-clipping-with-phantomjs'),
(120, 'Automatic Inlining in JavaScript Engines(`_|_`)\n\n\nBack when JavaScript interpreters were still slow, avoiding a function call inside a performance-critical code was very much recommended. With the recent improvements to the modern JavaScript engines, this practice becomes less relevant. One important feature which reduces the need to worry about function call overhead is automatic function inlining.\n\nConsider the following code:\n\nfunction square(x) {\n  return x * x;\n}\n \nfunction f(x) {\n  var sum = ;\n  for (var i = ; i < x; i++) {\n    sum += square(i);\n  }\n  return sum;\n}\n\n\nIf x is a large number, invoking f(x) will cause a lot of function call to square. Even if the overhead is small, it can become significant when accumulated over a bazillion calls. This promotes the best practice of avoiding function calls within such a loop.\n\nFortunately, a modern JavaScript engine may sense that this part of the code is pretty hot (due to the extensive loop) and decide to optimize it. Among many others optimization, a simple thing to do is not to invoke square for every iteration. Since the implementation of that function is rather simple and it does not have any side effects, it is rather easy to inline it automatically. In other words, your code would be executed as if you would have written it this way:\n\nfunction f(x) {\n  var sum = ;\n  for (var i = ; i < x; i++) {\n    sum += i * i;\n  }\n  return sum;\n}\n\n\nHow can we verify this? Here is one possible approach: by using V8 debugger shell (as described by Florian Loitsch). First, let add some more lines to the original code for the purpose of stressing the execution:\n\nfor (var x = ; x < 10000; ++x) f(1e4);\n\n\nNow, if you have built V8 and get its debugging shell d8, it’s a matter of running:\n\nd8 --trace-inlining sum.js\n\n\nwhich will give (among other informational messages):\n\nInlined square called from f.\n\nindicating that V8 finally decides not to invoke the function too many times and to just inline it.\n\nIf you always worry about manual function inlining, this is a good time to revisit that thought. Simply write the code to be readable even if it means breaking the code into multiple small functions! In many cases, we can trust the modern JavaScript engines to automatically inline those functions.\n\n(`_|_`)Apr 11, 2013(`_|_`)ariya.io(`_|_`)automatic-inlining-in-javascript-engines', 'automatic-inlining-in-javascript-engines'),
(121, 'CSS Preload Scanner in WebKit(`_|_`)\nIn WebKit world, preload scanner refers to a side parser which kicks in if the main HTML parser is halted by a blocking script loading. Because this preload scanner can see what other resources (e.g. stylesheets, images, inputs) are to be fetched, it can trigger the associated network requests as early as possible, without waiting for the main parser to finish, thereby improving the overall loading time. Now, what about speculatively loading dependent resources on a stylesheet instead of the main HTML file? Fortunately, WebKit has something called CSS Preload Scanner.\n\nDuring the implementation of a standard-compliant HTML5 parser in WebKit, the preload scanner got cleaned up. While the bulk of the scanning still resides in the main HTMLPreloadScanner, a small portion went into its own CSSPreloadScanner. Like its HTML cousin, the job of CSS Preload Scanner is to scan the stylesheet for resources which can be fetched early. For now, it only supports CSS @import rule.\n\nLet us have a look at the following example. In this fragment (not the best practice, only for illustration purposes), we see a script element and a stylesheet:\n\n<p>The quick brown fox jumps over the lazy dog.</p>\n<script>setTimeout(function() { document.title = document.title }, 1000);</script>\n<p>The quick brown fox jumps over the lazy dog.</p>\n<style>\n@import url(\"another-style.css\");\nbody { background-color: white }\n</style>\n\n\nDue to the script element, WebKit parser will invoke the preload scanner, both HTML and CSS flavors. The preload scanner quickly realizes that there is this particular URL within @import. It then schedules the process of fetching another-style.css (the actual request will be tackled by the network stack).\n\nBecause CSS preload scanner is pretty simple (it does not need to understand the full CSS grammar), it does the job pretty well. In fact, there was an optimization so that it bails out quickly if @import is not found early in the stylesheet. This is important so that the CPU cycles are not wasted on large CSS files.\n\nThe use of @import is often discouraged (see Steve Souder’s don’t use @import). With the current and future improvements inside the browser engine, such a best practice needs to be evaluated again from time to time. Of course, I wouldn’t recommend sprinkling @import everywhere on your web sites. Use the tools available to you (e.g. Web Inspector) to analyze the network performance and then you will be in the position to make an informed decision.\n\nLike in Hamlet, “To import, or not to import”.\n\nNote: Special thanks to Ilya Grigorik for reviewing the draft of this blog post.\n\n(`_|_`)Apr 9, 2013(`_|_`)ariya.io(`_|_`)css-preload-scanner-in-webkit', 'css-preload-scanner-in-webkit'),
(122, 'Automagic Removal of JavaScript Logging(`_|_`)\nWhen writing a large JavaScript application, it is quite often that console.log and other debugging statements are sprinkled here and there. Obviously, at one point those extraneous statements need to be removed for the production version or even when the code needs to be checked in into the source repository. There are many different ways to do this, there exists a new tool called groundskeeper which can do this removal for you.\n\nWritten for Node.js, groundskeeper (GitHub: github.com/Couto/groundskeeper) is created by Luís Couto to handle logging removal by understanding the syntax tree of the code and deleting the relevant parts. It is not based on regular expression at all. Groundskeeper parses the code (via Esprima) and modify the syntax nodes (via falafel) associated with any logging. Beside a command-line tool, groundskeeper is also a library ready to be used in any other tools and build systems.\n\nUsing groundskeeper is terribly simple (as its documentation explained). Let’s assume we have the following filter-debug.js:\n\nfunction filter(list, age) {\n  var result = [];\n  list.forEach(function (person) {\n    if (person.name && person.age > age) {\n      console.log(\'including\', person.name);\n      result.push(person);\n    }\n  });\n  return result;\n}\n\n\nAfter its package is installed, running something like:\n\ngroundskeeper < filter-debug.js > filter.js\n\n\nwill give the following filter.js:\n\nfunction filter(list, age) {\n  var result = [];\n  list.forEach(function (person) {\n    if (person.name && person.age > age) {\n \n      result.push(person);\n    }\n  });\n  return result;\n}\n\n\nThe line containing console.log is now a blank line. Because groundskeeper doesn’t delete the line, the processed output still has the same amount of lines of code as the original one.\n\nHow about debugger? We know that this statement may cause some problems with old web browsers. Fortunately groundskeeper can also get rid of any debugger statements in the code. In fact, you can even nuke any other custom application logger you might have. Here is a code fragment:\n\ndebugger\nvar list = filter(customers, 25);\nRentalApp.Logger.print(JSON.stringify(list, null, 2));\n\n\nwhich can be processed via:\n\ngroundskeeper -n RentalApp.Logger < rental.js\n\n\nand give you the remaining output:\n\nvar list = filter(customers, 25);\n\n\nThe biggest benefit of automatic removal is when it is combined with Git pre-commit hook so that no more manual step is necessary. This is pretty similar to the use of syntax validation trick. Here is an example of such a hook:\n\nfiles=$(git diff-index --name-only --diff-filter=ACM HEAD | grep -P \'\\.js$\')\nfor file in $files; do\n  groundskeeper < $file > $file.tmp && mv $file.tmp $file\ndone\n\n\nAll touched *.js files will be processed via groundskeeper before they are checked in. This way, none of them will have stray console.log, debugger statements, or any other custom logger calls anymore. Thus, your repository is guaranteed to be free from debugging leftovers!\n\n(`_|_`)Apr 6, 2013(`_|_`)ariya.io(`_|_`)automagic-removal-of-javascript-logging', 'automagic-removal-of-javascript-logging'),
(123, 'Spring 2013 Conferences(`_|_`)\n\n\nSpring is in the air! Time for me to hit the road and give some tech talks.\n\nFor HTML5 Developer Conference in San Francisco, April 1-2, I’ll try to show a 30,000-foot WebKit overview to those who are new to the wonderful world of browser rendering. WebKit Rendering: Overview for HTML5 Developers is the official title of the talk and it is scheduled for the 1.30 pm session on the second day. This will be my first time for HTML5 Developer Conference and due to its scale, it’s both thrilling and exciting for me!\n\nIn addition to that, there is Fluent 2013 coming pretty soon (San Francisco again, May 28-30). This event is focused heavily on JavaScript and hence my presentation will be on Improving JavaScript Code Quality: Strategies and Tools. The current schedule shows that this is intended for Thursday 11.30 am. Last year, it was quite fascinating and I hope I’ll have some fun again this time.\n\nIf you attend one of these events, feel free to ping me to have a chat!\n\n(`_|_`)Mar 26, 2013(`_|_`)ariya.io(`_|_`)spring-2013-conferences', 'spring-2013-conferences'),
(124, 'ECMAScript 6 and Method Definitions(`_|_`)\nUsing an object literal populated with some member functions is a common practice in any serious JavaScript applications. This is also useful for all kind of frameworks, in particular to setup object prototypes. The upcoming ECMAScript 6 introduces method definition, a nice shorthand which eliminates the need to use function when using that pattern.\n\nBefore we see method definition in action, let us have a quick refresh on property setter and getter. This is part of the current ECMAScript 5.1, see Section 11.1.5 on Object Initialiser. The idea is to use set and get to bind an object property to a function which will be invoked when that property is set and looked up, respectively. The following code fragment demonstrates its usage:\n\nvar BigLoco = {\n  locoName: \'Gordon\',\n  get name() { return this.locoName; },\n  set name(n) { this.locoName = n }\n};\n \nconsole.log(BigLoco.name); // \'Gordon\'\n\n\nPractically, we have a way to define a function without using the function keyword. With ECMAScript 6, this is extended further so that the syntax applies not only to property getter and setter, but also to plain functions. This is called Method Definitions, see Section 13.3 in the latest ES6 draft.\n\nTake a look at an example ECMAScript 6 code here, in particular to the start and stop functions.\n\nvar SteamEngine = {\n  color: \'blue\',\n  get name() { return \'Thomas\' },\n  start() { console.log(\'Hurry up!\'); },\n  stop() { console.log(\'Screech...! That was close.\'); }\n};\n \nconsole.log(\'My name is\', SteamEngine.name);\nSteamEngine.start();\nSteamEngine.stop();\n\n\nIf we were about to transpile the code to ES5, the construct will look like:\n\nvar SteamEngine = {\n  color: \'blue\',\n  get name() { return \'Thomas\' },\n  start: function() { console.log(\'Hurry up!\'); },\n  stop: function() { console.log(\'Screech...! That was close.\'); }\n};\n\n\nThe ECMAScript 6 version shows a nice symmetry thanks to this syntactic sugar. Every property on that literal looks the same and it’s not really difficult to spot the functions due to the necessary parentheses. Sweet!\n\n(`_|_`)Mar 20, 2013(`_|_`)ariya.io(`_|_`)es6-and-method-definitions', 'es6-and-method-definitions'),
(125, 'Frame Rate HUD on Chrome for Android(`_|_`)\nTo have a silky smooth experience on mobile web, it is important to gather relevant performance data so that a suitable optimization can be carried out. Traditionally, such a measurement activity is full of (black) magic since the web browser itself often does not expose enough performance metrics. These days, the situation is much better since browser vendors start to hook various types of instrumentation. The latest Chrome 25 for Android can even display a very useful frame rate HUD to gauge the rendering performance.\n\nUsing Chrome’s FPS Counter requires a very simple initial step: going to the special URL chrome://flags and enabling that particular option (note that this is also the exact same setup for Chrome for desktop). In many cases, it is also useful to enable Composited render layer borders. With these debugging borders, you will be able to see which DOM element is mapped into a GPU texture for the hardware-accelerated compositing. For some info on the machinery of GPU compositing, check out the video (and the slide deck) of my recent W3Conf talk.\n\n\n\nAfter a relaunch, pay attention to the top right corner. This is where Chrome (more precisely, its Compositor module) displays some essential metrics in a simple head-up display (HUD):\n\n\nActual frame rate (average, minimum, maximum)\nFrame rate chart (as a function of time)\nFrame rate histogram\nGPU memory status\n\n\nThe last information is quite useful. Like what I mentioned in my W3Conf talk, GPU memory should be treated as a cache. Simply doing a blind translate3d on every single element will be quite harmful because you will quickly fill that memory (overbudget). Having this memory statistics, combined with the actual frame rate rendered by Chrome, means that front-end developers won’t be flying blind anymore when it gets to rendering performance analysis and optimization.\n\nTo the glory of 60 fps!\n\nUpdate: Later versions of Chrome improve the HUD for better readability.\n\n\n\n(`_|_`)Mar 18, 2013(`_|_`)ariya.io(`_|_`)frame-rate-hud-on-chrome-for-android', 'frame-rate-hud-on-chrome-for-android'),
(126, 'ECMAScript 6 and Spread Operator(`_|_`)\nWe have seen how a rest parameter can help the handling of a variable number of function arguments. What about the other way around? Can we turn an array into a series of function arguments? Apparently, ECMAScript 6 defines a new type of operator called the spread operator which does exactly that.\n\nLet us review again our previous example with a supplier truck and a grocery store. Assuming the API of the store accepts a variable number of items for a particular category:\n\nstore.add(\'fruit\', \'apple\');\nstore.add(\'dairy\', \'milk\', \'cheese\', \'yoghurt\');\nstore.add(\'pastries\', \'donuts\', \'croissants\');\n\n\nWe assume that these delicious items are stored in some boxes, each box happens to be an array:\n\nvar dairyBox = [\'milk\', \'cheese\', \'yoghurt\'];\n\n\nA possible solution (out of many others) to invoke store’s add function with the items in the above array is by using Function.prototype.apply. Since we need to pass the food category as the first argument, a little bit dancing with Array.concat is necessary:\n\nstore.add.apply(store, [\'dairy\'].concat(dairyBox));\n\n\nFor the untrained eyes, it looks like one of those magical JavaScript incantations.\n\nWith ECMAScript 6, this can be simplified by using ... prefix in a spread expression (section 11.2.5, ES6 draft Rev 14).\n\nstore.add(\'dairy\', ...dairyBox);\n\n\nThat dairyBox array is simply spread to fill the remaining argument list.\n\n\n\nObviously, one possibly common place where spreading is always useful is when dealing with arrays. We know that push accepts multiple number of arguments. The implementation of add function originally looks like:\n\nstore.add = function(category, ...items) {\n  items.forEach(function (item) {\n    store.aisle[category].push(item);\n  });\n};\n\n\nwhich can be further shortened to become something like the following fragment. Nifty, isn’t it?\n\nstore.add = function(category, ...items) {\n  store.aisle[category].push(...items);\n};\n\n\n(This is of course unnecessary if you choose to change the API to simply accept a single array for the items, instead of a rest parameter combined with spreading).\n\nThe use of a spread operator can lead to a different way of combining arrays:\n\nvar x = [1, 2];\nvar y = [3, 4];\nx.push(...y);  // x is [1, 2, 3, 4]\n\n\nWhat other tricks do you have in mind once you have the spread operator ready to abuse?\n\n(`_|_`)Mar 13, 2013(`_|_`)ariya.io(`_|_`)es6-and-spread-operator', 'es6-and-spread-operator'),
(127, 'JavaScript Editing with Autocomplete(`_|_`)\nCode autocomplete is probably one of the exciting features of a programmer’s text editor. Ever since Eclipse Orion started to demonstrate its wonderful Content Assist feature last summer, I do believe that an online, web-based editing component should always provide a minimalistic and convenient autocompletion. Fortunately, this is rather easy to achieve these days, thanks to Orion and Scripted.\n\nWith the recent growing interests to improve the state of JavaScript language tooling, I thought it is a good time to publish a simple example that I have put together some time ago. The editor itself is the same one used in Eclipse Orion. With its recent version 2.0 release, it becomes rather easy to embed Orion editor in any web page: one JavaScript file, one CSS file, and a bit of of glue code.\n\n\n\nFor the autocompletion itself, Scripted’s Content Assist is employed. As I have written before, it has a well-developed type inferencer. Using a simple static code analysis, it can detect the possible matches on a best-effort basis. In addition to that, JSDoc-style of type annotation is also supported.\n\nYou can enjoy the working example at esprima.org/demo/autocomplete.html. Have fun!\n\n(`_|_`)Mar 11, 2013(`_|_`)ariya.io(`_|_`)javascript-editing-with-autocomplete', 'javascript-editing-with-autocomplete'),
(128, 'ECMAScript 6 and Rest Parameter(`_|_`)\nHandling a function with a variable number of arguments is always tricky in JavaScript. At least, we still have this arguments object which can be used to retrieve all arguments used to invoke a function. With the upcoming ECMAScript 6, no such hack is necessary anymore since we can start using its rest parameter feature.\n\nTo see how a rest parameter works, consider the following scenario. You drive a truck which delivers some supplies to a grocery store. As you unload the supplies, you add them to the store:\n\nstore.add(\'fruit\', \'apple\');\nstore.add(\'dairy\', \'milk\', \'cheese\', \'yoghurt\');\nstore.add(\'pastries\', \'donuts\', \'croissants\');\n\n\nwhereby add is implemented as something like:\n\nstore.add = function(category) {\n  var items = [].slice.call(arguments, 1);\n  items.forEach(function (item) {\n    store.aisle[category].push(item);\n  });\n};\n\n\nNote how arguments object can’t be treated as a normal array, although it behaves almost like an array. A well-known trick with Array.prototype.slice and Function.prototype.call is the workaround, giving us the list of all arguments which comes after the first one (category).\n\nWith a rest parameter (Section 13.1, ES 6 draft Rev 13), the implementation is much simpler. It is even self-explanatory.\n\nstore.add = function(category, ...items) {\n  items.forEach(function (item) {\n    store.aisle[category].push(item);\n  });\n};\n\n\nAnother typical use-case where a rest parameter could be useful is a pubsub-like pattern. If you write a Backbone.js-based application, triggering an event via Backbone.Event.trigger is a common practice. Because an event may require one or more parameters, the implementation of the trigger function itself looks like:\n\ntrigger: function(name) {\n    if (!this._events) return this;\n    var args = slice.call(arguments, 1);\n    /// ... do something with args ...\n    return this;\n},\n\n\nfor which I’m sure you can come up with a slightly different look if you have the rest parameter feature as your disposal!\n\nObviously we don’t need a rest parameter if we switch the API to accept an array as the second argument. However, in some cases, it would feel less natural. For example, a string formatter implementation is expected to follow the de-facto printf format string rather than grouping every parameters in a simple array.\n\nJust like other syntactic sugar in ECMAScript 6, a rest parameter does not radically change you write your JavaScript code. It does however make the code more tool-friendly, shifting the semantic interpretation of the code from the run-time behavior into something at the syntax level. Once editors and IDEs understand the construct, a simple code hint which reveals the function signature is more than enough to indicate that the said function accepts a variable number of arguments.\n\nIsn’t it exciting?\n\n(`_|_`)Mar 6, 2013(`_|_`)ariya.io(`_|_`)es6-and-rest-parameter', 'es6-and-rest-parameter'),
(129, 'ECMAScript 6 and Object Literal Property Value Shorthand(`_|_`)\nConstructing an object using the literal syntax is something that is very familiar to every JavaScript developer, quite likely because this reminds everyone of JSON. While every object property needs to be either a key-value pair or getter/setter, this may change in the near future. Another syntactic sugar in the upcoming ECMAScript 6 is the object literal property value shorthand.\n\nConsider the following ECMAScript 5 fragment:\n\nfunction createMonster(name, power) {\n  return { type: \'Monster\', name: name, power: power };\n}\nfunction createWitch(name) {\n  return { type: \'Witch\', name: name };\n}\n\n\nWith the new shorthand form, this can be rewritten as the following code:\n\nfunction createMonster(name, power) {\n  return { type: \'Monster\', name, power };\n}\nfunction createWitch(name) {\n  return { type: \'Witch\', name };\n}\n\n\nAs you can see, this works because the property value has the same name as the property identifier. This a new addition to the syntax of Object Initialiser (section 11.1.5) in the latest ECMAScript 6 draft Rev 13. Of course, just like the limitations set from ECMAScript 3, you can’t use a reserved word as your property name.\n\nWhat about real-world code which can use the shorthand notation? Somewhere in Backbone.js, we should be able to use the following form instead of its longer one:\n\nroute: function(route, callback) {\n  this.handlers.unshift({route, callback});\n},\n\n\nFor improved readibility, many times we use temporary variables before constructing an object out of the properties. As another example, a piece of code QUnit may have the following simplified syntax:\n\ntest = new Test({nameHtml, testName, expected, async,\n  callback,module: config.currentModule,\n  moduleTestEnvironment: config.currentModuleTestEnvironment,\n  stack: sourceFromStacktrace(2)\n});\n\n\nSuch a shorthand won’t dramatically change your code, it only makes everything a little bit sweeter!\n\nAddendum. While the literal shorthand is useful on its own, in many cases it would be more frequently encountered as it is combined with object pattern (see my previous post on ECMAScript 6 destructuring). Thus, the following code fragment:\n\nbooks.forEach(function ({title: title, author: author}) {\n  console.log(title, \'is written by\', author);\n});\n\n\nturns into something like this one:\n\nbooks.forEach(function ({title, author}) {\n  console.log(title, \'is written by\', author);\n});\n\n\nAs you can see, such a symmetry is well suited for this case.\n\n(`_|_`)Feb 28, 2013(`_|_`)ariya.io(`_|_`)es6-and-object-literal-property-value-shorthand', 'es6-and-object-literal-property-value-shorthand'),
(130, 'The Fascinating W3Conf 2013(`_|_`)\n\n\nLast week, the annual W3C conference for web professionals, W3Conf 2013, was held in San Francisco. It was packed with tons of interesting talks. The event was professionally organized and it attracted the attention of various Who’s Whos in the front-end development world.\n\nThere was an extremely positive vibe, in particular because the theme varies a lot, from ECMAScript 6 to CSS secrets. WiFi worked really well, social medias were flooded with thoughts and opinions from the attendees. There was an ample supply of lunch boxes, snacks, drinks, and even cupcakes to keep everyone energized. The entire conference was live-streamed. In addition to that, Faruk Ateş did a fantastic job of live tweeting the running topic and Chris Coyier posted his excellent notes after every session.\n\nI did a talk on Fluid User Interface with Hardware Acceleration and received a lot of good feedback and follow-up discussion. For those who were not there, check out the slide deck and the following recorded video (make sure you check other talks as well).\n\nKudos to Doug, Lea, Divya, Liz, and many others who were involved in organizing this amazing conference. See you at W3Conf 2014!\n\n(`_|_`)Feb 25, 2013(`_|_`)ariya.io(`_|_`)the-fascinating-w3conf-2013', 'the-fascinating-w3conf-2013'),
(131, 'ECMAScript 6 and Arrow Function(`_|_`)\nExperienced JavaScript programmers take advantage of function expressions, they are used a lot in callbacks, either for DOM access or any other related setup. Another syntax addition to the upcoming ECMAScript 6 is the arrow function expression to let us write a shorter function expression.\n\nA simple way to look at this arrow function notation (section 13.2 in the latest ES6 draft) is as a shorthand form of a normal function expression. This is best illustrated with an example. Say you want to produce the list containing the salary of every employees. By using Array map, it will look like the following snippet:\n\nsalaryList = employeeList.map(function (e) { return e.salary; });\n\n\nNote the function expression as the callback for map() is rather verbose. With an arrow function expression, that construct can be shortened to:\n\nsalaryList = employeeList.map(e => e.salary);\n\n\nNo need for function and return. In fact, if you are about to implement the same task with other languages (such as Scala, CoffeeScript, C#), you would end up with a very similar syntax.\n\nHow does a syntax tree look like when there is an arrow function? Rather straightforward, no surprise there.\n\n\n\nAn arrow function expression is designed primary for the case where you need to return a value. However, it still works if you don’t care about returning anything and just want to execute some statements. Take a look at this example:\n\nemployeeList.forEach(e => { console.log(e.name); });\n\n\nAnother fun thing with such a shorthand is when you start cascading more functions. For example, if now we are interested in the average salary, this can be computed by:\n\nvar total = employeeList.map(e => e.salary).reduce((p, q) => p + q);\nvar averageSalary = total / employeeList.length;\n\n\nThat’s just way shorter and less crowded compare to function expressions everywhere. It is important to notice that if you have more than one parameter, you need to enclose the parameters with brackets.\n\nSince an arrow function expression is just another form of an assignment expression, we can keep it as a normal object (either for further reuse or just to make it easy to follow), as illustrated in the following fragment (neat, isn’t it?):\n\nvar adder = (p, q) => p + q;\nvar avg = employeeList.map(e => e.salary).reduce(adder) / employeeList.length;\n\n\nCombine it with array comprehension and magically it does not look to JavaScript-y anymore!\n\nI believe the use of arrow function expression strikes a good balance between readability and expressiveness. What do you think?\n\n(`_|_`)Feb 19, 2013(`_|_`)ariya.io(`_|_`)es6-and-arrow-function', 'es6-and-arrow-function'),
(132, 'ECMAScript 6 and Default Argument(`_|_`)\nMany programming languages support the concept of a default argument for a function parameter so that the caller does not always need to specify the argument value. Unfortunately, JavaScript does not have a default argument support in its syntax. This may soon change with the upcoming ECMAScript 6.\n\nA few JavaScript programmers employ various different run-time tricks to achieve the effect of an argument with a default value. The common approach is by leveraging the fact that if an argument is not given a value, then it’s simply undefined.\n\nfunction foobar(a) { return typeof a; }\nfoobar(); // \"undefined\"\n\n\nThis can lead to some code like:\n\nfunction runApp(appName) { console.log(\'Running\', appName || \'AUTOEXEC.BAT\'); }\n\n\nThat function will print Running AUTOEXEC.BAT if invoked as runApp() only (without any argument). The use of logical expression OR (operator ||, see section 11.11 on Binary Logical Operators) means that if the left side (appName) is true (see section 9.2 on ToBoolean), then the short-circuiting kicks in, otherwise we will get the right side (AUTOEXEC.BAT). Note how the result is the same if you execute that function with other value such as null, `,![], or even~~{}`.\n\nAnother variant which are often encountered is really checking the type of the parameter. Now we can distinguish between undefined and others. Therefore, a suitable value substitution can be carried out.\n\nfunction runApp(appName) {\n  if (typeof appName === \'undefined\') appName = \'AUTOEXEC.BAT\';\n  console.log(\'Running\', appName);\n}\n\n\nIn other cases, we really really need to know whether the function is invoked with a certain number of argument or not. For this purpose, the arguments object comes to the rescue.\n\nfunction runApp(appName) {\n  if (arguments.length === ) appName = \'AUTOEXEC.BAT\';\n  console.log(\'Running\', appName);\n}\n\n\nAll this fancy dance is not necessarily anymore once the syntax itself supports a default argument. In the section 13 of the latest ECMAScript 6 draft, it is mentioned that the formal parameter (for a function) is not a simple list of identifiers anymore (as in ECMAScript 5) as it is generalized to allow BindingElement. While this new construct is there to permit the object and array pattern (see my previous blog post on destructuring assignment), it is important to realize that BindingElement supports an optional initialization, pretty much like in a variable declaration.\n\nIn plain English, this means that a function declaration can specify a default value for every parameter. The previous runApp function will turn into something as simple as:\n\nfunction runApp(appName = \'AUTOEXEC.BAT\') {\n  console.log(\'Running\', appName);\n}\n\n\nWhile waiting for browsers and JavaScript engines to implement this feature, such a construct can be used already these days with help of Traceur or TypeScript. It is interesting to note the different desugaring, Traceur will use the arguments object while TypeScript performs the undefined type check.\n\nHaving a built-in syntax support for default argument is fantastic. A JavaScript editors could give a better content assist (autocomplete). A code analyzer will be able to track function invocation which omits parameters that do not have default values. I can’t wait until a linter complains to me:\n\nguide.js:42 Specify the non-optional parameter \'stop\' to function \'createSeries\'\n\nBetter language tools will no doubt reduce any coding mistake as best as it can.\n\n(`_|_`)Feb 13, 2013(`_|_`)ariya.io(`_|_`)es6-and-default-argument', 'es6-and-default-argument'),
(133, 'JavaScript Editing with VMware Scripted(`_|_`)\nScripted (GitHub: github.com/scripted-editor/scripted) is a new JavaScript editing tool from VMware. It is relatively new, the first edition was launched just a few months ago. However, so far it seems to be a capable and usable editor for your JavaScript needs.\n\nInstallation is dead easy. Assuming Node.js is running well on your machine, it’s a matter of installing the scripted package (the recent stable is version 0.3). After that, go to your working JavaScript project and launch it:\n\nscripted yourfile.js\n\n\nScripted does not have a dedicated GUI. It will launch its interface in your web browser. So far I’ve tried it with the latest Firefox, Chrome, Safari, Opera and they all work quite well.\n\nThe main editing component of Scripted is the same as the one used in Eclipse Orion. It has many features you would expect from a modern editor: shortcut keys, split view, syntax highlighting, bracket matching, high-performance scrolling, file search, navigation, autocomplete, and many others. To reduce coding mistakes, Scripted also integrates JSHint for inline analysis. Also, since a typical JavaScript project involves the use of modules, its module dependency solvers will be surely appreciated.\n\n\n\nOne thing I really from Scripted is its smart autocomplete, or as it is often referred, content assist. Scripted has a type inferencer which consumes your code and deduces the variable and object types (using control flow analysis). The parsing back-end is based on Esprima, with some additional enhancement to make it more tolerable to incomplete construct as the code is still being typed by the user.\n\nIn addition to that, Scripted also understands type annotation in the style of Google Closure Compiler, in JSDoc-style comment parsed using Doctrine. For example, if you have the following annotated fragment:\n\n/**\n * Adds two numbers.\n * @param {number} x First number\n * @param {number} y Second number\n * @return {number} The value\n */\nfunction add(x, y) { return x + y; }\n\n\nand then later on you want to use function add somewhere, Scripted’s content assist (e.g. upon Ctrl+Space) will show that add is accepting x and y and returning a number. If you accept the suggestion, it will prepare the complete function signature add(x, y) for you. Furthermore, content assisting on each parameter will still work and Scripted kindly tells you the required type for each parameter (in this case, a number). If you come from a language with strong/optional typing, this kind of type annotation is quite helpful to reduce the amount of time needed to consult the API documentation.\n\nIn its current state right now, Scripted is already usable. It is still actively developed so expect to see more goodies in its upcoming releases. If you are still not sure which JavaScript editor you want to use, give Scripted a try!\n\n(`_|_`)Feb 11, 2013(`_|_`)ariya.io(`_|_`)javascript-editing-with-vmware-scripted', 'javascript-editing-with-vmware-scripted'),
(134, 'ECMAScript 6 and Destructuring Assignment(`_|_`)\n\n\nIn a programming language, destructuring assignment denotes the use of patterns to extract parts of an object. If we refer to Common LISP, destructuring assignment binds a set of variables to a corresponding set of values, where normally bind a value to a single variable. For the next-generation ECMAScript 6, destructuring feature is slated to be an important addition to the assignment expression.\n\nPython developers might be already familiar with the concept of sequence unpacking. CoffeeScript also already has the syntax for destructuring. SpiderMonkey, the JavaScript engine in Firefox, has been supporting destructuring assignment for a while. The latest ECMAScript 6 defines the grammar for destructuring assignment in Section 11.13.1. There are two different forms: array pattern and object pattern.\n\nArray Pattern\n\nVariables can be initialized in one go. The following two lines have the same effect, the first one is employing an array pattern.\n\nvar [m, d, y] = [3, 14, 1977];\nvar m = 3, d = 14, y = 1977;\n\n\nSwapping two variables is rather trivial, this one works just as expected. Internally, it does the sequence as if there is a temporary variable temp and the usual value exchange.\n\nx = 3; y = 4; [x, y] = [y, x]\ntemp = [y, x]; x = temp[]; y = temp[1];\n\n\nAnother typical use of array restructuring is for a function which has multiple return values. We don’t need to wrap it in an object anymore. Also, there is no need to accept all elements in the array.\n\nfunction now() { return [2, 6, 2013, 8, ]; }\nvar [m, d] = now(); // m = 2, d = 6\nvar [,,year] = now(); // year = 2013\n\n\nWith the syntax visualization feature of Esprima, it is rather easy to illustrate the syntax tree of an array pattern. The following figure shows an example thereof. Compared to a vanilla assignment or variable declarator, the obvious different here is that we have an array pattern instead of a plain identifier.\n\n\n\nObject Pattern\n\nThis pattern is very similar, except it works by matching object properties instead of array indices. Thus, we can easily pick the ones we are interested in while ignoring the rest. A similar example as before, e.g. when processing the return value of a function:\n\nfunction today() { return { d: 6, m: 2, y: 2013 }; }\nvar { m: month, y: year } = today(); // month = 2, year = 2013\n\n\nOf course, instead of a pattern, nothing stops you from assigning a holder object before accessing each property. However, the lack of such extra object makes the code looks cleaner (or sweeter, since destructuring is supposed to be a syntactic sugar), in particular when it is part of a loop.\n\nbooks.forEach(function ({ title: title, author: author }) { console.log(title, author) }; )\n\n\nIn the above construct, every element in that books array may contain a lengthy information about that particular book. Since we just want some properties, it is possible to extract them directly via the object pattern.\n\nIt gets even more interesting once we combine with array comprehension. For example, the following line is exactly the same as the above snippet:\n\n[console.log(t,a) for ({title: t, author: a} of books)];\n\n\nHow do you plan to (ab)use array and object pattern?\n\n(`_|_`)Feb 6, 2013(`_|_`)ariya.io(`_|_`)es6-and-destructuring-assignment', 'es6-and-destructuring-assignment'),
(135, 'Impact Factor(`_|_`)\n\n\nAs with many professionals, I am occasionally asked for some random career advice by a few young engineers. Since I am usually not the right person to ask, typically what I share are the thoughts and perspectives which I wish I had when I was still early in my career. One of them is the impact factor.\n\nPursuing the Trophy\n\nLike many other boys, high school time for you probably means running after the most attractive and charming girl/boy in the class. While you might enjoy the experience, you do need to realize that the rest of your life won’t be spent doing that kind of activity. The challenges in the next stages of life are completely different, anything from forging a long-lasting relationship to the constant-learning of good parenting.\n\n\n\nThe mantra of achieving early win in a new job often gets translated into being extremely competitive as early as possible. For young and inexperienced engineers, this could lead to being too conscious about the superficial impression. You don’t want to look mediocre and hence you spend the waking hours cranking out the most reliable code possible. You need to prove yourself and kickstart assorted imaginable activities although you quickly run out of time handling every aspect of the project.\n\nYou are thrilled to build a faster and better version of your nemesis’ project because obviously you need to be ahead of everyone else. You end up looking too much to the rear-view mirror, growing the (unconscious) fear of being defeated. Chasing the supreme qualities is the name of the game.\n\nAlchemy of Great Vision\n\nAt one point, this fast-paced juggling will not be sustainable anymore. You start to compete with a flood of young folks with the fresher and adaptive brain. There are evenings with family obligation, no chance for another round of hackathons (and pizza). A handful of emerging tools, which look alien to you, suddenly empower those youngsters and multiply their intellectual level. Your very own spells are outdated, the rusty magic wand starts to complain. Before you know it, yoga is more attractive to the decaying body than another adrenaline rush.\n\nAs you climb the career ladder, individual contribution and technical excellence are still implicitly demanded, they are however not the ultimate (instant) gratification. The goal shifts towards the impact on the team and the organization in general. Instead of coding the fastest possible implementation in a weekend, you are challenged to inspire your peers to build a long-lasting, maintainable project. While achieving an engineering marvel is still in the objective list, a smooth collaboration with the product team, marketing folks, and other stakeholders is higher on the priority. Racing alone to the finish line is a forgotten feat, handling the logistics of the entire troops marching to the conflict zone is the new valued skill.\n\nBeing the smartest is useful. However, a real-world battle is far from what Hollywood depicted in Rambo. Adept playmaking, instead of personal glory, is what elevates the game. Inspire others, promote collaborations, and maintain the positive attitude.\n\n(`_|_`)Feb 4, 2013(`_|_`)ariya.io(`_|_`)impact-factor', 'impact-factor'),
(136, 'ECMAScript 6 and Array Comprehension(`_|_`)\n\n\nMany modern programming languages support list comprehension, a concise way to create a list based another list where each entry is the result of some operations. If comprehension is used properly, it eliminates the need for the traditional and error-prone manual iteration. Next-generation JavaScript will have the similar feature via array comprehension.\n\nFirst of all, let’s do a quick refresh on Array’s map and filter functions.\n\nArray.prototype.map\n\nSection 15.4.4.19 of the official ECMAScript 5.1 specification defines the official behavior of Array.prototype.map. This function returns a new array resulting from applying the given callback function to each entry.\n\nTwo quick examples:\n\n[1, 2, 3].map(function (i) { return i * i }); // [1, 4, 9]\n[650,123,4567].map(String).join(\'-\'); // \"650-123-4567\"\n\n\nThis facilitates a one-liner to build a sequence of numbers:\n\nArray.apply(, Array(3)).map(function(x, y) { return y }); // [0, 1, 2]\n\n\nor even English alphabets ‘ABCDEFGHIJKLMNOPQRSTUVWXYZ’:\n\nArray.apply(, Array(26)).map(function(x,y) {\n  return String.fromCharCode(y + 65);\n}).join(\'\');\n\n\nFor other variants, see also Brandon Benvie’s usage of apply-map and Ben Alman’s Object.keys technique.\n\nUpdate: For details, see also my other blog post Sequences with JavaScript Array.\n\nArray.prototype.filter\n\nSection 15.4.4.20 of the official ECMAScript 5.1 defines the official behavior of Array.prototype.filter. As the name says, this function lets you include or exclude some entries of the array based on some certain criteria. Take a look at the following example:\n\n[1,4,2,3,-8].filter(function(i) { return i < 3 }); // [1, 2, -8]\n\n\nLet’s extend the previous sequence number generation, say to have only odd number:\n\nArray.apply(, Array(6)).map(function(x,y) { return y }).\nfilter(function(x,y) { return y & 1 }); // [1, 3, 5]\n\n\nWe can also do a complicated dance to print all consonants by excluding the vowels:\n\nArray.apply(, Array(26)).map(function(x,y) { return String.fromCharCode(y + 65) }).\nfilter(function(s) { return \'AEUIO\'.indexOf(s) <  }).join(\'\');\n\n\nReal-world applications are likely more practical than the above snippets. It could be something like:\n\n\nGive me the list of house prices in a certain ZIP code\n\nWhat is the total expense of our Engineering department?\n\nFind the best paid professions of Gen X\n\n\nArray Comprehension\n\nArray comprehension is a syntax feature which has been available in Firefox for a while. It is however not part of the 5th edition of ECMAScript and hence no other browser supports it. The good news is that array comprehension is being incorporated into the next ECMAScript 6. The latest 2012/12/21 draft includes the grammar of array comprehension in section 11.1.4.2. Update: The following code examples have been adjusted to follow the latest comprehension syntax (left-to-right).\n\nAn easy way to understand how array comprehension works is by comparing it with map and filter. See the following two lines, they give the same exact result. The second line is something you have seen in the previous map example.\n\n[for (i of [1, 2, 3]) i * i]; // [1, 4, 9]\n[1, 2, 3].map(function (i) { return i * i }); // [1, 4, 9]\n\n\nThe fun part is when you use two for clauses or more. The following line creates a list which contains the references to all 64 possible squares in a chess board, from ‘a1’ to ‘h8’.\n\n[for (x of \'abcdefgh\'.split(\'\')) for (y of \'12345678\'.split(\'\')) (x+y)];\n\n\nIf this still looks confusing, I highly recommend understanding the syntax tree, for example by using Esprima’s syntax visualization.\n\n\n\nNote: Firefox’s array comprehension also support for-in form (I am not sure whether this will make it into ES6). It can simplify some construct, generating a sequence of numbers can be rewritten as [j for (j in Array.apply(0, Array(3)))].\n\nFiltering using array comprehension is straightforward. Again, compare the two different forms here:\n\n[for (i of [1,4,2,3,-8]) if (i < 3) i];\n[1,4,2,3,-8].filter(function(i) { return i < 3 }); // [1, 2, -8]\n\n\nAnd the simplification of printing the sequence of all alphabets:\n\n[for (i of  Array.apply(, Array(26)).map(function(x, y) { return y; }))\nString.fromCharCode(65 + i)].join(\'\');\n\n\nand just the consonants:\n\n[for (j of\n  [for (i of Array.apply(, Array(26)).map(function(x, y) { return y; }))\n   String.fromCharCode(65 + i)]\n) if (\'AEUIO\'.indexOf(j) < ) j];\n\n\nAs an exercise, analyze the following expression. What it does is producing the list of all prime numbers less than 100. You can see that there is no need for a manual loop at all. Note that since we are talking about next-generation JavaScript, we also use the arrow function (Section 13.2) to shorten the incantation.\n\n[\n  for (x of Array.apply(, Array(99)).map((x, y) => y + 2))\n    if ([\n      for (i of Array.apply(, Array(1 + Math.round(Math.sqrt(x)))).map((x,y) => y))\n      if ((i > 1) && ((x % i) === ))\n      (x % i)\n    ].length === )\n  x\n];\n\n\nWith the support for array comprehension, JavaScript is getting more and more functional. If you come from Python, Haskell, Scala, or another modern language, you won’t feel so powerless anymore!\n\n(`_|_`)Jan 30, 2013(`_|_`)ariya.io(`_|_`)es6-and-array-comprehension', 'es6-and-array-comprehension'),
(137, 'W3Conf 2013(`_|_`)\n\n\nThis year starts with a good event, W3Conf, the annual W3C confer­ence for web pro­fes­sion­als. It will be held in San Francisco, 21-22 Feb. There are many interesting talks, featuring a few known experts in the field.\n\nThe event is also exciting for me because I have the opportunity to talk about Fluid User Interface with Hardware Acceleration. These days, there has been a variety of black magic tricks on the use of hardware acceleration, often centered around “use 3-d transform”. This talk gives a more fundamental understanding on how the browser rendering engine talks to the graphics processing (GPU) and explain what happens behind the scenes.\n\nRegister now and see you there!\n\n(`_|_`)Jan 28, 2013(`_|_`)ariya.io(`_|_`)w3conf-2013', 'w3conf-2013');
INSERT INTO `ariyaio` (`id`, `content`, `url`) VALUES
(138, 'Two Years of Wandering Headlessly(`_|_`)\n\n\n\nLine drawing of McDonnell Douglas F-4 Phantom II.\n\n\n\nIt has been two years since I decided to announce my fun WebKit tool and to run it as an open-source project, PhantomJS. Better than the situation a year ago, the traction is increasing as more and more users adopt PhantomJS as a helping utility for various web page automation tasks.\n\n\n\nProbably the total number of downloads is the easiest metric which demonstrates this. There have been a few releases since last year and the numbers look quite convincing. The mailing-list is also quite alive with a lot of interesting discussions while the members grows from 300 last year to 1020 to date. The code repository github.com/ariya/phantomjs attracts more than 4500 stargazers and hopefully someday it will appear in GitHub\'s Popular Starred hall of fame.\n\n\n\n\n\nOver a dozen test frameworks/libraries work well with PhantomJS. In addition to that, more high-profile FOSS projects are integrating PhantomJS in the testing workflow. So far we know that Bootstrap, CodeMirror, Ember.js, Less.js, Modernizr, YUI3, and Zepto.js are using it. This is particularly easy to achieve since PhantomJS is preinstalled on Travis CI, the continuous integration solution every cool kid uses these days. In a setup combining YUI Test, PhantomJS, and Grover, the YUI3 project runs millions of tests in the last few months.\n\n\n\nObviously you are not necessarily limited by Travis CI, there are other paid hosted CI systems with PhantomJS support, from Circle CI, Semaphore, Codeship (nee Railsonfire) and many others. For DIY solution, nothing beats spinning your own Amazon EC2 instance and run PhantomJS in the cloud, possibly using Jenkins or TeamCity. Too lazy to administer a virtual machine? Use IronWorker, it\'s dead easy and you will be up-and-running in 2 minutes.\n\n\n\nThese days, often people use PhantomJS indirectly. For example, there are projects like CasperJS and Poltergeist which turn PhantomJS into something more domain-specific. Grunt, the emerging JavaScript build tool, takes advantage of PhantomJS to run your unit tests. Furthermore, Grunt is in turn utilized by Yeoman for build-related tasks.\n\n\n\nTaking page screenshot is another popular use. We have seen how this is utilized to check site rendering at various screen resolution or even simulate the color blindness situations. There are tons of screen capture tools combining PhantomJS with anything from Django to Play framework.\n\n\n\nA whole new class of use cases was initiated with the initial WebDriver support. For those who invested heavily on Selenium, a complementary command-line solution is just a few tweaks away. There have been examples on using PhantomJS WebDriver feature with Ruby, Python, and even .NET.\n\n\n\nPhantomJS is of course far from perfect. The development progress is not as fast as we all want it to be, in particular because none of the contributors is paid to work on features and bug fixes. In fact, some of us are still in the zone which I denote as “negative spare time”. With a high adoption and a huge user demand, often the mailing-list and the issue tracker are flooded with discussions way more than what we can humanly handle. If you are passionate about web page automation and you are willing to spend some time helping this project, you are more than welcomed.\n\n\n\nMeanwhile, here is to another adventurous year! Stay hungry, stay headless.\n\n\n(`_|_`)Jan 23, 2013(`_|_`)ariya.io(`_|_`)two-years-of-wandering-headlessly', 'two-years-of-wandering-headlessly'),
(139, 'JavaScript Code Complexity Visualization(`_|_`)\nI have written about the concept and the tool for complexity analysis of JavaScript code before. In addition to that complexity monitoring strategy, apparently it is also useful to produce the so-called complexity report. Fortunately, now we have a visualization tool which allows us to prepare such a report.\n\nGiven a set of JavaScript files, Plato from Jarrod Overson (GitHub: github.com/jsoverson/plato) will happily consume it, run some analysis (using JSComplexity, among others), and output an interactive chart at your disposal. If you missed my previous post on code complexity, JSComplexity basically uses Esprima to parse your code, obtain the abstract syntax tree (AST), and then process it based on the complexity analysis algorithm.\n\nThere are some ready-to-enjoy exemplary Plato reports, such as the one for jQuery. The summary page, as shown below, is useful to give a quick comparison of the different source files, in terms of code complexity, lines of code (LOC), etc.\n\n\n\nClicking on one of the bars will open a detailed report. Particularly interesting here is the complexity distribution (depicted in a fancy donut chart) of various functions in that particular source file. Even better, when you choose a segment and click on it, it will jump to the source code directly.\n\n\n\nWhile the code view is beautiful (with syntax highlighting and such), an interesting feature here is the analysis overlay. If a function is marked with dotted border, you can hover there and there will be a nice analysis tip.\n\n\n\nIf you want try it yourself, Plato is very easy to use. Just install the plato package (you need Node.js) and you are ready to analyze your own code.\n\nWho says code analysis can’t be fun?\n\n(`_|_`)Jan 17, 2013(`_|_`)ariya.io(`_|_`)javascript-code-complexity-visualization', 'javascript-code-complexity-visualization'),
(140, 'Nexus 4 Web Performance Quick Check(`_|_`)\nUpdate: Read also the performance quick check of Nexus 5, the successor to Nexus 4.\n\nNexus 4 is the latest generation of stock Android smartphone from Google. It sells like a hot cake. The overall reception seems to be quite favorable (see the reviews from The Verge, Ars Technica, Wired, TechCrunch, and many others). How does it improve the web browsing experience compared to its predecessor, Galaxy Nexus?\n\nAs with my previous benchmarks with Nexus 7, Kindle Fire, and other smartphones, DOM performance has been always my favorite. I still believe that high-performance DOM access has an immediate positive impact on the browsing experience. Using the set of DOM core tests from Dromaeo, I obtained the following chart when running Google Chrome 18 (special thanks to Donald Carr for letting me playing with his Galaxy Nexus).\n\n\n\nIt is obvious that the performance is within 5% of each other. In fact, if we run another test suite, such as Octane benchmark for JavaScript-oriented performance check, we come up with a very similar chart.\n\n\n\nNow let us use Vellamo, the new mobile benchmark tool from Qualcomm (note that Vellamo mainly tests the built-in system WebKit library, not Chrome browser). If we run its overall HTML5 speed tests, the score will look like the chart depicted below. Apparently, if we take other aspects of the browsers (page loading, canvas rendering, image decoding, etc) into account, then Nexus 4 manages to score a narrow win.\n\n\n\nIt is clear that Nexus 4, armed with the latest quad-core Snapdragon S4 Pro clocked at 1.5 GHz, does not demonstrate a significant increase of firepower compared to its older sibling Galaxy Nexus, which only runs dual-core 1.2 GHz Cortex-A9 (TI OMAP 4460). We can certainly hope that future generations of mobile web browsers would take advantage of the presence of such extra CPU cores for parallelism and performance improvements.\n\nHow do you like your Nexus 4?\n\n(`_|_`)Jan 15, 2013(`_|_`)ariya.io(`_|_`)nexus-4-web-performance-quick-check', 'nexus-4-web-performance-quick-check'),
(141, 'TrueType Fonts and PhantomJS Crash(`_|_`)\nSome Mac OS X users of PhantomJS reported that it crashed every one and then. This also affects other related projects such as Poltergeist. A reduced test case revealed that it has something to do with the use of some TrueType fonts. I decided to investigate this issue and learned a few things along the way.\n\nThere are bad news and good news. The bad news is that I still don’t fully understand how and why this happens, in particular since I only set so much time during the holidays to track the problem. The good news is that the workaround exists, it is very minimal since all I need to do is to comment out one line of code.\n\nThe stack trace of the crash may vary, but one example looks like the following:\n\n#0  0x9254bd47 in objc_msgSend ()\n#1  0x0267b7b0 in ?? ()\n#2  0x9a9b8310 in TCFRetained<cgfont *>::Retain ()\n#3  0x9a947102 in TCGFont::TCGFont ()\n#4  0x9a946dee in TCGFontCache::CopyFont ()\n#5  0x9a946ca8 in TBaseFont::CopyNativeFont ()\n#6  0x9a955338 in CTFontCopyGraphicsFont ()\n#7  0x00bace39 in QCoreTextFontEngine::QCoreTextFontEngine ()\n#8  0x00bae0cb in QCoreTextFontEngineMulti::init ()\n#9  0x00baa530 in QCoreTextFontEngineMulti::QCoreTextFontEngineMulti ()\n#10 0x00ddb247 in QFontDatabase::load ()\n#11 0x00dc3e55 in QFontPrivate::engineForScript ()\n#12 0x00dd22da in QFontMetricsF::descent ()\n#13 0x00692f1b in WebCore::SimpleFontData::platformInit ()\n#14 0x00553cad in WebCore::SimpleFontData::SimpleFontData ()\n#15 0x0023cf2e in WebCore::CSSFontFaceSource::getFontData ()\n#16 0x0023702c in WebCore::CSSFontFace::getFontData ()\n</cgfont>\n\nNote the suspicious CTFontCopyGraphicsFont. I believe this function should not crash at all, but maybe it just follows the expected behavior of wrong reference counting (again, how this is even possible is beyond my imagination). The mysterious thing, as evidenced from the test case, is that it does not happen all the time. There is an exact sequence (could be one of the many possible others) which lead to the crash. Apparently, PhantomJS is not the only one affected by this. There is an upstream QtWebKit bug which tracks the issue. For Qt 5, the crash will never happen thanks to the use of QRawFont.\n\nA little bit context about Qt font handling follows (this is obviously an oversimplified version). Everytime a font needs to be handled (e.g. looking up its metrics, drawing a text using that font, etc), a query is made to the font database (QFontDatabase). This database has a cache mechanism to minimize creating the font data and platform-specific font engine for every possible font combination of family, weight, style, size, etc. The font cache is however invalidated (and thus becomes completely empty) every time a new application-specific font is added or removed. With some TrueType fonts, removing the font data and recreating it again apparently causes the above crash. I thought it was because of a mishap with the reference counting (mismatched of CFRetain and CFRelease), but strangely it does not happen with every single font, only with particular fonts (consistently reproduceable).\n\nMy workaround is simply to break that crash sequence, i.e. avoiding the removal of the font from the font database. This leads to some small leak of font data. It is not a disaster since we don’t expect PhantomJS to be used in a long running process. In addition, with some popular sites I have tried with, there are only few cases (like The Verge) where more than 4 custom fonts are being used.\n\nA patch release, PhantomJS 1.8.1, has been rolled out to fix this crash problem. If you are using PhantomJS on OS X, get this release immediately.\n\n(`_|_`)Jan 8, 2013(`_|_`)ariya.io(`_|_`)truetype-fonts-and-phantomjs-crash', 'truetype-fonts-and-phantomjs-crash'),
(142, 'Software Maintenance and Self-Restraint(`_|_`)\n\n\nMany articles have been written about some unacceptable elitist behaviors of software maintainers and other project leaders. I couldn’t agree more, I think nobody should be a jerk. On the other side of the story, do you ever wonder what kind of problems a maintainer usually encounters in his daily routines?\n\n\n\nThis question is harder to answer, particularly since not everyone ever maintains a software project (while almost everybody is a user of one or more software). From years of observing many different communities, and also from my own experience, this a typical list I can come up with. Note that some parts are biased towards FOSS (free/open-source software).\n\nDemanding users. As soon as an application gains some traction, it is almost guaranteed that some users will start to ask for unreasonable things. Many times a maintainer will be requested to solve the design or architectural problem of the user’s project. The line which defines the responsibility often gets blurred.\n\nImpatient (potential) contributors. Just because a project is hosted on GitHub, it does not mean somebody can create a patch, submit a pull request, and expect it to be immediately accepted. There are still house rules, everything from the testing workflow to the commit log format.\n\nOpinionated, non-constructive rant. Someone looks at the project for 10 minutes, decides that it doesn’t satisfy him, and then ends up writing a philosophical dissertation about it. Aggressiveness and drama do not bring anything anywhere.\n\nNote that some activities above can be still helpful, it always depends on the context. And obviously, there is no strong reason to be extremely upset if such things occur in our life.\n\nBeing Positive\n\nIf you are a project maintainer, what would be the best strategy to handle such an influx of negative energy? Here are my tips, feel free to share yours.\n\nEstablish an explicit contract. For example, if you are doing this on your spare time, simply state the situation. Who am I to judge when you prefer to spend time with the family instead of fixing a bug?\n\nNever take it personally. When an expectation is not fulfilled, it is very natural to find a scapegoat. Human has a knack for passing the frustrating problem to someone else down the food chain. Often, you just happen to be in the wrong place at the wrong time.\n\nFocus on things that matter. If you are tempted to respond to every single attack on Hacker News, you are doing a disservice to your happy users. Critics are important but they should never redefine who you are or even reschedule your priorities.\n\nTake some time off. Surprisingly, life goes on even if you stop doing anything anymore. It’s just a piece of software, if it gets abandoned then someone will pick it up and continue where you left off. No pressure!\n\nSoftware maintenance is a nice exercise to self-restraint. As with any other emotional exercises, it will make you a better person. Remember that maintaining a software project is an honor. For an open-source project, it is an important mission to the community.\n\nStay hungry, stay passionate!\n\n(`_|_`)Jan 3, 2013(`_|_`)ariya.io(`_|_`)software-maintenance-and-self-restraint', 'software-maintenance-and-self-restraint'),
(143, 'PhantomJS 1.8 \"Blue Winter Rose\"(`_|_`)\n Photo by christopher goodband CC BY-SA 2.0.\n\nWinter is coming. The recent December solstice occurred on Dec 21 where I also tagged version of 1.8.0 of PhantomJS, headless WebKit for page automation. The code name for this release is Blue Winter Rose, as chosen by Ivan:\n\n\nBael the Bard climbed the Wall.\n\nTook the Kingsroad and entered Winterfell.\n\nHe made himself known as Sygerrik of Skagos, a singer.\n\nHe sang until midnight for the Lord’s pleasure.\n\nImpressed by his skills, Lord Brandon Stark asked him what rewarded he wanted.\n\nBael asked for the most beautiful flower in Winterfell’s gardens.\n\nBlue winter roses were just blooming.\n\nBrandon Stark agreed to offer him one.\n\n\nOne of major highlights in this 1.8 release is the integration of Ivan’s excellent project Ghost Driver. It is an implementation of WebDriver Wire Protocol on top of PhantomJS. Selenium users might be excited because now there is also an easy way to run your tests without launching a browser. Thanks to the integration, setting up PhantomJS as a remote WebDriver is ridiculously trivial:\n\nphantomjs --webdriver=9134\n\n\nYou can control this from many different environments, from Ruby to Java. As also mentioned in the release notes, here is a Ruby example (pardon my slight deviation from the classic Cheese example):\n\nrequire \"selenium-webdriver\"\ndriver = Selenium::WebDriver.for(:remote, :url => \"http://localhost:9134\")\ndriver.navigate.to \"http://google.com\"\nelement = driver.find_element(:name, \'q\')\nelement.send_keys \"PhantomJS\"\nelement.submit\nputs driver.title\ndriver.quit\n\n\nHere is another simpler example in JavaScript using Node.js and the WebDriver module:\n\nvar wd = require(\'wd\');\nvar driver = wd.remote(\'localhost\', 9134);\n \ndriver.init(function() {\n    driver.get(\"http://casperjs.org\", function() {\n        driver.title(function(err, title) {\n            console.log(title);\n        });\n    });\n});\n\n\nBecause of the setup, running via PhantomJS is typically faster for many types of test scenarios. Of course, it does not eliminate the need for a comprehensive cross-browser testing. Rather, use it as an additional development helper, particularly with the strategy of multiple layers of defense.\n\nLast but not least, here is the chart comparing the total downloads of some recent releases.\n\n\n\nI’m fairly sure that some of the downloads are caused by automatic PhantomJS installation for some continuous integration workflow. Nothing is wrong about that of course. On the other hand, looking at tons of recent blog posts/articles about PhantomJS, obviously we get more and more (happy) users.\n\nMany thanks to everyone who contributed to this release. You guys rock!\n\n(`_|_`)Dec 23, 2012(`_|_`)ariya.io(`_|_`)phantomjs-1-8-blue-winter-rose', 'phantomjs-1-8-blue-winter-rose'),
(144, 'Complexity Analysis of JavaScript Code(`_|_`)\nNobody likes to read complex code, especially if it’s someone’s else code. A preventive approach to block any complex code entering the application is by watching its complexity carefully.\n\nThere are many measures of code complexity, the popular ones are McCabes cyclomatic complexity and Halsteads complexity. For JavaScript applications, there is a new tool from Phil Booth called JSComplexity which can be used to analyze your code and find out the complexity measures. Besides the above two code metrics, JSComplexity also produces the logical line of code (LOC) and the overall maintainability index. There is a whole page dedicated to explain the definition of these metrics and how they are computed.\n\nJSComplexity can be used online via its web interface. Just paste your code and it will show you the analysis result. Under the hood, JSComplexity uses Esprima to parse your code and get the abstract syntax tree (AST). The syntax tree is then traversed according to the complexity analysis algorithm. For command-line use, you can use complexity-report package for Node.js.\n\nCyclomatic complexity is particularly interesting because (in laymen’s terms) it maps to the craziness of your program flow. If the code has tons of branches and paths, your cyclomatic complexity is catapulted to the sky. For the fun of it, here is the chart showing the cyclomatic complexity of some popular JavaScript libraries.\n\n\n\nOf course, just like any other code metrics, code complexity should not be treated religiously. We also don’t have to think about complexity only in a one-dimensional way. In fact, correlating complexity with other variables usually reveals a much more useful insight. For example, plotting cyclomatic complexity vs time will display the dynamics of the code as the engineers refactor some parts or rewrite other stuff. Mapping complexity with different modules may give some hints as to which modules still need more TLC.\n\nUse complexity measures to your advantage and hopefully you are better prepared in the battle zone!\n\n(`_|_`)Dec 20, 2012(`_|_`)ariya.io(`_|_`)complexity-analysis-of-javascript-code', 'complexity-analysis-of-javascript-code'),
(145, 'Ant Task to Validate JavaScript(`_|_`)\nApache Ant is quite popular for automating build-related tasks, especially in the enterprise environment and continuous integration systems. Many organizations which already standardized on Ant and start to adopt web application development would want to explore the possibility of keeping Ant for a variety of JavaScript-related workflow. One of the tasks is to ensure that the JavaScript program is syntactically valid. It turns out that this is not difficult at all.\n\nA few weeks ago, I have written about validating JavaScript files from the command-line, text editor, git pre commit hook, or continuous integration system. In this installment, we will expand the approach so that the syntax verification can be invoked as an Ant task. So that you can follow along, I have prepared a git repository, github.com/ariya/ant-javascript-validate, which serves as a complete example.\n\nThe working principle is very similar as the previous blog post. We utilize the power of Ant scripting feature and ince Bean Scripting Framework (BSF) supports running JavaScript code (using\n\nMozilla Rhino under the hood), we will use it to run Esprima-based syntax validator. For convenience, this will be wrapped as an Ant task called jsvalidate.\n\nThe example repository demonstrates the usage. After you clone the repo, all you need to do is running:\n\nant validate-javascript\n\nwhich will give an output similar to this:\n\nvalidate-javascript:\n[jsvalidate] /Users/ariya/ant-jsvalidate/src/invalid.js:\n[jsvalidate]   Error: Line 1: Missing catch or finally after try\n[jsvalidate] /Users/ariya/ant-jsvalidate/src/strictmode-invalid.js:\n[jsvalidate]   Line 3: Octal literals are not allowed in strict mode.\n[jsvalidate]   Line 4: Parameter name eval or arguments is not allowed in strict mode\n[jsvalidate]   Line 5: Parameter name eval or arguments is not allowed in strict mode\n[jsvalidate]   Line 6: Strict mode function may not have duplicate parameter names\n[jsvalidate]   Line 7: Parameter name eval or arguments is not allowed in strict mode\n[jsvalidate]   Line 8: Function name may not be eval or arguments in strict mode\n[jsvalidate]   Line 9: Function name may not be eval or arguments in strict mode\n[jsvalidate]   Line 10: Use of future reserved word in strict mode\n[jsvalidate]   Line 10: Strict mode code may not include a with statement\n\n\nIf you open build.xml, here it is obvious that validate-javascript is the target which uses jsvalidate task to run the syntax validation on every *.js files under a specific directory. Obviously, you can tweak it to suit your application configuration.\n\nThe implementation of jsvalidate task itself is very simple, just about 50 lines. The spirit its very much the same like the command-line tool esvalidate (part of Esprima). Given the file set, read the content of every file, check the syntax, and shows the errors (if any). Esprima code is loaded by reading lib/esprima.js and evaluate it. The included report is minimalistic but informative. If there is at least one syntax error, the task will be marked as failed. As an exercise for the reader, tweak the task so that you can output the validation result in the format of JUnit XML.\n\nWho says Java and JavaScript can’t live together in harmony?\n\n(`_|_`)Dec 12, 2012(`_|_`)ariya.io(`_|_`)ant-task-to-validate-javascript', 'ant-task-to-validate-javascript'),
(146, 'JavaScript Code Coverage with Istanbul(`_|_`)\nAchieving a good code coverage is a useful practice in today’s software craftsmanship. For JavaScript applications, whether it is for the browser or for the server, many tools to check the statement coverage are available. What about branch coverage? Fortunately, such a tool is finally available: Istanbul.\n\nMade by Krishnan Anantheswaran from the YUI team Yahoo! Cocktail team, Istanbul is extremely easy to use. It is suitable for both browser-based instrumentation or Node.js application analysis. Under the hood, Istanbul uses Esprima to parse JavaScript code and Escodegen to generate the instrumented version of the code. Istanbul is pure JavaScript, there is no native code or other kind of native libraries wrapper involved.\n\nIstanbul requires Node.js, the package can be installed as:\n\nnpm install istanbul\n\nUsing Istanbul with command-line Node.js application is fairly straightforward. Assuming you have test.js like this:\n\nx =42;\nif(false)\n     x =-1;\n\n\nWe can analyze the coverage by running:\n\nistanbul cover test.js\n\n\nwhich gives the following outcome:\n\n=============================== Coverage summary ===============================\nStatements   : 66.67% ( 2/3 )\nBranches     : 50% ( 1/2 )\nFunctions    : 100% ( 0/0 )\nLines        : 66.67% ( 2/3 )\n================================================================================\n\n\nEven if you put all the above code in just one line, Istanbul can still give the correct coverage result. This is because Istanbul does not work based on line-by-line coverage, it does fully understands JavaScript syntax. Beside the quick text-based report, Istanbul also produces the coverage report in LCOV format. This way, the coverage report can be nicely shown, with color coding and other fancy features:\n\n\n\nWhat about something more complicated? I wrote some time ago about the trap of checking only statement coverage, the example which demonstrated that is the following fragment. Now, if your unit test only verify the result of running inc(4) and you forgot you also need the check for inc(4,2), you won’t see the bug easily. This example is of course just an oversimplified example, in real-world application the problem is much harder to spotted.\n\nfunction inc(p, q){\n    if(q ==undefined) q =1;\n    return p + q/q;\n}\n\n\nHowever, if we run Istanbul so that we can see the branch coverage, the report reveals the issue. Here the marker ‘E’ indicates that the else path of the branch is never executed and that should provoke a suspicion.\n\n\n\nHow does Istanbul work under the hood? It takes a JavaScript program and passes it through Esprima to get the syntax tree. Then, it injects some instrumentation by wrapping various syntax constructs. After that, a new JavaScript program is generated from the syntax tree by using Escodegen. When the program runs, the injected annotation is also executed accordingly and thereby the statistics of the program execution can be gathered.\n\n\n\nWhile Istanbul has a mechanism to automate running Node.js application with instrumentation, nothing stops you from using the instrumented code in other JavaScript environments (such as web browsers). For this purpose, Istanbul has a special instrument command to perform only the instrumentation. It is up to you to process the coverage hooks and reports.\n\nWith Istanbul, tracking JavaScript code coverage has never been easier!\n\n(`_|_`)Dec 5, 2012(`_|_`)ariya.io(`_|_`)javascript-code-coverage-with-istanbul', 'javascript-code-coverage-with-istanbul'),
(147, 'JavaScript Performance Analysis: Sampling, Tracing, and Timing(`_|_`)\n\n\nPerformance optimization of web applications is a hot topic these days. One of the related areas is of course optimizing the application code itself. For client-side application running in the web browser, this means speeding-up JavaScript code whenever possible. Premature optimization is not a good practice, it is crucial to locate which parts cause the slow down and need some improvement. Enter the logical first step of every optimization: initial performance analysis.\n\nSampling\n\nAre you familiar with a JavaScript profiler? Many modern browsers already include a very useful profiler to look for JavaScript performance problem. The workflow is like this. First, you press a button to start the full performance monitoring of your application. After the application runs for a while, you can press another button to stop the monitoring. The outcome is something top-down like the following screenshot, the breakdown gives a very useful information on where your application spends the most time.\n\n\n\nUnder the hood, activating the monitoring causes the JavaScript engine to kick an sampling profiler. It is named that way because the profiler will look at the state of the virtual machine at a predefined interval, e.g. 1 ms in case of V8. The important state information will be collected and later it will be used to construct the profiling view as depicted in the above screenshot.\n\nWhen carrying out a profiling like this, be advised of the observer effect. The extra monitoring adds a certain overhead to the code execution and hence, the actual timing would be different to the case where there is no instrumentation at all. The difference is usually minimal, in particular since the entire application is affected. Yet, take that into account as you move forward to make any conclusion.\n\nTracing\n\nWhile timing information obtained from the profiler is useful, sometimes you are also interested not in how fast a certain operation is carried out, but also what happens during that time. This is like doing an X-ray on your program execution. Fortunately most modern browsers support the console API console.trace will give you exactly that information:\n\n\n\nAnother way to gather the traces is by instrumenting the JavaScript source. This is a technique I’ve used to find out the exact execution sequence when an application starts. For example, in that experiment I found out that a simple jQuery Mobile site will invoke over 4000 function calls. Note that the number of calls itself does not tell you much. However, tracking this over time, or even for every check in, can be really helpful. For example, if suddenly someone commits a bug fix which brings the function calls to 8000, this should trigger a red flag. That can be one of your protective multilayer defense.\n\nScalability is another excellent area of application tracing. If you have an address book application, sorting the contacts the alphabetically can be really fast if you only have 10 entries. However, here you are not interested in the absolute time of the sorting. You also want to know how it handles the address book with 100 entries, 1000 entries, and so on.\n\nFormal analysis of the complexity can be complicated or prohibitively expensive. This is where empirical run-time analysis kicks in. For example, you can instrument Array#swap and plot the number of function calls vs address book entries. If your team member implemented it using bubble sort instead of something faster like binary sort, that chart will reveal it.\n\nTiming\n\nAfter you locate the problematic spot in the performance, the next step is obviously to fix it. In many cases, speeding up some parts of the application is not really difficult. In other cases, you have to try different strategies and see which one fits the performance criteria. Often, it is as simple as figuring out which implementation is the fastest. This is where timing the execution of a function is useful.\n\nAccurate timing is far from trivial, this has been covered in many articles, e.g. Bulletproof JavaScript benchmarks. Unless you have a lot of time to learn statistics and uncover cross-browser secrets, it is easier to use a ready-made benchmark library such as Benchmark.js. For a quick comparison, using the popular JSPerf (which uses Benchmark.js under the hood) is highly recommended. You would also have the chance to try it on different browsers and devices, just to ensure that your strategy is not biased towards a particular implementation.\n\n\n\nAddendum: Pay attention to timing accuracy and precision! You need to measure the right thing (accurate) and with a confident level of repeatability (precise).\n\nBeside careful timing, it is also important to pay attention to the benchmark corpus. Whenever possible, choose something which resembles its real-world usage. For example, if you try different ways to sort the contacts in the address book application, make sure you supply a representative list for the benchmarks, more than just a useless array of [\'a\', \'b\', \'c\'].\n\nLast but not least, remember that optimization is not the destination, it is a journey!\n\n(`_|_`)Dec 3, 2012(`_|_`)ariya.io(`_|_`)javascript-performance-analysis-sampling-tracing-and-timing', 'javascript-performance-analysis-sampling-tracing-and-timing'),
(148, 'Quality Code via Multiple Layers of Defense(`_|_`)\nHave you written a book, a dissertation, or a report? If you prepare well, everything should be almost perfect until you need to submit it to the editor, the professor, or the supervisor. In fact, almost likely you will read the manuscript again and again, just to ensure that there is no silly mistake, from typos to missing figures, which can be spotted easily in the draft. Before the document is going through another stage of proof-reading, you want to know as early as possible if something needs some fixes.\n\nFortunately, the same “multiple layers of defense” strategy applies to modern software development. For example, even though the compiler will scream at you if your code does not make sense, there is no reason to skip fixing it, if you happen to see it on your editor. Many complex application requires a rigorous testing procedure, yet it does not harm anyone to run the application through a fast smoke testing first. In fact, by the use of git pre-commit hook, you can run the smoke test before the defective code gets landed in the repository.\n\n\n\nThe principles are summarized as:\n\n\nIf you screw up, you want to know earlier than later\nThe first layer should have the lowest cost and effort\n\n\nFor client-side web development, this approach can be a time-saving. When you are in the coding stage, ideally the editor or the IDE which you use would give an instant feedback whenever there is something suspicious. It does not need to catch all possible cases, it has to be just good enough to filter the most common mistakes. If you leak a variable and it pollutes the global, there is no need to launch the unit tests before it gets caught.\n\nUsing CoffeeScript/Dart/TypeScript? Verify the compiled JavaScript with a syntax validator (because those code generators sometime have bugs, too). If you don’t use strict mode properly, there is no reason to wait for the full-blown QA workflow which involve a dozen web browsers (possibly even cloud-based) to kick in and then tell you that something is wrong. If your template handling does not produce the right DOM element, there is no use of running the functional tests on a whole set of mobile devices.\n\nJust like a bodyguard, your layers of protection can be very subjective. Newbies may want more aggressiveness so that they can reduce the mistake probability. A typical configuration of those layers may look like the following:\n\n\nEditor/IDE with real-time code inspection\nSyntax validator\nGit pre-commit hook\nQuick headless testing\nMetrics guard, e.g. for code coverage\nSelenium-based comprehensive testing\n\n\nThis also demonstrates that an overlapping functionality does not always mean a substitution. Many tools complement each other quite well. Just because you have 100% code coverage does not mean you can’t benefit from a blazing-fast syntax error checking. Even if you aim to support legacy browsers, it does not mean you exclude yourself from doing headless testing.\n\nEveryone makes mistakes. Fix them quickly and move on.\n\n(`_|_`)Dec 1, 2012(`_|_`)ariya.io(`_|_`)quality-code-via-multiple-layers-of-defense', 'quality-code-via-multiple-layers-of-defense'),
(149, 'IE 10 Web Performance Quick Check(`_|_`)\nMicrosoft finally made Internet Explorer 10 available for Windows 7. It is still in the preview stage, however I’m already curious about its performance characteristics. I decided to run some quick check to see how it stacks up. The test machine is an average Toshiba laptop (Core i3, 2 GHZ) running a fully up-to-date Windows 7 Home Premium (with SP1).\n\nLike what I did with Nexus 7, other tablets, and various smartphones, my first interest is (always) in the DOM performance. Many rich/interactive sites and single-page web application still benefits a lot from a speedy DOM manipulation. I ran the quick Dromaeo DOM core tests and here is the result (longer is better). Firefox is the undisputed, Internet Explorer is unfortunately not in the same ballpark.\n\n\n\nMicrosoft always claims that the graphics performance of Internet Explorer is really good. Fortunately for us, this is not a baseless claim at all. Running my underwater demo, which stresses the speed of pixel manipulation in HTML5 Canvas, proves that the statement holds water. The chart follows.\n\n\n\nSome time ago Mozilla released Kraken, the benchmark suite geared towards the representation of code patterns found in real-world application (shorter is better). Firefox and Chrome dominate, Internet Explorer is twice as slow (although it manages to beat Opera).\n\n\n\nFor pure JavaScript performance, many others have tested various Windows browsers with SunSpider, V8, or Octane benchmarks. I opted for something different, i.e. running a parser written in JavaScript. This is easy via the online Esprima benchmark. It exercises string processing, object construction, and recursive functions call. The chart below demonstrates that Internet Explorer 10 still needs to catch up.\n\n\n\nWindows 7 is still used by millions desktops users, having many choices of fast browsers would be delightful to those users. Hopefully Microsoft would address some of these performance issues in the final release of Internet Explorer 10.\n\n(`_|_`)Nov 26, 2012(`_|_`)ariya.io(`_|_`)ie-10-web-performance-quick-check', 'ie-10-web-performance-quick-check'),
(150, 'Polluting and Unused JavaScript Variables(`_|_`)\n\n\n\n\nThere are two common mistakes when handling JavaScript variables, accidentally making a variable global and declaring a variable which is never used anywhere. Many well-known code linters can warn the developers when those cases are observed. How does the detection process actually work?\n\n(The leakage sign was made by Robert Ingil)\n\nGlobal Pollution\n\nLet us see the first one, the case of global pollution. A code fragment which demonstrates the issue follows:\n\nvar height;\n// some fancy processing\nheigth = 200;\n\n\nDue to a spelling mistake, the value is assigned to some variable different that what it is declared in the first line. Checking for this case is rather easy. As long as we get the AST (abstract syntax tree) of the code, we can look for such an assignment. The syntax tree itself is relatively trivial to obtain, we just pass the code to a parser like Esprima. Walking the syntax tree, we keep track of variable declaration so that we can cross-reference it within any assignment (of course, we must take into account complications such as variable hoisting and function scope). In fact, there is a tool that does these verification steps, it’s called leaky, made by David Björklund. It must be used with Node.js and the package can be installed easily with\n\nnpm install leaky\n\nThe above mentioned logic, along with the syntax tree traversal, is less than 100 lines. Running leaky with the previous example code gives this output:\n\ntest.js:3\nheigth = 200;\n^\nLeakError: global leak detected: heigth\n\n\nIf you develop an application or a library, this leak detection is suitable to be inserted in your testing workflow. A non-zero exit code is used to indicate that there is something wrong. Thus, the test section in your package.json could be something like:\n\n\"scripts\": {\n  \"test\": \"leaky mycode.js && node run-tests.js\"\n}\n\n\nIf you update your code and it unintentionally leaks some variables, your test won’t even run as leaky will block further steps until the situation is resolved. Obviously, you could also plug the check as part of your git pre-commit hook.\n\nNow, there can be few corner cases of global polluting which won’t be detected purely by static analysis. In that case, it is suggested to use strict mode so that such a pollution will be caught at run-time.\n\nUnused Variables\n\nFor the second case, declaring a variable which is never used anywhere, the principle is surprisingly quite similar. Here we need to do the opposite because a variable needs to be marked as used if it is encountered in an expression. While we still need to traverse the syntax tree, it will require more steps as every possible usage of a variable, from the loop initializer to postfix operation, needs to be verified. All in all, the implementation won’t exceed 200 lines as demonstrated by the unused project from Tomaz Muraus and Roman Shtylman. Again, Node.js users can get the package easily via:\n\nnpm install unused\n\nRunning it on the previous code fragment shows before gives:\n\ntest.js\n     height - on line 1\n\n\nMost certainly, this tool can be used on a much more complicated code. In addition, an unused function argument can be valid, in particular when the function is part of the callback. For example, see the following block:\n\n[4, 5, 6].forEach(function (value, index) {\n    console.log(index);\n});\n\n\nIn this case, value will be correctly reported as being unused. However, it is perfectly valid to keep it in that construct. Fortunately, unused can be invoked with an additional command-line parameter which would ignore specific argument (place)holders.\n\nJust like leaky, it is perfectly reasonable to include unused as part of your development workflow, either within the test procedure or the pre-commit hook, or even integrating it as your editor’s behavior.\n\nTry leaky and unused on your favorite application code and see if they show something interesting!\n\n(`_|_`)Nov 22, 2012(`_|_`)ariya.io(`_|_`)polluting-and-unused-javascript-variables', 'polluting-and-unused-javascript-variables'),
(151, 'Checklist vs Mission(`_|_`)\nImagine the following situation. Your little brother starts to smoke cigarettes and your parents are worried about that. As you are close to him, they ask you for your help. The goal is to have your brother stop smoking. What would you do?\n\nA straightforward, pure logical way of convincing your poor brother to avoid smoking is by collecting a stack of medical research paper containing the encyclopedic proof of all negative effect of cigarettes. It is very unlikely that this strategy will be successful. And if it does not work, your parent won’t be happy about it. However, you can shrug off and walk away, claiming that you have done your part. This is the exact mentality if you only want to get rid of the burden you bear. Your objective from the very beginning is sadly only to mark an item in the checklist.\n\nThings will be different if you are committed to a mission. Now the game play is different. You will do an extensive research on why things happened in a certain way. You will ask around, perhaps checking some of your brother’s close circle, and collect a better understanding of the sudden behavior change. You are doing your best to maximize your chance of success, regardless whether you can achieve the ultimate success or not (some things are beyond your power).\n\nThe same philosophy applies to software development as well. A sprint can fail miserably if everyone carries out a task so that he can have something to say in the next day’s scrum meeting, the goal is shifted from “creating a solid product” to “working on FooBar so I won’t get fired”. A testing workflow can be very ineffective if every quality engineer looks forward to fill the test worksheet as much as he can, the objective is no more “ensuring high-quality product” as it is merely “checking all the marks in the plan”. An engineering organization can disintegrate quickly once each VP only optimizes for the annual target, the responsibility gets degraded from “promoting a great team” to “making hay while the sun shines”.\n\nNext time you want to respond to an idea, to propose a new change, to share an interesting development, or just to defend your own opinion, think about it again: is this part of your (life) mission or is it only to cross an entry from your checklist?\n\n\n\n(`_|_`)Nov 20, 2012(`_|_`)ariya.io(`_|_`)checklist-vs-mission', 'checklist-vs-mission'),
(152, 'Language Tools for Reducing Mistakes(`_|_`)\nAn engineer relies on his best tools to carry out tasks which are repetitive, error-prone, or time consuming. For a software engineer, an advanced language tool can improve his life. One of the immediate impacts of using the right tool is the reduced amount of mistakes.\n\nThe following picture is something I have shown to some people, including when I did my EmpireJS talk some weeks ago. It looks rather cryptic and I think my 30-second explanation never conveyed the real message of the diagram. Hopefully the following description is easier to understand.\n\n\n\nThe charts basically show the contour lines of the mistake probability as a function of application complexity (vertical axis) and developer skill (horizontal axis). The zone where the mistakes are less produced is where the happy cat is located. The opposite of this is obviously the disaster area where there is nothing but mistake, one after another. When a tool is used to reduced coding mistakes, the contour map is transformed from the left chart to become something like in the right side. In other words, the tool is successful if it enlarges the area where mistakes are low.\n\nWe can imagine a situation where a genius programmer, perhaps also a coding ninja, does not really need an advanced tooling to build an application. Yet, as the complexity of his application increases, he will become more and more vulnerable to mistakes. There is a physical limitation of human brain, at one point something will crack. I don’t know about you but I have witnessed seasoned developers making stupid little mistakes, sometimes when using their own framework (ironic, isn’t it?). Heck, even a chess champion may enjoy a serious blunder from time to time.\n\nGranted, when the developer is not as skilled, he is at a disadvantage compared to his ninja-grade coworker. Even if the application does not really get too complicated, he will be exposed to various traps, the ones which someone usually manage to avoid based on the past experiences. For a really really newbie, the collection of rookie’s mistakes is waiting patiently in that dark corner, ready to jump at any moment of weakness. For this group of developers, a proper development tool is very valuable so that their destiny becomes something like the one depicted in the right contour map. Mistakes might still happen, but the overall situation is not as bad as in the left chart.\n\nThe fact that a tool might improve the development workflow is often forgotten if one sees it only from a one-dimensional point of view. For example, a veteran hacker can have a knee-jerk reaction “I don’t need a stinking IDE, I live and die with my Vim” because he projects the value of such an IDE in his own skill axis. Even then, if we enlarge that particular skill corner, people with different Vim skill can use a variety of scripts to improve their life. For example, plain vanilla Vim is useful yet many developers become more productive with additional time-saving functionalities, anything from a fast file navigation to an easy-to-use syntax validator. The same goes for the common phenomena when a new stuff is announced (whether it is a programming language or a development paradigm): a lot of snarky comments. While some of the them are just random short-term poking fun or a show of passionate analysis, a few other opinions are dangerously in the border between militant and passive-aggresive.\n\nThe key is here is simple, let us think about other people. Take a look at JavaScript, an expressive language which is easy to learn. Nothing is more rewarding than making a little JavaScript application which does a simple task. Yet, there are gotchas and latent pitfalls in many places. We may not be able to help those who do not posses basic computer science skills, but there are many programmers out there who are capable enough to carry out complex web development even though they don’t have rockstar-esque expertise. This is of course not a question of intelligence (again, another overrated one-dimensional axis). Your mentor at the local chess club isn’t always a grandmaster and your physics professor didn’t always have his internship at CERN. Not everyone has a photographic memory and remembers everything from the 258-page ECMAScript 5.1 specification.\n\nNext time someone steps up and promotes a way to improve someone’s coding quality, think about the beyond-the-horizon implication. Like Jason Fried once wrote, give it five minutes, because the right idea could start out life as the wrong idea.\n\n(`_|_`)Nov 12, 2012(`_|_`)ariya.io(`_|_`)language-tools-for-reducing-mistakes', 'language-tools-for-reducing-mistakes');
INSERT INTO `ariyaio` (`id`, `content`, `url`) VALUES
(153, 'Optimization: Journey vs Destination(`_|_`)\n\n\nEven though modern computing hardware is getting faster by days, the performance of a software starts to be treated as a feature. Optimization effort, whether it is for mobile applications or for high-volume web sites, generates tons of jobs in the industry. Squeezing the last drops of performance becomes a hot trend.\n\nWhat I learn from several large-scale software projects is that optimization should be treated as part of the journey. It is not a goal per se, your destination is not to reach the intended performance criteria. If we draw the quadrant of maintainable vs optimized code, we may end up like the following diagram. Note that the dichotomy does not always apply in real-world; for this purpose however, it does illustrate the point.\n\n\n\nIn the beginning…\n\nObviously, the dream of every software team is to produce a very readable code which also performs magically well. This may not be always the case, in particular because not every engineer is a rock star. High performance code that is also easy to follow is an ideal case and if you can hit that on the first attempt, keep up the good work.\n\nAnother scenario is where you start from a clean implementation of a concept. This version follows the design faithfully, it does resemble the vision of the product. Since it comes pretty much fresh from the specification, the code is optimized for conformance and not necessarily for speed. At this point, the fun with the optimization begins. Steps are taken to ensure that the performance is getting some improvement along the way. This is the journey denoted with the the green arrow in the above diagram.\n\nAn equally challenging starting point is when there is already a fantastic piece of code which runs extremely well. However, that code is badly written, hard to digest, not well commented, or simply unmaintainable (or worse, the combination thereof). This often happens as the organization adopts a foreign library, e.g through an acquisition. The usual clean-up kicks in and the code will be refactored so that it adheres to the new hygiene, as depicted by the blue arrow in the illustration.\n\nThe final possibility is when you have to deal with the worst state: incomprehensible and dog-slow. In this case, either rewrite everything from scratch or do a massive review so that it reaches some sensible state before even trying to optimize anything.\n\nIncremental is the new black\n\nIn the previous two starting points, performance improvement is very often designed with some specific goals in mind. It can’t be a vague objective, it needs to be reproduceable and measureable. The typical strategy is to create a performance test suite which acts as the benchmark baseline. Every attempt to speed-up various aspects of the application must ensure that the benchmark score increases. Thus, it’s also equally important to have the representative tests in that benchmark suite, something that resembles real-world usages from the customer and not just some synthetic setup.\n\nGenerally, it’s a good practice to have a series of small commits than huge change that touches everything. For performance improvement, this gets even more important. Many optimization tricks are about compromise. Over the time, the compromise changes and therefore it is imperative to revisit again all the hacks which have been done to fulfill the obsoleted compromise. This activity is possible only if every single tweak is isolated and easily accounted for. Undoing and redoing a big commit which may or may not impact different parts of the application is a risky move. Not only that, but the technology and the environment very often improve with time. For example, JavaScript developers were used to the trick of caching array length:\n\nvar i, len;\nfor (i = , len = contacts.length; i < len; ++i) {\n    // do something\n}\n\n\nThese days, JavaScript engines are smart enough to understand this case and the non-cached version will perform equally well.\n\nIf you start from the performant-but-unreadable quadrant, iterative clean-up will reveal how far you can sacrifice the performance to gain future maintainability. Again, a trade-off must be set. For example, are you willing to have 5% penalty by changing this code fragment into something which is easier to review?\n\nvoid hsv_to_hsl(double h, double s, double v, double* hh, double* ss, double *ll)\n{\n    *hh = h;\n    *ll = (2 - s) * v;\n    *ss = s * v;\n    *ss /= (*ll < = 1) ? (*ll) : 2 - (*ll);\n    *ll /= 2;\n}\n\n\nOver the time, the readability scale can change as well. If everyone becomes really good at mastering the language, the above construct may become very natural and therefore it is OK to keep this form and abandon the longer version.\n\nDropping a 500-line patch with a comment such as “Rewrite, 3x faster now” is not a recommended act in today’s craftsmanship standard. Record the optimization steps in a logical series of check-ins which also mirrors your train of thought. Think of other people, and that also includes the Future version of you!\n\n(`_|_`)Nov 8, 2012(`_|_`)ariya.io(`_|_`)optimization-journey-vs-destination', 'optimization-journey-vs-destination'),
(154, 'FIFA 2012 for Android(`_|_`)\n \n\nAs I wrote in my review of PES 2012, it is now time to look at its closest competitor, FIFA 2012 from Electronic Arts. This Android game is fantastic for football fans, it costs only $5 and the fun lasts forever. The latest Android tablet, Nexus 7, is a perfect device to play the game.\n\nAfter playing hundreds of matches, I must say that FIFA 2012 is a quite impressive game. Because it has a proper license, there are tons of leagues and teams you can choose. Players look familiar from the appearance and they also have their actual names.\n\nGetting started with the game is rather easy. There is a Kick-Off mode right from the main menu. For more than just a casual time-killing match, go to Leagues or Cups. Obviously, simple practicing is also a possibility. You can tweak few aspects of the game, from the team formation to the choice of the venue. In addition to that, there is an achievement system to motivate you to explore all the game features.\n\n \n\nGame controls are decent, it’s slightly more challenging than PES 2012 because of the three buttons along with various possible combinations. While attacking, you can shoot, pass, or sprint. Defense mode gives you the ability to switch player, slide, or tackle the opposite player. Combining some buttons and gestures controls your player to do a lot of other tricks, everything from a fast dribbling to a fake shot. Mastering all these combos can be frustrating. Fortunately, in many loading screens, there is always a random tip on how to carry out certain tricks.\n\nHow about the game play? It is really really fun. The AI system is very good, your team mates are extremely helpful setting up different variants of attacks. And of course, after a while, the secret of winning a match is rather obvious: be really patient! This is quite important as you play against a stronger team. If you pick midfield-optimized formation (my favorite is 3-5-2) and dominate the ball possession, at one point the other team’s defense will show its weakness.\n\n \n\nCompared to PES 2012, there are some game aspects which make the match more lively. For a start, the commentary is not too repetitive, it is hardly annoying. The goalkeeper often shows his frustation, sometimes to the defenders, every time there was a close call. When a throw-in needs to be made, there is a running animation (although this gets boring after all). There is also a slight delay between the moment the referees indicates a foul until all the players stop their move. A protesting player when yellow/red card is given is really amusing to observe.\n\nWhat could be improved in FIFA 2012?\n\nGraphics would be my first request. Granted, it’s already looking quite good and I’m sure care must be taken to ensure that the performance is still acceptable. However, knowing that many Android tablets are based NVIDIA Tegra 3 or other GPU of the same grade, pushing the details to the limit would give an even fascinating game play.\n\nOtherwise, it will be a matter of finishing touches here and there. Controls could be simplified without reducing the flexibility. Multiple leagues and cups should be allowed. In-game animation can use some variations. Smarter fellow players do not hurt as well.\n\nLast but not least, if you can only pick one Android game and you are torn between PES 2012 and FIFA 2012, get FIFA 2012 instead. Have fun with the game!\n\n(`_|_`)Nov 5, 2012(`_|_`)ariya.io(`_|_`)fifa-2012-for-android', 'fifa-2012-for-android'),
(155, 'Issue Tracker: GitHub vs Google Code(`_|_`)\nAn issue tracker is a valuable asset for any serious software development. Beside serving as a bug database, the tracker can be easily leveraged for technical discussion. GitHub, a popular code hosting service, provides a basic issue tracking system. How does it compare against another established player, Google Code Project Hosting?\n\nFrom using the service of Google Code for a while, I found out that there are some important things which really help any software maintenance workflow: voting system, custom grid view, and issues relationship.\n\nAn easy way to determine what the users want is by giving them the choices and let the popularity contest begins. Google Code simplifies this approach, there is no need to create an external survey. Every issue filed in the tracker can be starred by anyone. From the maintainer’s point of view, if he wants to have a glance on what to prioritize in the future releases, he can simply let the issue tracker shows the most voted ones. As an example, here is the state of PhantomJS issue tracker, sorted by the number of stars:\n\n\n\nCurrently GitHub does not offer such a voting mechanism. The workaround is rather simple, just add a short comment, e.g. ‘+1’, to an issue. Because you gave that comment, you are enrolled in the participant list. An issue which gets a very long participant list means that a lot of people are involved there. It is another form of popularity contest.\n\nHowever, care must be taken so that the issue does not get exploded into a Reddit-esque discussion. Due to its popularity, controversial or opinionated issues on GitHub tend to attract a particular set of crowd which often add a ridiculous level of noise to the subject. Many project owners are fine with it (after all, it drives the traffic and increases the exposure). However, some others still prefer to keep the issue tracker to its original intention and not to become a replacement for Hacker News.\n\nFor managing the issues, GitHub gives you a very nice color-coded labeling system. As for Google Code, you still get labels but they are not as fancy. One thing where it beats GitHub is the custom grid view. If you arrange it properly, it can be a quick substitute to a Kanban board. Change the arrangement again and now you can see who’s doing what. As another example, here is the screenshot of Esprima issues in a specific grid view:\n\n\n\nSlightly related to above dashboard, one thing I really like from Google Code is being able to set-up a blocking/blocked relationship between issues. Granted, it’s not as flexible as JIRA (where you can have various types of relation) and I also miss the dependency tree like in Bugzilla, but this basic link of two or more issues proves to be very valuable. For example, I can designate a master issue, that kind of umbrella or catch-all for a big story (see Esprima issue 189), and then have the sub-tasks as individual issues which block the master. I am not aware of the same blocking relation for GitHub, although I think using the combination of issue cross-references, labels, and milestones will be the equivalent approach.\n\nDo you like your issue tracker? Which features help you the most? Tell us!\n\n(`_|_`)Nov 1, 2012(`_|_`)ariya.io(`_|_`)issue-tracker-github-vs-google-code', 'issue-tracker-github-vs-google-code'),
(156, 'JavaScript Validator with Esprima(`_|_`)\nDue to the nature of the language, it is possible to construct JavaScript code that contains syntax errors which do not get detected until it is quite late. Yes, everyone should be using a smart editor or an intelligent IDE or a thorough linter or any other fancy tools, but an engineer is just human and mistakes happen all the time. I have seen such a blunder coming from experienced JavaScript developers, even those who are involved with many popular libraries. How do we prevent this?\n\nFortunately, it is rather easy to craft a command-line syntax validator once we have a modern JavaScript parser. You probably have seen the online version of Esprima-based validator when I blogged about checking strict mode conformance. While that online validator is useful for a quick verification of some code fragment, it is not optimal for any programmatic verification. Look no more! With the 1.0 version of Esprima some weeks ago, a simple-but-useful validator is included. It’s called (surprisingly) esvalidate.\n\nIf you are using Node.js, getting it is as easy as:\n\nsudo npm install -g esprima\n\n\nNow you can validate any JavaScript source files:\n\nesvalidate foo.js bar.js baz*.js\n\n\nIf your files are syntatically valid, checking few megabytes of source should be completed in a second. Thanks to Google V8, Esprima under Node.js is really really fast.\n\nSay you don’t like to depend on Node.js, no need to worry since you can also use the ubiquitous Java. The trick is to leverage Mozilla Rhino. The setup is rather simple; place the three files, js.jar from Rhino, esprima.js and esvalidate.js, all in the same directory. After than, run the validator as follows:\n\njava -jar js.jar bin/esvalidate.js foo.js bar.js baz*.js\n\n\nThe above technique should work on Windows, Linux, and OS X. Hate to launch Java that way? Create a shell script or a batch file which wraps it. On Mac OS X, this is even easier since Rhino installation via Homebrew already prepared the wrapper /usr/local/bin/rhino and the above invocation is therefore simplified to:\n\nrhino esvalidate.jsw foo.js bar.js baz*.js\n\n\nAre you curious about the speed? Even though we have the overhead of running via Rhino on a JVM, the entire process is typically very fast. I measured the duration of validating three.js source (that’s 36K lines, total 800 KB) on a fairly modern laptop, it took just about 5 seconds. For a huge source file reaching over 5.5 MB, the validation was slowed down to around 20 seconds. Also, future version of Esprima will have some interesting tweaks to speed-up this particular use case. Thus, unless you write GB of JavaScript, expect the validation cost to be quite reasonable.\n\nNote that a validator is slightly different than a linter. If you use some of the famous linter for JavaScript (JSLint or JSHint), you know that they are pedantic (to a certain extent) about the coding style. This validator does not care about style since its purpose is only to check for syntax errors. Thus, it is also perfect to use it with generated files as the result of minification or compilation (CoffeeScript, Dart, TypeScript, etc).\n\nIf you use Vim, you can set esvalidate as the makeprg for JavaScript files, rather easy via after/ftplugin. Launching make (better done through a shortcut) will inspect the validity of the edited file. Via the quickfix window, you can view the result and jump to any particular syntax problem.\n\n\n\nI’m sure it is possible to integrate the validator with other popular editors such as Emacs, TextMate, or Sublime Text. Update: Sublime Text package for the validator is now available, see github.com/duereg/sublime-jsvalidate.\n\nExecuting esvalidate manually is annoying. We can take advantage of any preflight check mechanism of modern version control systems, for example see my previous blog post on Git pre-commit hook and smoke testing. Here is an example of the hook script. Every JavaScript file which has been touched since the previous check-in will be validated. If one of them fails the check, your commit will be aborted immediately.\n\nfiles=$(git diff-index --name-only HEAD | grep -P \'\\.js$\')\nfor file in $files; do\n  esvalidate $file\n  if [ $? -eq 1 ]; then\n    echo \"Syntax error: $file\"\n    exit 1\n  fi\ndone\n\n\nAre you using Grunt for your build workflow? Look no more, install grunt-jsvalidate (which I created some time) and you have a new task jsvalidate which does the validation just like the above. Of course, under the hook it also uses Esprima.\n\n\n\nRunning a continuous integration system? There is a support for JUnit XML format as the output. This means, the validation report can be consumed easily by e.g. Jenkins or TeamCity.\n\nWith these multiple layers of defense during editing, code check-in, build, and continuous integration, hopefully the chance of making a stupid mistake is significantly reduced. How would you plan to guard yourself with a syntax validator?\n\n(`_|_`)Oct 29, 2012(`_|_`)ariya.io(`_|_`)javascript-validator-with-esprima', 'javascript-validator-with-esprima'),
(157, 'Detecting Nested Ternary Conditionals(`_|_`)\nNested ternary conditional operators can be useful. In some cases, e.g. to promote better code readability, you may want to outlaw that practice. Armed with a code parser, a simplistic code analysis allows such a pattern detection.\n\nOnce somebody understands the power of the ternary operation, it is very tempted to harness it in multiple ways. Sometimes it leads to something (still) logical and readable, e.g.:\n\nvar str = (age < 1) ? \"baby\" :\n    (age < 5) ? \"toddler\" :\n    (age < 18) ? \"child\": \"adult\";\n\n\n\n\nThe corresponding syntax tree of that code, produced by Esprima online parser, looks like this (some branches are collapsed):\n\n\n\nIn other cases, complicated and deep ternary operator abuse is a pattern you want to detect. Fortunately it is rather easy once you obtain the syntax tree. Such a tool is included in Esprima examples subdirectory, detectnestedternary.js (100 lines). Use Node.js to launch it as\n\nnode detectnestedternary.js /some/path\n\n\nAn exemplary output of the script if you run it against our example code above:\n\nLine 1 : Nested ternary for \"age < 1\"\n  Line 2 : Nested ternary for \"age < 5\"\n\n\nThe working principle of this script is very similar to previous example of Boolean traps detection I have already covered before. In fact, we will use the same syntax tree traversal function. All we have to do differently is to change the analyzer. Here we need to see if a ternary condition is immediately followed another ternary condition in either its consequent or alternate code path. Pretty easy to achieve:\n\nfunction checkConditional(node) {\n    var condition;\n \n    if (node.consequent.type === \'ConditionalExpression\' ||\n            node.alternate.type === \'ConditionalExpression\') {\n \n        condition = content.substring(node.test.range[], node.test.range[1]);\n        if (condition.length > 20) {\n            condition = condition.substring(, 20) + \'...\';\n        }\n        condition = \'\"\' + condition + \'\"\';\n        report(node, \'Nested ternary for \' + condition);\n    }\n}\n\n\nTo improve the report, the condition which triggers this nested conditionals is also printed out. Here we use Esprima’s feature of locating the range of that particular syntax node, this enables us to extract the portion of the source corresponding to that condition.\n\nAs an exercise for the reader, tweak the analyzer so that it triggers the warning only if the nesting goes deeper than a certain threshold. This way, the first ternary in the simple age detection case illustrated above may be skipped. You may also want to check the situation where the nested ternary is enclosed in another expression, i.e. it does not immediately show up as the direct child one (consequent or alternate).\n\nNeedless to say, not every use of nested ternary operators is bad. Set the criteria, look for the code pattern, and then guard yourself against unreadable and confusing code!\n\n(`_|_`)Oct 16, 2012(`_|_`)ariya.io(`_|_`)detecting-nested-ternary-conditionals', 'detecting-nested-ternary-conditionals'),
(158, 'Web Page Screenshot with PhantomJS(`_|_`)\nPhantomJS is quite popular for headless testing of web applications. Because it packs real WebKit engine and it does not use any emulated implementation of DOM, CSS, Canvas, etc, PhantomJS can render a web page almost as good as what is expected from a web browser. This feature turns out to be quite useful to programmatically capture the content and save it as an image.\n\nThe simplest example of web page capture using PhantomJS is the following script. It is self-explanatory.\n\nvar page = require(\'webpage\').create();\npage.open(\'http://google.com\', function () {\n    page.render(\'google.png\');\n    phantom.exit();\n});\n\n\nA web service to capture web sites is something a lot of people would want to have. There are commercial solutions like url2png and websnapr to do that. If you want a DIY approach, this is however rather easy with PhantomJS. In fact, there are few ready-to-use screenshooting projects based on PhantomJS you need to look at, see the complete list for more info.\n\nThe working principle of such a project is dead simple. There is a front-end which deals with the API, i.e. handling the URL to be requested, the size of the preview, and so on. This will further kick a PhantomJS process which rasterizes the requested page. It is rather easy to construct and thus people have combined PhantomJS with anything from Node.js to Play2 framework.\n\nFor an online example of a screenshot project, take a look at Screener with its simplistic interface. Give it a try with your favorite web site and see how it handles it.\n\nSince PhantomJS version 1.6 (Lavender), there are two additional features which can be useful for this screen capture purposes. The first one is zoom factor, implemented by Milian. By default it is 1, setting this value to 0.25 you will get the rendered web page in 25% zoom. This is really good if all you want is a thumbnail preview only. Another feature, this time coded by Ivan, is to output the rendering as base64 encoded image (preferably in PNG). This means, there is no need to save the capture into a temporary image file.\n\nIf we tweak our previous example to use these two features, the code would look like snippet. It will snapshot Google homepage, make it 4x smaller, and encode it as PNG in base64 straight to stdout.\n\nvar page = require(\'webpage\').create();\npage.open(\'http://google.com\', function () {\n    page.zoomFactor = 0.25;\n    console.log(page.renderBase64());\n    phantom.exit();\n});\n\n\nFor some final inspiration, let’s see two projects which leverage the power of PhantomJS screen capture: Media Queries and ChromaNope.\n\nmediaqueri.es from Eivind Uggedal is a collection of web sites with responsive design in mind. Every web page in the collection will be capture with a variety of viewport dimensions, thereby automating the look as if the page is visible on different mobile devices.\n\n\n\nChromaNope, built by Kris Hedges, is a simple web service which captures a web page and display it in 4 variants, normal and dichromacy: protanope, deuteranope, and tritanope. The goal is to simulate your sites for the color blinds. As Kris himself has written, “This helps designers make informed decisions about accessibility by identifying potential problems that color-blind users might have, problems that might have otherwise gone unnoticed.”\n\nAs an example, the following screenshot shows the look of PhantomJS web site, phantomjs.org, rendered by ChromaNope:\n\n\n\nLast but not least, remember that PhantomJS on Linux is pure headless”) and therefore setting it up on a barebone Amazon EC2 instance is fairly painless (standard AMI or Ubuntu image should work). In fact, if you do not want the hassle of server management, use IronWorker, a service from Iron.io, to run your PhantomJS scripts with zero setup.\n\nWhat do you want to capture today?\n\n(`_|_`)Oct 9, 2012(`_|_`)ariya.io(`_|_`)web-page-screenshot-with-phantomjs', 'web-page-screenshot-with-phantomjs'),
(159, 'Validating Strict Mode(`_|_`)\nStrict mode of JavaScript is useful to catch common mistakes, especially from someone new to the language. To get familiarized with strict mode, a real-time online validator can be useful. Such a validator spots all possible strict mode violations which can be detected at parsing time.\n\nEsprima, the standard-compliant ECMAScript parser I am working on, has full support for strict mode. I already wrote about the use of Esprima to detect strict mode problems. Since then, I have added some improvements so that Esprima does not stop immediately on the first strict mode issue. This is done as part of Esprima tolerant parsing feature (see issue 228).\n\nLet’s have a look at the following code fragment.\n\nfunction f() {\n  \'use strict\';\n  var a = 021;\n  var b = function (eval) {}\n  var c = function (arguments) {}\n  function d(foo, foo) {}\n  function e(eval, arguments) {}\n  function eval() {}\n  function arguments() {}\n  function interface(){}\n  with (x) { }\n  try { eval++; } catch (arguments) {}\n  return { x: 1, y: 2, x: 1 }\n}\n\n\nUsing Esprima’s online syntax validator, you will get tons of warnings for every single line in that function for various restrictions because you can’t do any of the following\n\n\nuse with statement\n\nuse octal literal\n\nuse eval or arguments as variable, function name, or function parameter\n\nuse eval or arguments as a variable in a catch clause\n\nuse reserved words, e.g. interface, as variable or function name\n\nmodify eval or arguments (with an assignment, prefix, or postfix)\n\nhave duplicated parameter names in a function\n\nhave duplicated setters, getters, or property names in an object\n\n\nThanks to the tolerant mode of Esprima, it does not stop right away after locating the first issue. You can witness how the parser attempts to continue as far as it can (in this case, until the end of the code) and then reports all its finding.\n\nObviously, there are strict mode violations which will be triggered at run-time only. Here is an example:\n\nfunction createMonster(){\n  \'use strict\';\n  function Monster(p) {\n    this.power = p;\n  }\n  return Monster(42);\n}\n\n\nThe above snippet is a syntactically correct code. However, if you call function f, what happens is:\n\n\nTypeError: Cannot set property ‘power’ of undefined\n\n\nIt is because this inside function g is bound to undefined. With strict mode, undefined this does not become the global object anymore. As a comparison, remove the strict directive and the call happily finishes, although it sets power at the global level, e.g window.power in a browser environment. This is likely not what you want, the mistake here is due to the missing new when constructing the Monster object.\n\nIn the above scenario, it is impossible for a parser to spot the problem. The actual value of this within the function invocation depends heavily on how the code gets executed, something not predictable upfront.\n\nWhile run-time strict mode issues may occur, it is definitely a good idea to protect yourself as early as possible by eliminating all the parsing-time problems. I believe that any future JavaScript tools should not treat strict mode as a second-class citizen. And if you are not yet using strict mode because it is still mysterious to you, I hope Esprima online validator can give some useful immediate feedback as you sanitize your code.\n\n(`_|_`)Oct 3, 2012(`_|_`)ariya.io(`_|_`)validating-strict-mode', 'validating-strict-mode'),
(160, 'Autumn 2012 Conferences(`_|_`)\n\n\nSummer is gone. A little plan for me for this autumn is to deliver some tech talks.\n\nThe first one will be this weekend at the Silicon Valley Code Camp 2012 in Los Altos. I’ll be giving a talk Understanding WebKit Rendering (Sunday, 1:15 pm). Showing web contents as pixels on your screen is one very important responsibility of a rendering engine like WebKit. If you are curious how this happens behind the scene, check out my session. In addition, you will learn why blindly applying magical spell such as “use translate3d” can have unintended effects to your page performance.\n\nThe next one will be very exciting for me because it will be held in New York, a place I really wanted to visit since ages. In about 3 weeks, I should be speaking at EmpireJS. This time, I’ll continue my push towards a better tooling for JavaScript, with a talk on the topic of Bringing JavaScript Code Analysis to the Next Level. If you are passionate about tools and eager to improve the development workflow of front-end developers, engage on this discussion with me. Expect to see some materials around parser, code coverage, instrumentation and profiling, static code analysis, code regeneration, and many related subjects.\n\nMy summer conferences experience was a blast. Could this season be better?\n\n(`_|_`)Oct 1, 2012(`_|_`)ariya.io(`_|_`)autumn-2012-conferences', 'autumn-2012-conferences'),
(161, 'PhantomJS 1.7 \"Blazing Star\"(`_|_`)\n\n\nPhoto by Frank Wouters CC-BY via Wikimedia Commons.\n\nSummer is gone. During the equinox, I have tagged version of 1.7.0 of PhantomJS, the headless WebKit for page automation. The code name for this one is Blazing Star with the following back story:\n\n\n“Blazing Star” is a mesmerizing and beautiful flower, it is often used as a symbol representing happiness and satisfaction. Tending these flowers requires some patience, the reward is however worth all the hassle. Its beautiful appearance makes it popular among gardeners, don’t be surprised if you are stunned by the florets for hours and hours. Blazing star is also known to have mild medicinal characteristics. A fabulous combination of outer beauty and inner beauty I would say. These days, with almost every web-related test framework gets connected to PhantomJS in one way or another, presenting these attractive yet romantic blossoms marking a joyful relationship could not be a better honor for us.\n\n\nRegular, predictable releases of PhantomJS have been something people always like, judging from the feedback. Blazing Star is another update which adds some incremental improvements such as better cookies handling, support for keyboard events, and module system. For a quick overview of all the new stuff, refer to the release notes.\n\nOn the infrastructure side, our homework is only partially done. For the timeline of this release, I managed to move “static” information (installation, release notes, FAQ, …) straight to the website (via GitHub pages). Meanwhile, Wiki pages are now hosted at GitHub since everyone seems to like it that way. It is not searchable, I just trust that Google crawlers will boost the discoverability. This kind of transition always takes time, e.g. API documentation is still being worked on. Don’t be surprised if there are missing bits and pieces in random places. We also take advantage of a new GitHub feature: contributing hook, a smooth way to remind everyone about the house rules.\n\nThe trend so far shows that PhantomJS user base keeps increasing. Comparing the total downloads in the 1.5 (Ghost Flower) and 1.6 (Lavender) series, this chart is what we got:\n\n\n\nThat is a pretty healthy growth! More and more people discover PhantomJS and start using it. This is also because various web-related tools, such as Grunt and Yeoman, leverage its page automation feature. In fact, if you are using a JavaScript testing framework, there is a likely chance that a suitable PhantomJS-runner for your headless testing is available.\n\nLast but not least, many many thanks to everyone who contributed to this Blazing Star release!\n\n(`_|_`)Sep 25, 2012(`_|_`)ariya.io(`_|_`)phantomjs-1-7-blazing-star', 'phantomjs-1-7-blazing-star'),
(162, 'JavaScript\'s Future Class Syntax in Today\'s Browsers with Esprima and Harmonizr(`_|_`)\nOne interesting proposal for a class syntax for JavaScript is the so-called maximally-minimal classes. There is no guarantee that this will become the future standard which everyone follows, nevertheless its simplicity is the attractive main point. It may even take years until the popular JavaScript engines support this syntax. What if we want to use it today so that we can experiment with the construct? This permits us to understand its advantages and drawbacks as early as we can.\n\nTo a certain extent, this is made possible by converting this future syntax to something which can be understood by this generation’s JavaScript engine, a technique popularly known as transpilation. I already wrote about this in my previous blog post Esprima and Harmony Module where Harmonizr is used the transpiler to convert ES6 module construct into something less futuristic.\n\nRecently Harmonizr got a support for class syntax conversion. It works by desugaring the construct into prototypical inheritance. This is likely not going to give you full compatibility of the run-time behavior with the intended class semantics. In many cases it should be fine because (1) we don’t know the exact behavior yet (2) this is enough to rewrite most cases using class syntax.\n\nTo see how Harmonizr class transpilation works, you can use its online converter or Esprima transpiler demo. If you paste the following snippet:\n\nclass Vector3 {\n \n  constructor (x, y, z) {\n    this.x = x; this.y = y; this.z = z;\n  }\n \n  // Euclidian norm\n  magnitude() {\n \n    // Arrow function\n    var sqr = p => p * p;\n \n    return Math.sqrt(sqr(this.x) + sqr(this.y) + sqr(this.z));\n  }\n}\n\n\nthen what you get is something like this:\n\nvar Vector3 = (function () {\n \n  function Vector3 (x, y, z) {\n    this.x = x; this.y = y; this.z = z;\n  }\n \n  // Euclidian norm\n  Vector3.prototype.magnitude = function() {\n \n    // Arrow function\n    var sqr = function(p) { return p * p; };\n \n    return Math.sqrt(sqr(this.x) + sqr(this.y) + sqr(this.z));\n  }\n; return Vector3;})();\n\n\nIt’s rather straightforward, isn’t it? The converted code fragment is pretty much what you would expect should you carry out the conversion by hand. Note also the use of arrow function syntax, this is intentional to demonstrate that Harmonizr supports that as well. Obviously magnitude can be also be a getter, give it a try and see the interesting converted version.\n\nAs with many Esprima-based JavaScript tool, you may notice that the result is non-destructive. All the comments are still present in the converted version. The coding style is preserved, the indentation is following the original code. The line numbers also match, which facilitates easy debugging. Because of this characteristic, the resulting code does not feel like machine-generated. There is a little bit of human touch, if you may say so.\n\nBeside using Harmonizr, it’s also possible to use Google’s project Traceur to convert the class syntax. Traceur however does not generated prototypical version of the construct, it’s rather using some helper function from its small supporting run-time traceur.runtime.createClass. Since Traceur works by code regeneration, it unfortunately loses any formatting and comments.\n\nFor completeness’ sake, the syntax tree of our example (produced by Esprima online parser) looks like this:\n\n\n\nI can imagine that many JavaScript fans will keep using prototypical inheritance for their OOP usages (after all, it’s not called class-oriented programming). The presence of the class syntax however will be attractive to those who are classically trained, e.g. having learned different types of programming languages.\n\nHmm, can JavaScript be classual then?\n\n(`_|_`)Sep 19, 2012(`_|_`)ariya.io(`_|_`)javascripts-future-class-syntax', 'javascripts-future-class-syntax'),
(163, 'The Hidden Trap of Code Coverage(`_|_`)\nCode which never gets tested is an accident waiting to happen. The coverage of the code as it is exercised by the suite becomes an important metric. It is not a surprise if everyone aims to hit that magical 100% coverage. This applies also to the world of front-end web development with JavaScript.\n\nI’ve written previously on the use of coverage tool to ensure Esprima code quality (with a minor twist that the coverage tool is also based on Esprima). This allows us to claim that we reach the maximum possible statement coverage since the set of 500 unit tests touches every meaningful statement in the code.\n\nWhile statement coverage is important and you should definitely try to hit its peak, care must be taken to ensure that this is not the only coverage analysis being considered. As an illustration, let’s have a look at the following function:\n\nfunction inc(p, q) {\n    if (q == undefined) q = 1;\n    return p + q/q;\n}\n\n\nThe task of this function is very simple. I’m sure you can quickly notice the glaring bug in that function. This is intentional to demonstrate the point. Please do realize that in real-word scenarios, functions tend to be bigger and a logic mistake is often hidden in multiple layer of complexity.\n\nTo test that function, a simple assertion should be enough:\n\nassert(\"inc(4) must give 5\", inc(4) == 5);\n\n\nThe test reporter will not complain since it will pass with flying colors. If the test library supports checking the code coverage of the function, it will also say that both the if statement (including its body containing the assignment to q) and the return statement are executed. From the statement coverage point of view, such a reporter will say Congrats, 100% covered!.\n\nAt this point, if you stop writing more tests because you are confident of the achievement, you will never expose the bug in the function. Only if you add another test, e.g checking for inc(4, 2), you would realize that something is fishy with the implementation.\n\nLooking at the code, how is the situation different if it would have been written like the following?\n\nfunction inc(p, q) {\n    if (q == undefined) {\n        return p + 1;\n    } else {\n        return p + q/q;\n    }\n}\n\n\nRunning the same test will still mark it as pass but now the coverage analyzer loudly complains that you only hit one of the return statements. It’s definitely not 100% covered. You are then forced to continue writing more tests which hit another return statement and eventually reveal the bug.\n\nWhy is this possible? Mainly because typical statement coverage analysis does not reveal the actual code sequence. In the above example, there are two code paths to the end of the function and the unit test only follows one of them. The two code paths are unfortunately not obvious in the first version of the code.\n\nAs I always said, we still need to push JavaScript tools to the next level. I hope someone out there is working on JavaScript LCSAJ.\n\nUpdate: Now you can use Istanbul to track JavaScript branch coverage. Very useful!\n\n(`_|_`)Sep 12, 2012(`_|_`)ariya.io(`_|_`)the-hidden-trap-of-code-coverage', 'the-hidden-trap-of-code-coverage'),
(164, 'Git Viewer: GitHub vs Google Code(`_|_`)\nI often still use Google Code Project Hosting service to keep my public repositories. In this age where GitHub is very popular, I often get asked why I bother to do that and not just stick with GitHub. Here is a short explanation.\n\nThe first motivation is to avoid intentional centralization. Git is distributed, there is no master server. I can always push my repository to any place I want, thereby creating an automatic mirror in case one server is down. It is ironic if people do not work during any GitHub outage. For a start, you can always work offline as that is the main benefit of Git at the first place. In addition to that, code collaboration can still be carried out using any remote repository everyone can push to and pull from. There should not be any single point of failure in modern software craftsmanship.\n\nAnother advantage of Google Code is its online Git viewer. With GitHub as of today, you can get the branches overview via the graph visualizer. For my preference, I still think Google Code’s way of visualizing the relation between various branches is more useful to the project maintainer. It also follows the standard of various client-side version control tool. For Google Code, this is not specific to Git. Even if you choose to use Mercurial, you will get the same feature. It was available since Google Code only supported Subversion a long time ago.\n\n\n\nOne very useful aspect of Google Code viewer is the ability to see every change as a side-by-side diff. After all these years, I can’t believe that GitHub still does not have it. Even Gitorious and BitBucket give that choice of side-by-side view.\n\n\n\nAs I mentioned many times before, I really like GitHub. There seems to be just few remaining issues before it can be the ultimate collaborating tool. Beside the above concerns with its repository viewer, I hope some day GitHub will also address the lack of searchability and a way to enforce contribution rules. Surely everyone wants the one-hub-to-rule-them-all, right?\n\n(`_|_`)Sep 8, 2012(`_|_`)ariya.io(`_|_`)git-viewer-github-vs-google-code', 'git-viewer-github-vs-google-code'),
(165, 'Ternary Conditional and Boolean Values(`_|_`)\nMany programming languages support the ternary conditional operator. It is very useful to shorten the code since something like:\n\nif (fast)\n  speed = 70;\nelse\n  speed = 25;\n\n\ncan be rewritten to look like the following (C-style syntax). In such a form, it is also concise, readable, and unambiguous.\n\nspeed = fast ? 70 : 25;\n\n\nChaining or cascading ternary conditions is also a common practice although it is not always recommended, especially if it is more than two operations.\n\nA few times I’ve seen code written by experienced programmers that mixes the ternary operator with Boolean values in a weird way:\n\nyoung = (age < 18) ? true: false;\n\n\nThis is quite baffling since technically what you need to write is only:\n\nyoung = (age < 18);\n\n\nAnother variant of such a redundancy is something resembling:\n\nspeed = (warp == true) ? 2.5 : 0.3;\n\n\nThere are different theories as to why this scenario occurs. The most obvious reason is of course an oversight, a simple honest mistake. Another explanation is that originally the said line of code did not deal with Boolean values, perhaps some constants or enums, and then got refactored incompletely, leaving the nonchalant historical structure.\n\nHave you spotted a similar situation? How did it happen?\n\n(`_|_`)Sep 4, 2012(`_|_`)ariya.io(`_|_`)ternary-conditional-and-boolean-values', 'ternary-conditional-and-boolean-values'),
(166, 'Real-Time Clock with MC146818(`_|_`)\nA timer is essential to the working of many electronics circuits. For modern consumer devices, the software won’t work properly if the timer does not behave as expected. This blog post presents a quick look at something which is quite ubiquitous: real-time clock.\n\nBack in the days, an IBM PC machine (or compatible one) sets the date/time to a predefined value everything it starts, Tuesday, January 1, 1980. It was quite common to place the DATE in the AUTOEXEC.BAT so that the user can supply the correct date/time. This information is however lost when the power is down.\n\nTo solve this annoyance, later models employed a real-time clock, a simple machinery to keep track of the time, even when the system is switched off. This can be an external or a built-in circuitry. IBM PC/AT started to have this feature by using MC146818 chip from Motorola, now Freescale Semiconductor (see also the 1984 version of the datasheet). There are many other compatible drop-in substitutes, e.g DS12885 from Dallas Semiconductor (now part of Maxim) and M48T86 from STMicroelectronics. If you have played with all kind of motherboards, you know that it has this CMOS battery which ensures, among others, that the date and time are always correct because it keeps powering the circuit even if the main supply is cut off.\n\nThe functional diagram (from the datasheet) of MC146818 is shown below. Typically a crystal is connected to the chip at OSC1 and OSC2 pins.\n\n\n\nHow to get and set the date/time? This is done via register read and write. Register 7, 8, and 9 are for day of the month, month, and year, respectively. There is also register 6 to know the day of the week, in case there is no room to implement the calendar algorithm to find it the harder way. The current time is obtained or altered via register 0, 2, 4, each for the seconds, minutes, and hours.\n\nA series of divider gives the ability to prescale the frequency. A crystal with a frequency of 32.768 KHz is particularly useful since it can be combined with a 15-bit prescaler to give a good 1 Hz signal for the clock.Note that the prescaler can be programmed as well, specially to trigger IRQ (interrupt request) at a predefined frequency. In the datasheet, Table 5 gives possible different values for Register A, essentially setting up the frequency divider to invoke IRQ at any rate (depending on the crystal frequency) from 8 KHz to 2 Hz. If you use a microcontroller, MC146818 does not only help keep tracking of date and time, this extra IRQ can be used for triggering any periodic tasks.\n\nNow the fun part is trying to figure out what modern operating systems do with the real-time clock? Fortunately, it’s rather easy to answer that question with a little bit of experiment using a virtualization approach. We will take a look at QEMU, a very capable open-source emulator. If you want to play with QEMU yourself, read my previous blog post on building QEMU.\n\nA quick glance at the code proves that it does already support real-time clock by emulating MC146818 (surprise!) , hw/mc146818rtc.c in its source tree. The handling of setting and getting the time has been there since the early days of QEMU, the custom time interval by Register A programming was implemented as early as 2004. Note that it is also possible to use VirtualBox. If you look at VirtualBox source code, its implementation of real-time clock, VBox/Devices/PC/DevRTC.cpp, is pretty much derived from the QEMU version.\n\nTo monitor what the virtualized operating system does with respect to MC146818 we can just active the logging for two important functions: cmos_ioport_read and cmos_ioport_write. Launching Windows and checking the log gives something like:\n\ncmos: read index=0x00 val=0x14\ncmos: read index=0x02 val=0x11\ncmos: read index=0x04 val=0x05\ncmos: read index=0x06 val=0x04\ncmos: read index=0x07 val=0x29\ncmos: read index=0x08 val=0x08\ncmos: read index=0x09 val=0x12\ncmos: write index=0x00 val=0x14\ncmos: write index=0x02 val=0x11\ncmos: write index=0x04 val=0x05\ncmos: write index=0x06 val=0x03\ncmos: write index=0x07 val=0x29\ncmos: write index=0x08 val=0x08\ncmos: write index=0x09 val=0x12\n\n\nwhich clearly proves that Windows reads the date/time during its system initialization and possibly adjusts it as well. Running QEMU with Linux demonstrates the same behavior.\n\nWhat about the IRQ? Monitoring what happens to register A shows that either Linux or Windows do not really do something useful with it. The guest OS leaves the value at its default (0x26) which corresponds to a divider of 32 (see Table 5 and 6 in the datasheet), giving the output signal at a frequency of 1024 Hz (assuming 32 KHz crystal is being used).\n\nAs a final note, a software implementation of MC146818 can be found also in the source code of MAME, Multiple Arcade Machine Emulator. This is interesting because it means some arcade machines out there are using it. If you are a fan of classic games, real-time clock investigation for such arcades is left as an exercise for you.\n\nThat’s all about real-time clock! Don’t hesitate to dig the datasheet to find more useful info and sprinkle QEMU/MAME with more logging to investigate how an operating system is using the RTC chip. In some weeks, let’s have a look at programmable interval timer.\n\n(`_|_`)Aug 31, 2012(`_|_`)ariya.io(`_|_`)real-time-clock', 'real-time-clock');
INSERT INTO `ariyaio` (`id`, `content`, `url`) VALUES
(167, 'Determining Objects in a Set: Examples in JavaScript(`_|_`)\n\n\nIn practical programming, it is quite common to determine whether an object belongs to a set or not. For example, if you implement a spell checker, it is essentially a comparison against the set of all correctly-spelled words. If the set itself is fixed and it never changes, what are the approaches we can use?\n\nThe usual initial solution is by using an associative container, often denoted as dictionary data structure. We populate the dictionary with the members of the set. Looking up whether the set contains the search word or not will reveal the outcome of the spell checking.\n\nJavaScript, also known as ECMAScript, is unique in a sense that every object can act as an associative array. Obviously, this is not what you are supposed to do because of the abuse, but to give an idea:\n\nvar valid_words = {\n  \'foobar\': true,\n  \'bar\': true,\n  \'baz\': true,\n  \'quux\': true\n};\n \nfunction is_valid(word) {\n  return valid_words.hasOwnProperty(word);\n}\n \nis_valid(\'fox\'); // false\n\n\nIf you are using ECMAScript 5 only, you can use Object.create from null so that valid_words does not inherit some properties from Object.prototype.\n\nAnother (better) approach is to use array lookup, i.e. indexOf method, in particular since we can store the list of valid words in an array anyway:\n\nvar valid_words = [\'foobar\', \'bar\', \'baz\', \'quux\'];\n \nfunction is_valid(word) {\n  return valid_words.indexOf(word) >= ;\n}\n\n\nThe problem with the above tricks is that the performance depends very much on the implementation inside the JavaScript engines. Since this is not the primary use case of object or array, often this technique does not lead to a good performance, especially if the set is large.\n\nHow about using the native comparison in the language itself? Using switch statement is one possibility. It could be even a series of if statements.\n\nfunction is_valid(word) {\n  switch (word) {\n  case \'foobar\':\n  case \'bar\':\n  case \'baz\':\n  case \'quux\':\n    return true;\n  }\n  return false;\n}\n\n\nBeside generating a lot of code (since the checking is done for each possible set members), a string comparison is not the fastest thing to do. Depending on the size of the set, the performance may vary.\n\nSomething I learned from Roberto Raggi few years ago is the use of prefix tree or trie to build a sort of decision tree. This is used in his C++ parser to detect whether an identifier is a keyword or not, pretty similar to our spell checker example. For the code of that cppparser, take a look at lexer.cpp. How do we apply the same approach to the simple spell checker? It will look like the following. Note that there can be dozens of other variants, but you get the idea.\n\nfunction is_valid(word) {\n  switch (word.charAt()) {\n  case \'f\':\n    return word === \'foobar\';\n \n  case \'b\':\n    switch (word.charAt(2)) {\n    case \'r\':\n      return word === \'bar\';\n    case \'z\':\n      return word === \'baz\';\n    }\n    return false;\n \n  case \'q\':\n    return word === \'quux\';\n  }\n  return false;\n}\n\n\nA simplified construct that I use for Esprima, the fast JavaScript parser, is to take the word length as the first level comparison and then a simple conditional for the second one. This leads to:\n\nfunction is_valid(word) {\n  switch (word.length) {\n  case 3:\n    return word === \'bar\' || word === \'baz\';\n  case 4:\n    return word === \'quux\';\n  case 6:\n    return word === \'foobar\';\n  }\n  return false;\n}\n\n\nI found out that the above method works fast enough (tested with its benchmark suite) and there is no reason to micro-optimize further. Just like in PGO (profile-guided optimization), combining the short-circuit behavior of the logical condition with the representative distribution of the words can be used for branch optimization.\n\nIf the set is large and some members are quite similar to each other, DAG or directed acyclic graph (or rather directed acyclic word graph in this case), can be a better solution with respect to the memory usage. For many cases, generating this graph would be too complicated and not worth the effort.\n\nOf course, it would be incomplete if I don’t mention no-collision hash, i.e. perfect hash. This is the approach used to recognize keywords in the tokenizers of various GNU compilers, from C++ to Java, as well as projects like WebKit and Mozilla. A popular perfect hash function generator is gperf, it generates C code though it is possible to transform the generated code to JavaScript.\n\nWhat we need to feed to gperf is the following input:\n\n%{\n%}\n%%\nfoobar\nbar\nbaz\nquux\n%%\n\n\nNow it will spit out some C code. For your convenience, I have crudely transformed it into JavaScript as follows. I also did change the asso_values look-up table since many entries in that table are duplicated. The (perfect) hash function itself is unexpectedly quite primitive. Combined with the short wordlist array, this gperf-based solution works rather quite well.\n\nvar MIN_WORD_LENGTH = 3;\nvar MAX_WORD_LENGTH = 6;\nvar MIN_HASH_VALUE = 3;\nvar MAX_HASH_VALUE = 8;\n \nfunction hash(str) {\n  var asso_values = [];\n  for (var i = ; i < 256; ++i)\n    asso_values.push(9);\n  asso_values[111] = ;\n  asso_values[114] = 5;\n  asso_values[117] = ;\n  asso_values[122] = ;\n  return str.length + asso_values[str.charCodeAt(2)];\n}\n \nfunction is_valid(word) {\n  var wordlist = [\'\', \'\', \'\', \'baz\', \'quux\', \'\', \'foobar\', \'\', \'bar\'];\n \n  if (word.length <= MAX_WORD_LENGTH && word.length >= MIN_WORD_LENGTH) {\n    var key = hash(word);\n    if (key < = MAX_HASH_VALUE && key >= ) {\n      var value = wordlist[key];\n      return word === value;\n    }\n  }\n  return false;\n}\n\n\nBefore you create microbenchmarks comparing all the different methods, let me remind you again that it is always good to have the right data for your benchmark. In other words, write the most descriptive implementation first, create the benchmark suite properly with the representative corpus, and then do your comparison. In the above example, if you just measure the speed of running is_valid(\"foo\"), you would be led astray.\n\nObviously, all the approaches mentioned above are not the only possible solutions. Computer scientists surely have studied and understood few more tricks. What is your favorite? Share it with us!\n\n(`_|_`)Aug 23, 2012(`_|_`)ariya.io(`_|_`)determining-objects-in-a-set-examples-in-javascript', 'determining-objects-in-a-set-examples-in-javascript'),
(168, 'Pro Evolution Soccer 2012 for Android(`_|_`)\n \n\nPro Evolution Soccer (PES) 2012 is the football simulation game from Konami, available in its Android version since a few months ago. As of now, it costs $5.52. How does it feel to play this game on Nexus 7, the latest tablet device from Google? How does it compare with FIFA 2012 from Electronic Arts?\n\nAfter playing it for several days, I would say that this game is worth the few dollars which otherwise would have gone to some fancy coffee. The graphics quality is decent, the game feels slick and solid, various modes will keep you entertained and digging for some more fun.\n\nThe 7-inch tablet is perfect for the game, it’s not too small to make the controls difficult to handle and yet the larger view is enjoyable without straining both hands. When I try to play the same game on Nexus S, controls become more challenging. Also, the slower CPU and GPU on Nexus S make the experience less optimal since there will be few rendering hiccups once a while.\n\nAs with the licensing issue PES always struggles with, this one also still does not come with the full stack of all FIFA-blessed leagues. That should not prevent the fun, though. For example, I enjoy very much the classic teams as nothing beats the feeling of watching Classic England vs Classis Germany with players like Linden (Gary Lineker) and Clantzgan (Jürgen Klinsmann).\n\n \n\nThere are various play modes available. Beside Quick Match and Exhibition for the impatients, League and Cup are likely where you want to spend most of your time. There are also UEFA Club Competitions and Copa Santander Libertadores for a quicker experience than the full leagues. Challenges mode is supposed to be real fun since you can play with your friends, but for whatever reasons, in my case it was stuck during the attempt to contact the servers. There is also Training playground, useful to get familiarized with the controls.\n\nSpeaking about controls, there are three ways possible: virtual joystick with A and B buttons, virtual joystick with touch gestures, and finally accelerometer-based. Even with various sensitivity adjustment, tilting the tablet to move the players does not feel natural to me. Touch gestures have its limitation and thus I stick the familiar A/B buttons approach.\n\nThe AI (artificial intelligence) is very good. When attacking, your fellow team mates are quite smart in positioning themselves, whether for combination passings, a long through ball, or a quick wing play. Also, beware of the opponent’s defenders as they are ready to set an offside trap! The referee himself is also quite a character, he is eager to give yellow and even red cards for most of your tackles.\n\n \n\nThe strategy that you choose will entirely depend on how well you control your players. Since I’m not at terribly good at playing games like this, I usually pick the formation which maximizes midfield domination such as 3-5-2 or 4-4-2. Lots of ball movements are often needed before my striker has a chance to hit the goal. The fantastic movement off the ball from other players greatly helps this tactic, as they can create the necessary space and draw the opponents away. It requires some patience, the reward is that most of the time the resulting goal is quite satisfying, often as classic as how it would have been played in a real pitch.\n\nMy wishlist for PES 2013 is rather short.\n\nFirst, make it easy for a great player to avoid being stopped by an opponent. I think for Messi or Torres to lose to the ball easily on the first pressure is quite unrealistic, the system should permit a sort of player’s trick to avoid that to happen.\n\nAnother good thing to help improving the skills is tips and achievement system like in FIFA 2012. Having assorted tricks displayed while the game is loading the assets is a good chance to let the users review the controls. Achievements, particular during the training session, set as a reminder of different skills need to be mastered.\n\n \n\nThe commentary needs some real polishes. Currently there is one expression for every situation. When the goalie does his magic, it’s always “Saved by the keeper”. Now, when that already happens for several times, you will switch off the commentary because it becomes rather annoying.\n\nAnd last, while the visual is already stunning, there is no doubt that it could be improved. Many high-end Android phones and tablets run on NVIDIA Tegra 3 or other similarly capable processor. Exploiting the more powerful graphics core for high-polygon models, detailed textures, and various special effects will surely improve the game experience dramatically.\n\nFinally, there is always this question whether to get PES 2012 or FIFA 2012. My personal take is simple: play both! Depending on your preference, you might like one of them better but I’m fairly sure the margin for that decision is quite small. For the record, I still prefer FIFA 2012. Wait for my similar review of that game.\n\nIn the mean time, PES 2012 is definitely a 5-star game for me!\n\n(`_|_`)Aug 21, 2012(`_|_`)ariya.io(`_|_`)pro-evolution-soccer-2012', 'pro-evolution-soccer-2012'),
(169, 'Eid Mubarak(`_|_`)\nHappy Eid Al-Fitr everyone!\n\n(`_|_`)Aug 19, 2012(`_|_`)ariya.io(`_|_`)eid-mubarak-6', 'eid-mubarak-6'),
(170, 'QEMU on Ubuntu to run Windows(`_|_`)\nQEMU is a very nice virtual machine and system emulator. Running QEMU on a typical Ubuntu installation proves to be quite straightforward. Here is a quick step-by-step tutorial.\n\nObviously the easiest way to install it is via the binary package:\n\nsudo apt-get install qemu\n\n\nHowever, sometimes you want to play with the emulation, e.g. adding some extra logging here and there to understand how the guest system behaves. For this purposes, QEMU is a good choice. VirtualBox is another open-source virtualization solution, however it’s quite large compared to QEMU. Tweaking QEMU is a lot easier, the code base is small and humanly manageable.\n\nTo compile QEMU from source, we need to have all the necessary tools and libraries available. If your system is not set for compiling anything, then get it ready:\n\nsudo apt-get install build-essentials libsdl1.2-dev\n\n\nAfter that, let’s grab the source and build it:\n\ngit clone git://git.qemu.org/qemu.git\ncd qemu\ngit checkout origin/stable-1.1\n./configure --target-list=i386-softmmu --enable-sdl --disable-xen --disable-kvm\nmake\nsudo make install\n\n\nNote that the above is the minimalistic build, it can be used to launch typical operating systems though it is not optimized for maximum speed. If you want a better performance, I highly recommend enabling Xen and kvm, refer to the documentation for more detailed info.\n\nOnce it’s installed, let’s verify the setup by running a simple Linux system. For this purpose, use the small 20 MB Linux image readily available from QEMU testing page. Launch it like the following command and if nothing goes wrong, you’ll see a window with the terminal indicating a successful Linux boot.\n\nqemu-system-i386 linux-0.2.img\n\n\nWhat about running a much more mainstream OS like Windows? From my experience, installing Windows in a QEMU virtual machine is terribly slow. The technique that I finally used is to have it installed first on a faster virtualizer like VMware or VirtualBox. The latter works quite well. Simply download it from virtualbox.org and install it. After that, create a new virtual machine and then install Windows (32-bit version) there. Once it is done, we just need to convert the image so that QEMU can consume it, as easy as:\n\nqemu-img convert Windows.vdi -O qcow2 Windows.qcow\n\n\nNow launch the converted image:\n\nqemu-system-i386 -m 1024 Windows.qcow\n\n\nThe specified option is to give the virtual machine 1 GB RAM. This is often needed since Windows is quite hungry for memory space. Now you should have Windows up and running. Even networking should work out of box and thus you can use it to run Internet Explorer (for web site testing etc). Granted, the performance is not the best but it works.\n\n\n\n(`_|_`)Aug 15, 2012(`_|_`)ariya.io(`_|_`)qemu-on-ubuntu-to-run-windows', 'qemu-on-ubuntu-to-run-windows'),
(171, 'GitHub and Lack of Search(`_|_`)\n\n\nJust like many of you, I really love GitHub. It is almost perfect for day-to-day development and nothing beats its social features. However, there are still few gaps to fill until it becomes my top choice for more professional development. One thing which still drives me crazy is its lack of full project search.\n\nI am known to discourage the use of GitHub pull request workflow as a form of code review, at least for some projects I maintain. The biggest issue that I have is because the review comments are useless in the long run. Years of working collaboratively taught me two important things about any group discussion:\n\n\nIt has to be persistent: save and restore it again the way you want it\nYou need to be able to search for it\n\n\nThis is why e-mail and wiki work really well. E-mail can be retrieved, fetched, backed up, and restored again in various ways. No e-mail server is holding your emails hostage. Many wiki systems store the contents in a database and as long as you can have the access, you can always get a hand of the full history of the collaborative editing. Using the proper front-end client, you can also search any emails or wiki text you need.\n\nSearch is often forgotten until you have this deja-vu moment, can’t recall exactly what it is but at least you have to chance to narrow down some fuzzy possibilities. If someone gives a nice feedback on a particular pull request you made, there is little chance you or someone else to be able to find it again in few weeks time. You can still dig your email (if you enable the notifications), but that’s one more place you need to hunt.\n\nIf you look at projects like Mozilla and WebKit, the way the code review works is different. Every patch needs to be attached to the corresponding Bugzilla entry. Any review to that patch will appear as another entry comment. This means, you can easily find it later (should you still remember some important keywords) by using the search interface of Bugzilla. Update: Explore this topic in another blog post Cross-Reference: Commit Message and Issue Tracker.\n\nI sincerely hope that GitHub will fix this in the near future. That’ll be really awesome!\n\n(`_|_`)Aug 10, 2012(`_|_`)ariya.io(`_|_`)github-and-lack-of-searchability', 'github-and-lack-of-searchability'),
(172, 'Nexus 7 Web Performance Quick Check(`_|_`)\nThe latest Android tablet Nexus 7 powered by Jelly Bean (Android 4.1) gets many favorable reviews (see the analysis from e.g. Ars Technica, AnandTech, or The Verge). Google Chrome, the default web browser for Jelly Bean, works quite well on this 7″ tablet. How does it compare with other tablets? I’ve done a quick check and here is the result.\n\nMy first test is DOM performance. Looking at how millions of web pages use JavaScript to spice up the contents, I am always a believer that a fantastic performance of DOM access and modification will have an important impact in the perceived smoothness of the page interaction. That was also the basis for my previous web performance analysis of various tablets and smartphones (also for testing Amazon Kindle Fire and Nokia N9/N950). Using the collection of DOM core tests from Dromaeo, here is the colorful chart of the comparison (longer is better) of some tablets within my reach:\n\n\n\nFor more detailed results, check out the Dromaeo numbers (left to right: Playbook, Nexus 7, iPad 2). Playbook is running Playbook OS 2.0.1, Nexus 7 is obviously powered by Android 4.1.1, and iPad 2 has the latest iOS 5. Seems that the race is rather neck and neck.\n\nAs for pure JavaScript performance, there are already tests like SunSpider and V8. I decided to pick something else, namely running the parser benchmark suite of Esprima. Since I already spent a crazy amount of time of optimizing Esprima, I was anxious to see how it performs on devices with limited computing power. It is also interesting to witness how the system copes with a complicated parsing process which involves a lot of recursions, object constructions, and branching. The outcome is as follows (shorter is better), showing that the latest V8 helps Chrome to be ahead of the others:\n\n\n\nAll in all, by no means the above tests were extensive and complete. In addition, it would be nice to get some numbers with the new iPad and the upcoming iOS 6. In few months, perhaps including Windows Surface as well.\n\nFeel free to stress-test your Nexus 7 tablet and share your findings!\n\n(`_|_`)Aug 6, 2012(`_|_`)ariya.io(`_|_`)nexus-7-web-performance-quick-check', 'nexus-7-web-performance-quick-check'),
(173, 'Three Strategies for Your Next Resume(`_|_`)\n\n\n\n\nThere are suggestions out there on how to improve the quality of an online resume (such as LinkedIn) or the dead-tree classic version thereof. Amazingly, I’ve seen tons of cases where people simple ignore those valuable tips. Based on years staring at hundreds of CVs, the following three points are simple ways which have been proven again and again to capture the attention of the hiring crew.\n\nHighlight your achievements, not your responsibilities\n\nIf you are a good family man and you want to brag about it, you won’t just say “I provide food and shelter to my family” since that’s just given. What kind of family man are you if you don’t do that? You need to go further and excite people with how you love your wife and kids.\n\nIt’s very common to see a resume which contains items such as:\n\n\nInstall CentOS, setup Node.js, configure MongoDB.\n\nUse Microsoft Visual Studio.\n\n\nNone of this stands out. There are millions college kids who can do that. In fact, if that is part of your job responsibilities, then by default those things are already expected from you. Write down assignments which you have successfully achieved:\n\n\nDevelop a Node.js module to interface with Oracle Big Data Connector.\n\nImproved the speed of Mercurial plugin for Visual Studio by 250%.\n\n\nDescribe your project, not your alter ego\n\nIf you are a fresh graduate, not much of career experience you can highlight. On the other hand, various projects you have done during your university time can be presented as a show case of what you have mastered. The trick here is the point of view.\n\nConsider the following description in your CV:\n\n\nPassionate about graphics.\n\nLove to inspire other developers.\n\n\nMost recruiter won’t have an idea of what that is. Your potential new boss can’t figure out how your passion and inspiration would help his big project. And what does this sentence even mean? Did you read Foley and van Dam cover to cover and that’s just it? The fact is, nobody cares. You might as well express your love to cats and horses and that won’t change anything.\n\nOnce you turn this into something like:\n\n\nDesigned and coded a multithreaded ray tracer (5000 lines of C++).\n\nOrganize a monthly Scala meetup, with over 50 participants\n\n\nthen it becomes more meaningful. Now it’s rather easy for the hiring manager to guess what you have gone through. If your recognized skill won’t fit exactly to what he needs, he may keep that in mind and match that with other things he plans. And of course, it’s all about metrics so keep everything as quantitative as possible.\n\nMake every word count\n\nYour CV is your strategy to land an amazing new position, it should not become your dissertation. If possible, capture the essence and turn it into a list with just a few items. Learn mind mapping and harness its power for this purpose. Avoid lengthy, buzzword-laden paragraphs if the same thing can be described in fewer words. It can’t go worse if you sprinkle the resume with the overused Linked buzzwords:\n\n\nDynamic, motivated, and visionary technical leader with extensive organizational experience, proven track record in communication skills, and demonstrated history of delivering result-oriented innovative problem solving solutions. Skilled people manager and effective line manager for a creative, collaborative team in a global and diverse engineering organizations.\n\n\nWhy don’t you just say something like the following?\n\n\n15 years of management experience\n\n\nSurely your potential new employer can easily deduce that those years were spent dealing with various organization issues. Making it less bombastic does actually help. Obviously, supply more metrics and other achievements as outline in the previous two strategies.\n\nNot every hiring staff has a photographic memory. Keep it short, simple, and easily memorized.\n\nGood luck with the adventure!\n\n(`_|_`)Aug 1, 2012(`_|_`)ariya.io(`_|_`)three-strategies-for-your-next-resume', 'three-strategies-for-your-next-resume'),
(174, 'Cloud PhantomJS with IronWorker(`_|_`)\nPhantomJS is cloud-friendly as it runs well on Amazon EC2, Heroku, and other server platforms. But what if you want to use PhantomJS without the hassle of setting up and maintaining a server? The solution is to use IronWorker, an elastic task queue service.\n\nAs a service from Iron.io, IronWorker permits running background tasks with very minimal setup and reasonable pricing. In the latest blog post from the team, Serverless PhantomJS with IronWorker, there were already step-by-step instructions on how to run PhantomJS-based tasks with IronWorker. In this blog, I present another complementary quick tutorial which shows the (deadly) combination of PhantomJS and IronWorker. The basic code is taken from IronWorker examples repository.\n\nFirst of all, we need the command-line tool to easily manage any IronWorker tasks. This is available as a Ruby gem called iron_worker_ng, thus it’s rather easy to install:\n\nsudo gem install iron_worker_ng\n\n\nAfter that, sign up for an account. The free plan gives you 5 hours/month service with IronWorker. After you sign in, create a new project and give it a name. After that, you need to find the project ID to retrieve the authentication info. Look for the link Download json file because this simplifies the step (no need for manual copy and paste). Save that JSON to a working directory, rename it to .iron.json and now we are ready to rock.\n\nThe worker itself is rather simple. Create a file phantom.worker with the following contents:\n\nruntime \"binary\"\nexec \"run.sh\"\nfile \"task.js\"\nremote_build_command \'curl http://phantomjs.googlecode.com/files/phantomjs-1.6.1-linux-x86_64-dynamic.tar.bz2 -o p.tar.bz2 && tar xf p.tar.bz2 && rm p.tar.bz2\'\n\n\nThe actual task is task.js (this is the PhantomJS script containing the task you want to carry out) which will get executed by run.sh:\n\nphantomjs-1.6.1-linux-x86_64-dynamic/bin/phantomjs task.js\n\n\nLet’s have a simple task to run in task.js:\n\nvar account = \'PhantomJS\';\nvar page = require(\'webpage\').create();\n \npage.settings.loadImages = false;\n \npage.open(\'http://mobile.twitter.com/\' + account, function (status) {\n  if (status === \'fail\') {\n      console.log(\'Error\');\n  } else {\n    var num = page.evaluate(function () {\n      var selector = \'div.profile td.stat.stat-last div.statnum\';\n      return document.querySelector(selector).innerText;\n    });\n    console.log(\'@\' + account, \'has\', num, \'followers\');\n  }\n  phantom.exit();\n});\n\n\nThis is a simple script which tells you the number of Twitter followers for a specific account, in this case it’s for @PhantomJS, the official Twitter account for PhantomJS. Run it first locally with your installation of PhantomJS to make sure that the script works.\n\nOnce you have these 3 files, phantom.worker, run.sh, and task.js, now all you have to do (from the console) to setup the task is as easy as:\n\niron_worker upload phantom\niron_worker queue phantom\n\n\nGive it a few seconds (or minutes) and then check your project in Iron.io dashboard (look in the Tasks tab). You should see the report that the task has been executed, along with the result (log). Very simple, isn’t it?\n\nNote that you can also take advantage of the scheduling power of IronWorker. For example, you can create a time-based repeated task. There is also a possibility to queue a task at a very specific time. The sky’s the limit.\n\nIn the mean time, I’m back to work on my project proposal to Stark Industries…\n\n\n\n(`_|_`)Jul 30, 2012(`_|_`)ariya.io(`_|_`)cloud-phantomjs-with-ironworker', 'cloud-phantomjs-with-ironworker'),
(175, 'Most Popular JavaScript Tokens(`_|_`)\nAfter you have seen the distribution of JavaScript keywords and statements, it is time for another fun statistics. Now we will take a look at the histogram of various JavaScript tokens.\n\nWhat is a token? According to ECMAScript specification (see Section 5.1.2):\n\n\nInput elements other than white space and comments form the terminal symbols for the syntactic grammar for ECMAScript and are called ECMAScript tokens. These tokens are the reserved words, identifiers, literals, and punctuators of the ECMAScript language.\n\n\nIn Section 7.5, the list of all tokens are provided:\n\n\nIdentifierName\n\nPunctuator\n\nNumericLiteral\n\nStringLiteral\n\n\nFurthermore, Section 7.6.1 says something about reserved words:\n\n\nA reserved word is an IdentifierName that cannot be used as an Identifier.\n\n\nFor example, you can’t use keywords such as if, while, and many others as your variable name. In addition, there are also literals like null, true, and false (the last two are Boolean literals) which belong to this reserved group.\n\nArmed with this information, now it’s time to mine the data. Fortunately, it’s rather easy with the help of Esprima, the standard-compliant and high-performant JavaScript parser. Since Esprima can optionally output the list of all tokens, we just need to harvest them properly. The result will look like the following chart:\n\n\n\nThe corpus is the collection of several libraries in Esprima’s benchmarks test suite. For a good measure, I also added regular expression to the mix, although technically it is not a token per definition. From the look of the chart, seems that our JavaScript programs consist mostly of various punctuators!\n\nIf you like to run the analysis yourself, simply use the tokendist.js example in Esprima source tree, which is also reproduced here for your pleasure:\n\nvar fs = require(\'fs\'),\n    esprima = require(\'esprima\'),\n    files = process.argv.splice(2),\n    histogram,\n    type;\n \nhistogram = {\n    Boolean: ,\n    Identifier: ,\n    Keyword: ,\n    Null: ,\n    Numeric: ,\n    Punctuator: ,\n    RegularExpression: ,\n    String: \n};\n \nfiles.forEach(function (filename) {\n    var content = fs.readFileSync(filename, \'utf-8\'),\n        tokens = esprima.parse(content, { tokens: true }).tokens;\n \n    tokens.forEach(function (token) {\n        histogram[token.type] += 1;\n    });\n});\n \nfor (type in histogram) {\n    if (histogram.hasOwnProperty(type)) {\n        console.log(type, histogram[type]);\n    }\n}\n\n\nRun it using Node.js like the following:\n\nnode tokendist.js /path/to/some/*.js\n\n\nHappy lexing!\n\n(`_|_`)Jul 23, 2012(`_|_`)ariya.io(`_|_`)most-popular-javascript-tokens', 'most-popular-javascript-tokens'),
(176, 'Behind Esprima: Fast, Readable, Heavily Tested, Error Tolerant, Forward Looking(`_|_`)\n\n\nEvery now and then I got someone asking me why I did bother to create Esprima at all. There exists already several great JavaScript parsers written in JavaScript. Most likely, it is easier to use the existing parser than writing a new one. This post summarizes my reasoning behind the birth of Esprima (in no particular order). These are some distinctive features of a parser I’d like to have but there was no parser fulfilling all the requirements at the time and hence why I embarked on a journey to create that parser. Necessity is the mother of invention.\n\nOf course, Esprima is by no means perfect, nor complete. If you have suggestions on how to improve it, join the mailing-list and let’s work together. Esprima already provides the basis for for various tools such as source modification (Esmorph), coverage analyzer (node-cover and coveraje), source-to-source compiler (Harmonizr), syntax formatter (Code Painter), and code generator (escodegen). The exciting Mozilla project LLJS (Low-Level JavaScript) is using the modified version of Esprima parsing routines. Eclipse Orion, the new web-focused development tool, also uses Esprima as the back-end for its smart autocompletion logic.\n\nLet’s bring the state of JavaScript tooling to the next level.\n\nBlazing fast\n\nFor an obvious reason, a faster parser is always better, provided that it does not sacrifice the correctness. Esprima is designed from the ground-up to be fast. In fact, the corpus for the benchmarks suite was among the first thing I planned from day one. As long as the code readability is not degraded, some selected optimizations (such as tuned branching, switch case deoptimization, and object structure) were carefully applied. Even its run-time scalability is monitored closely. Speed matters!\n\n\n\nThe above bar chart (short is better) shows how Esprima compares against the parser from the well-known UglifyJS project. The test machine is a dated Toshiba laptop from 2009 (preinstalled with Windows 7 Home Premium) running the online speed comparison tests.\n\nSensible AST Format\n\nFor the abstract syntax tree (AST), I decided to settle for the same format used in Mozilla SpiderMonkey parser reflection. The reason is simple, the format is closely following the actual ECMAScript language specification. This is also manifested in the source code of Esprima, I stick with the standardized terminologies used in the specification. Having the source code, the specification, and the parser output all speak the same language helps a lot. Even the syntax tree visualization will look familiar.\n\n\n\nHeavily unit tested, with full code coverage\n\nEsprima has more than 500 unit tests, and it keeps growing. While the parser needs to handle unpredictable source the user is throwing at, comprehensive sanity check is still compulsory. For reasons already described elsewhere, every bug fix and feature must be logged in the issue tracker (zero tolerance!). I try to reject a pull request without a filed issue or a test case, somehow that helps (often, indirectly) to harden the parser and to ensure that it remains stable.\n\nCode coverage is just the logical next step after the above. Code that is never executed gives a false sense of accomplishment, it is an accident waiting to happen. Esprima has a full code coverage (to the best the coverage tool can prove it). In fact, reducing code coverage is considered a fatal issue that the contribution guide specifically forbids it: No coverage regression. Again, zero tolerance.\n\nWriting a parser is hard. Even with tons of unit tests, there is no guarantee that it will be bug-free. However, those tests help us sleeping better at night, both these days and in the near future.\n\n\n\nDon’t give up easily\n\nIn a JavaScript engine, the parser is not really forgiving. If the code does not follow the syntax, there is no use in going further because that code can’t be sensibly executed anyway. The parser is therefore built to follow the language specification faithfully, it will bail out when it detects a fatal syntax error.\n\nOn the other hand, a parser which can deal with incomplete or broken code (to a certain threshold) would be particularly useful for various uses cases, among others static analysis and code autocompletion. In fact, this is how smart autocompletion in Eclipse Orion, also known as Content Assist, gets implemented. The completion logic needs to handle invalid syntax because the user can be still in the middle of typing. Being tolerant to such errors (to certain extent), it would have a good semantics overview of the broken code on a best-effort basis.\n\nError tolerant parsing is tricky, it’s still an ongoing work. Expect to see continuous improvements as we try various recovery strategies and refine the implementation.\n\n\n\nForward looking: strict mode, ES.Next, Harmony\n\nStrict mode, ES.Next and Harmony are not second-class citizens in Esprima land. There is no use living in the past. With upcoming language features showing up in modern browsers, the developers will start using it. This is indeed essentials, if the tools (syntax checker, coverage, parser, compressor) do not understand modern language constructs, then developers won’t use it. For example, it would drive you crazy if the editor warns you Code has no effect for that “use strict” (hello NetBeans!).\n\nWhether it’s about strict mode, lexical block scope via let or using Harmony module declaration, Esprima aims to support it. Some of the fun bleeding-edge stuff happens in the special harmony branch. You can see support for ES.Next features such as module, destructuring, class, for-of statement, and many others.\n\nBecause Esprima facilitates non-destructive partial modification (only specific portions of your code are touched, everything else including the comments and indentations are left intact), it can be used for instrumentation purposes such function prolog injection or application startup tracking. Combined with the latest ES.Next goodies, this can lead to an interesting transpiler which permits you to use future JavaScript syntax and run it with today’s browser. As demonstrated by the Harmonizr project, it’s totally possible to write something like:\n\nmodule LinearAlgebra {\n    export const CoordinateSystem = \'Cartesian\';\n \n    // Create 2-D point.\n    export function Point(x, y) {\n        return { x, y };\n    }\n}\n\n\nand gets transpiled into (note how the formatting and comment are not destroyed):\n\nvar LinearAlgebra = function() {\n    const CoordinateSystem = \'Cartesian\';\n \n    // Create 2-D point.\n    function Point(x, y) {\n        return { x: x, y: y };\n    }\n \n    return {\n        CoordinateSystem: CoordinateSystem,\n        Point: Point\n    };\n}();\n\n\nObviously, it is also entirely possible to target AMD or CommonJS module syntax as well.\n\nShall we not have the taste of the bright ES.Next future?\n\n(`_|_`)Jul 18, 2012(`_|_`)ariya.io(`_|_`)behind-esprima', 'behind-esprima');
INSERT INTO `ariyaio` (`id`, `content`, `url`) VALUES
(177, 'Dolphin Engine for Android: First Look(`_|_`)\n\n\nDolphin is a popular alternative web browser for Android. Until recently, it is essentially a custom browser interface on top of the system Android WebKit library. This is now changed with the new Dolphin Engine which promised boosted performance and improved HTML5 support. How does it stack up?\n\nIce Cream Sandwich on Steroid\n\nPreliminary analysis suggests that Dolphin Engine is basically an improved version Android WebKit available in the latest Android 4.0 (Ice Cream Sandwich, often shortened to ICS). There are some characteristics unique to ICS WebKit which are also found in Dolphin Engine. These characteristics are astonishingly similar, it is hard to believe that coincidence is the only possible explanation. You will see some of them as you continue reading.\n\nWhile Android WebKit library is part of the system, it is not impossible to build your own version and distribute it with the application, thereby eliminating the dependency. This however increases the application size, the price you have to pay by bundling your own stuff. Since Dolphin Engine packages its own flavor of WebKit, it is possible to run it on pre-ICS devices and still enjoy ICS-grade features.\n\nAndroid WebKit is always available from its git repository. This is a legal implication since WebKit is distributed under the LGPL and thus the Android has to share their modifications. It is not specific to Android, you can always download the similar part of iOS library since Apple makes it available on its open-source site. Of course, since Dolphin Engine is bounded by the same legal requirement, I hope that whatever tweaks the Dolphin team has made to improve their own flavor of Android WebKit, they will release it either as patches or source code.\n\nThe Score Race\n\n\n\nOne of the major claims of Dolphin Engine is its leading HTML5 support. According to HTML5 Tests, Dolphin Engine gets the score of 450 points (with additional 3 bonus points). As a comparison, the built-in web browser of Android 4.0.4 (Ice Cream Sandwich) only gets 280 points (+3 bonus points) while Chrome for Android (version 18) scores 371 points (+11 bonus points). Looking at just the score, Dolphin Engine is miles ahead of these other two browsers.\n\nLet’s examine in which areas Dolphin Engine has a better feature set. The distribution of additional 170 points of Dolphin Engine compare to ICS Browser looks as follows:\n\n\n  \n    \n      Elements\n    \n    \n    \n      +2\n    \n  \n  \n  \n    \n      Forms\n    \n    \n    \n      +41\n    \n  \n  \n  \n    \n      Microdata\n    \n    \n    \n      +15\n    \n  \n  \n  \n    \n      Web applications\n    \n    \n    \n      +4\n    \n  \n  \n  \n    \n      WebGL\n    \n    \n    \n      +16\n    \n  \n  \n  \n    \n      Communication\n    \n    \n    \n      +24\n    \n  \n  \n  \n    \n      Files\n    \n    \n    \n      +10\n    \n  \n  \n  \n    \n      Storages\n    \n    \n    \n      +10\n    \n  \n  \n  \n    \n      Workers\n    \n    \n    \n      +15\n    \n  \n  \n  \n    \n      Local Multimedia\n    \n    \n    \n      +20\n    \n  \n  \n  \n    \n      Notification\n    \n    \n    \n      +10\n    \n  \n  \n  \n    \n      Others\n    \n    \n    \n      +2\n    \n  \n  \n  \n    \n      Video and Animation\n    \n    \n    \n      +2\n    \n  \n\n\nIt is interesting to notice that in every other category not listed above, Dolphin Engine has the same exact result as ICS Browser. That should the first sign which indicates a close similarity between the two.\n\nThe most significant boost comes from the support of advanced form element. Dolphin Engine understands many input types, anything from date to color. This is done by hooking the input field to the native Android control, either from the standard picker or a custom-built one. This turns out not to be too difficult to achieve yet the impact on the HTML5 score is massive. Although ICS Browser is still a bit behind, both Chrome for Android and Opera Mobile almost reach the full score on this form element support.\n\n  \n\nNext score improvement is due to the better communication support, including server-sent events, XHR2, and WebSocket. Modern browsers have a fully-functional support for these features. On the WebKit-side, the code to deal with them was implemented since some time ago. Again, ICS Browser does not enable them yet but Chrome for Android gives a much more feature coverage in this category.\n\nFurther improvements come for a variety of device access API, 3-D context, and many others, some of which will be discussed in the following sections.\n\nJavaScript, DOM, and CSS\n\nThe comparison of pure JavaScript performance is always fascinating. For a start, let’s compare the running-time of SunSpider tests (shorter is better) between Dolphin Engine, ICS Browser, and Chrome for Android. The tests were carried out on Nexus S running the latest Android 4.0.4.\n\n\n\nThe result again demonstrates how incredibly close Dolphin Engine gets to ICS WebKit performance. Chrome for Android however shows its level, the updated V8 within Chrome makes SunSpider tests run slightly faster.\n\nNow, let me pick the benchmark suite of Esprima, the fast JavaScript parser I’ve started some months ago. The tests are more intensive, they also contain a lot of recursion which is very typical for a parser. Again, ICS WebKit and Dolphin Engine are on the same stage while Chrome leaves them behind. The similar running time of ICS WebKit and Dolphin Engine was another proof that they are basically in the same family.\n\n\n\nPure JavaScript performance is fun but it’s not the only important thing. As I wrote before when I analyzed the web performance of smartphones and tablets, the performance of DOM access and manipulation plays an important role. Many web sites are adding richness to the web page with various user interactions which involves such operations. My favorite tool for this case is Dromaeo, the DOM-oriented benchmarks from Mozilla. Unfortunately, running the smallest set of Dromaeo tests will crash Dolphin Engine. Quite unsurprisingly, the stock Android Browser on ICS also crashes, exactly at the same spot like with Dolphin Engine.\n\nThe performance of CSS transition and animation is pretty good. I can’t really notice the difference between ICS Browser and Dolphin Engine, again likely because their close relation. In some cases, ICS Browser is known to have some performance problem (see issue 25147) thought it does not become so bad anymore with the latest update. I can witness the same problem exists in Dolphin Engine.\n\nSpeaking about animation, the resolution of JavaScript timer can play an important when doing a frame-based manual animation. I have this little timer test which gives a rough idea how many ticks per second at most we can expect from setTimeout with a 0 timeout. Dolphin Engine will settle to around 85 ticks/seconds, this is also the same number you would get from ICS Browser while Chrome for Android gives a result almost double to that. This is again another undisputed proof that Dolphin Engine shares a lot of machinery with ICS Browser.\n\nFor application development, having the ability to debug the web page is a time-saving feature. WebKit remote debugging, which is activated in iOS 6, Blackberry Playbook, and Chrome for Android, proves to be a favorite. Having its root in ICS WebKit, the new Dolphin Engine apparently does not support it. I certainly wish that some future version of Dolphin Engine will enable remote inspection.\n\n2-D Canvas: Very Fast vs Very Slow\n\nIn general, we also need to be careful whenever there is a strong claim like 5-10X faster. As any performance guru can tell you, speeding up few specific scenarios is different than making sure that the performance improvements won’t regress other cases. Dolphin Engine demo page has three examples (using Canvas), demonstrating its acceleration technology: Dolphins, Windmill, and Poker. Running these examples with Dolphin Engine, ICS Browser, and Chrome for Android shows how fast Dolphin Engine is at rendering the animation.\n\nWhen we look carefully, it’s rather obvious that the examples focus only on image drawing with different transformation matrix. In these 3 examples, the same sprite is drawn over and over again but each sprite may get unique scaling and translation. This use-case can be optimized by taking advantage of GPU texture buffer, once the pixels for the sprite is pushed as a texture, drawing it anywhere with any transformation is a piece of cake for modern mobile GPU.\n\nCanvas however does not only have an API to draw image. You can draw various other shapes, you can even read and write individual pixel. All these operations can be interleaved and they are supposed to work together really well. This is where Dolphin Engine is not up to its claim. When running examples which involve pixel manipulation, such as the Underwater effect or Crossfading, Dolphin Engine gets stuck, possible saturating the pipeline to the GPU.\n\nAgain, being fast on certain operations does not translate to the necessary acceptable performance across the board. Canvas optimization is tricky. I certainly believe that this still must be improved over the time.\n\n  \n\nWebGL\n\nCanvas is mainly used for 2-D graphics, WebGL is more useful for doing 3-D. Many desktop browsers, including WebKit-based ones such as Safari and Chrome, support WebGL just fine. The problem with WebGL usually lies in the graphics system of the machine, either because of sub-par graphics card or buggy drivers. On the mobile front, enabling WebGL in WebKit is not difficult. However, the challenge is on the actually delivered performance. Since Android runs on many different devices, it is not trivial to predict the performance characteristics. The proliferation of Android devices means that QA plays an important role in the product development.\n\nDolphin Engine supports WebGL most likely by having its WebKit library built with that feature flag enabled. Most of the code to deal with WebGL has been available for quite some time. On iOS, although it is available from Mobile Safari, you can already use it via iAd. Playbook from RIM can also run many WebGL applications.\n\nRunning Dolphin with simple WebGL examples and demos does not present any problem. However, once the use of WebGL is a little bit more complicated, things start to fall apart. Often some textures won’t show up, in other cases the browser itself crashes. This is a good example why merely getting the full WebGL’s 25 points on HTML5Test score does not mean much if the feature itself does not always give what you want. Maybe there is a reason (beside the security issue) why other WebKit-based browser does not enable it by default.\n\n \n\n \n\nDevice Access\n\nDolphin Engine has some nice features in the category of device access. Most notable here is the camera access. There is an included link to the demo which basically grabs the frame from the camera and show it live. It works pretty well, smooth and fluid. There is some annoyances if you try to go fullscreen and then come back again, as well as when you switch application while the camera is still running. I believe such bugs should be solved rather easily as Dolphin Engine goes through more extensive QA.\n\nThe only scary thing about the camera access is because there is no permission mechanism at all. If you recall the well-known geolocation feature, the browser needs to ask explicit permission from the user before it gets the access to the location data. For this camera capture on Dolphin Engine, there is no prompt asking for such access, the JavaScript application is simply granted the permission to the camera data. Compare this to Opera Mobile which also supports camera access but with a permission prompt.\n\n\n\nOne of my favorite feature of a mobile device is accelerometer access. Combined with a simple physics (based on Box2D, the popular physics engine which powers Angry Birds, among others), acceleration can lead to a simple demo which I call Box of Marbles. Amazingly, Android WebKit since Honeycomb has this weird bug, the acceleration vector for the gravity direction is upside down. This means, those colorful marbles actually flying to the top of the phone, as opposed to bouncing down to the bottom. This problem does not show up in Chrome for Android. Just like ICS WebKit, Dolphin Engine also demonstrates this upside down behavior, another proof that those two are very close family indeed.\n\n\n\nVerdict\n\nIs Dolphin Engine good? Without doubt. We have to give the team some credit for the tweaks and improvements. Is it earth-shattering? I don’t think so, unfortunately. As evidenced from the above analysis, the Dolphin team took Android WebKit as the basis, compiled it with various flags enabled, and the added some improvements here and there. The enhancements are more last-mile than anything groundbreaking. There is even a noticeable Canvas performance regression.\n\nIn all cases, the world of Android web browsers is getting exciting. Google Chrome becomes the default browser for Android 4.1 (Jelly Bean) and later. There are also Opera Mobile and Firefox which keep getting better and better. Fun times ahead!\n\n(`_|_`)Jul 17, 2012(`_|_`)ariya.io(`_|_`)dolphin-engine-for-android-first-look', 'dolphin-engine-for-android-first-look'),
(178, 'Mac OS X: Tracking Disk I/O Activities(`_|_`)\nMany modern laptops come with an SSD (solid-state drive) instead of a traditional magnetic disk. Because it is silent, it is not possible to hear the spinning sound anymore as the disk enters a period of high activities. This can be bad, often a continuous I/O access indicates a problem in the running system.\n\n\n\nFor latest Mac OS X versions, fortunately we have iotop and fs_usage (need sudo to run). The former will sample I/O events by process, sampled in a periodic interval (default to 5 seconds). The latter does the work different as it simply fills the screen with all disk-related system calls and related activities. I found out that iotop works really good as a general monitoring, just to ensure that nothing really saturates the disk bandwidth, while fs_usage is fantastic to find out who is actually doing something crazy there.\n\nGenerally, I prefer to do some filtering, e.g.:\n\nsudo fs_usage -f filesys\n\n\nonly bugs you with file system events, everything else is ignored. There are other filter modes such as network, exec, path, etc. Refer to the manpage for more detailed info.\n\nRunning fs_usage once a while reveals how web browsers are still very chatty with respect to disk I/O. For example, running Chrome and opening about:blank still shows countless calls like the following. Of course without knowing what files are associated with that handle 20 and 21, it’s impossible to reach any conclusion.\n\n22:16:39.355599  write   F=21   B=0x1         0.000004   Google Chrome.4147134\n22:16:39.355611  write   F=21   B=0x1         0.000002   Google Chrome.4147134\n22:16:39.355779  read    F=20   B=0x1         0.000003   Google Chrome.4147134\n22:16:39.355788  read    F=20   B=0x1         0.000002   Google Chrome.4147134\n\n\nAt least when I close Chrome, all those calls disappear. The same goes with many applications, until I hit Parallels Desktop. There are some running services which keep accessing the virtual machine files every second, long after any virtual machine have been shutdown. This is quite mysterious to me. I solve the issue by stopping the launch daemon:\n\nsudo launchctl stop com.parallels.desktop.launchdaemon\n\n\nObviously, before launching Parallels again, I’ll start the daemon manually (do the same like above but replace stop with start).\n\nIf you never use iotop or fs_usage before, give them a try. Do you find any I/O activities from some application you would never thought before?\n\n(`_|_`)Jul 12, 2012(`_|_`)ariya.io(`_|_`)mac-os-x-tracking-disk-io-activities', 'mac-os-x-tracking-disk-io-activities'),
(179, 'JavaScript Code Editing with Autocompletion in Eclipse Orion(`_|_`)\nVersion 0.5 of Eclipse Orion, the web-focused IDE, has been released. One of its improved features is a better editing autocomplete, known in the Eclipse world as Content Assist or within Microsoft Visual Studio users as IntelliSense. The logic to drive the autocompletion is made possible because the parser understands syntax errors in the source text and keeps going without the need to stop immediately.\n\nOrion autocompletion backend is based on Esprima, the fast JavaScript parser I’ve started some months ago. In the Esprima world, the ability to recover from a parsing error is denoted as tolerant mode. This is still a work-in-progress, see issue 130, although it already works to a certain extent. Orion itself uses a modified version of Esprima with a higher level of error tolerance, this will be somehow merged back into upstream at some point in the near future.\n\n\n\nThe blog post Better JavaScript content assist in Eclipse Orion from Andrew gives a detailed information how content assist works. This is a must read if you want to know what happens behind the scene and would like to apply the approach for other uses cases.\n\nThe parser in a real JavaScript engine usually will refuse to continue once it finds an error. This makes sense, there is no benefit of processing the code if it is not valid anyway. However, we can see from the above smart autocompletion feature that sometimes a tolerant parser can be really useful!\n\n(`_|_`)Jul 10, 2012(`_|_`)ariya.io(`_|_`)code-editing-with-autocompletion-in-eclipse-orion', 'code-editing-with-autocompletion-in-eclipse-orion'),
(180, 'Lazy Parsing in JavaScript Engines(`_|_`)\nModern JavaScript engines can defer the parsing process of a function body until it is completely needed. Why is this done and how does this work?\n\nThe last blog post titled Advances in JavaScript Performance in IE10 and Windows 8 from the Internet Explorer team mentions the use of deferred parsing to improve the performance. In fact, the stable IE 9 already implements such optimization while IE 10 improves it further to take account the popular module pattern. According to team (Chakra refers to the JavaScript engine used in IE):\n\n\nTo further reduce the time to first executed instruction, Chakra processes and emits bytecode only for functions that are about to be executed using a mechanism called deferred parsing.\n\n\nLet’s have a simplified example to see how this works. Supposed your web application looks like the following JavaScript code.\n\nfunction add(x, y) { return x + y; }\nfunction mul(x, y) { return x * y; }\nalert(add(40, 2));\n\n\nBefore the engine can execute the code, it has to feed the source into its parser. The purpose of the parser is to perform the syntactic analysis and to produce an abstract syntax tree (AST). For an illustrative example on how the syntax tree may look like, you can use the online parser demo of Esprima (a JavaScript parser project I have started some months ago). The full syntax tree will be quite complex, but if we translate the work of the parser to plain English, this is what happens:\n\n\nDeclare a function called add. It accepts x and y as the arguments. It has one statement, a return statement.The return value is a binary operation + of x and y.\n\nDeclare a function called mul. It accepts x and y as the arguments. It has one statement, a return statement. The return value is a binary operation * of x and y.\n\nCreate a function call to alert. The argument is the result of function add with 40 and 2 as the arguments.\n\n\nBased on this syntax tree, some more magic occurs. At the end of the day, when the interpreter executes your code, it pops-up the dialog with the answer. Now, if you pay attention carefully, there is a wasted step from the above work of the parser, namely the effort to parse function mul because it is not being called at all, the later alert only invokes function add. While this example might be really simple and obvious, in real-world (according to Microsoft JSMeter research), a lot of declared functions are never called at all.\n\nInstead of dutifully parsing everything at one, modern JavaScript engine uses the lazy parsing approach. The work of the parser changes into something like:\n\n\nDeclare a function call add with the function body “{ return x + y; }”.\n\nDeclare a function call mul with the function body “{ return x * y; }”.\n\nCall alert with the result of function add with 40 and 2 as the arguments.\n\n\nHere the parser does not bother to go deep into the statements of each and every function. At the execution stage, the sequence continues:\n\n\nCall function add. Hmm, it is not parsed yet. Call the real parser for “{ return x + y; }”.\n\nIt accepts x and y as the arguments. The return value is a binary operation + of x and y.\n\n\nBasically the task of parsing the source for that function is deferred, it is only carried out when it is necessary, right before executing it. The lazy parser still needs to parse the incoming source because it needs to locate the entire function body. If you see function add(x, y) { then you need to locate the matching } which ends the function body. It can’t be done by regular expression or any form of scanning, the parser needs to consume the code as if it is a real code. The good news is that the parser does not need to do much beside trying to find that closing curly brace. This means it can optimize a certain thing. For a start, we do not need the syntax tree because it is not going to be processed by anyone. In addition, the code path does not need to use any memory from the heap. Allocating memory eats the system resource, avoiding it will lead to a speed-up.\n\nHere is an analogy in real-life. You stumble upon a nice article (maybe this blog post) but then you realize that you only want to read it later when you need it. You decide to stash the text (digitally of course) in your note. You still have to scan the blog post to find out where it starts and where it ends, though you can do this scanning rather quickly (faster than reading the entire text). Once you get the start and the end markers, you can just select the text, copy it to the clipboard, switch to the note application, and finally paste the content. When it is finally the time to use the information in to the article, you open the note and complete the reading.\n\nLet’s compare some hypothetical code to parse a while statement. As you already know, this statement has the following grammar:\n\n\n‘while’ ‘(‘ Expression ‘)’ Statement\n\n\nThe real parser needs to understand this and produce an abstract syntax tree (AST) which represents the construct. The code for doing that, if it would have been in JavaScript, may look like:\n\nfunction realParseWhileStatement()\n{\n  expect(\'while\');\n  expect(\'(\');\n  var expression = parseExpression();\n  expect(\')\');\n  var statement = parseStatement();\n \n  // node for the AST\n  return {\n    type: \'WhileStatement\',\n    test: expression,\n    body: statement\n  };\n}\n\n\nIn the case of lazy parsing, we don’t care about the result and thus the code is simplified to:\n\nfunction lazyParseWhileStatement()\n{\n  expect(\'while\');\n  expect(\'(\');\n  parseExpression();\n  expect(\')\');\n  parseStatement();\n}\n\n\nObviously there are other functions to parse various constructs as specified in the grammar. The bottom line is that the parser has to consume all the tokens and advances as farther as it can until the function body is completed. That way, it knows where is the closing curly brace to to match the opening curly brace that starts the function body.\n\nWhat if during lazy parsing we stumble upon another nested function declaration? The same rule applies and therefore that function will be lazily parsed. Function Inception, anyone?\n\nIn reality, lazy parser can be slightly complicated, this involves handling strict mode properly, making sure parsing error is taken care, avoiding stack overflow (for recursive descent parser), and many other delicate situations.\n\nLet’s see how this lazy parsing approach is implemented in two popular JavaScript engines.\n\nFirst, we look at JavaScriptCore (JSC), the engine used in WebKit and powers the popular Apple Safari browser (desktop and mobile). The source code for JavaScriptCore resides in Source/JavaScriptCore subdirectory, if you check out WebKit code. The files relevant to the lazy parsers are:\n\nparser/Parser.h\nparser/Parser.cpp\nparser/SyntaxChecker.h\n\n\nThe normal parser and the lazy parser in JavaScriptCore are essentially the same code, the specialization is done through C++ template. The parser itself does not construct a syntax tree, the job is delegated to a TreeBuilder. There are two builders available, ASTBuilder and SyntaxChecker. The latter essentially does nothing, but since it is driven by the parser, the parser can go forward and consume the constructs to any point it wants to stop. It acts as some kind of syntax checker, hence the name.\n\nJSC parser uses the SyntaxChecker builder whenever it needs to parse a function body, see parseFunctionBody, which gets called from parseFunctionInfo (this leads to a funny variable name in the code, FunctionBodyBuilder). After the syntax checker stops at then of the function body, the range which scopes the curly braces will be stored, this is needed when the real parsing kicks in at some later stage, i.e. when that function is invoked. Because JSC keeps the entire source, storing the range is sufficient and there is no need to copy the source string.\n\nThe situation is similar in V8, the JavaScript engine used in Google Chrome and Node.js. Files related to the lazy parsing in V8 source code are:\n\nsrc/preparser.cc\nsrc/preparser.h\nsrc/preparser-api.cc\n\n\nUnlike JSC, V8 has two different code base (but with similar interface) for the normal parser and the lazy parser. The latter is called PreParser in V8 terminology. This PreParser kicks in when V8 encounters a function body during the parsing, i.e Parser::ParseFunctionLiteral. Interesting enough, V8 does an optimization for a special case. This is the case for immediately invoked function expression, a pattern popular to provide better namespacing without polluting the global and therefore perfect to implement a module, e.g.:\n\nvar foobar = (function() {\n    //  do something\n    //  return the module object\n})();\n\n\nBecause this pattern is quite common nowadays, V8 detects the usage using a simple heuristic: if there is ( before function, then forget the lazy parsing and do the real parsing. In the above example, V8 will produce a syntax tree for the statements inside the function.\n\nWhat about SpiderMonkey, Mozilla JavaScript engine used in Firefox? Lazy parsing is not there yet but it is being implemented, just track Mozilla bug 678037. This will be another awesome move to improve Firefox performance.\n\nLast but not least, since this blog post is quite long, you might just quickly scan it and read it later. That’s called deferred reading!\n\n(`_|_`)Jul 3, 2012(`_|_`)ariya.io(`_|_`)lazy-parsing-in-javascript-engines', 'lazy-parsing-in-javascript-engines'),
(181, 'Nitro, JavaScriptCore, and JIT(`_|_`)\n\n\n\n\nThe subject of UIWebView not using JIT-enabled JavaScript engine becomes popular again, mainly due to the fresh release of Google Chrome for iOS. Unlike Chrome on other platform, Chrome on iOS is just an alternative user-interface on top of the UIWebView component hence making Chrome slightly inferior to Safari in pure JavaScript performance. This is usually not a problem since general web browsing does not involve heavy computation done in JavaScript. Update: Chrome under the hood packs some network awesomeness (SPDY, prefetching, etc).\n\nA term which often shows up when discussing UIWebView is Nitro. What is exactly Nitro? First, let’s go back to the early moment when Apple mentioned Nitro. The press release Apple Announces Safari 4 says:\n\n\nSafari 4 is built on the world’s most advanced browser technologies including the new Nitro JavaScript engine that executes JavaScript up to 30 times faster than IE 7 and more than three times faster than Firefox 3.\n\n\nThis was from February 2009. Later on, during WWDC in June, Safari 4 hit the final release. From the marketing material, there is hardly any mention of JIT, presumably because it is too technical for the general audience. However, if we look at the WebKit history, clearly this engine has that advanced JIT support. This is evidenced from the blog post Introducing SquirrelFish Extreme back in late 2008.\n\nNote that technically speaking the JavaScript engine in WebKit is called JavaScriptCore. Its source code directory is called Source/JavaScriptCore. When it is installed in the system, the library JavaScriptCore.Framework is also using that name. If you are old enough to remember, JavaScriptCore was originally derived from KJS, KDE’s JavaScript engine. In fact, this was way before Safari time.\n\nThese days, there are apparently two schools of thoughts about what Nitro is.\n\nNitro = Booster via JIT\n\nAfter Safari 4, a lot of people associate Nitro with JIT. This is emphasized again when iOS got updated to get JIT-powered Mobile Safari. When UIWebView did not get the JIT version of the engine, there was a lot of buzz, even Gruber wrote something like:\n\n\nThe Nitro JavaScript engine is only available within Mobile Safari.\n\n\nIn this interpretation, Nitro is identical to the some sort extra injection (Nitrous oxide) to boost the performance. This leaves a room for question: is there a name of the non-Nitro situation?\n\nUpdate: For this camp, referring to the UIWebView situation would be:\n\n\nMobile Safari uses Nitro\nUIWebView still uses who-can-remember-that-JavaScript-engine-without-JIT\n\n\nNitro = JavaScriptCore\n\nAnother group of people argue that Nitro is nothing but a marketing term for JavaScriptCore. It is the same thing, nothing more and nothing less. Two names for the same code. Apple’s press release did not insist that Nitro is JIT-only engine. The statement reads like “This fast engine is named JavaScriptCore by our engineers, but you can just call it Nitro”.\n\nWhether it has JIT support or not, the name shall not change. It’s rather easy to refer both situations:\n\n\nMobile Safari uses Nitro with JIT support\nUIWebView still uses Nitro without JIT support\n\n\nTo further reduce the ambiguity, we might even drop Nitro completely and stick with JavaScriptCore. Hence, Gruber should have written:\n\n\nJavaScriptCore, the JavaScript engine, only supports JIT within Mobile Safari.\n\n\nI believe calling it JIT vs no-JIT gives a clear meaning. It’s less confusing than Nitro vs whatever-engine-which-does-not-have-JIT. Why are we confusing ourselves?\n\nWhich school of thought are you subscribed to?\n\n(`_|_`)Jun 29, 2012(`_|_`)ariya.io(`_|_`)nitro-javascriptcore-and-jit', 'nitro-javascriptcore-and-jit'),
(182, 'PhantomJS 1.6 \"Lavender\"(`_|_`)\n (By Fir0002/Flagstaffotos (Own work) CC-BY-NC, via Wikimedia Commons)\n\nSome days ago, right during the solstice, I have tagged version 1.6.0 of PhantomJS, the scriptable headless WebKit. This version is named Lavender, the story goes as follows:\n\n\n…for this summer release, I pick the code name “Lavender”. This summer flower is not only beautiful, it is also known for its wonderful scent and soothing quality, often served as a remedy for anything from sore joints to insomnia. Well, with the widespread use of PhantomJS in various testing frameworks since some releases ago, isn’t that exactly what this headless WebKit also brings to many web developers? Helping people to stay calm, avoid anxiety, and increase their productivity is surely a decent goal to have!\n\n\nLavender is a rather minor update, you are welcomed to check the release notes to see what is inside there. Some of the features are added because they are necessary to other PhantomJS-based project. For example, Ivan has added functionalities important for Ghost Driver, an implementation of the Remote WebDriver Wire protocol. If you are currently using Selenium, keep an eye on Ghost Driver as it will be very useful to complement your Selenium-based testing workflow. In another front, Jon improved various aspects of PhantomJS such as stack trace and crash reporting, which in turns will benefit Poltergeist. If you develop Rails applications and use Capybara, consider looking at using Poltergeist since it can capture screenshots, debug remotely, give meaningful error information, and many more.\n\nThe last release, Ghost Flower, was a smashing success. The total download for all the source and binary packages reaches almost 30 thousands, the mailing-list grows to about 600 members. Let’s see if we can repeat the success with this summer edition.\n\nKudos to all contributors to this Lavender release!\n\n(`_|_`)Jun 23, 2012(`_|_`)ariya.io(`_|_`)phantomjs-1-6-lavender', 'phantomjs-1-6-lavender'),
(183, 'Esprima and Harmony Module(`_|_`)\nWhen developing a large-scale application, modularity becomes an important factor. If the environment is JavaScript, several module patterns, from AMD to CommonJS, are available for your disposal. Every one of them usually works around the fact that there is no linking stage in JavaScript, all compilation units are loaded together. Fortunately, this issue is addressed in Harmony, aka the next-generation ECMAScript, since it will introduce a new form of module system.\n\nAs of now, no JavaScript environment understands the Harmony module syntax yet. Therefore, there is no way you can use the syntax directly. One possible solution is to convert this future syntax to something which can be consumed by this generation’s browsers. It’s like Back to Future, except it’s going the other way around. This approach is often denoted as transpilation. Google’s project Traceur is probably one example of such a transpiler. For example, given this futuristic code:\n\nmodule LinearAlgebra {\n    export const CoordinateSystem = \'Cartesian\';\n \n    // Create 2-D point.\n    export function Point(x, y) {\n        return { x, y };\n    }\n}\n\n\nTraceur will compile it to something like this (note that any comments will be removed):\n\nvar LinearAlgebra =(function() { \n  \"use strict\"; \n  Object.defineProperty(this, \"CoordinateSystem\", { \n    get: function() { \n      return CoordinateSystem; \n    }, \n    enumerable: true \n  }); \n  Object.defineProperty(this, \"Point\", { \n    get: function() { \n      return Point; \n    }, \n    enumerable: true \n  }); \n  Object.freeze(this); \n  var CoordinateSystem = \'Cartesian\'; \n  function Point(x, y) { \n    return { \n      x: x, \n      y: y \n    }; \n  } \n  return this; \n}).call(Object.create(null));\n\n\nCareful readers might spot return {x, y}, which is invalid in today’s JavaScript. This is another Harmony feature: property value shorthand for object literals.\n\nUsing transpiler seems to be an optimal solution since we can already use the syntax (until one day all JavaScript engines understand the module system) and therefore it’s future-proof. Of course, even better if we can tweak the transpiler to output something which suits our need. Some projects use AMD and might prefer that format as the target compilation. Others may want to preserve all comments, possibly because of important annotation and/or API documentation.\n\nFortunately, it’s rather possible to create your own transpiler based on Esprima, the ECMAScript parser project I started few months ago. In the harmony branch of Esprima, support for features available in future generation JavaScript is being developed. As of now, it does understand Harmony module syntax on a best-effort basis, since the proposed syntax may change again. You can already try this with the online parser demo. If you paste the previous example and visualize the syntax, it will be like the following (collapsed at the statement level, but you get the idea):\n\n\n\nOnce you get the syntax tree, it’s now easy to convert the syntax. Because Esprima can track the location of each syntax node, there is no need to regenerate the entire code (like what Traceur does). This is what I often call as non-destructive partial modification (those who follow my blog may notice that I’ve previously used the same technique to change string literal quote, inject function prolog, and track application startup). Essentially we are just interested in the module construct (since we want to transpile it) and therefore we won’t touch anything else, hence the term non-destructive. This also means that comments and formatting will be intact!\n\nAs the demo, please just use Esprima-based online transpiler (part of the harmony branch, not the master branch). The previous example will be converted into (note how the the single-line comment there is not removed at all):\n\nvar LinearAlgebra = function() {\n    const CoordinateSystem = \'Cartesian\';\n \n    // Create 2-D point.\n    function Point(x, y) {\n        return { x: x, y: y };\n    }\n \n    return {\n        CoordinateSystem: CoordinateSystem,\n        Point: Point\n    };\n}();\n\n\nThe core functionality of the module transpiler is actually a separate project by Jason Diamond, it’s called Harmonizr. In fact, Harmonizr can target other types of module including AMD and Node.js, see its really cool online demo you can play with. It should not also come as a surprise that Harmonizr transpiles itself.\n\nIt’s hot, don’t you think so?\n\n(`_|_`)Jun 20, 2012(`_|_`)ariya.io(`_|_`)esprima-and-harmony-module', 'esprima-and-harmony-module'),
(184, 'Detecting Boolean Traps with Esprima(`_|_`)\nA bad API can lead to ambiguities and reduced readability. One very common thing I still encounter in various JavaScript frameworks is the so-called Boolean trap, i.e. the unwise use of Boolean argument(s) in a function call. Reviewing or reading code which gets trapped there is not fun. The earlier we can catch such as a bad behavior, the better our chance is to prevent it to become widespread.\n\nFortunately, with the help of a syntax parser, catching possible Boolean traps is not a monumental job. This blog post describes the strategy to do it. Here we are using Esprima, the blazing-fast standard-compliant ECMAScript parser which I started some time ago. In fact, this tool is now part of Esprima examples, check out examples/findbooleantrap.js (less than 200 lines). Invoke the script as follows:\n\nnode findbooleantrap.js /some/path\n\n\nEvery file in that specified directory will be located and parsed. If parsing does not fail, the syntax tree will be analyzed to find 5 (five) possible Boolean problems:\n\n\nA non-setter function having the Boolean literal as its argument. It’s assumed that a setter function will start with set, e.g. setEnabled. An example which will be caught:\n\nthis.refresh(true);\n\n\nDouble-negative function name, e.g. setHidden. In this case setVisible will be less confusing.\n\nitem.setHidden(false);\n\n\n“Can you make up your mind?” moment, such as jQuery stop:\n\nelement.stop(true, false);\n\n\nA crazy stream of Boolean literals, as demonstrated by the DOM initKeyEvent:\n\nevent.initKeyEvent(\'keypress\', true, true, null, null, false, false, false, false);\n\n\nUseless last parameter which can’t explain anything (unless you read the documentation):\n\nreturn getSomething(obj, false);\n\n\n\nSince this is just a simple script, obviously you can tweak it to suit your need. For example, many projects do not use an explicit setter function which leads to code like enable(true) and thus the first check can produce a lot of noise. The double-negative warning is done by a cross-reference to a short blacklist, hence you may want to populate the blacklist with more entries.\n\nThe main gut of this script is a syntax tree traversal function with a visitor. The traversal can be carried out in many different ways, the script uses this simple approach:\n\nfunction traverse(object, visitor) {\n    var key, child;\n \n    if (visitor.call(null, object) === false) {\n        return;\n    }\n    for (key in object) {\n        if (object.hasOwnProperty(key)) {\n            child = object[key];\n            if (typeof child === \'object\' && child !== null) {\n                traverse(child, visitor);\n            }\n        }\n    }\n}\n\n\nwhich will be used like this:\n\ntraverse(syntax, function (node) {\n    if (node.type === \'CallExpression\') {\n        // check node\n    }\n});\n\n\nAs an illustration, the code fragment to detect the fifth condition mentioned in the list before is as follows:\n\nfunction checkLastArgument(node) {\n    var args = node[\'arguments\'];\n    if (typeof args[args.length - 1].value === \'boolean\')\n        report(node, \'Ambiguous Boolean literal as the last argument\');\n}\n\n\nRather straightforward, isn’t it? Similar logic exists to handle other four suspicious usages of Boolean literals. Because Esprima can give location information for every syntax node, it’s rather trivial to display the line number where the problem is found. Feel free to explore the code and possibly even improve it.\n\nSo what are you waiting for? Install Node.js if you don’t have it yet, grab Esprima from its Git repo, and off you go. Beside fixing the existing API, you may also want to consider running the checks as part of your project pre-commit hook. Enjoy and haveFun(true)!\n\n(`_|_`)Jun 14, 2012(`_|_`)ariya.io(`_|_`)detecting-boolean-traps-with-esprima', 'detecting-boolean-traps-with-esprima'),
(185, 'Sierra Foxtrot Oscar Alpha Mike Sierra(`_|_`)\nLast week Fluent Conference in San Francisco was a blast. I got to meet old friends, made new ones, and finally got to speak to some people I know only from the online media. For a nice wrap-up (along with the list of interesting videos), check out Axel’s blog post.\n\nFor the next week, I’m scheduled to be in Amsterdam for another event, Dutch Mobile Conference. Like I wrote before, this will be my second conference in this short summer tour. My two tracks at this one will be about Understanding Hardware Acceleration on Mobile Browsers and Strategies for End-to-End Web Apps Testing.\n\nFrom this cafe, I can see the big bird I’m supposed to board in some moment. SFO-AMS, be nice to me.\n\n(`_|_`)Jun 5, 2012(`_|_`)ariya.io(`_|_`)sierra-foxtrot-oscar-alpha-mike-sierra', 'sierra-foxtrot-oscar-alpha-mike-sierra'),
(186, 'Summer 2012 Conferences(`_|_`)\n\n\nIt’s summer! Time for me to hit the road and give some tech talks.\n\nFor O’Reilly’s Fluent 2012 in San Francisco, May 29-31, I’ll be talking about JavaScript Parser Infrastructure for Code Quality Analysis (Thu 1:45pm). If you know me and some of my latest activities, you probably can guess what this is all about. I’m excited about this because it is the first Fluent conference, no doubt there will be a lot of important JavaScript folks there. The short description of this talk is as follows.\n\n\nModern web frameworks, libraries, and applications will grow to be more complex. Maintaining the quality of such complex system is far from trivial. However, the currently available tools do not grow fast enough to accomodate the exploding need for advanced code quality analysis, likely due to the lack of the building blocks to build such high-level tools. One of the missing blocks is a future-looking JavaScript parser. This talk discusses the development of Esprima, a new JavaScript parser designed from the ground-up to be readable, high performant, easily extensible and able to accommodate future ES Harmony features. Since the parser output is a simple JSON-formatted AST, a few further tools have been built, among others source minification and rewriting, function tracing, static analyzer, run-time complexity profiling, and many more.\n\n\nAnother O’Reilly conference in the pipeline is the high-profile Velocity 2012. Just like last year, it is held in Santa Clara, June 25-27. This time, my talk is titled Understanding Hardware Acceleration on Mobile Browsers (Tue 5:20 pm), with the following abstract:\n\n\nGPU acceleration on mobile browsers, if it is leveraged correctly, can lead to a smooth and fluid applications, thus improving the user experience. There has been a lot of mentions and best practices of hardware acceleration these days, although so far it has been pretty general and hasn’t provided much technical direction apart from simple magical advice such as “use translate3d”. This talk sheds some more light on browser interactions with the GPU and explain what happens behind the scenes, covering the topic of acceleration of primitive drawing, the use of tiled backing store, and composited layer. Knowing the actual machinery behind hardware acceleration, you will be in the position to plan your strategy to improve the performance of your web application.\n\n\nNow, if you live in Europe and for some reason can’t make it to any of these conferences, don’t lose hope yet. There’s Dutch Mobile Conference in Amsterdam (June 6-9) where I will be presenting the similar variants of the above two talks, under the track Understanding Hardware Acceleration on Mobile Browsers and Strategies for End-to-End Web Apps Testing. I’ve been to Amsterdam once (quiz: does anyone remember for what it was?), I can’t wait to get to try rijsttafel again!\n\nIf you will be around in any of these places, drop by and say hello!\n\n(`_|_`)May 21, 2012(`_|_`)ariya.io(`_|_`)summer-2012-conferences', 'summer-2012-conferences'),
(187, 'Software Project and House Rules(`_|_`)\n\n\nThere was a lot of discussion about the recent rejection of Github pull request workflow by Linus Torvalds, the father of Git (and Linux). Note that Linus does like Github, “great at hosting”. Unfortunately the submission via the pull request mechanic does not meet the standard of kernel contribution.\n\nI’m all for lowering the barrier to contribute something useful to a software project. Sadly, these days I also witness a lot of “shoot first, ask later” attitude. Just because a project is hosted on Github, it does not mean you can fire your editor and register a pull request and be done with it. Often, the first thing I have to write to comment a pull request is (with the suitable hyperlink):\n\n\nPlease read the contribution guide.\n\n\nBelow I highlight a few good practices which should serve as a laundry list, should you want to send an improvement or a bug fix to the project maintainer. Some of them are just common sense, but then we live in a generation where common sense starts to become a rarity. In one way or another, you may observe that some maintainers are very picky about this because they need to live with what you have produced for the lifetime of the project, while you can just perfectly disappear the next day and won’t care about it.\n\nCheck first for a contribution process. Because of legal reasons, some organizations mandate a special arrangement, e.g. Contribution License Agreement (CLA). In other cases, few maintainers want the assurance that your work is really yours, i.e. not owned by your current employer. Licensing is also a tricky matter, make sure you are aware of the implication of whatever you share with an external project.\n\nNext, observe how the past contributions were made. Is there an official guide which gives the step-by-step instruction? Or maybe it is not that formalized and thus do you have to consult the maintainer or the mailing-list? Does everything need to filed in the issue tracker? Do you need to format your patch in a certain way? Is there a ChangeLog file? By adopting the way the members of the project discusses and carries out the development, you will be easily familiar with the process.\n\nWrite a decent commit log, e.g. a model Git commit message. A short message like “Fix stuff” won’t help anyone. You may need to write in proper English and avoid e.g. txt lingo. Nowadays, many projects also require that the link to the bug/review is to be included somewhere. Look at the past commits and find the patterns there.\n\nFollow the testing procedure. Sending a pull request which provokes tons of regressions will not impress anyone. Watch for all kind of tests, from unit tests, functional tests, code coverage, performance stress, and even coding style. Being careful with your contribution shows how you value the project and its future, you will earn some respect in due time.\n\nAsk for some review as early as possible. Writing software is about iteration, it’s all continuous improvement and refactoring. Don’t wait until your stuff is fully ready before screaming for some feedback. Those who work on the project for a while might have a big-picture understanding which you don’t have. Showing a half-baked patch which can be polished as you learn is better than pushing a perfect improvement which later gets rejected by the maintainer.\n\nLast but not least, remember that sharing is beautiful and it is great that you are willing to give back something to the community. However, do not forget that project maintenance is hard (that’s why you find a lot of rotten projects out there). Engage in a discussion, share responsibly, and surely world domination will be in our hand someday!\n\nBut I have no doubt, one day the sun will come out.\n\n(`_|_`)May 17, 2012(`_|_`)ariya.io(`_|_`)software-project-and-house-rules', 'software-project-and-house-rules');
INSERT INTO `ariyaio` (`id`, `content`, `url`) VALUES
(188, 'JavaScript Identifier Length Distribution(`_|_`)\nAfter the fun distribution charts of statements and keywords in popular JavaScript libraries, it is time for another metrics analysis. For a while, I was wondering how JavaScript developers come up with a variable name, function name, and other identifiers. Is it just few characters? Is it not that short? Is it always descriptive? The following script idlen.js (to be executed with Node.js) uses the parser from Esprima to dump all the identifiers, excluding the duplicates, of each file in its its corpus of libraries (for the benchmark suite).\n\nvar fs = require(\'fs\'),\n    esprima = require(\'esprima\'),\n    files = process.argv.splice(2);\n \nfiles.forEach(function (filename) {\n    var identifiers = {},\n        content = fs.readFileSync(filename, \'utf-8\'),\n        syntax = esprima.parse(content);\n \n    JSON.stringify(syntax, function (key, value) {\n        if (key === \'name\' && typeof identifiers[value] === \'undefined\') {\n            identifiers[value] = value.length;\n        }\n        return value;\n    });\n \n    for (var key in identifiers) {\n        if (identifiers.hasOwnProperty(key)) {\n            console.log(identifiers[key]);\n        }\n    }\n});\n\n\nWith the help of Unix tools:\n\nnode idlen.js /path/to/some/*.js | sort -n | uniq -c\n\n\nthe distribution will look like the following diagram:\n\n\n\nThere is a long tail from 15 characters and above, which makes sense since an identifier that long will be likely special cases only (excluding this long tail region, the data roughly follows the expected normal distribution). The actual mean of the identifier length is 8.27 characters.\n\nFor the fun of it, the top 5 longest identifiers found among the libraries, with over 34 characters, are:\n\nprototype-1.7.0.0.js   SCRIPT_ELEMENT_REJECTS_TEXTNODE_APPENDING\nprototype-1.7.0.0.js   MOUSEENTER_MOUSELEAVE_EVENTS_SUPPORTED\n     jquery-1.7.1.js   subtractsBorderForOverflowNotVisible\njquery.mobile-1.0.js   getClosestElementWithVirtualBinding\nprototype-1.7.0.0.js   HAS_EXTENDED_CREATE_ELEMENT_SYNTAX\n\n\nWhat kind of distribution do you get for your own JavaScript project?\n\n(`_|_`)May 14, 2012(`_|_`)ariya.io(`_|_`)javascript-identifier-length-distribution', 'javascript-identifier-length-distribution'),
(189, 'Defense Against the Dark Plug-ins(`_|_`)\nAccording to Albus Dumbledore:\n\n\n“You see, we have not been able to keep a Defence Against the Dark Arts professor for more than a year since I refused the post to Lord Voldemort.”\n\n\nThere have been various recent events which showed how dangerous it is to pass the control to a proprietary binary, especially the one with a rather disastrous security track record. Zero-day Flash exploit was used to attack the big security firm, RSA. At the last Pwn2own, Chrome was exploited likely through the included Flash plugin, even with Chrome having its plugin sandboxed. Faux billing email from Vodafone was circulating, mostly targeting the Germans, with the attached malicious PDF which leverages Adobe Reader exploit to automatically download the real trojan payload. A huge number of Mac systems were lately infected by the Flashback botnet, originally started as a fake Flash installer and now taking advantage of Java vulnerabilities. While this was still hot, SabPub malware surfaced, this time using Word security hole to trigger a backdoor.\n\nSecurity in the browsers needs to be hardened, otherwise the users will be left in the open. It’s no wonder that the future version of Firefox may have built-in support for plugins opt-in, also popular as click-to-play. For the current version of Firefox, a solution is to use Flashlock add-on, Flash content in the web page will be blocked and not played immediately, rather an explicit click from the user is needed to activate it. For those with Safari, there are ClickToPlugin and ClickToFlash which have the similar functionality.\n\nAs for Google Chrome, the opt-in feature is available built-in. Go to the Wrench menu, Settings. From the settings interface, choose Under the Hood, scroll to the Plug-Ins section, and simply choose Click to play instead of Run automatically. From now on, Flash and other plugins will be forced to stop. Only if you think it’s legitimate and click on it, then the plug-in will run.\n\n\n\nAs a bonus, using this opt-in feature somehow improves the browsing experience because all those annoying Flash ads cease to disrupt the actual business of information consumption.\n\n(`_|_`)Apr 23, 2012(`_|_`)ariya.io(`_|_`)defense-against-the-dark-plug-ins', 'defense-against-the-dark-plug-ins'),
(190, 'Most Popular JavaScript Statements(`_|_`)\nAfter you’ve seen the chart of JavaScript keywords distribution, it’s time to go a bit deeper to the syntax level. This time let’s find out the most popular JavaScript statements. The specification lists 15 different types of statements, with the iteration statements having four possible variants. Like the previous attempt, using Esprima and its corpus of libraries (for the benchmark suite), I got the following chart:\n\n\n\nFor all intents and purposes, I also throw VariableDeclaration and FunctionDeclaration into the analysis. For the latter, the difference between a properly hoisted declaration and a declaration inside e.g. ForStatement is not taken into account, which is likely just fine.\n\nAgain, real-world applications can show a different chart. If you are interested in running the analysis on your own code, use the following quick tool statement.js (utilizing Esprima package):\n\nvar fs = require(\'fs\'),\n    esprima = require(\'esprima\'),\n    files = process.argv.splice(2);\n \nfiles.forEach(function (filename) {\n    var content = fs.readFileSync(filename, \'utf-8\'),\n        syntax = esprima.parse(content);\n \n    JSON.stringify(syntax, function (key, value) {\n        if (key === \'type\') {\n            if (value.match(/Declaration$/) ||\n                value.match(/Statement$/)) {\n                    console.log(value);\n                }\n        }\n        return value;\n    });\n});\n\n\nand run it with Node.js as follows:\n\nnode statement.js myapp.js mylib.js others/*.js | sort | uniq -c | sort -nr\n\n\nHow’s the statement distribution in your application?\n\n(`_|_`)Apr 19, 2012(`_|_`)ariya.io(`_|_`)most-popular-javascript-statements', 'most-popular-javascript-statements'),
(191, 'Sierra Foxtrot Oscar Charlie Golf Kilo(`_|_`)\nFor the next few weeks, don’t expect much updates on this blog. Within few hours I am scheduled to take a flight SFO-HGK-SIN-CGK. Unless something is going terribly wrong, I’ll be in Indonesia to handle some important matters. I will not maintain a strict radio silence, but since I plan to leverage the opportunity to keep my focus, I may not be super responsive at times.\n\nJust like the last time, bracing for the impact of tasty food (putu, martabak, sponge cake, sate kelapa, …).\n\n(`_|_`)Apr 16, 2012(`_|_`)ariya.io(`_|_`)sierra-foxtrot-oscar-charlie-golf-kilo', 'sierra-foxtrot-oscar-charlie-golf-kilo'),
(192, 'PhantomJS Myths: Busted(`_|_`)\n\n\nWhile PhantomJS is far from perfect, there are still some misconceptions out there. This blog post attempts to clarify some of them.\n\nPhantomJS on Linux is not truly headless, I still need to run X11 or Xvfb.\n\nThat is not true anymore since for quite some time (I spare you the details, but it is involving the Lighthouse project). In fact, it works like a charm that it is now the standard setup if you build PhantomJS Linux from source. Pure headless, pure possibilities.\n\nRead also the blog post”) where I describe the workflow when I finalized and tested the X11-less version PhantomJS. In short, install a barebone Ubuntu server with no GUI (i.e. no KDE, no GNOME, no X server at all) and you can use PhantomJS just fine. That’s as minimalistic as it can get, perfect for continuous integration (Jenkins, TeamCity, etc). Want to run on Amazon EC2? Be my guest, PhantomJS goes to the cloud already.\n\nInstalling PhantomJS is really slow.\n\nThat’s only true if you do it via a tool which compiles PhantomJS from source, e.g. old MacPorts or Homebrew. I mean, when did the last time you compile your web browser from source?\n\nAs this blog post mentions, the most recommended way to install PhantomJS on Mac is by using its binary package which weighs at just 10 MB. The entire process might take just 5 minutes of your time. Even the updated Homebrew formula for PhantomJS does that exactly, brew install phantomjs is fast and efficient.\n\nI don’t like/want the binary because I still need to install Qt manually.\n\nIf you actually read the wiki page carefully, it mentions e.g. “fresh install of Snow Leopard or Lion…” for Mac OS X. In other words, the binary is stand-alone. It does not require you to install anything else beforehand. No prerequisites. Zero dependency. The same applies for the Windows version.\n\nThe situation is slightly different for Linux. Even though PhantomJS is completely headless”) there, text rendering still requires the de-facto Freetype and Fontconfig libraries (which does make sense since we don’t want to duplicate the functionalities). They are very simple to install. In fact, if a barebone minimalistic Ubuntu Lucid server sans GUI can run PhantomJS binary package just fine, most likely it would work well on your target host as well.\n\nHow is it possible? The build workflow of PhantomJS takes care of integrating Qt into the build, even optionally compress the final result so that at the end all you have to do is download + unzip + have fun. Let us handle all the trouble, you don’t need to.\n\nIt’s a PITA to install PhantomJS.\n\nThis is borderline. As of now, installation is not most trivial step to do. It might be a minor hassle, but it is definitely not PITA. Since PhantomJS project is driven by the community, unless someone volunteers to create a single-click installer, it will not happen. If you are ready to help, there is an open ticket (issue 466) for that!\n\nIf unzipping a package and playing with PATH are too complicated for you, well, now there’s an excuse to learn a thing or two. Think about it, unless you are Chuck Norris, what is likely chance that you become a Grand Master just by flipping two or three chess books?\n\nPhantomJS is too complicated, it’s difficult to use.\n\nAgain, it depends on your skills, experience, and expectation. Many people use PhantomJS directly, as evidenced from tons of reports out there. Others use PhantomJS in conjunction with other tools, for example Guard::Jasmine to drive Jasmine-based unit tests, Poltergeist as a driver for Capybara, GhostDriver to complement Selenium Web Driver scenario, and many others. There are even higher-level convenience libraries, notable here is CasperJS, which facilitate easy sequential navigation testing (among others). PhantomJS was designed from the ground-up to promote a healthy ecosystem and thus make sure you explore it.\n\nSome notable and popular frameworks, such as Ember.js, Modernizr, Zepto.js, and BrowserID, are already leveraging PhantomJS to conveniently run the automated tests. You may learn a thing or two from the way these projects use PhantomJS!\n\n(`_|_`)Apr 12, 2012(`_|_`)ariya.io(`_|_`)phantomjs-myths-busted', 'phantomjs-myths-busted'),
(193, 'JavaScript switch case Deoptimization(`_|_`)\nWhen I looked at some of the functions in the core parser of Esprima, I usually had one or two ideas on how to improve the readability. A week ago my concern was a pair of function important for parsing objects in the literal format. It’s a heavily branched code using a switch statement, as illustrated in the code for one of them:\n\nfunction parseObjectPropertyKey() {\n    var token = lex(),\n        key;\n \n    switch (token.type) {\n \n    case Token.StringLiteral:\n    case Token.NumericLiteral:\n        if (strict && token.octal) {\n            throwError(token, Messages.StrictOctalLiteral);\n        }\n        key = createLiteral(token);\n        break;\n \n    case Token.Identifier:\n    case Token.Keyword:\n    case Token.BooleanLiteral:\n    case Token.NullLiteral:\n        key = {\n            type: Syntax.Identifier,\n            name: token.value\n        };\n        break;\n \n    default:\n    }\n \n    return key;\n }\n\n\nSomehow my poor brain cells believed that the above construct can be simplified. I immediately thought of using an if statement but then many JavaScript optimization techniques often mention that the switch statement is a better approach than the branching via the if statement. My gut feeling said that for this particular case, if vs switch does not matter much. The question in my mind was, how can I know this for sure? That simple question turned my evening into a long one.\n\nMy journey started after I got myself a fresh build of V8 bleeding-edge, version 3.10. I also crafted a minimalistic script which loads every test fixture in the existing benchmark corpus and passes the content to the parser. After a few false starts, finally running the debugger shell with its various tracing options, most important in this context is --trace-bailout, suddenly gave me the answer (check also the post from Florian Loitsch about bail-out and other related V8 flags):\n\nBailout in HGraphBuilder: @\"parseObjectPropertyKey\": SwitchStatement:\nnon-literal switch label\n\n\nIn plain English, this is what happens. The high-level optimizer, part of V8 Hydrogen (H stands for high-level, its low-level counterpart is called Lithium), stops trying to “understand” parseObjectPropertyKey() function as it trips and bails out on one particular condition: the switch has one or more cases which are not small integers (smi) or strings. If you look back at the code of that function, the labels for each case are Token.StringLiteral, Token.NumericLiteral, etc. They are actually just integer numbers, here I abuse JavaScript object as a form of enumeration.\n\nOnce the problem is known, at least two possible solutions are available. First option is to use actual integer constants instead of fake enums, e.g.\n\nswitch (token.type) {\n    case 8: // Token.StringLiteral\n    case 6: // Token.NumericLiteral\n        ....\n    }\n\n\nI personally don’t like how it looks. Another alternative is to use an if statement, something that I originally wanted to do anyway (for the sake of readability). The function now looks like:\n\nfunction parseObjectPropertyKey() {\n    var token = lex();\n \n    if (token.type === Token.StringLiteral || token.type === Token.NumericLiteral) {\n        if (strict && token.octal) {\n            throwError(token, Messages.StrictOctalLiteral);\n        }\n        return createLiteral(token);\n    }\n \n    return {\n        type: Syntax.Identifier,\n        name: token.value\n    };\n}\n\n\nAfter this change, when I traced the bail out possibility again, V8 did not complain. I also modified the construct of the companion parseObjectProperty() function to follow the similar pattern. All is good!\n\nBut how about the overall speed? Running the full benchmark suite with the updated version of the code does not show any noticeable speed-up or slow-down. This is to be expected. After all, my original intention was to improve the code clarity without affecting the performance. The reason for no radical speed difference is very simple. First, the function is not executed too many times. When the parser consumes jQuery source, it hits parseObjectPropertyKey() function only about 600 times. Compare this to parsePrimaryExpression() which gets executed more than 11 thousands time. Second, the task carried out by this function is extremely simple, there is no heavy computation or back-breaking work.\n\nFor completeness, and also emphasized by the last point, the standard optimization disclaimer follows. Unless you are extremely sure that the switch statement is quite complex and being hit a gazillion times in a typical circumstance, do not hope that changing it into another way of branching will magically make it faster. Take into account that different JavaScript engines might behave differently and therefore verify your theory with various JavaScript environments. Even two different versions of the same engine can show two different results, e.g. the above bail out condition I stumbled upon may just become obsolete in the future.\n\nAs a closing trivia, you might notice that V8 has two different optimizers: high-level and low-level, referred in source code as Hydrogen and Lithium (notice the initial letters, H and L). There can be many reasons why these names are picked. My own fictionalized backstory is simple: the compound Lithium hybride (LiH) …\n\n\n…was once tested as a fuel component in a model rocket.\n\n\nIn any case, that long evening I had was educational and entertaining. That matters!\n\n(`_|_`)Apr 10, 2012(`_|_`)ariya.io(`_|_`)javascript-switch-case-deoptimization', 'javascript-switch-case-deoptimization'),
(194, 'Bootstrapping a New Look(`_|_`)\nAs you can see, this blog finally gets a new look based on the excellent WordPress Bootstrap theme from 320press (modelled after Twitter Bootstrap). Behind the scene, there is also another major change as I moved from self-hosted WordPress with Dreamhost to the managed WordPress service from Page.ly (Note: this is a referral link), the widely known high-performance and secured WordPress hosting. If you think my blog is now much faster than before, that’s hopefully one of the impacts.\n\nThe major reason behind this recent move is rather scary. My previous WordPress installation was breached and the content was modified for some dubious SEO campaign. It might be just an accident but apparently at around the same time 18 million hosted blogs at WordPress.com were also compromised. It could be the case of cross-contamination, something which is known to trigger the Blackhat SEO malware. Since I am not a security expert and I know almost nothing about WordPress, it was hard for me to find out what went wrong (I did the usual basic steps to harden WordPress as I did the installation). Perhaps my shell account was simply cracked.\n\nDuring the back-up and the moving process to the new setup, the only forensic act I did was to check the WordPress installation itself. Compared to the fresh 3.3.1, there is this malicious injection:\n\n@@ -1,4 +1,5 @@\n-< ?php\n+<?php\n+@include_once $_SERVER[\'DOCUMENT_ROOT\'].\'/wp-includes/license.txt\';\n /**\n  * WordPress DB Class\n  *\n\n\nThat referred license.txt is timestamped March 29, 2012 (if that can be trusted at all). As expected, the content of the file is not the actual license of WordPress but rather the obfuscated PHP code to carry out suspicious bootstrapping sequences as the initial attack. After formatting it, you can see the full content at gist.github.com/2338282. I know very little PHP and I don’t have the motivation to decipher the entire attack machinery, but I hope this can be useful for some security experts and/or malware analyzers out there. \n\nIn the last half a year, my blog gets an average of 12K visits/month, with the bandwidth consumption reaching up 15 GB/month. If there will be another incident like this in the near future, perhaps I should just give up dynamic content management and write or generate plain document instead. In the mean time, keep reading!\n\n(`_|_`)Apr 9, 2012(`_|_`)ariya.io(`_|_`)bootstrapping-a-new-look', 'bootstrapping-a-new-look'),
(195, 'JavaScript syntax tree visualization with Esprima(`_|_`)\nOne little feature I added to Esprima parser demo was syntax tree visualization (using YUI TreeView). While it is already possible to see the JSON version of the parsed AST, often a much more visual representation improves the syntax analysis workflow. It is also more educational. An example code that follows:\n\nanswer = 42\n\n\nwill produce this view:\n\n\n\nNeat, isn’t it? Since Esprima AST is compatible to Mozilla Reflect API, which also uses the same terminologies as in the official ECMAScript specification, this makes it easy to follow if you learn the language grammar.\n\nEven though Esprima only parses the code and does not actually evaluate it, the tree version of the syntax can be useful to decipher a mysterious construct. Take a look at something that Stoyan Stefanov tweeted some time ago:\n\n{1 + \"\"} + 10;\n\n\nPasting the snippet into Esprima parser demo yields (make sure you tick the raw checkbox):\n\n\n\nThat should explain a lot. Apparently here the curly braces have nothing to do with an object literal, which what people usually expect, but it’s just a simple block statement. The code can be treated as two statements, the block statement is the first and another expression statement follows.\n\nAnother tweet from Joe Armstrong (of Erlang fame):\n\n\"a\" + + + + 10\n\n\n\n\nThis did happen because he missed the two +’s in a row. From the parse tree, this is easy to spot. Once we collapse the whole unary subexpressions (i.e. +(+x) is just x), the entire expression is essentially the same as:\n\n\"a\" + 10\n\n\nwhich gets executed as a string concatenation with the addition operator.\n\nInterested in? Go to Esprima live parser demo and give it a go!\n\n(`_|_`)Apr 4, 2012(`_|_`)ariya.io(`_|_`)javascript-syntax-tree-visualization-with-esprima', 'javascript-syntax-tree-visualization-with-esprima'),
(196, 'Cloud PhantomJS on Amazon EC2(`_|_`)\nJoining the buzzword-laden crowd, here I’d like to say that PhantomJS goes to the cloud.\n\nBack to the realistic world, this blog post shows how easy it is to build and deploy PhantomJS on a Linux instance of Amazon EC2. If you are not familiar with EC2, it’s the Elastic Compute Cloud platform from Amazon Web Service, essentially computer resource you can rent and scale up/down as neeeded. EC2 is quite popular, it powers various consumer-oriented services, from Amazon.com itself to Netflix.\n\n\n\nArtwork credit: Internet cloud, Cartoon ghost.\n\nThere are two keys to the enablement of PhantomJS on EC2: the improved build workflow and the true headless”) feature. Assuming you have an instance running, it’s a matter of the following commands:\n\nsudo yum install gcc-c++ git chrpath openssl-devel freetype-devel fontconfig-devel\ngit clone git://github.com/ariya/phantomjs.git && cd phantomjs\ngit checkout 1.5\n./build.sh --jobs 1\n\n\nThat was tested in a 64-bit image with the following /etc/system-release:\n\n\nAmazon Linux AMI release 2011.09\n\n\nNote: With Amazon Linux AMI release 2012.03, make is also needed, i.e. sudo yum install make.\n\nAs expected, there is no need to have any sort of GUI to run PhantomJS. Pure headless.\n\nFor some tweaks and other notes, read the complete PhantomJS build instruction info. Please note that the build may take a long time, the Linux Micro Instance (free usage tier) took about 28 hours to complete the entire process. You may also switch to another Linux image or even build locally first on a beefy machine and then upload the resulting build. In fact, you could also use the included script deploy/package-linux-dynamic.sh to pack the build into a tarball and transport it somewhere else, e.g. further AMI instances. The package will be self-contained, the proof is in the result of running ldd on the binary:\n\nlinux-vdso.so.1 =>  (0x00007fff02dff000)\nlibdl.so.2 => /lib64/libdl.so.2 (0x00007fc9d266b000)\nlibQtWebKit.so.4 => /home/ec2-user/deploy/phantomjs/bin/../lib/libQtWebKit.so.4 (0x00007fc9d0cf3000)\nlibQtGui.so.4 => /home/ec2-user/deploy/phantomjs/bin/../lib/libQtGui.so.4 (0x00007fc9d01d6000)\nlibQtNetwork.so.4 => /home/ec2-user/deploy/phantomjs/bin/../lib/libQtNetwork.so.4 (0x00007fc9cfe92000)\nlibQtCore.so.4 => /home/ec2-user/deploy/phantomjs/bin/../lib/libQtCore.so.4 (0x00007fc9cf93e000)\nlibpthread.so.0 => /lib64/libpthread.so.0 (0x00007fc9cf722000)\nlibstdc++.so.6 => /usr/lib64/libstdc++.so.6 (0x00007fc9cf41c000)\nlibm.so.6 => /lib64/libm.so.6 (0x00007fc9cf197000)\nlibgcc_s.so.1 => /lib64/libgcc_s.so.1 (0x00007fc9cef81000)\nlibc.so.6 => /lib64/libc.so.6 (0x00007fc9cebe0000)\n/lib64/ld-linux-x86-64.so.2 (0x00007fc9d2877000)\nlibfreetype.so.6 => /usr/lib64/libfreetype.so.6 (0x00007fc9ce942000)\nlibfontconfig.so.1 => /usr/lib64/libfontconfig.so.1 (0x00007fc9ce70c000)\nlibrt.so.1 => /lib64/librt.so.1 (0x00007fc9ce504000)\nlibexpat.so.1 => /lib64/libexpat.so.1 (0x00007fc9ce2db000)\n\n\nNow that you have something wandering around in the cloud, what can you do with it? There are few example usages of PhantomJS which may inspire you. Personally what I’d like to appear someday are the screenshot service and the next-generation network monitoring service.\n\nFor the screenshot service, it’s necessary to combine PhantomJS with other web stack frameworks. Basically PhantomJS is just the back-end, its screen capture will be driven by another middleware. There are examples of such an implementation using Perl Dancer (Screenshot), Node.js (screenshot-app), Python/Flask (bookmarking service), and Play2 (screenshot-webservice). For a reference of a commercial screenshot service, take a look at URL2PNG which seems to capture the web page using the Linux version of Chromium 11 (that’s a release from a year ago). Using Chromium might give a better rendering fidelity although a headless optimized PhantomJS is guaranteed to be more resource/CPU friendly.\n\nOne underrated feature of PhantomJS is its ability to track network activity, i.e. every single network response and request along with the timing information. This is used in e.g. confess.js. An export to HAR format is almost trivial. Now imagine you build an advanced network traffic and monitoring service based on this feature. You can enrich the report with tons of useful (and useless) metrics and stats, everything from HTTP header analysis, detailed breakdown of assets size, complete network waterfall diagram, optimization opportunities, and many more. Maybe even the screen capture of the monitored site. If your client focuses on interactive web page or rich internet apps (RIA), you can even report the code coverage and full execution trace by leveraging my other project, Esprima.\n\nDo I hear a startup?\n\n(`_|_`)Apr 2, 2012(`_|_`)ariya.io(`_|_`)cloud-phantomjs-on-amazon-ec2', 'cloud-phantomjs-on-amazon-ec2'),
(197, 'Esprima and its scalable parsing(`_|_`)\nIt’s lunch time. You enter your favorite cafe and place an order for your beloved sandwich. Nobody else is there so your tasty meal is ready in some minutes. The next day, the same situation. This time, there are few other customers in front of you. You wonder if your waiting time (for the sandwich to arrive) remains the same or if it increases linearly or even quadratically. In other words, you are curious about the scalability of the sandwich preparation process.\n\nThis is the topic I’ve touched before. In complex client-side and server-side JavaScript-heavy application, the absolute running time of a critical procedure is important but that is not the only important thing. The performance of the system also depends on the ability of that critical procedure to scale as the input data grows.\n\nAnother real-world example here is given for Esprima, the ECMAScript parser I’m deeply involved with. From the very beginning, the performance of the parser is a major concern. The running-time of the benchmarks suite is something that we watch closely. The corpus of the benchmarks suite itself is a collection of popular libraries, from Underscore to jQuery Mobile.\n\nA formal analysis of the time complexity of the parsing code will be beyond my limited math skills. In addition, it could be extremely time consuming and not worth the effort. A practical alternative is doing a representative empirical analysis. For Esprima’s benchmarks suite, plotting the parsing time as a function of the code size gives the following chart:\n\n\n\nDue its recursive descent approach, it should be possible to craft a special source which abuses Esprima parser by carefully exhausting the call stack. However, for parsing real-world code, as demonstrated in the benchmark corpus, we can be quite content that there is a comfortable upper bound as to when it is going to finish. Even though Esprima is provided “as is” and without any warranties, somehow its run-time scalable behavior makes me sleep better at night!\n\n(`_|_`)Mar 29, 2012(`_|_`)ariya.io(`_|_`)esprima-and-its-scalable-parsing', 'esprima-and-its-scalable-parsing'),
(198, 'Pure headless PhantomJS (no X11 or Xvfb)(`_|_`)\nStarting from Ghost Flower, the recent PhantomJS 1.5 release, the standard build for Linux is pure headless without X11. Even Xvfb is not needed. That means you can compile and use PhantomJS in a system without any GUI at all. This would be really useful in some setup such as continuous integration systems, web service platforms, and many others.\n\nHow does this work? It’s actually rather easy since Qt supports platform abstraction in the form of QPA, formerly known as Lighthouse. This video should give a good technical overview of the magic of Lighthouse. Leo Franchi from KDAB started the initial work on bringing this Lighthouse awesomeness to PhantomJS some time ago.\n\nThe approach I used when finalizing this headless solution was to have Ubuntu 10.04 (Lucid Lynx) virtual machine running without any desktop environment, not even X libraries. Lucid was chosen due to its LTS status and many production systems are still based on it. In addition, if it works there then likely it would work on the newer Ubuntu releases. Here is a screenshot:\n\n\n\nAfter getting PhantomJS built, I ran the rasterizer example to render the famous Tiger head (SVG) to an image (PNG). The image was then uploaded using another example script which demonstrates HTTP POST to send the image to Imagebin. Everything works well in that barebone Lucid server.\n\nObviously it is not limited to SVG-to-PNG conversion. Normal web page can be captured to an image as well. As predicted, text is still rendered via FreeType and Fontconfig which is nice since we will still get high quality rendering even on an environment sans GUI.\n\nFor a quick try, just download the binary package prepared by Jon Leighton (of Ruby on Rails fame). Make sure you pick the right one, 32-bit or 64-bit, depending on your system. Note that there is no need to preinstall Qt or any other libraries as PhantomJS build workflow already takes care of that. You still need FreeType and Fontconfig for the reason mentioned above.\n\nCompiling from source is also quite easy, just follow the documentation:\n\nsudo apt-get install build-essential chrpath git-core libssl-dev libfontconfig1-dev\ngit clone git://github.com/ariya/phantomjs.git && cd phantomjs\ngit checkout 1.5\n./build.sh\n\n\nObviously other Linux distributions can handle that just fine. You may need to tweak the actual packages and package manager but the principle remains the same.\n\nNext: let’s bring PhantomJS to the cloud!\n\nStay hungry, stay foolish, and stay headless.\n\n(`_|_`)Mar 27, 2012(`_|_`)ariya.io(`_|_`)pure-headless-phantomjs-no-x11-or-xvfb', 'pure-headless-phantomjs-no-x11-or-xvfb'),
(199, 'The evolution of PhantomJS build workflow(`_|_`)\n\n\nThe above text cloud is created using Fotowall.\n\nStarting from the recently released PhantomJS version 1.5, also known as Ghost Flower, a minimalistic version of Qt library is bundled into its source tree. This blog post shows some history and reasoning behind it. If you just want to use PhantomJS, nothing changes for you. However, if you are curious about the machinery behind its build, then continue reading.\n\nOne thing I have wanted to experiment for a while is the rapid release cycle. For PhantomJS, it means four releases per year, each is aligned with the season and the release date is matched to the equinox or solstice. PhantomJS uses Qt (with its excellent WebKit integration) as the basis. Since Qt releases are not as often as PhantomJS, this caused some complications.\n\nThe first and foremost problem was the long wait until a new Qt release is available. In particular, every Qt release carries a fresh and updated WebKit module which usually solves a lot of compatibilities issues. However, longer release period means that a Qt bug will stay in few PhantomJS versions until a fix is available. In addition, an extremely long period of Qt 4.8 development did not help PhantomJS marched forward as fast I would like it to be. Qt 4.8.0 was out mid December last year, 15 months after Qt 4.7.0. As a comparison, the time lapse between Qt 4.6.0 to 4.7.0 was just over 9 months.\n\nAnother problem is the build issue. As much as I’d like Qt to be ubiquitious, unfortunately that’s not the case. On Windows, the situation is not that bad because it’s not very often someone is compiling from source on this platform. On Linux, there were often crash reports because people are using PhantomJS against outdated Qt 4.6 and no official fresh Qt package available on that distribution. That’s discouraging but not much we can do about it.\n\nOn Mac OS X, it was pretty hopeless since everyone tends to use MacPorts or Homebrew to install PhantomJS. They think PhantomJS is just a fun little tool. Unless Qt is already built by MacPorts/Homebrew, suddenly that innocent one line command keeps the machine busy for hours. Everyone complained about this all the time that I decided to put a notice about this situation everywhere: in the README, build instructions wiki, and even a blog post about it. Amazingly some people still prefer to “shoot first, ask later”, once a while the predictable ‘PhantomJS takes ages to build’-type of rant shows up somewhere.\n\nThis build issue is temporarily solved by having a special build script. The script automatically downloads latest Qt source code from Nokia web site, builds Qt locally, and compiles PhantomJS with it. As a bonus, the entire build on Mac OS X is faster than Homebrew/MacPorts because only the necessary parts of Qt were compiled (no need for demos, samples, documentation, various tools). Another advantage is that we can apply patches which improve various things. Here is an incomplete list of shortcomings of using plain vanilla or outdated Qt which other QtWebKit-based tools may suffer but we don’t (thanks to the custom build and patching):\n\n\nno cross-domain XHR (issue 28)\nconsole.log does not work with multiple arguments (issue 36)\nno file upload (issue 307)\nlack of error reporting and stack trace (issue 166)\npotential memory corruption (issue 274)\nno functioning remote debugging (issue 6)\ncrash or unexpected behavior with empty URL scheme (issue 365)\n\n\nOn Mac OS X, the build script even creates a static version of PhantomJS which is quite compact, around 10 MB (after extra compression). This Mac OS X static build is rather popular because (1) you can freely move the executable to any machine, any place you want (2) you don’t need to install Qt or other software, it is self-contained and guaranteed to work on a fresh install of Snow Leopard or later version. The size also helps. Guess which one is more convincing: (a) tell someone to download and unzip 10 MB file or (b) ask him/her to grab 178 MB binary install of Qt? Only in a very rare case choice (b) will win.\n\nThe final issue, most probably the most important one, is regarding the bridging mechanism between the native and the JavaScript world. The existing bridge provided by Qt is very good for the use cases of hybrid apps, e.g. web-based UI running a C++ logic. However, in the case of PhantomJS the flow actually goes a little bit different: JavaScript world, native (Qt) space, then goes back to JavaScript. This makes the situation very delicate to handle. It causes all sorts of “unexpected” behavior, from lack of argument binding to lossy null. In fact, we are already exhausting and abusing the bridging to a certain extent where we can’t go further.\n\nI secretly wished that the bridging will be different in the upcoming Qt 5. However, seems that as of now such a bridging is not high in the priority list. Beside, Qt 5 is still months away from the release, maybe even more if you want to wait for all initial bugs to be squashed (this is a 5.0.0 release after all). And speaking about Qt 5, it seems that for all intents and purposes, Qt 4.8 will be the last in the 4.x series and we’re stucked with it for at least a few months in the future.\n\nCombining the fact that we already custom-build Qt 4.8 and no chance to jumpstart to Qt 5 any time soon, finally a wild but pragmatic decision was made: we import Qt code into the source tree. What is being imported is only the necessary portion needed for PhantomJS (we do not care for e.g. declarative module). The obvious drawback is that the repository is getting larger although it is not actually that bad thanks to the efficient Git storage mechanism.\n\nFew more doors are available to us after this import, among others making pure headless (no Xlib, no Xvfb) as the canonical build for Linux, getting bleeding edge WebKit, immediate fixes to major deficiencies (e.g. error handling with stack trace), as well improvements to the bridging situation. We’ll find out if this experiment is worth the effort in the long run.\n\nEnjoy Ghost Flower!\n\n(`_|_`)Mar 26, 2012(`_|_`)ariya.io(`_|_`)the-evolution-of-phantomjs-build-workflow', 'the-evolution-of-phantomjs-build-workflow'),
(200, 'Ghost Flower(`_|_`)\n\n\nBy Stan Shebs (Own work), CC-BY-SA-3.0, via Wikimedia Commons.\n\nFew days ago we experienced the equinox. That also means a new release of PhantomJS, the scriptable headless WebKit. This time we hit version 1.5 under the code name Ghost Flower. You are recommended to check the full Release Notes, the notable highlights are pure headless without X11/Xlib/Xvfb on Linux, interactive mode (REPL), remote debugging (Linux only), and various other small improvements as well as bug fixes. And by the way, Flash (and other NPAPI plugins) support is also gone!\n\nDue to the more-than-usual amount of new features coming in to this version, expect some rough edges here and there. There are already fixes scheduled for 1.5.1. A lot of behind-the-scene development workflow also makes it easier to backport future 1.6 fixes to the 1.5.x series. Expect some of my upcoming blog posts to talk about this. Also, feel free to track the development on Github, the project page, and/or the mailing-list. If you are new to this wonderful world of headless WebKit, I suggest looking at various related projects and how people use it on assorted use-cases.\n\nKudos to all contributors to this Ghost Flower release!\n\n(`_|_`)Mar 23, 2012(`_|_`)ariya.io(`_|_`)ghost-flower', 'ghost-flower'),
(201, 'JavaScript code coverage and Esprima(`_|_`)\nA common approach to implement code coverage analysis for JavaScript code is by adding extra instrumentation to the code. Since the instrument function is also executed by the JavaScript engine, this gives additional information as to which part of the code is being executed. A naive trick is to wrap the instrumentation line-by-line. A better technique is to wrap every statement, and for more granularity also to wrap every single expression.\n\nInstrumentation can be carried out by parsing the code, injecting extra syntax nodes for the probing, and then regenerating a new, instrumented-version of the code. For running Node.js application, there are two good code coverage analyzers (among many others) you might want to look at: node-cover and coveraje. For each analyzer, the instrumenting process basically modifies the syntax tree as the code is parsed by Esprima, the high-performant ECMAScript parser I am involved with. By the way, these two projects are also examples of successful migration from UglifyJS parser to Esprima.\n\nUpdate: If you also need branch coverage support, consider using Istanbul.\n\nSurprisingly, coverage tool is easy to install and to use. I give a quick example here for node-cover but the principle of operations is the same for coveraje. After you install node-cover via its package, run it against our test.js example:\n\nx = 42;\nif (false)\n    x = -1;\n\n\nlike this:\n\ncover run test.js\ncover report html\n\n\nand then open the generated cover_report/index.html to see the color-coded coverage report. It is easy to spot which part of the code is not touched when the script was executed:\n\n\n\n(Note that for the purpose of continuous integration, or even as part of the pre-commit check, a quick text-based summary can be obtained via cover report).\n\nNow here comes the Inception part. Lately I’ve been using this coverage analyzer to improve the code coverage of Esprima own parsing routines (issue 221). It’s extremely helpful, often when you write some complex statement to implement a certain programming logic, there are corner cases which need to be verified thoroughly. Hundreds of Esprima unit tests catch most of the general common cases but there were few which were overlooked.\n\nA common approach to implement code coverage analysis for JavaScript code is by adding extra instrumentation to the code. Since the instrument function is also executed by the JavaScript engine, this gives additional information as to which part of the code is being executed. A naive trick is to wrap the instrumentation line-by-line. A better technique is to wrap every statement, and for more granularity also to wrap every single expression.\n\nInstrumentation can be carried out by parsing the code, injecting extra syntax nodes for the probing, and then regenerating a new, instrumented-version of the code. For running Node.js application, there are two good code coverage analyzers (among many others) you might want to look at: node-cover and coveraje. For each analyzer, the instrumenting process basically modifies the syntax tree as the code is parsed by Esprima, the high-performant ECMAScript parser I am involved with. By the way, these two projects are also examples of successful migration from UglifyJS parser to Esprima.\n\nUpdate: If you also need branch coverage support, consider using Istanbul.\n\nSurprisingly, coverage tool is easy to install and to use. I give a quick example here for node-cover but the principle of operations is the same for coveraje. After you install node-cover via its package, run it against our test.js example:\n\nx = 42;\nif (false)\n    x = -1;\n\n\nlike this:\n\ncover run test.js\ncover report html\n\n\nand then open the generated cover_report/index.html to see the color-coded coverage report. It is easy to spot which part of the code is not touched when the script was executed:\n\n\n\n(Note that for the purpose of continuous integration, or even as part of the pre-commit check, a quick text-based summary can be obtained via cover report).\n\nNow here comes the Inception part. Lately I’ve been using this coverage analyzer to improve the code coverage of Esprima own parsing routines (issue 221). It’s extremely helpful, often when you write some complex statement to implement a certain programming logic, there are corner cases which need to be verified thoroughly. Hundreds of Esprima unit tests catch most of the general common cases but there were few which were overlooked.\n\nA common approach to implement code coverage analysis for JavaScript code is by adding extra instrumentation to the code. Since the instrument function is also executed by the JavaScript engine, this gives additional information as to which part of the code is being executed. A naive trick is to wrap the instrumentation line-by-line. A better technique is to wrap every statement, and for more granularity also to wrap every single expression.\n\nInstrumentation can be carried out by parsing the code, injecting extra syntax nodes for the probing, and then regenerating a new, instrumented-version of the code. For running Node.js application, there are two good code coverage analyzers (among many others) you might want to look at: node-cover and coveraje. For each analyzer, the instrumenting process basically modifies the syntax tree as the code is parsed by Esprima, the high-performant ECMAScript parser I am involved with. By the way, these two projects are also examples of successful migration from UglifyJS parser to Esprima.\n\nUpdate: If you also need branch coverage support, consider using Istanbul.\n\nSurprisingly, coverage tool is easy to install and to use. I give a quick example here for node-cover but the principle of operations is the same for coveraje. After you install node-cover via its package, run it against our test.js example:\n\nx = 42;\nif (false)\n    x = -1;\n\n\nlike this:\n\ncover run test.js\ncover report html\n\n\nand then open the generated cover_report/index.html to see the color-coded coverage report. It is easy to spot which part of the code is not touched when the script was executed:\n\n\n\n(Note that for the purpose of continuous integration, or even as part of the pre-commit check, a quick text-based summary can be obtained via cover report).\n\nNow here comes the Inception part. Lately I’ve been using this coverage analyzer to improve the code coverage of Esprima own parsing routines (issue 221). It’s extremely helpful, often when you write some complex statement to implement a certain programming logic, there are corner cases which need to be verified thoroughly. Hundreds of Esprima unit tests catch most of the general common cases but there were few which were overlooked.\n\nA common approach to implement code coverage analysis for JavaScript code is by adding extra instrumentation to the code. Since the instrument function is also executed by the JavaScript engine, this gives additional information as to which part of the code is being executed. A naive trick is to wrap the instrumentation line-by-line. A better technique is to wrap every statement, and for more granularity also to wrap every single expression.\n\nInstrumentation can be carried out by parsing the code, injecting extra syntax nodes for the probing, and then regenerating a new, instrumented-version of the code. For running Node.js application, there are two good code coverage analyzers (among many others) you might want to look at: node-cover and coveraje. For each analyzer, the instrumenting process basically modifies the syntax tree as the code is parsed by Esprima, the high-performant ECMAScript parser I am involved with. By the way, these two projects are also examples of successful migration from UglifyJS parser to Esprima.\n\nUpdate: If you also need branch coverage support, consider using Istanbul.\n\nSurprisingly, coverage tool is easy to install and to use. I give a quick example here for node-cover but the principle of operations is the same for coveraje. After you install node-cover via its package, run it against our test.js example:\n\nx = 42;\nif (false)\n    x = -1;\n\n\nlike this:\n\ncover run test.js\ncover report html\n\n\nand then open the generated cover_report/index.html to see the color-coded coverage report. It is easy to spot which part of the code is not touched when the script was executed:\n\n\n\n(Note that for the purpose of continuous integration, or even as part of the pre-commit check, a quick text-based summary can be obtained via cover report).\n\nNow here comes the Inception part. Lately I’ve been using this coverage analyzer to improve the code coverage of Esprima own parsing routines (issue 221). It’s extremely helpful, often when you write some complex statement to implement a certain programming logic, there are corner cases which need to be verified thoroughly. Hundreds of Esprima unit tests catch most of the general common cases but there were few which were overlooked.\n\nI’m happy to share with you that now Esprima parser has a full code coverage. Report of node-cover shows that the remaining non-covered blocks are either (1)](http://code.google.com/p/esprima/issues/detail?id=22) for old versions of JScript of Internet Explorer, or (2)](http://code.google.com/p/esprima/issues/detail?id=210) which shall be valid all the time since otherwise we have a serious logic error. Thus, to best of our knowledge, the large set of the unit tests exercises every possible parser code branch in Esprima.\n\nEsprima has a typical contribution guide designed to maximize code quality and minimize future maintenance effort. Since it’s now rather easy to carry out this coverage analysis, a new criteria “No coverage regression” has been added to the laundry list of submitting a contribution, obviously with an added section on code coverage in the testing wiki page. Of course, kudos to Itay for his node-cover tool that makes this improvement rather fun to accomplish.\n\nYay for coverage!\n\n(`_|_`)Mar 19, 2012(`_|_`)ariya.io(`_|_`)javascript-code-coverage-and-esprima', 'javascript-code-coverage-and-esprima');
INSERT INTO `ariyaio` (`id`, `content`, `url`) VALUES
(202, 'Most popular JavaScript keywords(`_|_`)\nMost popular keywords? The quick short answer is: it depends.\n\nWhile investigating the proposal for a faster isKeyword() function in Esprima, I decided to see the frequency of JavaScript keywords appearing in most common libraries. Esprima already has a selection of popular libraries as part of its comprehensive benchmark suite. When I eliminated the duplicated versions (so that each library is represented only once), the distribution of the keywords is depicted in the following chart. The dominant ones are this, function, if, return, and var, followed by a long tail of other keywords.\n\n\n\nThere are several things which are validated by the above data. For example, it is expected that finally should occur less, or at least the same, as try. Due to then nature of the construct, case typically shows up more often than its parent switch. Also it will be weird if else is found more than if, same case with do and while pair.\n\nObviously the above beautiful color chart is only for keywords in libraries and frameworks. For real-world user applications, the situation could be different. If you are interested in running the analysis on your own code, use the following quick tool keyword.js:\n\nvar fs = require(\'fs\'),\n    esprima = require(\'esprima\'),\n    files = process.argv.splice(2);\n \nfiles.forEach(function (filename) {\n    var content = fs.readFileSync(filename, \'utf-8\'),\n        tokens = esprima.parse(content, { tokens: true }).tokens;\n \n    tokens.forEach(function (token) {\n        if (token.type === \'Keyword\') {\n            console.log(token.value);\n        }\n    });\n});\n\n\nand run it with Node.js:\n\nnode keyword.js myapp.js mylib.js others/*.js | sort | uniq -c | sort -nr\n\n\nor alternatively, to go recursive in a certain directory:\n\nfind /path/to/dir -type f -name \'*.js\' -exec node keyword.js \'{}\' + |\n  sort | uniq -c |  sort -nr\n\n\nWhat do you get for your project?\n\n(`_|_`)Mar 13, 2012(`_|_`)ariya.io(`_|_`)most-popular-javascript-keywords', 'most-popular-javascript-keywords'),
(203, 'Underwater effect with HTML5 Canvas(`_|_`)\nFor the impatients, the demo is ariya.github.com/canvas/underwater.\n\nCombining pixel manipulation with geometric distortion can be fun, see for example the underwater effect in my Qt code example from 4 years ago (which itself was a porting of the SDL-based effect from almost 6 years ago, time flies!). This was my attempt to achieve the same feeling as in the Quake game when you submerge (into the water). The actual code itself is pretty simple, it’s a matter of shifting the pixels horizontally and vertically in a periodic manner.\n\nRecently I ported this effect to HTML5 Canvas with pixel manipulation routine for the distortion written in JavaScript. Before I show you the relevant code fragment, let’s see first the distortion result which we want to get, applied to a checkerboard pattern to better reveal its effect (left: original, right: distorted):\n\n\n\nThe main gut of the effect is the following code (yes, it’s only a dozen lines!):\n\nT = frames * interval * frequency / 1000;\nfor (x = amplitude; x < width - amplitude; ++x) {\n    for (y = amplitude; y < height - amplitude; ++y) {\n        xs = amplitude * Math.sin(2 * Math.PI * (3 * y / height + T));\n        ys = amplitude * Math.cos(2 * Math.PI * (3 * x / width + T));\n        xs = Math.round(xs);\n        ys = Math.round(ys);\n        dest = y * stride + x * 4;\n        src = (y + ys) * stride + (x + xs) * 4;\n        r[dest] = pixels[src];\n        r[dest + 1] = pixels[src + 1];\n        r[dest + 2] = pixels[src + 2];\n    }\n}\n\n\nFor every pixel, we find out from where we shall get the pixel value due to the periodic modulation. Since it’s just a linear combination of horizontal shift and vertical shift, the computation is rather easy. Once the location is known, it’s a matter of copying 3 values (for RGB) from the pixel array to the canvas image data.\n\nFor your pleasure, try the online demo at ariya.github.com/canvas/underwater or the embedded (via iframe) below:\n\nThe complete example code is available in the usual X2 repository, look under javascript/underwater directory (set up a web server, due to the same origin limitation). Feel free to convert the animation routine to use requestAnimationFrame instead.\n\nBecause of the rather intensive processing, forget about getting a high frame-rate with this demo, even on the desktop machines. In my test machine, Firefox 10 easily gets 30 fps, Safari 5.1 follows with 20 fps, and both Opera 11.61 and Chrome 17 struggle at 15 fps. On many mobile devices, you are lucky if you get more than 2 fps!\n\nFrom the performance perspective, using WebGL and a suitably written shader is still the best approach. However, for some fun weekend hack, nothing beats a simple underwater Canvas effect.\n\n(`_|_`)Mar 12, 2012(`_|_`)ariya.io(`_|_`)underwater-effect-with-html5-canvas', 'underwater-effect-with-html5-canvas'),
(204, 'Strict Mode Checks with Esprima(`_|_`)\nStrict mode (see Annex C in ECMAScript 5 specification) is known as a mechanism to use the a restricted variant of JavaScript. Some developers don’t really like it, however my personal experiences demonstrates a lot of good advantages (including catching the unintentional globals) when leveraging this mode.\n\nOne of the latest development in Esprima is allowing the parser to understand strict mode (see issue 160). This means, some restrictions of this mode which can be caught at the parsing time will be reported to you. For example, the following snippet:\n\n\'use strict\';\nblock = {\n  color: \'blue\',\n  height: 20,\n  width: 10,\n  color: \'red\'\n};\n\n\nwill provoke this error:\n\n\nError: Line 6: Duplicate data property in object literal not allowed in strict mode\n\n\nbecause two properties can’t have the same name (color in the above example) under strict mode. While this seems like a glaring error, in some cases such as a mistake is not necessary easy to spot if the object literal is huge. This is a typical situation when you use various frameworks to implement an object using class-like construct.\n\nIf you use JSLint (or its fork JSHint) to lint the above snippet, it will happily report about the duplication. However, this happens even if you don’t specify strict mode (which makes sense, they are checking for code quality after all). Meanwhile, UglifyJS parser won’t complain at all.\n\nStrict mode support for Esprima is still in the development branch. Eventually it would be rolled out in the official web site but meanwhile you can always check the bleeding-edge version and play with it. In one way or another, hopefully this will help you improving the quality of your code!\n\n(`_|_`)Mar 7, 2012(`_|_`)ariya.io(`_|_`)strict-mode-checks-with-esprima', 'strict-mode-checks-with-esprima'),
(205, 'PhantomJS and Travis CI(`_|_`)\nWhat Github does to project repository and collaboration, Travis CI does it to continuous integration. If you have an open-source project, there is a huge chance that you can benefit a lot from hooking your testing via Travis CI. As of now, it supports projects using Clojure, Erlang, Groovy, Java, Node.js, Perl, PHP, Python, Ruby, Scala and I’m sure the list will continue to grow.\n\nWhat if your project is a web application? PhantomJS to the rescue! I already wrote about using PhantomJS to drive your tests as part of the preflight check via Git pre-commit hook. The same technique applies here. In fact, there are few projects using Travis CI which already use the approach, mainly because Travis CI has built-in install of PhantomJS.\n\nTo see how to set it up, let’s have a look at one project: Modernizr . Its .travis.yml (see the repository, as of now in the travis-ci branch) looks like the following:\n\nlanguage: node_js\nnode_js:\n  - 0.6\nbefore_script:\n  - \"export DISPLAY=:99.0\" \n  - \"sh -e /etc/init.d/xvfb start\"\n  - npm install connect\n  - sudo node test/js/server.js ../../ 80 &\n  - sleep 5\nscript: phantomjs test/qunit/run-qunit.js \"http://localhost:80/test/index.html\"\n\n\nPer Travis CI documentation, the before_script is the prep stage. It is actually very simple: start Xvfb (important for now, not necessary anymore in the next version), launch the server (Node.js-based) which provides the tests, wait 5 seconds. After that, the actual magic kicks in, i.e. running PhantomJS to drive the QUnit-based test suite. Isn’t it really simple?\n\nUpdate: Travis CI has updated its PhantomJS installation to the latest version 1.5 (Ghost Flower) which is pure headless”) and does not need X anymore. This means, there is no need to execute Xvfb nor to set up DISPLAY.\n\nOf course, you don’t have to use Node.js to launch your test server. Take a look at how Ember.js uses PhantomJS in its Travis CI setup (it just launches Ruby-based Rack):\n\nrvm:\n  - 1.9.3\nbefore_script:\n  - \"export DISPLAY=:99.0\"\n  - \"sh -e /etc/init.d/xvfb start\"\n  - bundle exec rackup &\n  - sleep 5\nscript: phantomjs tests/qunit/run-qunit.js \"http://localhost:9292/tests/index.html?package=all\" &&\nphantomjs tests/qunit/run-qunit.js \"http://localhost:9292/tests/index.html?package=all&jquery=1.6.4\" &&\nphantomjs tests/qunit/run-qunit.js \"http://localhost:9292/tests/index.html?package=all&extendprototypes=true\" &&\nphantomjs tests/qunit/run-qunit.js \"http://localhost:9292/tests/index.html?package=all&extendprototypes=true&jquery=1.6.4\"\n\n\nLast but not least, there is no need to use a web server if you don’t need to. CasperJS simply uses PhantomJS to execute the test suite directly (BTW, in case you haven’t seen CasperJS yet, go and take a look, it’s an extremely useful companion to PhantomJS):\n\nbranches:\n  only:\n    - master\nbefore_script:\n  - \"export PHANTOMJS_EXECUTABLE=\'phantomjs --local-to-remote-url-access=yes --ignore-ssl-errors=yes\'\"\n  - \"export DISPLAY=:99.0\"\n  - \"sh -e /etc/init.d/xvfb start\"\nscript:\n  - \"DISPLAY=:99.0 ./bin/casperjs test tests/suites\"\n\n\nWith popular projects such as Modernizr, Ember.js, and CasperJS taking advantage of the (dangerous) combination of PhantomJS and Travis CI, what are you waiting for?\n\n(`_|_`)Mar 5, 2012(`_|_`)ariya.io(`_|_`)phantomjs-and-travis-ci', 'phantomjs-and-travis-ci'),
(206, 'A tale of a chef(`_|_`)\n\n\nThere is this chef, working hard in a prominent Michelin-rated restaurant. His kitchen is always busy, although what he and his staff are doing is not always visible. As a respected customer you just want to enjoy a beautifully decorated tasty meal. Whether is done through magic or sweat-and-blood does not matter much.\n\nAfter a long day, the chef goes home and always enjoys himself, whenever family duty is not calling. Do you think he grabs a bag of pop-corn and then watches some cheap flick on the TV? Apparently he prefers to sharpen his craftsmanship in his personal kitchen. It’s private and less glamorous, yet that is a new stage of freedom. No restaurant satisfaction is at risk, no serving deadline is approaching. Zen moment.\n\nEvery now and then, fellow chefs from the neighboring joints drop by, providing a shower of advice and critique (and if that is not enough, Twitter is just a few taps away) in exchange for some cups of carefully brewed best-of-the-best coffee. In that hidden corner, an otherwise boring task to a layman is often carried out. One day it is about perfecting zest-flavored crème brûlée, another time the challenge is forging the most delicious Inarizushi ever.\n\nIn many aspects, the situation above resembles the good traits of an engineer whom an organization loves to employ. It is therefore in the best of interests of all involved parties to cultivate and promote the passion. The restaurant owner should not worry that the chef’s innovative crème brûlée becomes a masterpiece which steals the spotlight, as the chef most likely does not plan to open his own cafe anytime soon. Meanwhile, hours and hours spent in the kitchen, personal or not, would indirectly benefit whoever employs him, present and future.\n\nAfter all, like what George Bernard Shaw once said,\n\n\n“There is no love sincerer than the love of food.”\n\n\n(`_|_`)Mar 3, 2012(`_|_`)ariya.io(`_|_`)a-tale-of-a-chef', 'a-tale-of-a-chef'),
(207, 'Git pre-commit hook and smoke testing(`_|_`)\nA pre-commit check is invoked right before a change is committed into the repository. This is a perfect place to run a quick smoke test to ensure that no broken code is ever checked in. Many source control systems, including the powerful Git, support pre-commit check as part of its hooks system. Unfortunately, based on my (limited) observations, leveraging pre-commit feature is not something every single developer practices yet.\n\nFor Git, the pre-commit script is a single file located under the hidden subdirectory .git. Creating a new one is as easy as:\n\ntouch .git/hooks/pre-commit\nchmod +x .git/hooks/pre-commit\n\n\nfrom the top-level working directory of your repository. When the script is executed (right before a commit), the exit code will be inspected. If it is zero, the commit will continue. If it is non-zero, the commit is blocked and the working directory is left in the “dirty” state (you can inspect it with git diff).\n\nHere is a simple pre-commit script (Unix only, sorry!) which prevents you to commit something on Sunday.\n\nif [ `date +%w` -eq 6 ]; then\n  echo \"Enjoy your life. Do not work on Sunday!\"\n  exit 1\nfi\nexit\n\n\nMany software projects drive the test via make test. Provided that the exit code is suitably set, the pre-commit script needs only that line:\n\nmake test\n\n\nFor Node.js applications which use npm test to run the unit-test, making a pre-commit script is never been easier. The content of the script is as simple as:\n\nnpm test\n\n\nEven style checking (which is usually very fast) can be carried out easily. For JavaScript-based apps, JSLint or JSHint fits perfectly in this situation. Perhaps use my EightPack project to get such command-line tools easily. As an example, here is my pre-commit script for typical day-to-day Esprima development:\n\njslint esprima.js && jslint test/test.js\n\n\nIf your script needs to be more sophisticated and handles all the files being added, copied, or modified, you can take advantage of Git filtering feature:\n\ngit diff --cached --name-status --diff-filter=ACM\n\n\nBy some piping machinery, or even just through xargs magic, the list of the files can be fed and processed appropriately. In most cases, especially large projects, checking only the files affected by the commit will save a lot of time.\n\nWhat if your project is a web app? Well, hopefully your app has unit tests. In that case, you can use PhantomJS to invoke the tests without the need to launch a web browser. PhantomJS has a nice integration with some popular frameworks such as Jasmine, QUnit, and many others.\n\nThis post is just a cursory look at pre-commit hook from Git. You may want to read more about various other hooks. Since it is quite common, you are also recommended to look for and investigate various tools out there (e.g. git-hooks) which let you manage multiple hooks easily. Pre-commit is easy to use and yet quite powerful. Invest a minute to set it up and it would save you from future nightmares!\n\n(`_|_`)Mar 1, 2012(`_|_`)ariya.io(`_|_`)git-pre-commit-hook-and-smoke-testing', 'git-pre-commit-hook-and-smoke-testing'),
(208, 'From double-quotes to single-quotes(`_|_`)\nInconsistency begets insanity. If every developer follows the agreed coding conventions, life feels more wonderful. When a string literal can be enclosed in single or double quotes (ECMAScript 5 specification section 7.8.4), often it helps to stick with one type of quotes. For example, jQuery code style mandates the use of double-quotes.\n\nPersonally I prefer single-quotes. That’s just my preference, though. When looking at Esprima, I realize that I can use its non-destructive partial modification feature (see also the summary of its other features, from source location info to code generation) to force every string literals to use single-quotes. And thus the following singlequote.js example was born.\n\nvar fs = require(\'fs\'),\n    esprima = require(\'esprima\'),\n    input = process.argv[2],\n    output = process.argv[3],\n    offset = ,\n    content = fs.readFileSync(input, \'utf-8\'),\n    tokens = esprima.parse(content, { tokens: true, range: true }).tokens;\n \nfunction convert(literal) {\n    var result = literal.substring(1, literal.length - 1);\n    result = result.replace(/\'/g, \'\\\'\');\n    return \'\'\' + result + \'\'\';\n}\n \ntokens.forEach(function (token) {\n    var str;\n    if (token.type === \'String\' && token.value[] !== \'\\\'\') {\n        str = convert(token.value);\n        content = content.substring(, offset + token.range[]) + str +\n            content.substring(offset + token.range[1] + 1, content.length);\n        offset += (str.length - token.value.length);\n    }\n});\nfs.writeFileSync(output, content);\n\n\nRun it with Node.js like this:\n\nnode singlequote.js inputfile outputfile\n\nHow does this work? Let’s assume that the content of the input file is:\n\nconsole.log(\"Hello\")\n\n\nWhen we ask Esprima parser to consume it, with the option tokens set to true, the parser also outputs the list of all tokens collected during the parsing process in an array. For our example above, the array is:\n\n[\n    { type: \"Identifier\", value: \"console\", range: [, 6] },\n    { type: \"Punctuator\", value: \".\", range: [7, 7] },\n    { type: \"Identifier\", value: \"log\", range: [8, 10] },\n    { type: \"Punctuator\", value: \"(\", range: [11, 11] },\n    { type: \"String\", value: \"\"Hello\"\", range: [12, 18] },\n    { type: \"Punctuator\", value: \")\", range: [19, 19] }\n]\n\n\nOnce the tokens are available, all we have to do is to iterate and find the token associated with a string literal. Each token also contains the location info in its range property which denotes the zero-based start and end position (inclusive). Of course, what interests us is only the String token:\n\n{ type: \"String\", value: \"\"Hello\"\", range: [12, 18] }\n\n\nThis facilitates some string operations to replace the original source, for the above example it’s between [12, 18]. Care must be taken that if the literal value contains one or more single-quotes, those single-quotes must be properly escaped (see SingleEscapeCharacters in section 7.8.4). Since this may change the total literal length, offset adjustment is often needed as well. An example follows:\n\n// before\n\"color = \'blue\'\";\n \n// after\n\'color = \'blue\'\';\n\n\nThe conversion still does not have the ability to do the reverse, i.e. removing unnecessary escaped characters. This is the case where double-quotes in the literal need not be escaped anymore. This functionality is left as an exercise to the readers!\n\nObviously this tool is nothing more than an academic exercise. Most editor supports search-replace, though you need to be careful not to change unrelated quotes intentionally. I’m sure there is an IDE out there which can carry out the same task efficiently. I do hope that whatever techniques you would use would take into account the escaping issue mentioned above.\n\nGot some other ideas with the token list and partial modification?\n\n(`_|_`)Feb 27, 2012(`_|_`)ariya.io(`_|_`)from-double-quotes-to-single-quotes', 'from-double-quotes-to-single-quotes'),
(209, 'Rexx: one-based indexing and built-in tracing(`_|_`)\n\n\nA software engineer’s life is not complete without implementing a programming language. While I did create a lightweight BASIC interpreter targeting embedded systems eighteen years ago, I’m still longing to design and work on my own style of programming language. Looking around various languages which have the goals of being powerful and yet easy to use at the same time, I stumbled upon Rexx (more precisely, IBM’s flavor of NetRexx) and boy, I do like it!\n\nMany things have been said about Rexx advantages. However, if you allow me to pick two excellent features of Rexx which I would consider to steal for my own toy programming language, that will be these…\n\nOne-based index\n\nConsider the following Rexx program:\n\nmessage=\'Hello world\'\nsay message.word(2)\n\n\nThe result is ‘world’. For “normal” mortals, it is not terribly surprising. The plain English version of the code is basically:\n\n\nSay the 2nd word from the message ‘Hello world’\n\n\nIn many other languages, even BASIC, the first item in an array is denoted as the 0-th. That makes things complicated for “normal” people without computer or math background. In addition, often the array needs to have strict preallocated items and then it’s easy to go out of bound.\n\nOff-by-one error is very common, I’ve seen many junior programmers fall into the trap. The choice of making the indexing resembles the human language is simply fabulous.\n\nBuilt-in tracing\n\nSince Rexx’s goal is to be appealing to normal Joe Sixpack, it has ways to simplify debugging. In fact, the traditional concept of debugging, with breakpoints and watches, would be too cumbersome. I am very delightful to see the concept of Rexx: tracing. Yes, this is very similar to my approach to trace the execution of JavaScript code (using automatic instrumentation). Rexx however has this as its built-in feature built in the core run-time.\n\nWhat does tracing do? It basically simulates the troubleshooting steps of a normal human being if he is about to figure out the problem with his logic. This means doing a step-by-step analysis, following each line of the program and watching the impact of executing the line. Rexx does that faithfully.\n\ntrace results\ntrace var sum\nsum = \nloop i=1 to 3\n  sum = sum + i\nend i\nsay sum\n\n\nRunning the above program gives:\n\n3 *=* sum = 0\n   >v> sum \"0\"\n 4 *=* loop i=1 to 3\n   >>> \"3\"\n   >v> i \"1\"\n 5 *=*   sum = sum + i\n   >v> sum \"1\"\n 4 *=* loop i=1 to 3\n   >v> i \"2\"\n 5 *=*   sum = sum + i\n   >v> sum \"3\"\n 4 *=* loop i=1 to 3\n   >v> i \"3\"\n 5 *=*   sum = sum + i\n   >v> sum \"6\"\n 4 *=* loop i=1 to 3\n   >v> i \"4\"\n 6 *=* end i\n 7 *=* say sum\n   >>> \"6\"\n6\n\n\nEven if at first the log looks daunting, after a while most people can appreciate why the step-by-step tracing is helpful. In fact, it’s a matter of matching what the program does (for each step) vs what you think it should do. For those who don’t have computer science background, this is learnable.\n\nObviously there is other fun stuff baked into Rexx. For example, precision arithmetic, just like in SpeedCrunch, always feels good. Finally, I don’t know how functional Rexx plugin for Eclipse is, but that would be the next thing I’m likely going to find out!\n\n(`_|_`)Feb 24, 2012(`_|_`)ariya.io(`_|_`)rexx-one-based-indexing-and-built-in-tracing', 'rexx-one-based-indexing-and-built-in-tracing'),
(210, 'Up close and personal(`_|_`)\nWork-life balance always fascinates me. After all, we all have personal and work email addresses for a good reason. Sometimes it helps to avoid conflicts of interests, often it is useful to draw the demarcation line between the career and personal life.\n\nSome people I know are very good at this, e.g. not doing any work-related activities in the afternoon because that is family time. I had done multiple attempts, including setting a specific gadget-free evening, without much success. Being passionate about your work and being passionate with your family are not the easiest thing to do. Thus, herewith I’d like to set up another experiment, as simple as limiting the social media to particular groups and setting a clear boundary of both side of my life.\n\nThe implications, if you are following me on various channels, are not much. For a start, from now on I treat this blog (which you are currently reading right now), my @ariyahidayat Twitter account, my Google+ profile, and my Facebook page as personal space. You won’t expect to find anything related to my professional work. Stuff I would discuss in the future, anything from magical Qt tricks to crazy JavaScript projects, are something which are not endorsed, sponsored, encouraged, funded, nor recommended by my employer.\n\nWhat if you like my Sencha-related activities? Fortunately, Sencha has a wide variety of social outreach. Follow me at @AriyaFunAtWork for Sencha-oriented streams I personally curate. Also there is always Sencha blog corner, where I sometimes wrote about anything from browser hardware acceleration to building JavaScript engines. In addition, Sencha Vimeo hosts some recordings of my talk, Sencha SlideShare gives you the slide decks.\n\nNote that I mention this as an experiment. If things won’t work well, I might have to come back to unified social media again. Until then I can try to get more personal with you. Finger crossed!\n\n(`_|_`)Feb 22, 2012(`_|_`)ariya.io(`_|_`)up-close-and-personal', 'up-close-and-personal'),
(211, 'JavaScript branching and code shuffling(`_|_`)\nModern CPU is equipped with a branch predictor to help with optimizing program execution. For example, a loop typically exits only once and the flow is kept inside the loop for a while (it’s called a loop for a reason). Since the terminal condition to quit the loop is only hit once, the loop predictor assumes the path of going back into the loop and preempts the next step of execution.\n\nGeneralizing the concept to a higher level is certainly possible. For a decision branch where one path is likely taken more than the others, let’s just optimize for that (hence, the term fast code path). After all, engineering is nothing but setting the right compromise. In this case, we incline ourselves towards the fast case and penalize any other slow cases (hopefully only by a very small margin).\n\nWhile profiling Esprima, I stumbled upon a case where fast code path optimization makes sense, see issue #171. Consider the simplified version of its primary expression parsing function (see ECMAScript specification section 11.1):\n\nfunction parsePrimaryExpression() {\n \n    if (match(\'[\')) return parseArrayInitialiser();\n    if (match(\'{\')) return parseObjectInitialiser();\n    if (match(\'(\')) return parseBracketExpression();\n \n    if (matchKeyword(\'function\')) return parseFunctionExpression()\n    if (matchKeyword(\'this\')) return createThisExpression();\n \n    if (match(\'/\') || match(\'/=\')) return createRegExpLiteral();\n \n    var token = lex();\n    if (token.type === Token.Identifier) return createIdentifier(token);\n    if (token.type === Token.NullLiteral) return createNullLiteral();\n    if (token.type === Token.NumericLiteral) return createNumericLiteral(token);\n    if (token.type === Token.StringLiteral) return createStringLiteral(token);\n    if (token.type === Token.BooleanLiteral) return createBooleanLiteral(token);\n \n    return throwUnexpected(token);\n}\n\n\nThe code should be pretty self-explanatory. All the ‘match’ functions look ahead the next token. While logically nothing is wrong with the code, the profiler outcome suspiciously provoked me into thinking that this function should be biased towards the most common cases. It is hard to believe that primary expressions in a typical JavaScript programs are mostly about arrays and object literals, yet those cases are inspected first.\n\nJust like any profiling strategy, assumption needs to be verified with experiments. By inserting a simple extra line:\n\nconsole.log(tokenTypeAsString(token));\n\n\nand running the parser with the corpus of the benchmarks suite, which includes well-known libraries from jQuery to Backbone, I got some pretty exciting result, in particular after filtering it with the pipes:\n\nsort | uniq -c | sort -rn\n\n\nThe result is as follows:\n\n\n\nor, for number freaks:\n\n54362 Identifier\n10419 Keyword\n 8170 String\n 5820 Punctuator\n 5213 Numeric\n 1575 Boolean\n  909 Null\n\n\nThis means that 63% of the time, the function has to deal with identifiers and yet it has to pass several hoops until it comes to the point of processing one! Once the hot spot is identified (no pun intended), the remedy is rather straightforward (the order of various checks after the identifier fast path apparently does not matter much):\n\nfunction parsePrimaryExpression() {\n    var token = lookahead();\n \n    if (token.type === Token.Identifier) return createIdentifier(token);\n    if (token.type === Token.NumericLiteral) return createNumericLiteral(token);\n    if (token.type === Token.StringLiteral) return createStringLiteral(token);\n \n    if (matchKeyword(\'this\')) return createThisExpression();\n    if (matchKeyword(\'function\')) return parseFunctionExpression()\n \n    if (token.type === Token.BooleanLiteral) return createBooleanLiteral(token);\n    if (token.type === Token.NullLiteral) return createNullLiteral();\n \n    if (match(\'[\')) return parseArrayInitialiser();\n    if (match(\'{\')) return parseObjectInitialiser();\n    if (match(\'(\')) return parseBracketExpression();\n \n    if (match(\'/\') || match(\'/=\')) return createRegExpLiteral();\n \n    return throwUnexpected(lex());\n}\n\n\nWhile branch predictor can help reducing the impact of slow paths, the dynamic nature of JavaScript often does not make the life of the JavaScript engine easy. For example, it needs to be careful to preempt the condition check because match function may do crazy thing such as changing the implementation of matchKeyword function! Modern engines are getting smarter these days and can collect enough data flow to exclude such a rare dynamic run-time patching, however nothing is easier than helping the JavaScript engines to take care of the common cases first.\n\nJust like previous trick to keep the object structure unchanged, be careful and please optimize responsibly. I highly recommend doing the initial profiling to ensure that you are dealing with the hot code, executed a bajillion times (like in the Esprima example above). If the suspicious branch is only hit a dozen times, do not worry about that. The purpose of high-level programming language is to free you from fiddling around with micro-optimization unless you reach the point where you absolutely need to.\n\nThis approach also shows that there is a requirement to have a representative benchmark suite for your use cases, way before you go crazy with any types of optimizations. Avoid creating a simplistic loop to test your theory. Apply the code reorganization with a set of real-world stress tests and monitor the impact under various conditions. Code shuffling is fun but don’t forget to lather, rinse, and repeat throughly!\n\n(`_|_`)Feb 22, 2012(`_|_`)ariya.io(`_|_`)javascript-branching-and-code-shuffling', 'javascript-branching-and-code-shuffling'),
(212, 'Primavera updates of Esprima(`_|_`)\n\n\nIt’s spring, it’s primavera! Meanwhile, all your code are belong to us.\n\nOn a more serious front, it’s been a while since I announced Esprima, the lightning-fast ECMAScript parser project. I already wrote a bit about the idea behind its development strategies, in particular since Esprima was one of my important FOSS focus last year.\n\nNow after two months, what kind of new goodies you can get from it? The executive summary (TLDR) will be the following list:\n\n\nImproved browser compatibility\nOptional collection of comments\nLocation information for all syntax nodes\nSource code modification\nExperimental code generation\n\n\nOne parser to rule them all\n\nLet me start with browser support. There have been lots of fixes and tweaks so that Esprima finally runs also on less-than-modern web browsers, as old as Internet Explorer 6, Safari 3, and Opera 8. Of course, any versions of Firefox and Chrome will handle Esprima just fine. However, keep in mind that older generations of browsers were not equipped with a fast JavaScript engine (nothing we can do about it) and therefore the performance of Esprima parsing may not be as fantastic as you would want it to be.\n\nSpeaking about browsers, the recent releases of Chrome 17 and Firefox 10 pack some serious speed improvements on the JavaScript execution. Since Esprima also received minor tuning here and there in order to leverage features like type inference and property-access optimization, these browsers highlight the performance boost as well. An updated speed comparison of Esprima parser to its closest competitor, parse-js from the well-known UglifyJS project, when running the benchmarks suite is clear from the following chart:\n\n\n\nThe test machine is the same like the last comparison: an iMac from late 2010, with 3 GHz Intel Core i3. Don’t be surprised if your shiny 2012 computer shows an even more impressive performance. It’s not uncommon to witness the parser consumes the entire jQuery source code (and not the minified version) in just 50 ms. Expressed differently, in a duration of one second, 240 KB jQuery code can be parsed 20 times.\n\nDocument it, and they will come\n\nOne use case I had in mind when I started working on Esprima is the basis for a documentation tool. Since such a tool relies heavily on the source code comments, as a form of annotations, this means that Esprima optionally has to keep all the comments in the code. This mechanism is now in place, every comment found in the source is collected in an array, along with its location. As a quick example, the following code:\n\n// Hello, world!\n42\n\n\nwill yield a syntax tree which looks like (pay attention to the comments block):\n\n{\n    type: \'Program\',\n    body: [{\n        type: \'ExpressionStatement\',\n        expression: {\n            type: \'Literal\',\n            value: 42\n        }\n    }],\n    comments: [{\n        range: [, 16],\n        type: \'Line\',\n        value: \' Hello, world!\'\n    }]\n},\n\n\nBoth types of comment, line (// ...) and block (/* .. */), are supported.\n\nIn the future, there will be improvements to this comment handling (see issue 71). For example, each comment should be attached to the nearest syntax node so that it is easier to find an annotation to its associated annotated function declaration.\n\nOne’s destination is never a place\n\nLocation info can be added to every syntax node. This could be in the form of index-based range. For example, this source string:\n\n(1 + 2 ) * 3\n\n\nwill generate a syntax tree which has the following:\n\n{\n    type: \'ExpressionStatement\',\n    expression: {\n        type: \'BinaryExpression\',\n        operator: \'*\',\n        left: {\n            type: \'BinaryExpression\',\n            operator: \'+\',\n            left: {\n                type: \'Literal\',\n                value: 1,\n                range: [1, 1]\n            },\n            right: {\n                type: \'Literal\',\n                value: 2,\n                range: [5, 5]\n            },\n            range: [, 7]\n        },\n        right: {\n            type: \'Literal\',\n            value: 3,\n            range: [11, 11]\n        },\n        range: [, 11]\n    },\n    range: [, 11]\n}\n\n\nNote the presence of range array, the numbers represent the zero-based index where the node starts and ends (inclusive). This is quite powerful since you can then refer back to the original source string to find the part associated with a syntax node. We’ll see shortly how this can be beneficial to us.\n\nFor compatibility with Mozilla (SpiderMonkey) Parser API, location info based on line and column number is also supported. If this is specified, then the syntax tree for the above example source will look like:\n\n \n{\n    type: \'ExpressionStatement\',\n    expression: {\n        type: \'BinaryExpression\',\n        operator: \'*\',\n        left: {\n            type: \'BinaryExpression\',\n            operator: \'+\',\n            left: {\n                type: \'Literal\',\n                value: 1,\n                loc: {\n                    start: { line: 1, column: 1 },\n                    end: { line: 1, column: 2 }\n                }\n            },\n            right: {\n                type: \'Literal\',\n                value: 2,\n                loc: {\n                    start: { line: 1, column: 5 },\n                    end: { line: 1, column: 6 }\n                }\n            },\n            loc: {\n                start: { line: 1, column:  },\n                end: { line: 1, column: 8 }\n            }\n        },\n        right: {\n            type: \'Literal\',\n            value: 3,\n            loc: {\n                start: { line: 1, column: 11 },\n                end: { line: 1, column: 12 }\n            }\n        },\n        loc: {\n            start: { line: 1, column:  },\n            end: { line: 1, column: 12 }\n        }\n    },\n    loc: {\n        start: { line: 1, column:  },\n        end: { line: 1, column: 12 }\n    }\n}\n\n\nLine number and column index are very useful when giving a message back to the user. For example, the regex collector demo tracks every node which represent a regular expression and then uses the location info to let the user knows where each regex is to be found.\n\nNote that index and line/column are not mutually exclusive, both can be enabled together.\n\nNothing is permanent except change\n\nGetting a complete syntax tree, along with the exact position of every node, gives you the power of non-destructive code modification. An example of such modification is adding a generated prolog in every function entrance. Being able to instrument function invocation like this permits advanced probing, see my previous blog posts on run-time analysis of complexity and execution tracking during application startup for the details.\n\nThe trick is rather simple. Given the following function:\n\nArray.prototype.swap = function (i, j) {\n    var k = this[i]; this[i] = this[j]; this[j] = k;\n}\n\n\nautomatically it is modified to be:\n\nArray.prototype.swap = function (i, j) {\nLog({ name: \'Array.prototype.swap\', lineNumber: 1, range: [23, 94] });\n    var k = this[i]; this[i] = this[j]; this[j] = k;\n}\n\n\nThe extra call to that Log function, which is totally customizeable, is the key. This is accomplished via the new Esprima modification API.\n\nAs of now, only FunctionEntrance modifier is available. However, I do expect that several built-in modifiers will be at your disposal some time soon. The modification API itself is pretty generic, it’s rather easy to plug in your own modifier implementation.\n\nNote that this modification approach only touches the relevant part of the source code. It is quite important because often you don’t want any automatic tool to mangle your specially formatted code or change the various indentations. Since the goal is partial source modification, each modifier shall stick to whatever syntax node it is actively targeting. Now you should understand why location info, mentioned before, is extremely important.\n\nOne generation plants the trees, another gets the shade\n\nWhile Esprima was started with a parser project in mind, one thing which was waiting to happen is the opposite of parsing. What if we carefully construct a syntax tree representing the logic we want to accomplish and then the corresponding code will appear? Such a feature will let us do more crazy things!\n\nThat’s exactly what code generation is all about. This is still a work in progress (track issue 89). The initial implementation of Esprima code generator already allows you to do some useful thing.\n\nFirst, you can create the syntax tree yourself. Esprima expects an input formatted to Mozilla (SpiderMonkey) Parser API. Even partial or incomplete sub-tree would work (to a certain extent). A rather simplistic example follows.\n\nesprima.generate({\n    type: \'BinaryExpression\',\n    operator: \'+\',\n    left: { type: \'Literal\', value: 40 },\n    right: { type: \'Literal\', value: 2 }\n});\n\n\nThe result of the above is as expected:\n\n40 + 2\n\n\nIf you create a more sophisticated expression, the code generator understands the operator precedence very well (read its design idea) and would produces sensible output. For example, it won’t insert unnecessary parentheses depending on the expected order of evaluation.\n\nAnother use-case is for code regeneration after some syntax tree modification. This is different than the previous partial modification approach. By regenerating the source code, the modification is rather destructive, i.e. the outcome may or may not resemble the original. It is still very powerful, in a different way.\n\nThe snippet below is a representative example:\n\nvar syntax = esprima.parse(\'answer = 42;\');\nsyntax.body[].expression.right.value = 1337;\nesprima.generate(syntax)\n\n\nWhat would you get? Surprisingly, the string:\n\nanswer = 1337;\n\n\nPretty neat! And if you’re thinking what we’re thinking, there will be few more tools which can be derived from this idea. Let’s keep the suspense and save it for another blog post.\n\nTo boldly go…\n\nThe above (rather long) explanation outlines all the recent highlights of Esprima development. In addition, there are also the usual tons of bug fixes and standard conformance improvements. For more info, always visit its website esprima.org, project page, and issues dashboard. Feedback can also be sent to the mailing list. Contribution is always welcomed, follow the contribution guide.\n\nLast but not least, special thanks to Yusuke Suzuki, Kris Kowal, Joost-Wim Boekesteijn, and Arpad Borsos for the important contribution in the last two months.\n\n(`_|_`)Feb 20, 2012(`_|_`)ariya.io(`_|_`)primavera-updates-of-esprima', 'primavera-updates-of-esprima'),
(213, 'JavaScript object structure: speed matters(`_|_`)\nA common pattern to speed-up the performance of your JavaScript code is to leverage the optimized property access found in modern JavaScript engines. In fact, fast property access is a key in design elements of V8. It is also achieved in JavaScriptCore, the default engine behind WebKit, via polymorphic inline cache. Firefox enjoys the same speed-up also through the same polymorphic inline cache available in its JägerMonkey project.\n\nHow would you take advantage of this feature? It’s very simple. In practice, it’s a matter of being careful with object construction. For example, rather than doing the following:\n\nvar universe = {\n  answer: 42\n};\n// do something else\nuniverse.panic = false;\n\n\nit’s recommended to implement it this way:\n\nvar universe = {\n  answer: 42,\n  panic: true\n};\n// do something else\nuniverse.panic = false;\n\n\nBasically, try to keep the object structure unchanged (obviously it may require some change in your logic). If you don’t know the value of a certain property, e.g. panic in the above example, that’s totally fine. You can always change the property value later, but you would help the JavaScript engine if you avoid adding and removing properties after the object is created.\n\nFor real-world examples, check out Esprima development. In revision 4f9af77ddc, carefully fixing the structure of token object improves Firefox 9 performance. The similar trick is used to regain the speed as a new feature was introduced.\n\nBefore you go wild and obfuscate your code to take advantage of this speedier property access, remember one thing: always optimize responsibly. First, make sure that the bottleneck is not somewhere else. In addition, avoid the temptation of a higher performant variant if that will significantly reduce the readability of the code.\n\nOK properties, off you go!\n\n(`_|_`)Feb 17, 2012(`_|_`)ariya.io(`_|_`)javascript-object-structure-speed-matters', 'javascript-object-structure-speed-matters');
INSERT INTO `ariyaio` (`id`, `content`, `url`) VALUES
(214, 'Tracking JavaScript execution during startup(`_|_`)\nApplication startup time gives the first perception of the overall performance. When your app launches in 3 seconds, your user may think twice before he runs it again. Optimizing the startup time involves a lot of investigation effort, covering areas from fast transport/delivery to compact (minified) contents.\n\nFor a JavaScript-heavy web application, tracking down the startup process is not always fun. Worse, this often can’t even be automated so that it can be used to prevent future performance regression. Let’s be honest, how many of us have systematic and reliable startup time checks in the continuous integration system?\n\nRecently I wrote about empirical run-time analysis of application complexity using Esprima code modification feature to insert a prolog in every function. In this blog post, I will show you how to apply the same technique to achieve automatic application startup logging. As a test case, we will work on a dummy page based on jQuery Mobile. The same approach should apply to other frameworks as well, including Sencha Touch, Ember.js, and many others.\n\nFirst, we need a test page, which could be very simple. The most important part is to load the necessary libraries. I took an example HTML file from jQuery Mobile demo and simplified it. It loads both jQuery and jQuery Mobile, nothing else. With some filler text, the page looks like the following screen capture:\n\n\n\nNext step is to apply automatic instrumentation to the library. Since jQuery Mobile requires jQuery, we need to handle both of them. A simple utility which runs via Node.js will apply the instrumentation, here is the code for our script trace.js.\n\nvar fs = require(\'fs\'),\n    esprima = require(\'./esprima\'),\n    filename = process.argv[2],\n    content;\n \nfunction customTracer(functionInfo) {\n    var trace = \'TRACE.enterFunction(\';\n    trace += \'\'\' + functionInfo.name + \'\', \';\n    trace += \'\'\' + filename + \'\', \';\n    trace += functionInfo.loc.start.line + \', \';\n    trace += \'arguments);n\';\n    return trace;\n}\ncontent = fs.readFileSync(filename, \'utf-8\');\ncontent = esprima.modify(content, esprima.Tracer.FunctionEntrance(customTracer));\nfs.writeFileSync(filename.replace(/.js$/, \'.traced.js\'), content);\n\n\nMore detailed info on Esprima’s Tracer.FunctionEntrance is available in the API reference.\n\nHere is how I run it:\n\nnode trace.js jquery.js\nnode trace.js jquery.mobile.js\n\n\nwhich will produce a new file jquery.traced.js, the instrumented version of the input file. If you open this, every time there is a function you will find an additional logging line. For example, the original fcamelCase function looks like:\n\n// Used by jQuery.camelCase as callback to replace()\nfcamelCase = function( all, letter ) {\n    return ( letter + \"\" ).toUpperCase();\n},\n\n\nInside jquery.traced.js, it becomes something like:\n\n// Used by jQuery.camelCase as callback to replace()\nfcamelCase = function( all, letter ) {\nTRACE.enterFunction(\'fcamelCase\', \'jquery.js\', 74, arguments);\n    return ( letter + \"\" ).toUpperCase();\n},\n\n\nNote the addition of TRACE.enterFunction line with its parameters of function name, source file name, line number, and actual arguments, respectively. Having this prolog is very powerful since now we can record every single function call, fully armed with all the necessary information on the invocation.\n\nAfter I got both jquery.traced.js and jquery.mobile.traced.js, it’s time to have some fun. The test page was modified to use these two files inside the script elements. In addition, I also include tracer.js which is an implementation of the TRACE object to be called from every function. One possible simplistic implementation looks like:\n\nvar TRACE = {};\nTRACE.enterFunction = function(name, sourceName, lineNumber, args) {\n    console.log(sourceName, lineNumber, name);\n};\n\n\nI do however have a slightly more complicated version which aligns the fields into a fixed column position. This is just small details, the principle remains the same.\n\nSince all the function execution is logged to the console, you can retrieve everything if you use Firebug or Web Inspector while opening the above test page. However, personally I would recommend using PhantomJS, the headless WebKit. It is very easy to install, usually doesn’t take more than 5 minutes. Create a simple script load.js with the following contents:\n\nvar page = require(\'webpage\').create(),\n    address;\n \nif (phantom.args.length === ) {\n    phantom.exit();\n} else {\n    address = phantom.args[];\n    page.onConsoleMessage = function (msg) {\n        console.log(msg);\n    };\n    page.open(address, function (status) {\n        setTimeout(function() {\n            phantom.exit();\n        }, 4000);\n    });\n}\n\n\nand now it’s a matter of launching our test page:\n\n/path/to/phantomjs load.js http://yourserver/test.htm > log\n\n\nBecause load.js redirects all console messages to stdout, it can be conveniently captured. The extra 4 seconds in the script is to merely ensure that any pending processing is finished.\n\nThe file log contains all recorded function call, neatly organized in four columns: source file, line number, function name, and call arguments. The following shows the last 10 calls:\n\njquery.js    26   jQuery\n       jquery.js   103   init                           undefined,  undefined,  [object Object]\n       jquery.js   274   each                           (Function)\n       jquery.js   631   each                           [object Object],  (Function),  undefined\n       jquery.js   495   isFunction                     [object Object]\n       jquery.js   512   type                           [object Object]\njquery.mobile.js  1857   [Anonymous]\njquery.mobile.js   642   [Anonymous]\njquery.mobile.js   624   enableMouseBindings\njquery.mobile.js   620   disableTouchBindings\n\n\nGuess how many function calls were there? 4640. Yes, I’m not kidding. Over four thousands calls were invoked just to display a rather simple page. Fortunately not every call is expensive, most of them is harmless. For a full log, take a look at gist.github.com/1823129 (warning: it’s very long).\n\nShould you try to focus on minimizing the calls, it’s important to find out which functions are called the most. A simple magical spell using various Unix tools is all we need:\n\ncut -c 1-55 log | sort | uniq -c | sort -rn | head -n 10\n\n\nThat conveniently finds the ten most invoked function calls, as shown here (surprisingly, everything is in the core jQuery library itself). The first column denotes the number of call made for the corresponding function.\n\n379        jquery.js   512   type                          \n 279        jquery.js  1651   acceptData                    \n 226        jquery.js   103   init                          \n 215        jquery.js  1445   data                          \n 185        jquery.js   518   isPlainObject                 \n 170        jquery.js  5149   Sizzle.isXML                  \n 168        jquery.js  1646   _data                         \n 154        jquery.js    26   jQuery                        \n 152        jquery.js   495   isFunction                    \n 106        jquery.js  4892   Sizzle\n\n\nIf you just want to find out the most invoked function in jQuery Mobile, change the magic spell:\n\ncut -c 1-55 log | grep \'mobile\' | sort | uniq -c | sort -rn | head -n 10\n\n\nwhich would yield the following:\n\n66 jquery.mobile.js  1976   $.find                        \n  22 jquery.mobile.js  1988   $.find.matchesSelector        \n  22 jquery.mobile.js  1920   $.fn.jqmData                  \n  22 jquery.mobile.js  1868   nsNormalize                   \n  14 jquery.mobile.js  1984   $.find.matches                \n  13 jquery.mobile.js   297   [Anonymous]                   \n  12 jquery.mobile.js   990   [Anonymous]                   \n  12 jquery.mobile.js    91   $.widget.bridge               \n  12 jquery.mobile.js    47   $.widget                      \n  11 jquery.mobile.js   295   [Anonymous]\n\n\nBasically the above data shows that $.find in line 1976 is executed the most, 66 times.\n\nIt is clear that having the above call log does not magically let you optimize everything. However, it does give you some more data when analyzing the startup time performance. Even better, the entire steps are easily automated. For example, you could have a simple check in the continuous integration system which monitor the ten most called function, this facilitates triggering the early warning system whenever there is a large deviation from the baseline reference. Make the startup slightly faster in every iteration, surely you will reach the intended world domination someday.\n\nLast but not least, if this blog post does not convince you of the combined power of Esprima and PhantomJS, I don’t know what else to say!\n\n(`_|_`)Feb 15, 2012(`_|_`)ariya.io(`_|_`)tracking-javascript-execution-during-startup', 'tracking-javascript-execution-during-startup'),
(215, 'Using the new frog compiler from Dart Editor(`_|_`)\nFrog is the name of the new Dart-to-JavaScript compiler (if the name does not ring a bell, read about poison dart frog first). In the near future, it will be the only way to compile Dart code to be usable in various JavaScript environments.\n\nFor Dart Editor users, there is a possibility to start using frog right now (and just forget about the soon-to-be-obsoleted dartc). All you have to do is to grab the Dart SDK. Unzip the SDK right under the editor directory. For example, on Mac OS X the directory structure should look like:\n\nDartEditor.app\nconfiguration\ndart-sdk\nfeatures\nlibraries\nplugins\nsamples\nworkspace\n\n\nAfter that, open Dart Editor’s Preferences dialog. You should be able to choose frogc under the SDK and Compiler page, as illustrated in the screenshot below:\n\n\n\nUsing frog gives the advantage of cleaner generated code. For example, look at this minimalistic Dart code:\n\nbool isdecimaldigit(String ch) {\n  return \'0123456789\'.indexOf(ch) > -1;\n}\n \nvoid main() {\n isdecimaldigit(\'3\');\n}\n\n\nUse Dart Editor’s Tools, Generate Optimize JavaScript menu. Guess how the JavaScript code would like? Well, there will be still some 150-line boilerplate code (for whatever reason, though I’m sure it will be more streamlined in the future). However, right at the end you’ll find the following:\n\nfunction isdecimaldigit(ch) {\n  return \"0123456789\".indexOf(ch) > (-1);\n}\nfunction main() {\n  isdecimaldigit(\"3\");\n}\nmain();\n\n\nPretty close to what I would have written by hand!\n\n(`_|_`)Feb 13, 2012(`_|_`)ariya.io(`_|_`)using-the-new-frog-compiler-from-dart-editor', 'using-the-new-frog-compiler-from-dart-editor'),
(216, 'Find V8 version of certain Chrome release(`_|_`)\nV8 is the JavaScript engine of Google Chrome. It’s also useful as a stand-alone library, for example I use it as the basis for EightPack, a collection of command-line utilities for web-oriented continuous integration tools. Of course, it’s well known that the famous Node.js project leverages V8 for the speed.\n\nIf you are an avid follower of V8 development, often you want to try out the same V8 version which is used in a certain release of Google Chrome. How do we find this? It’s actually rather easy. First, look at the releases branches of Chromium Subversion repository, conveniently browseable at src.chromium.org/viewvc/chrome/releases. Now it’s a matter of checking the right version. At the moment of this writing, my Google Chrome says its at version 17.0.963.46. When viewing the file 17.0.963.46/DEPS (used by Gyp, the build system), you’ll find the link to the right version of V8, i.e. v8.googlecode.com/svn/branches/3.7 revision 10521. This can be cross-referenced in V8 repository: branches/3.7&start=10521.\n\nEasy, isn’t it?\n\n(`_|_`)Feb 12, 2012(`_|_`)ariya.io(`_|_`)find-v8-version-of-certain-chrome-release', 'find-v8-version-of-certain-chrome-release'),
(217, 'Dart bootstrap: Dartium vs other browsers(`_|_`)\nLately there has been a change on how Dart can be started in the browser. Since no other browser except Dartium, a special build of Chromium, has built-in Dart support, the process has two possible strategies. This is evidenced if you start a simple project from Dart Editor and peek at the HTML file, especially the last script tag which points to dart.js in Dart project repository:\n\n<script type=\"application/dart\" src=\"hello.dart\"></script>\n<script src=\"http://dart.googlecode.com/svn/branches/bleeding_edge/dart/client/dart.js\">\n</script>\n\n\nWhat does this dart.js file do? The logic is basically as follows.\n\n\nIf navigator.webkitStartDart is defined, then run that function. I believe this is specifically intended for Dartium only.\nOtherwise, find all script tags which refer to .dart file and replace it with the corresponding .js file. For example, hello.dart will turn into hello.dart.js.\n\n\nThis also means that if you just care about non-Dartium browsers, the payload could be simplified by including the generated JavaScript directly and skipping the bootstrapper completely. For the simple project referred before, the content could be just like:\n\n<script src=\"hello.dart.js\"></script>\n\n\nLast but not least, this mailing-list post (dated Feb 5) states that this is still temporary, i.e. things may change again in the near future.\n\n(`_|_`)Feb 9, 2012(`_|_`)ariya.io(`_|_`)dart-bootstrap-dartium-vs-other-browsers', 'dart-bootstrap-dartium-vs-other-browsers'),
(218, 'PhantomJS and Mac OS X(`_|_`)\n\n\nThis blog post describes various ways to install PhantomJS, the scriptable headless WebKit, on Mac OS X system (Snow Leopard and Lion), sorted from the most recommended way to the least recommended way.\n\nWhile the documentation wiki contains a clear explanation on how to start using PhantomJS on Mac OS X, I understand temptation to skip reading something and start doing real stuff. This post thus serves as another safety net for such cases. It also helps to clarify some misunderstanding.\n\nNote that these instructions apply to PhantomJS 1.4 (Glory of the Snow). Future versions may or may not require different steps.\n\nInstall the binary package\n\nThis is the fastest and easiest way. Go to the download page, find the ZIP file for Mac OS X, then download it. The size is usually around 9 MB so it should be pretty fast. Once it is downloaded, unzip the file (e.g. click on Finder) and that’s it!\n\nIt’s recommended to store the executable somewhere in your PATH. Also, the special file Info.plist is needed to avoid the Dock icon from flashing.\n\nNote that the ZIP package is self-contained. You do not need to install Qt beforehand. I repeat: there is no need to install or prepare anything. In other words, the steps mentioned above would work on a fresh (clean) install of Mac OS X.\n\nAlways stick to this binary package approach unless there is a strong reason not to do so. It saves you a lot of time.\n\nCompile statically\n\nBuilding everything manually takes time and effort. Fortunately a convenient build script is included. From the download page, find the source tarball, get it and then extract it. After that:\n\ncd deploy && ./build-mac.sh\n\nWhat does the script do? It will download Qt 4.8 source code from Nokia web site, extract the tarball, apply some patches, run configure, build Qt statically, and then finally build PhantomJS.\n\nAs with the previous approach, the build script has zero dependency. You do not need to compile Qt manually. In fact, run the build script on any Mac OS X system and it should work (of course, you need to have Xcode installed for the compilers, SDK, etc). The download might take a while (since Qt tarball is huge, around 230 MB), thus make sure you are not on a slow Internet connection.\n\nSome patches are applied because of the urgent need, e.g. to prevent QUrl crash, to avoid library confusion, or to allow file upload. There are also others important requirements, see the release notes for details.\n\nThe entire build is carried out with 4 (four) simultaneous compile jobs under the assumption that everyone uses a Mac machine with at least hyperthreaded dual-core CPU. On a typical modern machine, the build step lasts for about 30 minutes. Fast hard drive is recommended, but it is not mandatory.\n\nIf UPX is detected on the system, the final executable will be compressed. This should significantly reduce the size from 26 MB to just about 10 MB.\n\nOnce you are finished with these steps, what you have is a statically built PhantomJS with no external dependency (you should be able to copy it to another machine if needed). In fact, this is exactly what you got as if you follow the first approach (using the binary package).\n\nUse MacPorts or Homebrew\n\nThis approach only makes sense if you already have Qt installed, possibly because it is needed by some other applications. Otherwise, running\n\nport install phantomjs\n\nor\n\nbrew install phantomjs\n\nwill potentially keep your machine busy for hours because it will build the entire Qt library first. With Homebrew, it’s not so bad because Bottle likely save the time.\n\nWhile the end result might look the same, there are two important differences compared to the second approach. First, the convenient static build script build-mac.sh only compiles the necessary parts of Qt needed for PhantomJS. For example, it skips building the examples, demos, tools, etc. This cuts the overall time. Second, since MacPorts and Homebrew builds the vanilla Qt, some problems which are solved by patching (see the second approach) might arise.\n\nKeep the above differences into account to avoid future headache.\n\nUpdate: PhantomJS Homebrew formula has been updated so it will install the same exact binary like in the first two approaches. If you already have Homebrew, this is easy and fast, so go ahead and brew install phantomjs and enjoy!\n\n(`_|_`)Feb 8, 2012(`_|_`)ariya.io(`_|_`)phantomjs-and-mac-os-x', 'phantomjs-and-mac-os-x'),
(219, 'The Real Dark Knight Rises(`_|_`)\n\n\nAs it was mentioned before, PhantomJS website phantomjs.org finally got a brilliant new face, thanks to Maurice Svay.\n\nOn a related one, its sister project CasperJS also adopted the similar color theme.\n\nDark is the new black!\n\n(`_|_`)Feb 7, 2012(`_|_`)ariya.io(`_|_`)the-real-dark-knight-rises', 'the-real-dark-knight-rises'),
(220, 'Unconfidential tricks to challenge brainwashing(`_|_`)\nIf you are a regular reader of The Altucher Confidential, his recently published book I Was Blind But Now I See can be high on your reading list. The book is essentially the “best of” collection of his blog posts, often expanded with some new supporting materials. This is both good and bad: it feels familiar if you already read what James wrote in the past and it triggers some questions if you have no idea about his personality.\n\nFortunately, in the typical Altucher style, the insight offered in the book is both courageous and honest. Since the premise of the book is the uncover the constant brainwashing occurs in the society, it has to provide some thought-provoking kicks to really rattle the ground. There are topics ranging from real estate situation (buying vs renting), formal education plan (college or no college), ideas sharing (via self publishing), to various self-improvement awareness practices.\n\nAt times the book seems to be picky on a particular solution (e.g. use CreateSpace to get started with self publishing). However, this is not a big deal, the problem domain requires a specific example on how to solve it but yet it can be generalized enough without losing the spirit of the idea. And of course this is not Inception, it’s perfectly allright to disagree with what James wrote in the book!\n\nThe Kindle edition costs only 99 cents. Get a copy while it’s hot.\n\n(`_|_`)Feb 6, 2012(`_|_`)ariya.io(`_|_`)unconfidential-tricks-to-challenge-brainwashing', 'unconfidential-tricks-to-challenge-brainwashing'),
(221, 'Scalable web apps: the complexity issue(`_|_`)\n\n\nHave you encountered a case where you are suspicious about the performance issue in some part of the application and your concern was dismissed? Imagine a typical comment like:\n\n\nDon’t worry. That function runs really fast.\n\n\nWhile in many cases this is a valid assertion, in other cases being fast is not enough. Future web apps won’t be judged by how the individual pieces are evaluated, rather by the way they run together in an orchestra.\n\nA simple function like this:\n\nArray.prototype.swap = function (i, j) {\n    var k = this[i]; this[i] = this[j]; this[j] = k;\n}\n\n\nis rather innocent. There is not much you can do to optimize it. Yet, when it is being invoked from an implementation of a very inefficient sorting algorithm, the overall outcome would be disastrous.\n\nPage optimization\n\nSo far, typical discussions and best practices on web page optimizations (WPO) are geared towards two things: transport and interface responsiveness optimizations. The former is about leveraging the available bandwidth to its potential, obviously very useful since nobody likes to stare at the blank page while it is loading. The latter is to ensure that the user is happy with the user interface, often involving tricks from minimizing DOM operations to using hardware acceleration.\n\nAs web applications become bigger and more complex, soon there will be one huge issue which needs a lot of attention: scalability. For many traditional developers who jump to the web, either from the desktop background (C++/Java) or RIA development (Flex) or server-side scripting (Ruby/ASP), this is especially important. They are going to build web apps of a different class. The apps won’t be just web pages sprinkled with some interactivity to add the richness of the user interface.\n\nMany future applications will be architected and designed from the ground-up to be seriously large-scale. In those cases, the transport and responsiveness will be still relevant, yet they can be dwarfed by the application complexity. Imagine a stereotyped business logic application which deals with customer data, the central problem is less about CSS minification or JavaScript scope access. The bottleneck lies somewhere else.\n\nOrders of growth\n\n\n\nLet’s take a simplified example of client-side data sorting. If this is about a simple phonebook on a mobile device, then the performance is not as critical as a corporate address book, mainly because of the amount of entries to be sorted is different. Using bubble sort, with its quadratic growth average complexity, would not be a smart choice if the application must scale to a large number of contacts. The determining factor that becomes very important is the upper bound of the amount of computation as the application needs to tackle larger volume of data.\n\nNote that it does not even have something to do with traditional data manipulation. If you are writing a parser, does it scale when the input which it consumes is getting bigger? If you create a layout system, does it behaves nicely as the application stacks and nests the layout beyond your wild imagination? If your regular expression extracts an important piece from the user, does it choke when he feeds an slightly longer string than the typical? If you deal with graph-based dependency analysis, does everything still not fall apart when new nodes pop up like there is no tomorrow? If you develop a query engine, does it run forever when the document has a gazillion elements?\n\nThe scalability strategy is very important for framework or library author. There is no way to completely predict beforehand how people are going to use (or rather, abuse) the framework. Customers totally understand that as their data grows, they can expect a performance degradation in the processing. What many customers want to know (and often they do not describe exactly like this) is the quantitative explanation. If my address book doubles its entries, how much slowdown I can expect from this grid component? Is it also 2x? Is it 4x? Is it 100x?\n\nEmpirical run-time analysis\n\nFor things like sorting and searching, theoretical analysis of the algorithm complexity is widely available. However, real-world application analysis, even for many operations inside jQuery, is often not available or prohibitively expensive to be carried out formally. The fallback solution is to perform the run-time analysis, i.e. monitoring the behavior of the application as the input data grows.\n\nIf we go back to the Array.prototype.swap example, we just have to monitor how many times this function is being called during the sorting process. Essentially we are adding instrumentation to our code. Change the size of the data to be sorted, monitor the growth in the function invocation. Voila! We have a report which demonstrates its run-time behavior.\n\nIn this simplified example, it’s rather easy to carry out the above analysis. A slightly more complicated cases, anything from a selector engine to code quality tool will need a different approach. What about automatic instrumentation?\n\nThis is where Esprima kicks in. In case you’re not familiar with it, Esprima is a JavaScript parser designed from the very beginning to be extremely fast. The newest demo that comes with Esprima is the so-called function entrance tracing. In fact, the live demo at esprima.org/demo/functiontrace.html exactly demonstrates the sorting example given before. Go ahead, try it out, and come back again later (I’ll wait, I promise). Bonus exercise: change the sort function to something else, e.g. a binary sort.\n\nBefore the demo executes your code, it inserts an additional statement before every function block. For example, the swap function can become something like:\n\nArray.prototype.swap = function (i, j) {\nLog({ name: \'Array.prototype.swap\', lineNumber: 1, range: [23, 94] });\n    var k = this[i]; this[i] = this[j]; this[j] = k;\n}\n\n\nThe function Log is the name of the tracer (easily customized, see below). It will receive an object which has the information about the function name, its location (line number) as well as the index-based range of the function in the source. Armed with this instrumentation, you can do whatever you want in the implementation of your Log function.\n\nThe demo actually does a little bit more in order to be able to show the number of calls for every function. The tracer is TRACE.enterFunction, where TRACE is a simple object with its implementation is fully shown below:\n\nwindow.TRACE = {\n    hits: {},\n    enterFunction: function (info) {\n        var key = info.name + \' at line \' + info.lineNumber;\n        if (this.hits.hasOwnProperty(key)) {\n            this.hits[key] = this.hits[key] + 1;\n        } else {\n            this.hits[key] = 1;\n        }\n    },\n    getHistogram: function () {\n        var entry,\n            sorted = [];\n        for (entry in this.hits) {\n            if (this.hits.hasOwnProperty(entry)) {\n                sorted.push({ name: entry, count: this.hits[entry]});\n            }\n        }\n        sorted.sort(function (a, b) {\n            return b.count - a.count;\n        });\n        return sorted;\n    }\n};\n\n\nRather simple, isn’t it? Yet, it produces a powerful outcome: the record of every function call in the code.\n\nBackstage: automatic instrumentation\n\nAdding the above automatic instrumentation is possible via Esprima new source modification feature. There is still little information about the modify API but hopefully this will be expanded further. Basically, what you have to do is:\n\nesprima.modify(code, esprima.Trace.FunctionEntrance(\'LOG\'));\n\n\nThat’s all! esprima.modify will pass your source string to esprima.Trace.FunctionEntrance which parses your code, figure out where the functions are, then insert the instrumentation by calling the supplied tracer function.\n\nBecause of the dynamic nature of JavaScript, Esprima will do a best-effort guess for the function name (or mark it as an anonymous one), in case it’s not obvious. The unit tests demonstrate clearly that all the following constructs present no problem whatsoever, the correct function reference is still obtained properly:\n\nfunction hello() {}\nhello = function() {}\nvar hello = function() {}\nvar hello = function say() {}\n(function(){})()\n[14, 3].forEach(function(x) { alert(x) })\nvar x = { y: function(z) {} }\n\n\nIf adding a prolog with a tracer function call is not sufficient for you, flexible customization is further possible by supplying a function (instead of a string) to esprima.Tracer.FunctionEntrace, e.g.:\n\nesprima.modify(code, esprima.Tracer.FunctionEntrance(function (info) {\n    return \'// Executing function \' + info.name +\n        \' at line \' + info.lineNumber + \'n\';\n}));\n\n\nThe modified code will look something like:\n\nArray.prototype.swap = function (i, j) {\n// Executing function Array.prototype.swap at line 1\n    var k = this[i]; this[i] = this[j]; this[j] = k;\n}\n\n\nIt is rather useless because what being inserted is just a line comment. For your real-world instrumentation, you might want to build a more sophisticated customized instrumentation.\n\nInstrumentation and testing workflow\n\nOf course the instrumented version of your code is useless without actually testing it. There are several possible approach. The easiest is to a create a separate build for the instrumented version to be used in various scalability tests. For example, the performance test suite of a phone book will watch the function call analysis as it slowly increases the amount of contacts or switches to a variety of different test fixture.\n\nIn many cases, run-time analysis of application complexity does not depend very much on the actual environment. To facilitate fast smoke test, the use of headless WebKit such as PhantomJS can be very beneficial. Executing the complexity tests headlessly still allows the collection of various performance data without the need to launch any real browsers. Should you use a continuous integration system, this fits nicely into the workflow. As a bonus, PhantomJS is also supported by Travis CI, making it really easy to stress-test your open source applications and libraries.\n\nHappy testing!\n\nP.S.: In the next installment I will discuss Esprima for startup performance analysis. Update: it’s available, read more about automatic JavaScript execution tracking.\n\n(`_|_`)Jan 30, 2012(`_|_`)ariya.io(`_|_`)scalable-web-apps-the-complexity-issue', 'scalable-web-apps-the-complexity-issue'),
(222, 'one year of wandering headlessly(`_|_`)\n\n\nOne year ago I decided to bite the bullet and released PhantomJS to the world. It was the opening move in my own initiative to curate at least three open-source projects. While it was far from being really really ready, I was very content that I didn’t postpone it much further. After all, isn’t worse actually better?\n\nAfter five stable releases, from the initial 1.0 to the latest Glory of the Snow (all named after flowers, read the full story), PhantomJS gets stronger and gains more traction and momentum. Let’s have a quick review on how people use it.\n\nSince it is essentially a headless version of WebKit, web page automation is the main use cases. For scraping and navigation, CasperJS (which is using PhantomJS) from Nicolas Perriault strikes as an excellent example on how to do this. Check its documentation and examples, most of your automation needs will be probably covered. For automated page analysis, see also James Pearce’s confess.js which you can use (among others) to analyze page speed and cache manifest usage.\n\nAutomatic manipulation of browser content is the key to application testing. PhantomJS slowly becomes a common way to run the tests headless in many test frameworks. It is really easy to hook PhantomJS to the testing infrastructure, there are reports people running it with Jasmine, QUnit, FuncUnit, etc. Of course that once it is done, making it part of the workflow with various continuous integration system, anything from TeamCity and Jenkins is rather fun.\n\nSpeaking about testing, Capybara is often the choice for Rails/Rack developers. Thanks to Jon Leighton, finally we have Poltergeist, a solid PhantomJS driver for Capybara. While it does not substitute multi-browser testings via Selenium/Web Driver of various real-world browsers, this driver facilitates very fast smoke testing, just to ensure that you don’t do any stupid mistake before launching the extensive browser testing.\n\nIn addition, again thanks to Jon’s effort and the cool guys at Travis, PhantomJS is supported as part of your testing for Travis CI. There are already projects which leverage this (again as part of quick automated smoke tests), among others CasperJS and Ember.js (formerly known as SproutCore 2.0).\n\nIf you are not still convinced, there is a bunch of companies out there who use PhantomJS internally as part of the application development, from Sencha, Torbit, Betfair, to Time Warner Cable. Last year alone there were more than 80 articles and blog posts showing different use cases. Also, we even have leading company such as KDAB which put engineering effort into improving PhantomJS. And while I can’t reveal the details yet, expect to see more support from commercial organizations to the future development of PhantomJS this year.\n\nThe rather simplistic official site phantomjs.org successfully gets more than 120 thousands visits. Thanks to Maurice Svay, the site will sport a fresh redesign very soon. In the mean time, the project page hosted at Google Code easily hits half million views from more than 20 thousands unique visitors. The community discussion happens mainly in the mailing-list which currently grows to more than 300 members.\n\nTechnically, PhantomJS also serves as my playground for some of the software development best practices I experiment lately, everything from predictable time-based release schedules to extensive uses of issue tracker (read about it in the previous blog post). If you understand the concept of lean startup, these strategies may sound familiar.\n\nIt’s been an extremely fun ride. Thank you PhantomJS users and contributors for the amazing one year. We will not stop here for sure. Welcome to the year of headless dragon!\n\n(`_|_`)Jan 23, 2012(`_|_`)ariya.io(`_|_`)one-year-of-wandering-headlessly', 'one-year-of-wandering-headlessly'),
(223, 'senchacon 2011 videos(`_|_`)\nWhat happens in Austin does not stay in Austin!\n\n\n\nAs I already wrote before, at the last SenchaCon 2011 in Austin, TX there were two presentations that Jarred and I delivered. The first one was about a high-level overview of WebKit, how to leverage WebKit for application testing and optimization. The second one discussed the machinery behind hardware acceleration on mobile browsers. The slide decks for these two talks have been made available recently.\n\nHere comes the good news. Now you can also enjoy the entire SenchaCon tracks since the recorded videos can be watched at your convenience. For these two talks I mentioned, here are the complete goodies:\n\n\nHacking WebKit & Its JavaScript Engines: slide deck and video\nHardware Acceleration on Mobile: slide deck and video\n\n\nIf you are interested in similar topics, check also other related talks I’ve involved with in the past.\n\nEnjoy!\n\n(`_|_`)Jan 20, 2012(`_|_`)ariya.io(`_|_`)senchacon-2011-videos', 'senchacon-2011-videos'),
(224, 'books 2011(`_|_`)\n\n\nI always tell myself to read more books. Somehow last year wasn’t too much of a success. Here are some books (not necessarily recently published) I managed to read in 2011, listed in no particular order, which I would not hesitate to recommend to others.\n\nnon-fiction\n\n\nHyperspace by Michio Kaku\nLinchpin by Seth Godin and Hugh Macleod\nCoders at Work by Peter Seibel\nFounders at Work by Jessica Livingston\nDrive by Daniel Pink\nWinning by Jack Welch and Suzy Welch\nI’m Feeling Lucky by Douglas Edwards\nJavaScript Patterns by Stoyan Stefanov\nThe Way of the World by Ron Suskind\n\n\nfiction\n\n\nAbraham Lincoln: Vampire Hunter by Seth Grahame-Smith\nThe Fist of God by Frederick Forsyth\nForce of Eagles by Richard Herman Jr.\nSpy Hook by Len Deighton\nHis Last Bow by Arthur Conan Doyle\n\n\n(`_|_`)Jan 16, 2012(`_|_`)ariya.io(`_|_`)books-2011', 'books-2011'),
(225, 'small-scale software craftsmanship(`_|_`)\n\n\n\n\nPhoto by Trey Ratcliff (license:  Noncommercial Creative Commons).\n\nBuilding software can be as tricky as managing a complicated metropolitan city. Yet, as with many other things related to delicate handling, there are always approaches which are, time and time again, proven to streamline the workflow and increase the chance of success.\n\nDuring my amateur and professional time doing software development, I collected selection of best development practices which I had hoped I could really exercise. With PhantomJS and Esprima, I finally got the chance to give these practices a try. Often they work, sometimes they don’t.\n\nNote that obviously these are not all what we are doing. There are the typical mandatory activities like test-driven approach, extensive code review, proper repository access, agile trick, and the usual yada yada.\n\nplan your release like you plan your wedding\n\nWhen you say, “Sweetheart, we’ll have our wedding on the 4th of July this year”, you mean it. You won’t come back again in several weeks and then express “I’m not ready yet, let’s postpone it by few months”. Barring any extraordinary events (earthquake, nuclear holocaust, or world war), you give your best to fulfill your commitment. You want badly that you two get married on that date.\n\nThe implication of this is huge: you give your words to the users that you will ship a release and you won’t slip at all cost. It helps if you put a sticky note with that fundamental premise in front of your desk. Read it every morning, loud if necessary.\n\nNever forget that real artists ship.\n\npredictable time-based release\n\nNow that you set a contract between you and your users about the release, pick a reasonable date and stick with it. I was always undecided about time-based releases but over the last few years I can see how this makes sense after all. Engineers are excited about cool new stuff, customers are thrilled about getting the best possible values. The first group is the early adopter, but the folks who stick with your product always need something stable to serve their own customers.\n\nThere is a dramatic consequence of this approach with respect to feature development. First of all, you need to align your development timeframe with the release plan. This is always good as not everyone can afford “release it when it’s done” strategy. But the best side effect that you want to isolate your refactoring, rewrite, redesign, and the other two dozens potential screw up. Modern version control, like Git, makes it easy to create a special feature branch, while at the same time also doing frequent merge and QA from the stable branch.\n\nA small choice I make for PhantomJS, it’s always released every season. To make it more fun, the release date is chosen to be a solstice or an equinox. Astronomy does not need to be boring, right?\n\nuse the project tracker extensively\n\nEven if you are the only developer working on your project, there is a chance that you don’t remember everything. Assume right now you still remember most of the important stuff, in few months things will look different. Real life takes over sooner or later.  Out of sudden you have a baby and good luck trying to recall how you ended up with that obscure design choice.\n\nA lot of projects use some sort of tracking software, usually web-based, which allows you to create an entry and track them. For software hosted at Google Code, Github, SourceForge, etc, the tracker software is pretty good. Use the tracker for note taking. Capture your Eureka moment and save it for your future kids. It is imperative that every little decision must be properly documented (I know, it’s just common sense!). For large-scale projects (like WebKit), this is logical but I believe any small-scale projects should do the same.\n\nIf you’re still not convinced, remember that commit log is frozen and read-only. If you commit a bug fix and 42 days later you realize it was a mistake, you can’t change the old commit log to say “oops”. However, if someone tracks some regression and finds that commit (via git blame, for example), then the commit log does not represent the current amended situation. Now, if there is an issue linked from the commit log, it’s easy to follow it and possible find the reopened bug, along with further investigation result. This also helps if the commit message blames/credits a wrong person or refers/excludes a different product.\n\nOne monumental benefit of recording everything in the tracker: it is searchable by anyone, including (of course) the future version of you. Now go one step further and mandate that the link to the issue is mentioned in the commit log. A tracking system usually has some sort of hooks so that it can automatically even link back to the commit or do other related activites (closing the bug upon a certain keyword), if the commit log mentions the issue.\n\nThis cross referencing is extremely time-saving in the long run. One day you will decide to run git blame, find the culprit check in, and thus can easily track the real issue. Perhaps even the other way around, a new bug is reopened and you can trace back the original changes related to the bug. On the DRY front, such a practice centralizes all the info related to future plan, defects, known problems, etc in the most logical place: the issue tracker itself.\n\nLast but not least, issues aggregated based on the targeted version can easily serve as your mission center, a quick overview of the status and the plan. For example, Esprima has this wonderful grid view which shows its status with regards to the next release, a kind of a project dashboard.\n\nsemi-esoteric code names\n\nWhy? Mostly because it is fun and it gives a sense of personality. Your software is not just a series of ones and zeros packaged in a nicely presented user interface, it actually has a lot of stories, dramas, and tragedies behind it. After all, I’d like to refer the capital of my country with its name, Jakarta, rather than 6°12′S 106°48′E.\n\nLook at how some browers are named (exploration theme): Navigator, Explorer, Konqueror, Safari. Perhaps you also see the connection in Android release names like Eclair, Froyo, and Gingerbread (beside the fact that they are tasty)? Are you aware that Maemo versions (Chinook, Diablo, Fremantle, and Harmattan) are named after winds, possibly a way for Nokia to indicate “the wind of change”? For some reasons, Mozilla JavaScript engine has a lot to do with a specific primate: SpiderMonkey, TraceMonkey, IonMonkey. Ubuntu is well-known for its funky codenames like Natty Narwhal and Maverick Meerkat.\n\nFor PhantomJS I pick up the name of specific flower related to the season of the release: Cherry Blossom, Birds of Paradise, Water Lily, Glory of the Snow. There is a whole wiki page on the story behind the names, if you care.\n\nAny other uncommon best practices for small-scale software you always practice?\n\n(`_|_`)Jan 12, 2012(`_|_`)ariya.io(`_|_`)small-scale-software-craftsmanship', 'small-scale-software-craftsmanship'),
(226, 'api shame: non-descriptive property names(`_|_`)\nI had a lot of fun writing about the Boolean trap issue. I also have more similar API-related discussions in the pipeline. Rather than writing a long-ish essay again, I decide to put out more bite-size chunks. Here is the first.\n\nCareful when choosing the name of an object property!\n\nLet’s say you create a date picker component, something like depicted in the following screenshot:\n\n\n\nTo set the range of the year where the user is allowed to choose a certain date, here is a bad examples of the property names:\n\npicker.yearFrom = 1900;\npicker.yearTo = 2100;\n\n\nIt’s quite “conversational” to decide the names like yearFrom and yearTo. A much better choice would be like this:\n\npicker.minimumYear = 1900;\npicker.maximumYear = 2100;\n\n\nYou could use other idioms, like start and end, if you like. The philosophy is the same, when you define a property, try to say it loud in a normal English sentence.\n\nHere is another example. Say you want to introduce yourself:\n\n\n“Hi. Call me Adam.”\n\n\nDoes that mean you are going to write code like this?\n\nperson.callMe = \'Adam\';\n\n\nObviously not. Imagine your introduction has been changed to:\n\n\n“Hi. My name is Adam.”\n\n\nwhich is analog to the following:\n\nperson.name = \'Adam\';\n\n\nas if you say it (loud):\n\n\nThe name of the person is Adam.\n\n\nLet’s for the moment assume that this introduction happens in an airport, as you exchange greetings with fellow passengers in the waiting room. The conversation continues:\n\n\n“My flight is from SFO to JFK.”\n\n\nLet’s write the code for that. Maybe these lines?\n\nflight.from = \'SFO\';\nflight.to = \'JFK\';\n\n\nAgain, it’s very conversational. Technically no grammar is violated is your original sentence, though imagine if it would have been rewritten as:\n\nflight.departure = \'SFO\';\nflight.destination = \'JFK\';\n\n\nLess ambiguous? I bet!\n\nIn many cases, it’s impossible to choose one-word property name. In fact, it’s better to avoid it if that may cause some confusion.\n\nIf you have a scrolling list, where the user can swipe his finger horizontally or vertically, one way to specify it is:\n\nX.scroll = \'horizontal\';\nY.scroll = \'vertical\';\n\n\nStill considering the original observation that:\n\n\nthe code is usually written once but read many times.\n\n\nthose two lines lead to an ambiguity because scroll as a word can mean a lot. At least, it’s a verb and also a noun (though the latter often connects to the magical world). What you really want people to understand is perhaps:\n\nX.scrollDirection = \'horizontal\';\nY.scrollDirection = \'vertical\';\n\n\nSay it loud and it makes sense:\n\n\nThe scroll direction of X is horizontal.\n\n\nI hope you get the idea. See you in the next installment!\n\n(`_|_`)Jan 6, 2012(`_|_`)ariya.io(`_|_`)api-shame-ambiguous-property-names', 'api-shame-ambiguous-property-names'),
(227, 'glory of the snow(`_|_`)\n\n\nBy Hedwig Storch (Own work), CC-BY-SA-3.0, via Wikimedia Commons.\n\nOne day in last December was a solstice. That also means, we have another PhantomJS release, this time at its version 1.4, codenamed Glory of the Snow. While it’s hot, check it out from its code repository and look for 1.4 tag and then compile it. Binary packages and executables may be available for download after few days or weeks, so if you don’t want to build from source, please be patient a little bit.\n\nOriginally I had a huge plan for this 1.4 release (see issue 226 for details). Unfortunately, since Qt 4.8 had a very long release process, 2 months from the release candidate to the final release, this timing was not in our favor. Still, if you follow the release notes, there are few goodies which I’d like to mention again here.\n\nThe first is the new WebServer module. In some use cases, people want to interact with running PhantomJS instance, as opposed to launching it again and again. For the implementation itself, we use the code from Mongoose, an excellent embedded HTTP server library. The addition of this HTTP server module allows such a kind of two-way communication. A shortened example of this module (refer to examples/simpleserver.js for the complete code):\n\nvar server, service;\n \nserver = require(\'webserver\').create();\n \nservice = server.listen(8080, function (request, response) {\n    response.statusCode = 200;\n    response.write(\'<html><body>Hello!</body></html>\');\n});\n\n\nTwo important notes before you go crazy. First, this is considered experimental. We still don’t have full integration with the rest of Qt and WebKit machinery, check for the issues related to this WebServer module. Second, use it for process communication and not as a production-grade web server.\n\nAnother extra goodie in this release is the convenient script to build PhantomJS statically. Some of you just want to use PhantomJS in e.g. a continuous integration server and thus care less about the availability of system-wide Qt libraries (or even when you don’t have the permission to modify the system). The build script, available for Mac OS X and Linux (see the deploy subdirectory) automatically downloads Qt source code, configures Qt suitable for the build, and finally starts the compile. Nothing will clobber your system, everything will be setup locally. On a modern machine, this process (excluding the download) takes about 30 minutes. For the Linux version, if you choose to use Qt 4.8, there are also additional benefits: remote web inspection, X11-less via QPlatformAbstraction (aka Lighthouse), as well as various PDF improvements (borrowed from wkhtmltopdf).\n\nLast but not least, the new features in 1.4 were not possible if KDAB did not assign their highly-skilled engineers to help with the improvements. Kudos to KDAB and we’ll be forever thankful for the contributions!\n\nNow back to work, we have PhantomJS 1.5 to be ready before March 20, 2012.\n\n(`_|_`)Jan 4, 2012(`_|_`)ariya.io(`_|_`)glory-of-the-snow', 'glory-of-the-snow');
INSERT INTO `ariyaio` (`id`, `content`, `url`) VALUES
(228, 'three charms in a year(`_|_`)\n\n\nLuck comes in threes. And I believe it’s mostly good luck, not bad luck.\n\nThis year alone I finally had the time to publish three new open-source projects (one of them is as part of Sencha Labs) at the beginning, middle, and end of the year.\n\nThe first in line is PhantomJS, the headless WebKit (based on the Qt port). Since it was announced back in January, it is mentioned in lots of online articles and used in many different projects, from assorted testing frameworks to screen capture service. Full review will be revealed during its first birthday in few weeks. If you like PhantomJS in its first year, expect to love its upcoming second one!\n\nSomething I have started back in June was CSS Beautify, a simple JavaScript library to format and indent styles written in CSS. For some cases where you would find it useful, read my brief announcement about this tool.\n\nLast but not least, Esprima. This project is also exciting for me because writing a JavaScript parser in pure JavaScript which hits the compromise of performance and readability has been always in my agenda. For the detailed insight, as well as Esprima’s speed feature, read its project announcement few weeks back.\n\nAnother year, another fun!\n\n(`_|_`)Dec 31, 2011(`_|_`)ariya.io(`_|_`)three-charms-in-a-year', 'three-charms-in-a-year'),
(229, 'most tweeted(`_|_`)\n\n\nThis year alone, Sencha blog corner hosts around 190 blog posts of assorted topics, anything from product announcements, basic learning guides, HTML5 scorecards, to web technologies highlights. The winning blog posts, in terms of how many tweets they got (at the time of this writing), are listed here:\n\n\n  \n    \n      635\n    \n    \n    \n      Understanding Hardware Acceleration on Mobile Browsers\n    \n  \n  \n  \n    \n      484\n    \n    \n    \n      IE10 Preview: HTML5 First Look\n    \n  \n  \n  \n    \n      416\n    \n    \n    \n      Motorola Xoom: The HTML5 Developer Scorecard\n    \n  \n  \n  \n    \n      324\n    \n    \n    \n      Ext JS 4.0 Final Available Today\n    \n  \n  \n  \n    \n      279\n    \n    \n    \n      Previewing Sencha Touch 2: Native Packaging and Performance\n    \n  \n  \n  \n    \n      204\n    \n    \n    \n      Sencha Touch 2 Developer Preview\n    \n  \n  \n  \n    \n      203\n    \n    \n    \n      Android–Ice Cream Sandwich: The HTML5 Developer Scorecard\n    \n  \n  \n  \n    \n      200\n    \n    \n    \n      Introducing PhiloGL: A WebGL Framework from Sencha Labs\n    \n  \n  \n  \n    \n      188\n    \n    \n    \n      A Web Developer\'s Wishlist for iOS 5\n    \n  \n  \n  \n    \n      187\n    \n    \n    \n      iPad 2: The HTML5 Developer Scorecard\n    \n  \n\n\nApparently the #1 in the above list, the relation between browser and GPU, is the article I wrote back then, which is essentially a different version of my other explanations on the use of backing store and compositing in WebKit. Thus, there is my shameless plug: even if this year does not seem too magical for me, at least what I wrote did get some interests from some of you.\n\nNow, while this is interesting, the fun part is actually how I came up with the list. While I’m sure it’s entirely possible to use various different API to get the numbers, I was playing with PhantomJS to see if I could do that with a simple site scraping approach. Since the number of tweets, embedded via the Twitter widget, is always displayed in each blog post, that shouldn’t be too difficult, should it? Likely I need to clean up the script before I can include it as one of PhantomJS examples, if at all, so in the mean time just look the complete script at this gist: gist.github.com/1519281.\n\nThe gut of the script is very simple. First, load the URL of the blog post and then try to find the iframe containing the embedded Twitter widget. This is accomplished easily with just the following lines of code:\n\npage.open(url, function (status) {\n    if (status === \'fail\') {\n        callback.call(this, count, title);\n    } else {\n        title = page.evaluate(function () {\n            return document.title;\n        });\n        openWidget(page.evaluate(function () {\n            return document.querySelector(\'iframe.twitter-share-button\').src;\n        }));\n    }\n});\n\n\nOnce the corresponding URL of the Twitter widget, completed with all the query string, is obtained, it is now a matter of loading it and extracting the count. This is actually handled in the openWidget() function referred above. The entire function is reproduced here verbatim for your pleasure.\n\nfunction openWidget(location) {\n    var widget = require(\'webpage\').create();\n \n    widget.open(location, function (status) {\n        if (status !== \'fail\') {\n            count = widget.evaluate(function () {\n                return parseInt(document.querySelector(\'a#count\').textContent, 10);\n            });\n        }\n        callback.call(this, count, title);\n    });\n}\n\n\nPretty straightforward.\n\nNow, for this to work, we also need the list of URLs of every single blog post. Again, while it is likely easy enough to get that list using FeedBurner API (through which Sencha serves the blog feeds), I decided to take a shortcut and use the feed view in my Google Reader. After ensuring that those posts in 2011 are available in the subscribed view, a quick hack with Web Inspector and its Copy as HTML feature gave me the complete list of these blog posts (including short text snippet for each, which we happily ignore). Getting the list of the blog URL is a single-line solution:\n\ngrep -Eo \'(http://feedproxy.google.com/[a-zA-Z0-9~/_-]*)\' reader.html\n\n\nEvery item in Google Reader gets its own short URL, in the form of http://feedproxy.google.com/~r/extblog/~3/leusWn2oYnc/, which will redirect to the actual blog post. Fortunately for me, the PhantomJS script illustrated here takes care of that automagically.\n\nLooking forward to seeing more successful 2012 blog posts!\n\n(`_|_`)Dec 25, 2011(`_|_`)ariya.io(`_|_`)most-tweeted', 'most-tweeted'),
(230, 'Introducing Esprima: Blazing-fast JavaScript Parser(`_|_`)\n\n\nIn a nutshell, Esprima (esprima.org) is a JavaScript parser written in pure JavaScript. In the near future, it will expand itself to something even more cooler, but as of now it’s just a parser. It uses the common recursive descent approach. The main parsing routine is not machine generated, everything is written by hand. The output of the parser is a syntax tree in JSON, formatted compatible to Mozilla Parser API.\n\nThe code is designed to be educational (no funky obfuscated tricks only a JavaScript ninja can decipher), self explanatory (the terminologies match the actual official 258-page specification), and high performant (it can tear apart jQuery source code, and not the minified version, in less than 0.1 sec). It’s always challenging to pick the sweet spot which nails all these three objectives, though I hope Esprima hits an optimal compromise.\n\nLike any complex parser, unit testing is an integral part of the development. To ensure faithful compatibility with Mozilla Parser API, hundreds of its tests have been imported as well. All in all, there are over a thousand tests. In addition, there is a benchmarks suite, it consists of most common JavaScript libraries out there. The performance of various web browsers running the benchmarks suite is depicted in the following chart (shorter is better). The test machine is an iMac from late 2010, with 3 GHz Intel Core i3.\n\n\n\nIf you think it’s not fast enough, wait for the improvements being made to major JavaScript engines out there. Preliminary tests showed that V8 engine in Chrome 17 (dev channel) executes the benchmarks suite 1.7 faster than Chrome 15. Related to that, JavaScriptCore in WebKit nightly speeds up the benchmark running time by 25% (and it keeps getting faster). In addition, Firefox 9 will feature type inference which shows 65% performance win when running the said benchmarks suite.\n\nWhat about mobile devices? As expected, it’s rather slower at this kind of job, limited pretty much by the CPU power. Some data of the running time for the benchmarks suite: 5.8 sec for Amazon Kindle Fire, 7.9 sec for Apple iPad 2, 12.8 sec for Nexus S, and 17.9 sec for Nokia N9.\n\nSince Esprima is written in JavaScript, it runs wherever there is a decent implementation of JavaScript. Supported browsers are (among others) IE 8+, Firefox 3.5+, Safari 4+, Chrome 7+, and Opera 10.5+. As expected, Esprima can also be used in Node.js applications by installing esprima package using npm.\n\nThe best way to try Esprima is right in the browser via the online syntax parser demo. Type in your code, and voila! Esprima will show you the corresponding syntax tree almost right away. There is also the operator precedence demo, inspired by previously similar demo. Beside comparing if an expressions is equivalent to another one, the example also rewrites your expression as if you would have written it using brackets to enforce the intended precedence, illustrated in the following screenshot:\n\n\n\nCompared to other parsers, Esprima is one of the fastest. There is a whole speed comparison page which puts Esprima head-to-head against parse-js (famously known as part of UglifyJS), ZeParser, and Narcissus. Since Esprima does not output location information yet (see issue #6), like ZeParser and Narcissus, a pure speed benchmark is only fair between Esprima vs parse-js. Here is the result, tested with different (stable version) browsers. Still not impressed? With the upcoming Chrome 17, Esprima will be actually 2x faster than parse-js.\n\n\n\nSo which parser should you pick? Narcissus has been around for a while so its stability and correctness are well tested. It does also support various JavaScript extensions, as well as features from ES.next. Both ZeParser and parse-js are not necessarily new anymore so they are more battle hardened than Esprima. Since the excellent minifier UglifyJS is based on parse-js, I’m not shocked if there are tons of peculiar JavaScript syntax which parse-js can handle really well. At the end of the day, I still hope that as the new kid on the block, Esprima is attractive enough since it’s readable, easy of follow, heavily unit tested, and yet carrying out the parsing task at blazing speed. Thus, if you feel adventurous, give Esprima a try!\n\nBeside dealing with code parsing, Esprima also has the ability to optionally collect the comments (see issue #71). Since it involves some extra steps, expect some minor performance penalty if you do that. Once those comments are extracted, a bit of additional cross reference will allow you to associate certain comment blocks with parts of the code. This is extremely valuable for an automatic documentation tool.\n\nTo keep an eye on Esprima development, go to its project page, watch the issue tracker for future plan, and join the discussion in the mailing list.\n\nGet the code and express yourself!\n\nP.S.: Special thanks to Thomas Aylott, Yusuke Suzuki, and Axel Rauschmayer for the useful initial discussion, suggestions, and feedback.\n\n(`_|_`)Dec 13, 2011(`_|_`)ariya.io(`_|_`)introducing-esprima', 'introducing-esprima'),
(231, 'typical ofi #50(`_|_`)\n\n\nLast week, WebGL Camp #4 was held at the main office of Mozilla in Mountain View downtown. Nicolas has written an excellent wrap-up. Slides are getting uploaded, recorded video will be available some time in the future. Such a camp always works as a reminder that if you aren’t yet excited about WebGL, maybe this is the right time to look at it. Stay ahead of the curve!\n\nFinally the destiny of Palm webOS was decided few days ago: it will join tons of other established open-source projects. An freely available and tweakable operating system is definitely of a great interest for many hobbyist, much remains to be seen whether any commercial entities will pick it up. As with any mobile OS these days, making it mainstream depends on the other parts of the puzzle: attractive hardware and growing ecosystem. On the other hand, Enyo framework can easily propagate as the alternative building blocks for various hybrid and web-based apps in many other platforms, including iOS and Android.\n\nSpeaking about tablet, just few weeks after Kindle Fire availability, it becomes clearer that this market is really brutal. Dell ultimately kills its Android-based 7-inch Streak. In mean time, the 7-inc Playbook is supposed to cost RIM close to half billion dollars. Does that mean we’ll see less and less 7-inch devices in 2012?\n\nOther (un)related battles you might enjoy, with the good company of some popcorn: AT&T with its T-Mobile merger attempt, Motorola’s injunction against Apple, Apple design vs Samsung’s, and Adobe vs zero-day exploiter.\n\nLast but not least, expect to see reviews and analysis of the mighty Ice Cream Sandwich on Galaxy Nexus in the inter tubes, in the few coming weeks.\n\n(`_|_`)Dec 12, 2011(`_|_`)ariya.io(`_|_`)typical-ofi-50', 'typical-ofi-50'),
(232, 'living with prepaid smartphones in the states(`_|_`)\n\n\nFor foreigners or new residents, getting a working cell phone in the United States often means going through some confusing (and sometimes also painful) steps. First, get the phone, i.e. the device itself. Second, get the service plan for the phone.\n\nWhile GSM is dominating in most parts of the world, US is still using both CDMA and GSM extensively. Verizon and Sprint are big CDMA operators, while AT&T and T-Mobile still stick with GSM. This needs to be taken into account if you already own a slick GSM phone and would like to use it.\n\nObviously, a service plan is also required. There are two approaches: subscription or prepaid. In the first case, you sign a contract agreement with the operator for a duration of 2 years (sometimes one-year contract is also possible). In the second case, you need to have the necessary credits upfront, before using the service and top it up whenever it is running out.\n\nIf you opt to get into the contract, then you are often eligible to buy a discounted new phone as part of the package. Since the service operator knows you’ll going to commit to the service for the duration of the contract, they subsidize the phone and thus can reduce the purchase price. There are also various deals possible, especially with bundled offer and multiple-line/family arrangement. It’s also common to see the price driven to zero, i.e. the phone itself is free.\n\nAs an example, at the time of this writing most US carrier offers the much-loved Apple iPhone 4S for the price of $200, provided you’ll be using their service in the next 24 months. This gives the explanatory answer to a very common question (especially from my countrymen):\n\n\nI heard you can get iPhone for $200 in the US. Can you buy one for me and bring it home? I’ll pay you back.\n\n\nOf course, the bulk of the carrier profit comes from the service plan. After losing $200 for the phone itself, now you still need to shell out $50 to $85 per month, depending on how much voice/text/data you would need. Along the 2-year duration of your commitment, this is equivalent to losing as much as $2240, i.e. $200 + $85/mo * 24 months.\n\nAnother way to reduce the cost is to use the prepaid strategy. Years ago, the prepaid situation in US was disastrous. These days, it is getting better and better. Surprisingly, many are still not aware of this.\n\nLet’s examine the iPhone 4S example above. Buying the unlocked, non-contract version from Apple will set you back $650. After that, get monthly plan from T-Mobile, ranging from the cheapest $30/month for basic service to $50/month for unlimited talk, text, and web. This service is also non-committal, you can stop at any time. In the span of 2 years, the total cost would be at most $1850. That’s like 20% saving vs $2240 for the contract-based.\n\nYou’ll save even more if you can live without an iPhone. Surely there is a suitable decent Android-based phone you’ll enjoy for less than $400. Amazon, Ebay, GSM Nation, as well as various deal sites are perfect places to hunt for unlocked smartphone bargains.\n\nIn addition, there are also mobile virtual network operators which can resell the service at a discounted price. For example, Simple Mobile piggybacks on T-Mobile network yet it offers only $40/month for the same unlimited plan. Virgin Mobile, which relies on Sprint network, can give you unlimited service for $35/month although you need one of its CDMA-based smartphones.\n\nSince WiFi becomes more ubiquitous, let’s pray that Republic Wireless hits a critical mass and thus reaches the success. I’m sure you’ll agree that $19/month is the best deal!\n\n(`_|_`)Dec 6, 2011(`_|_`)ariya.io(`_|_`)living-with-prepaid-smartphones-in-the-states', 'living-with-prepaid-smartphones-in-the-states'),
(233, 'simple html geolocation example(`_|_`)\nFor my collection of testcases of web technologies (check it online at ariya.github.com), I added a simple example demonstrating the use of HTML5 Geolocation feature. It should run without any problem on a web browser which has such support, including on several mobile devices which I have tested.\n\n\n\nI also added reverse geocoding using Google Maps API which should give the approximate human-readable address of the location.\n\nPoint your browser to ariya.github.com and choose Geolocation link. Have fun!\n\n(`_|_`)Nov 25, 2011(`_|_`)ariya.io(`_|_`)simple-html-geolocation-example', 'simple-html-geolocation-example'),
(234, 'first look: silk browser for kindle fire(`_|_`)\n\n\nKindle Fire from Amazon, one of the hottest tablet these days, is finally available. Based on the Android platform, this tablet differentiates itself from few tablets out there because of the integrated Amazon services, manifested in its completely different UI than other Android devices. For those who used to shop regularly, watch movies and TV series, buy and read books, then it is perfect companion. Of course, Amazon has the intention to lure new customers into the services with this wonderful gadget.\n\nA much discussed feature of Kindle Fire is its web browser called Silk. The marketing machine from Amazon basically promotes Silk as a Revolutionary Cloud-Accelerated Split Browser. It’s called split because one part resides in the tablet while the rest is running on Amazon Elastic Compute Cloud (EC2) and hence the cloud association. Another way to look at it is to imagine a browser using an advanced proxy mechanism that leverages Amazon server infrastructure.\n\nFor privacy reasons (or perhaps you just don’t like being rerouted ), this cloud-based loading acceleration can be disabled. From the browser, just pull the menu, choose Settings, and look for “Accelerated page loading” checkbox.\n\nLet’s have a look at the browser itself. First things first, the user agent of the browser (obtained from the navigator object) is:\n\n\nMozilla/5.0 (Linux; U; Android 2.3.4; en-us; Silk/1.1.0-80) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1 Silk-Accelerated=true\n\n\nAs predicted, this basically advertise that the underlying platform is Android 2.3 (famously known as Gingerbread). Nothing magical about this user agent, it’s pretty much similar to other Gingerbread-based devices. In addition, the Silk-Accelerated part reveals whether server assistance for the loading is activated or not. If it is not, the value would be false instead.\n\nAn interesting little feature of the browser is allowing mobile vs desktop view of the web page. Again, it’s available from the Settings menu in the form of 3 (three) possible choices: optimized for desktop, optimized for mobile, or automatic. For the last one, seems there is some way (heuristics perhaps?) for Silk to decide which mode to pick. Apparently, there is no magic behind the desktop mode as Silk browser simply switches the user agent to something like:\n\n\nMozilla/5.0 (Macintosh; U; Intel Mac OS X 10_6_3; en-us; Silk/1.1.0-80) AppleWebKit/533.16 (KHTML, like Gecko) Version/5.0 Safari/533.16 Silk-Accelerated=true\n\n\n\n\nBeside that, for all intents and purposes Silk browser is just a custom UI (tabbed browsing, thumbnails of bookmark, etc) on top of Gingerbread WebKit with its V8 JavaScript engine. In fact, looking at the available Kindle Fire source code, nothing indicates any major modification to Gingerbread WebKit. The cloud-based assistance in the form of accelerated page loading does exactly like the name says: to speed-up page loading. The change seems to be more on the network back-end. Thus, the client technologies such as HTML, CSS, JavaScript are not affected by such cloud-oriented changes.\n\nThis also means that if your rich sites or web apps work with Gingerbread, most likely it would work on Kindle Fire. I reckon it’s in Amazon’s interest to keep such compatibility as good as possible. On a less pessimistic view, if you were excited about Amazon Silk before, your experience using the browser might eclipse that excitement pretty soon. Because its root in Gingerbread WebKit, expect no support for SVG, CSS 3-D transform, WebGL, and other fancy goodies. By using Modernizr, it is easy to witness that the set of supported features (see this screenshot) are the same as any Android phones running Gingerbread. Amazon also excludes geolocation support, although from the technical point of view, a WiFi-based solution ala Skyhook should give the coarse location just fine.\n\nAs for GPU acceleration, there is no visible sign of it (again, just like in Gingerbread WebKit). If you follow my blog post or presentation about hardware acceleration on mobile browsers, there are basically three levels a browser can leverage the GPU: accelerated primitive drawing, tiled backing store (for progressive panning and zooming), and layer compositing (for fluid animation). Unfortunately, none of this is implemented. This is hardly a surprise since Gingerbread WebKit does not implement any advance support for GPU anyway. Thus, if you expect silky smooth CSS3 animation and all that stuff, adjust your expectation appropriately.\n\nWe know that Android WebKit improves only from Honeycomb (Android 3.x) onwards. Also, for the phone form factor, much of the enhancement is available starting from Ice Cream Sandwich only. If Amazon upgrades the software stack of Kindle Fire to catch up with the fresher WebKit implementation, that would be a huge boost to the browsing experience.\n\n \n\nWhat about the overall performance? Fortunately, it’s acceptable for casual browsing, which is likely what the target audience of Fire will do anyway. Static web pages render fast enough with sufficient fidelity. Since I’ve been using it only for few days, the impact of accelerated page loading was not visible. Presumably after some weeks the server side of Silk would understand my browsing behavior better and thus can offer some prediction and preempt my next move. While I am still not sure what would be the best method to compare accelerated vs non-accelerated speed, I will wait for a while so that Amazon aggregates enough information (creepy, isn’t it?) and then optimizes the delivery of the digital bits to my Kindle.\n\n \n\nAs for dynamic, JavaScript-heavy applications, the dual-core 1 GHz processor (TI OMAP 4430, same as in RIM Playbook and Motorola Droid RAZR) provides the necessary energy for the layout and rendering process, despite the lack of browser GPU support.\n\nIn the following chart, I compare Kindle Fire with some other popular (real) tablets: Apple iPad 2 running iOS 5.0.1, Honeycomb-powered Samsung Galaxy Tab 10.1, and RIM Playbook with its Playbook OS 1.0.7 firmware.\n\nWhile pure JavaScript speed is important (can be tested using SunSpider, V8, and Kraken benchmarks), for interactive web sites and complex web apps, DOM performance is critical. As with my previous tablet performance analysis, I use Dromaeo to investigate Kindle Fire ability to cope with DOM query, traversal, and attribute handling.\n\n\n\nSide note: I can’t use the full DOM suite from Dromaeo because a peculiar issue with Silk browser where it pauses the browser and gets back to the home screen after something is triggered. This forced me to run the test one at the time and compute the final outcome by hand. DOM modification test can’t be carried out at all, the browsing session is paused way before the test completes.\n\nAs for the speed of rendering when CSS transformation is involved, I use my kinetic scrolling in a flick list to test it. The chart looks as follows.\n\n\n\nFor pure pixel manipulation in JavaScript, a fast processor helps a lot. Take a look at the following results running my pixel cross-fading example:\n\n\n\nLast but not least, I used Vellamo, the extensive web performance tool from Qualcomm, to see how Kindle Fire stacks up against the others. Since Vellamo is specific to Android, the comparison is only with other Android 7″ tablets. Consider that new Android tablets these days are powered with Honeycomb, there is no surprise that our Gingerbread-based Kindle Fire comes at the very last.\n\n\n\nWith a powerful CPU and a capable graphics core (PowerVR SGX540), it’s sad that the silicon advantage has been not fully leveraged by the web stack. Look at iPad 1 which has less sophisticated hardware and see how smooth the browsing experience is. Or perhaps check out Nokia N9 (and N950) which is armed with its multi-process blazing-fast web browser. Of course, it is possible to fix this by merely a software update, which we hope the team at Amazon will be in the position to deliver it. Till then, use the Fire to burn your growing desire for books, music, videos, other medias, and shopping!\n\n(`_|_`)Nov 22, 2011(`_|_`)ariya.io(`_|_`)first-look-silk-browser-for-kindle-fire', 'first-look-silk-browser-for-kindle-fire'),
(235, 'typical ofi #47(`_|_`)\n\n\nKindle Fire is in da house! This $199 Android-based tablet from Amazon was pretty much the gadget of the week. There are multiple reviews already, among others from Ars Technica, The Verge, Engadget, Sencha, and many others. I have taken a first look at its Silk browser, expect to see my detailed review tomorrow. Update: the review is available.\n\nSpeaking about tablet, get ready for the upcoming Black Friday, for example to anticipate $199 Playbook deal. In addition, watch out for Nook Tablet.\n\nOn a different topic, Google finally made Google Music official. I’ve been using it for a while after getting the invite during the beta. The service is not breathtaking, it does what it is supposed to do. Granted, without having an actual Android phone running the Music app, the experience will be very much different.\n\nSpeaking about Android, the official site android.com received some face lift, the source code for Ice Cream Sandwich was made available, and I bet a lot of Android developers are in the middle of SDK update, bracing for the (hopefully) creamy and tasty impact.\n\nLast but not least, jQuery Mobile 1.0 is finally unleashed. Congrats to the jQuery Mobile team!\n\n(`_|_`)Nov 21, 2011(`_|_`)ariya.io(`_|_`)typical-ofi-47', 'typical-ofi-47'),
(236, 'matching a decimal digit(`_|_`)\nWhen you write a tokenizer, for example for a math expression evaluator, then it is unavoidable to find the category of a single character, whether it’s a number, an operator, etc. While the most logical way is to use regular expression, what if you would like to do it without one?\n\nA typical JavaScript function to carry out this monumental job is as follows:\n\nfunction isDigit(ch)\n{\n    var c = ch.charCodeAt();\n    return (c >= 48) && (c < = 57);\n}\n\n\nIf you want to use some slightly complicated branch statement, then do something like this (or again, a version which uses the character code instead):\n\nfunction isDigit(ch)\n{\n    switch (ch) {\n    case \'0\':\n    case \'1\':\n    case \'2\':\n    case \'3\':\n    case \'4\':\n    case \'5\':\n    case \'6\':\n    case \'7\':\n    case \'8\':\n    case \'9\':\n        return true;\n    default:\n        return false;\n    }\n}\n\n\nShould you know the internals of modern JavaScript engines, the above two forms translate to a nicely optimized form, ready to be executed at a blazing speed by the engine.\n\nHowever, if you don’t really care about microsecond-level of performance (your bottleneck is probably somewhere else, not in the above innocent function), an alternative would be (warning: careful JavaScript experts might be provoked into another variant using the property lookup of a constant object):\n\nfunction isDigit(ch)\n{\n    return \'0123456789\'.indexOf(ch) >= ;\n}\n\n\nString searching can’t beat the speed of simple integer comparison yet from time to time I find the construct depicted above is just beautiful and easy on eyes.\n\nYour take?\n\n(`_|_`)Nov 18, 2011(`_|_`)ariya.io(`_|_`)matching-a-decimal-digit', 'matching-a-decimal-digit'),
(237, 'strife of love in a dream(`_|_`)\nMountain View Public Library often holds special events such as regular book sales *. While combing the huge selection for some affordable treasures, I picked up few past best-sellers fictions which I always wanted to enjoy but never had the time to do so. Bracing for the flight to Austin, randomly I pulled two of them from the shelf, The Rule of Four and The Club Dumas.\n\nI started (and finished) the The Rule of Four first. The center of the story is Hypnerotomachia Poliphili, a mysterious book from several hundreds years ago. And guess which book is mentioned in the early part of The Club Dumas? Yes, the same one.\n\nSpeak about coincidence, this one is indeed really strange (and creepy).\n\n\nSupport your local community! Find the nearest public library and see how you can help.\n\n\n(`_|_`)Nov 15, 2011(`_|_`)ariya.io(`_|_`)strife-of-love-in-a-dream', 'strife-of-love-in-a-dream'),
(238, 'typical ofi #46(`_|_`)\n\n\nRepublic Wireless caught some attention because of its hybrid calling concept, where the call is routed to use WiFi network whenever it’s possible to do so. Due to this strategy, the plan costs only $19/month and this is without any long-term contract. There is only one smartphone offered so far, the Android-based LG Optimus S, though more choices in the future are not impossible. Obviously, this type of solution is geared towards those who are mostly on WiFi (home and office), a pretty sizable chunk of the market I would say.\n\nMeanwhile, the new HP CEO Meg Whitman still hasn’t put the final decision as to what would happen to webOS. A little bit more suspense does not harm, I think.\n\nWith everyone being enlightened after completing Walter Isaacson’s “Steve Jobs”, a different take on the subject by Malcolm Gladwell, The Tweaker, is a wonderful complement to the saga. Enjoyable, regardless your opinion about Steve.\n\nLast but not least, Adobe decides to stop doing Flash for mobile browsers and focuses on HTML5 instead. About time!\n\n(`_|_`)Nov 14, 2011(`_|_`)ariya.io(`_|_`)typical-ofi-46', 'typical-ofi-46'),
(239, 'beauty and the beast(`_|_`)\nSomething that I’ve been working on as a side project is CSS Beautify, an open-source project from Sencha Labs. It has a simple purpose: reformat styles written in CSS to a certain guideline, primarily to make it easier to read.\n\nAn example given there is this raw style:\n\nmenu{color:red} navigation{background-color:#333}\n\n\nwhich would be formatted as:\n\nmenu {\n    color: red\n}\n \nnavigation {\n    background-color: #333\n}\n\n\nCSS Beautify is implemented entirely in JavaScript. The online demo is available at senchalabs.github.com/cssbeautify (Update: the new site for the demo is cssbeautify.com), feel free to play with it. For the command-line version, just wrap it with NodeJS, Rhino, WSH, or your favorite JavaScript runtime environment. If you like to use a 1 MB executable with no external dependency, get it from my other project: EightPack.\n\nIf you are in the business of web development, it is often unavoidable to get minified or compressed CSS, e.g. coming from a theme for your CMS. Using CSS Beautify, those cryptic styles can be analyzed better.\n\nFurthermore, expressive CSS tools such as Sass or Less (or new the Closure Stylesheet) might produce CSS code in various format. In this case, CSS Beautify is handy to unify the style formatting.\n\nShould you need to check in your style into the source control system, storing the formatted version is really beneficial since it facilitates easy comparison between different versions. You may always use minified styles for performance reason, but keep also the formatted versions in case debugging is needed.\n\nIf it’s not Baroque, don’t fix it!\n\n(`_|_`)Nov 12, 2011(`_|_`)ariya.io(`_|_`)beauty-and-the-beast', 'beauty-and-the-beast'),
(240, 'parsing: imperative vs declarative(`_|_`)\nSyntactic analyzer, often referred as parser, is either written by hand or generated from the syntax declaration (grammar). While working on a certain parser project, I realize that sometimes the difference between these two strategies becomes rather blurry. For example, consider a typical math expression which has this fragment in its grammar:\n\nMultiplicative ::= Unary |\n                   Multiplicative \'*\' Unary |\n                   Multiplicative \'/\' Unary |\n                   Multiplicative \'%\' Unary |\n\nAdditive ::= Multiplicative |\n             Additive \'+\' Multiplicative |\n             Additive \'-\' Multiplicative\n\n\nThe hand-constructed JavaScript code for each of the rules above may look like this:\n\nfunction parseMultiplicativeExpression() {\n    var expr = parseUnaryExpression();\n \n    if (match(\'*\') || match(\'/\') || match(\'%\')) {\n        expr = {\n            type: Syntax.BinaryExpression,\n            operator: lexer.next().value,\n            left: expr,\n            right: parseMultiplicativeExpression()\n        };\n    }\n \n    return expr;\n}\n \nfunction parseAdditiveExpression() {\n    var expr = parseMultiplicativeExpression();\n \n    if (match(\'+\') || match(\'-\')) {\n        expr = {\n            type: Syntax.BinaryExpression,\n            operator: lexer.next().value,\n            left: expr,\n            right: parseAdditiveExpression()\n        };\n    }\n \n    return expr;\n}\n\n\nThus, although the manually crafted functions are essentially imperative, its closeness to the grammar declaration makes the implementation really easy to understand. A parser generator certainly has some advantages with respect to optimization. For educational and analysis purposes however, nothing beats debugging a chain of functions which you have written with your own bare hands!\n\n(`_|_`)Nov 10, 2011(`_|_`)ariya.io(`_|_`)parsing-imperative-vs-declarative', 'parsing-imperative-vs-declarative'),
(241, 'trying out dart(`_|_`)\n\n\nRegardless whether you love or hate Dart, I think it is a good move from Google to make Dart Editor available as early as possible. The editor is based on Eclipse (evidenced from the look-and-feel), the download is only around 36 MB. It requires Java, which is usually available in modern desktop systems. In a typical scenario, downloading and running Dart Editor with one of the sample applications just take few minutes.\n\nWhile it is being worked on, Dart Editor already enjoys the standard expected features from an IDE such as project handling, class outline, and code editor with syntax highlighting and code folding. Autocomplete in the editor also works, which is joyful. It does even understand DOM and thus can autocomplete the elements and the associated properties. Don’t be surprised if more advanced features such as better syntax highlighting and integrated debugging will appear in the next iteration of Dart Editor.\n\nNow the challenge is, where can I buy some spare time?\n\n(`_|_`)Nov 5, 2011(`_|_`)ariya.io(`_|_`)trying-out-dart', 'trying-out-dart'),
(242, 'post senchacon 2011(`_|_`)\n\n\nSenchaCon 2011 was a blast: tons of technical talks, great conversations with a lot of people, and lively Austin. Read more about the official mega-recap at Sencha blog.\n\nAs I mentioned earlier, this year I had a partner-in-crime running two presentations related to web technologies. Because the way Jarred and I ran our talks, the slides were there only for the supporting materials. Some of the concepts we showed were better understood through the demos. Having said that, hopefully the slides will whet your appetite until the recorded video becomes available in the near future. Update: the recorded videos are available now.\n\nFor the first talk Hacking WebKit and Its JavaScript Engine, the slides are as follows (or view it directly on SlideShare).\n\nWhen I find some spare time (which is rare these days), I’ll finish my draft blog post on the use PhantomJS as part of your development workflow via git precommit hook. And if you are still not convinced, wait until you really enjoy the per-pixel regression tests which run at lightning speed.\n\nFor Hardware Acceleration on Mobile talk, here is the slide deck or straight on SlideShare. It is basically the more elaborate version of the same topic I’ve written at Sencha blog corner Understanding Hardware Acceleration on Mobile Browsers (which is also one of the top tweeted Sencha blog posts in the last few months):\n\nWhile waiting till the videos are available, enjoy!\n\n(`_|_`)Nov 4, 2011(`_|_`)ariya.io(`_|_`)post-senchacon-2011', 'post-senchacon-2011'),
(243, 'typical ofi #44(`_|_`)\nBarely recovering from the shock of the loss of Dennis Ritchie, few days ago we had to say good bye to John McCarthy. He created Lisp programming language, undoubtedly very influential in the development of various languages for the last few decades. Not only that, he was also the pioneer in the field of artificial intelligence (AI), something that millions of iPhone 4S users are enjoying via Siri.\n\n\n\nNokia dominated the major tech reporting last week, due to its launch of Lumia phones, the anticipated Nokia devices running Windows Phone, for the first time. Two models were announced, Lumia 710 and Lumia 800, the latter resembles a physical similarity to Harmattan-powered Nokia N9. In fact, Engadget’s comparison of Lumia 800 vs N9 reveals that these phones are siblings with respect to the hardware configuration, thought they are day-and-night difference with respect to the software stack. Major hardware difference is the SoC, Lumia 800 is powered by Qualcomm Snapdragon S2 at 1 GHz clock speed.\n\nAt the same week, Munich enjoyed the annual Qt Developer Days. Major themes in this conference are the recently launched open-governed Qt project, a sneak peek of the next-generation Qt Quick, with the usual highly-technical content and use cases. If you miss Munich, wait few weeks and the same event will be held here in Burlingame.\n\nOn the mobile web front, there was SenchaCon 2011 in Austin last week so expect to see some wrap-ups as people are getting back from the travel.\n\nMeanwhile, jQuery Mobile announced the theming tool called ThemeRoller for Mobile. This is a drag-and-drop visual utility and should be very easy to use to create various different themes. ThemeRoller is open-source (github.com/jquery/web-jquery-mobile-theme-roller) and thus one can also use his own deployed version instead of using the online version.\n\nThough Samsung Electronics reported that the profit goes down 23 percent this Q3, it finally shipped more smartphone than Apple, more than 27 million units through the Galaxy lines and other series vs the shy 17.1 million iPhones. Of course, the numbers may look different in the next Q4 once the sales of the new iPhone 4S will be accounted for.\n\nThis week #44 is started with Halloween. Whether you like this trick or not, just enjoy the week!\n\n(`_|_`)Oct 31, 2011(`_|_`)ariya.io(`_|_`)typical-ofi-44', 'typical-ofi-44'),
(244, 'spooky testing: casper, ghostbuster, poltergeist(`_|_`)\n\n\nWith Halloween around the corner, it seems to be a good time to mention some interesting projects related to PhantomJS, the headless WebKit tool I have started some time ago.\n\nIf you think writing test cases for PhantomJS is too close to the metal, then have a look at Casper.js (github.com/n1k0/casperjs) from Nicolas Perriault. Spend few minutes reading the documentation and you’ll agree that this will simplify your PhantomJS scripts by a huge margin.\n\nAn alternative approach is Ghostbuster (github.com/joshbuddy/ghostbuster), created by Joshua Hull. Again, there are several very useful convenience functions, in particular to emulate the user behavior as he steps through your web applications.\n\nCapybara is a popular tool to test Ruby-based web applications. Integration of PhantomJS with Capybara has been requested (see issue #50). While waiting until this feature will be supported (if ever), one solution to run Capybara tests headlessly is by using Jonathan Leighton’s excellent Poltergeist (github.com/jonleighton/poltergeist), a PhantomJS driver for Capybara.\n\nPick Casper, GhostBuster, or Poltergeist or even all of them! “Trick or test?”\n\n(`_|_`)Oct 29, 2011(`_|_`)ariya.io(`_|_`)spooky-testing-casper-ghostbuster-poltergeist', 'spooky-testing-casper-ghostbuster-poltergeist'),
(245, 'detecting browser sniffing(`_|_`)\nThe latest version of PhantomJS has added the support for initialization callback, which allows you to modify the global objects which will be seen by the client code. The example I previously shown was changing the behavior of Math.random to return a constant.\n\nWhat follows is another example, available in the repository (look under examples/detectsniff.js), to create a fake navigator object so that you can detect if the code running on the web page tries to sniff your browser user agent. The most important piece is shown here:\n\npage.onInitialized = function () {\n    page.evaluate(function () {\n        (function () {\n            var userAgent = window.navigator.userAgent,\n                platform = window.navigator.platform;\n \n            window.navigator = {\n                appCodeName: \'Mozilla\',\n                appName: \'Netscape\',\n                cookieEnabled: false,\n                sniffed: false\n            };\n \n            window.navigator.__defineGetter__(\'userAgent\', function () {\n                window.navigator.sniffed = true;\n                return userAgent;\n            });\n \n            window.navigator.__defineGetter__(\'platform\', function () {\n                window.navigator.sniffed = true;\n                return platform;\n            });\n        })();\n    });\n};\n\n\nBasically what we do is logging the access to both platform and userAgent property of the navigator object. Because there is no message passing support yet (see issue 224), we store the status in another property which will be retrieved later. This is not the most bulletproof workaround since the client code can circumvent that, but it will go away once issue 224 is solved.\n\nExamples on how to use it:\n\nphantomjs examples/detectsniff.js http://ariya.github.com/js/useragent/\nChecking http://ariya.github.com/js/useragent/...\nThe page tried to sniff the user agent.\n\n\nand\n\nphantomjs examples/detectsniff.coffee http://m.bing.com\nChecking http://m.bing.com...\nThe page did not try to sniff the user agent.\n\n\nBTW, there is also the CoffeeScript version, find it in examples/detectsniff.coffee.\n\n(`_|_`)Oct 26, 2011(`_|_`)ariya.io(`_|_`)detecting-browser-sniffing-2', 'detecting-browser-sniffing-2'),
(246, 'typical ofi #43(`_|_`)\n\n\nGoogle announced Ice Cream Sandwich, officially known as Android 4.0. This version brings all the improvements from Honeycomb (Android 3.0) into the smartphone form factor, plus some more goodies. At the same time, Samsung demonstrated the premier phone featuring Ice Cream Sandwich, Galaxy Nexus. With 1.2 GHz dual-core OMAP 4460, 1 GB RAM, Super AMOLED 1280×720 display, Galaxy Nexus catapults itself into the top-of-the-line Android device.\n\nOn a different part of the (mobile) world, RIM let the official word that the next-generation BlackBerry OS will be based on QNX (which RIM acquired more than a year ago), thus dubbed as BBX. Notable in BBX is the use of Cascade for its advanced graphics, coming from TAT (which RIM acquired few months ago). Also the platform allows application development using native libraries, Flash, as well as HTML5. In the demo, George Staikos (formerly Torch Mobile, which RIM acquired two years ago) showed WebGL running on this next OS. In addition, apparently the previously-promised ability to run Android apps is coming, too!\n\nLast but not least, the Qt project finally goes live!\n\n(`_|_`)Oct 24, 2011(`_|_`)ariya.io(`_|_`)typical-ofi-43', 'typical-ofi-43'),
(247, 'javascript tools for continuous integration(`_|_`)\n\n\nYou want to build JSLint-based syntax checking into your continuous integration workflow? What about its variant JSHint? Perhaps even including the automatic minification for the deployed build? Look no more, just use EightPack, a convenience hassle-free collection of several command-line tools designed to help your application development process.\n\nAs of now, EightPack consists of the following JavaScript-related tools:\n\n\nsyntax checking with JSLint and JSHint\nconservative minification with JSMin\ncode reformatter, aka JS Beautifer\n\n\nBy finding the right settings for JSLint/JSHint for your project, you can preempt any stupid mistakes or coding errors into the source tree. Forcing the coding style is also easy using JS Beautifier. Last but not least, creating a deployed (minified) version of the code can be accomplished in a single stroke using JSMin.\n\n(There are also some CSS tools, but that’s the topic for another blog post)\n\nEach executable (of the tool) weighs at around 1 MB. Every one of them is a self-contained native application with no external dependency. You can copy or move the executable anywhere, it should just work. Yes, no installation necessary. I repeat, zero installation.\n\nEightPack can be built easily. Once you clone the repo, you should be up and running quickly. Compile time in a typical modern machine, with 4 parallel jobs, is less than 2 minutes. Those minutes will potentially save you a lot of headaches in the long run. Of course, it works on Linux, Windows, and Mac OS X.\n\nIf you have no time to build EightPack, just use the premade installer, available for Mac OS X or Windows. If you want to contribute packages for various Linux distributions, that would be very appreciated.\n\nWhatever your CI server is running, there is no excuse anymore not to integrate such QA tools. If hitherto you are hesitant to install Node.js or Java (Rhino) or any other JavaScript environment, get EightPack and “just do it”.\n\n(`_|_`)Oct 21, 2011(`_|_`)ariya.io(`_|_`)javascript-tools-for-continuous-integration', 'javascript-tools-for-continuous-integration');
INSERT INTO `ariyaio` (`id`, `content`, `url`) VALUES
(248, 'magnetic compass via device orientation(`_|_`)\nIn the specification of DeviceOrientation Event, it was mentioned that:\n\n\nTo get the compass heading, one would simply subtract alpha from 360 degrees. As the device is turned on the horizontal surface, the compass heading is (360 – alpha).\n\n\nUnfortunately, when iOS 4.2 added the support for this event, the value of alpha was rather arbitrary. It was consistent, but it bears no relation to the actual magnetic north. Though I did create a compass demo utilizing that event (check it out at ariya.github.com/device/compass), I never get to popularize it because of the drawback referred in its commit log (that’s why hitherto I kept calling it as a “fake compass”):\n\ncommit 4b97a9e07e67fff3a2ca38c177bae1c32ea6c209\nAuthor: Ariya Hidayat <ariya .hidayat@gmail.com>\nDate:   Fri Dec 10 18:53:29 2010 -0800\n\n    js/compass: Using device orientation to show rotating compass.\n    \n    Unfortunately, iOS 4.2 does not align the alpha value of the orientation\n    to the real magnetic North.\n    \n    The icon is from http://www.openclipart.org/detail/50329\n</ariya>\n\nFortunately, the excellent browser in Nokia N950 and N9 (read my review) has a faithful implementation of this device orientation event (mostly likely through the Qt Mobility module). Thus, a little fix on the example means that the demo works fine on these two phones. There are some issues I can’t resolve with respect to the actual accuracy, but nothing this app can do about it (since it just visualizes the data sent by the browser).\n\nThe code is likely easier to get from the usual X2 git repo (or the alternative repo), look under sensor/webcompass.\n\n\n\nHow about iOS 5? James demonstrated the use of the new webkitCompassHeading property for a compass. Based on this, I also updated my own compass example so now it works correctly on iOS 5 and still falls to the fake behavior when running on the older iOS (special thanks to Jay for getting the iOS screenshot).\n\nAlso notable here is the same CSS animation trick so that the rotation itself is smooth. Now, for a rotation, north presents a problem since the value wraps around if the needle passes it from west to east and vice versa (imagine 357, 358, 359, and then 0 degrees). Rather than turning off the animation, I used another trick. Instead of setting the absolute direction, the target property value of the CSS animation is actually relative to the current one, this works because the rotation angle in the CSS transformation will be internally reduced to the range of a full circle.\n\nThis compass example also support offline mode (via application cache). Thus, if you are iOS 5 or N950/N9 users and in the need of a compass, no need to install an app from the store. Go to ariya.github.com/device/compass, bookmark it, and enjoy!\n\n(`_|_`)Oct 20, 2011(`_|_`)ariya.io(`_|_`)magnetic-compass-via-device-orientation', 'magnetic-compass-via-device-orientation'),
(249, 'countdown to austin(`_|_`)\n\n\nAt the last Sencha Conference 2010, one of my presentations was JavaScript: Under the Hood. Much to my surprise, the video (also see below) and the slides become very popular after they are published. In fact, if you see the list of most popular Sencha’s SlideShare, it’s right there at #2 (as of now).\n\nBased on the feedback and the comments, I decide to have some fun again doing the explanatory talks about web technologies at Sencha Conference 2011 next week in Austin, TX. This time, I will be joined by Sencha’s other WebKit contributor, Jarred Nicholls. We will have two presentations, both on Monday, October 24.\n\nHacking WebKit & Its JavaScript Engines is basically about how browser works in general and how would you use WebKit to assist your rich web apps development. There will some best practices in JavaScript coding in particular. The official abstract looks as follows:\n\n\nWebKit, along with its JavaScript engines, is not a magical black box. We will show you the internal of various WebKit building blocks (10,000-foot overview) and how they work together. In particular, learn also the simple steps on how to experiment with WebKit with your own and leverage WebKit functionalities to find the performance problems, track the network issues, automate effective smoke tests, and implement per-pixel correctness tests. In addition, armed with a little extra knowledge about JavaScript engines, you will be ready to improve both the quality and performance of your JavaScript code.\n\n\nOn the other hand, Hardware Acceleration on Mobile is very specific to give you the information on how web browsers take advantage of modern GPU. This talk is the more elaborated version of the concise description I’ve written about Understanding Hardware Acceleration on Mobile Browsers, one of the most tweeted Sencha blog post in the last half a year. The official abstract says it all:\n\n\nGPU acceleration on mobile browsers, if it is leveraged correctly, can lead to a smooth and fluid applications, thus improving the user experience. There has been a lot of mentions and best practices of hardware acceleration these days, although so far it has been pretty general and hasn’t provided much technical direction apart from simple magical advice such as “use translate3d”. This talk sheds some more light on browser interactions with the GPU and explain what happens behind the scenes, covering the topic of acceleration of primitive drawing, the use of tiled backing store, and composited layer. Knowing the actual machinery behind hardware acceleration, you will be in the position to plan your strategy to improve the performance of your web application.\n\n\nIf you are coming to Austin, drop by and say hello!\n\nUpdate: the slide decks are now available. Another update: you can enjoy the videos now.\n\n(`_|_`)Oct 18, 2011(`_|_`)ariya.io(`_|_`)countdown-to-austin', 'countdown-to-austin'),
(250, 'printf(\"typical ofi _d\", 42);(`_|_`)\nIt’s another sad week. The computing world lost a great pioneer and a true visionary, the legendary one-and-only Dennis MacAlistair Ritchie. If all he did was only to invent C, we still owed him a lot. But he also cocreated Unix! Imagine if C and Unix weren’t born, our life could have been completely different. So long, dmr.\n\nprintf(\"Bye, world!\")\n\n\nIn the same universe, Dart, the structured web programming, was finally unveiled. It’s truly a controversial language since it draws a lot of critics. Seems that liking Dart is a minority stance these days. We just have to wait and see (and might as well grab some popcorns) if Dart manages to deliver what it promises. In particular, it would be interesting to see the use Dart for server-side programming due to some of its interesting concept such as isolate and type checking. In addition, I would not be too shocked if Google has a secret plan to rolls Dart for Android in the near future, that’ll be a nice way to avoid being strangled by Oracle.\n\nDart fans might also check what Dirk Nowitzki has to say:\n\n\nDear tony romo. Don’t worry abt all the critics. I heard that same garbage for a long time. Keep working hard and keep improving.\n\n\nMeanwhile, iPhone 4S (rumor is that 4S stands “for Steve”) was out. It was very common to see a lot of the new owners speaking to the phone and attempting to do different crazy thing with Siri. There were few hands-on reviews in the past week and I believe we will see more detailed analysis of this new magical box in the coming weeks. Now, the great question is of course whether the timing of a rather long BlackBerry outage was a conspiracy or not?\n\nLast but not least, don’t forget the 15th birthday of KDE! Cornelius has written a very nice wrap up of what happens in the last fifteen years. Is it a crazy ride? I’m sure it is. It’s been a while since Matthias original announcement (read it again, it’s fun!) and the initial version of the desktop environment:\n\n\n\nDon’t forget that the ubiquitous WebKit was started as Apple adopted KHTML, its JavaScript engine was also originated from KJS, and the SVG support had some roots from KSVG. Can you list any other traces of other KDE technologies in your geek life?\n\n(`_|_`)Oct 16, 2011(`_|_`)ariya.io(`_|_`)printftypical-ofi-d-42', 'printftypical-ofi-d-42'),
(251, 'hybrid native+web: using dialog boxes(`_|_`)\nAfter looking at some complex hybrid examples such as folder visualization and code editor, it’s time to take a step back and review some basic concept.\n\nThe following example is really simple, it should provide you a good starting point to explore the signal-slots handling in the web-to-native bridging. Basically we will trigger a native dialog from the JavaScript side of the application. Should you want to follow along, the whole code is in the usual X2 git repo (or the alternative repo), look under hybrid/nativedialog (you need Qt 4.6 or later versions).\n\nTo get a taste, here’s the screenshot first. I showed this for the first time during my presentation at Intel Elements 2011 in Bellevue, hence the choice of the sample message.\n\n\n\nIn the C++ side, we need to have the actual dialog implementation. For the sake of keeping it simple, here is the declaration:\n\nclass Dialog: public QObject\n{\n    Q_OBJECT\n \npublic:\n    Dialog(QObject *parent = );\n \npublic slots:\n    void showMessage(const QString& msg);\n};\n\n\nAll we care for now is that showMessage() function, which would just call QMessageBox. In real-world application, you can use other types of standard Qt dialogs and possibly even create your own custom dialog.\n\nvoid Dialog::showMessage(const QString &msg)\n{\n    QMessageBox::information(, \"Information\", msg);\n}\n\n\nOnce we have the instance of the above Dialog class, we inject it into our web page using addToJavaScriptWindowObject as follow:\n\nQWebFrame *mainFrame = webView.page()->mainFrame();\n   mainFrame->addToJavaScriptWindowObject(\"Dialog\", new Dialog);\n\n\nNow, whenever you want to pop up the dialog, i.e. via the handler of that Show Message button (which is just a normal input element), call it like this:\n\nDialog.showMessage(document.getElementById(\'msg\').value);\n\n\nThis is the simplest possible Qt and WebKit bridging example I can think of, so that’s all!\n\n(`_|_`)Oct 15, 2011(`_|_`)ariya.io(`_|_`)hybrid-nativeweb-using-dialog-boxes', 'hybrid-nativeweb-using-dialog-boxes'),
(252, 'flick list with its momentum scrolling and deceleration(`_|_`)\nThe launch of Apple iPhone few years ago popularizes the use of flick list, a touch-friendly list interface with a bit of physics when hitting the edge and scrolling. This effect is often known as momentum scrolling (although personally I prefer the more romantic term, kinetic scrolling).\n\nAges ago I was involved with the C++ and Qt side of this in the form of Flick Charm (a magic spell to flickify any QAbstractScrollArea) and Flickable (base class to enable flicking on any widget). The code is structured around a simple state-machine, making it easy to understand and debug. Note: you may collapse Pressed and Stop states, they were two separate ones due to a workaround which is not needed anymore.\n\n\n\nFor the mobile web, there have been attempts to reimplement this flick list concept using pure JavaScript. Out there, you can find projects like TouchScroll, iScroll, Scrollability, Zynga Scroller, and many others. The idea is rather straightforward: handle touch events yourself so that you can simulate the scrolling behavior that suits your need. This way, the lack of position:fixed and/or overflow:scroll is nicely compensated.\n\nAller guten Dinge sind drei. Third time is a charm. My third attempt to have a simplified way enabling kinetic scrolling was far from finished. I already put the initial usable version (also ported to JavaScript) more than a year ago. Rather than waiting for perfection, I decide to dissect one particular part which is my favorite: the deceleration. Also, now it comes both in C++/Qt and JavaScript flavors. To keep this blog post as short as possible, I’d focus only on the deceleration itself. Topics around rubberband/bouncing effect, snapping, direct style setting vs CSS3 animation, etc will be reserved for any future discussion.\n\nWhen I started to work on Flick Charm 3 years ago, I did not pay attention carefully to the way the scrolling works on iPhone. I was just assuming that the deceleration is based on Newton’s law of motion, i.e. a moving body receiving a friction which is forced to stop after a while. After a while, I realized that this is actually not how iPhone (and later iOS devices such as iPad) does it. Using a camera and capturing few dozens scrolling movement of various iOS applications, it came to me that all the scrolling will stop after the same amount of time, regardless the size of the list or the speed of the flick. How fast you flick (which determines the initial velocity of the scrolling) only determines where the list would stop and not when.\n\n(If you are a professional working with high-speed photography, I invite you to do the above camera analysis. By using a suitable high-speed camera, I’m fairly confident that the precise movement of every pixel can be accounted for, and thus would help to verify my postulate above. For example, this could be a nice episode of Mythbusters!)\n\nThis observation led me to believe that the momentum scrolling is a sort of exponential decay. It is characterized by the speed of the decay. There are two different ways to express it: half-life (remember radioactive decay?) or time constant. For the latter, it is very much related to the step response of a first order system. In other words, the deceleration system is just an overdamped spring-mass system. Turns out, everything is still based on physics.\n\nNote: Since two-dimension scrolling (x and y) is just a linear combination of two independent flick movements, it’s easier to implement the deceleration for each axis and then combine the result. For the rest of the blog post, this would be the assumption.\n\nA clever trick to set the scrolling position based on the exponential decay is by using the fact that it slows down at a rate proportional to its value. This simplifies the math of the deceleration a lot, there is no need for complicated way to keep track of the time, velocity, tweening using Bézier curve, etc.\n\nThe code to implement this above decay is ridiculously simple, here is one way to do it:\n\namplitude = initialVelocity * scaleFactor;\nstep = ;\n \nticker = setInterval(function() {\n    var delta = amplitude / timeConstant;\n    position += delta;\n    amplitude -= delta;\n    step += 1;\n    if (step > 6 * timeConstant) {\n        clearInterval(ticker);\n    }\n}, updateInterval);\n\n\nWe choose to stop after scrolling for about 6x the time constant because at that point the new position will be within 0.25% of the target position. Another variant would be to stop when the scrolling movement enters the subpixel area (i.e. it is going really slow). The time unit can be arbitrary, but be careful to normalize it with the timer resolution of setInterval. Using the above code fragment, the position as a function of time is depicted in the following graph (each tick in the horizontal axis represents the time constant):\n\n\n\nIn fact, this is how the deceleration is implemented in Apple’s own PastryKit library (and now part of iAd). It reduces the scrolling speed by a factor of 0.95 for each animation tick (16.7 msec, targeting 60 fps). This corresponds to a time constant of 325 msec. If you are a math geek, then obviously you realize that the exponential nature of the scroll velocity will yield the exponential decay in the position. With a little bit of scriblling, eventually you find out that 325 is -16.7 / ln(0.95).\n\nThe time constant itself is the solution to the two values of decelerationRate in UIScrollView: normal vs fast. Various scrollable lists in typical iOS applications are using a normal deceleration rate. However, UIWebView seems to be on the fast side. This is evidenced when you use Safari to browse a long web page as flicking the web page scrolls much less than as if you flick on e.g. the contact list. Usually, Safari completes the scrolling in less than half a second.\n\nIf you choose to have a slightly slower method, at the added benefit of being more robust against slower frame rate (see Android problem below), use the solution of the differential equation of the exponential decay:\n\n\n\namplitude = initialVelocity * scaleFactor;\ntargetPosition = position + amplitude;\ntimestamp = Date.now();\n \nticker = setInterval(function() {\n    var elapsed = Date.now() - timestamp;\n    position = targetPosition - amplitude * Math.exp(-elapsed / timeConstant);\n    if (elapsed > 6 * timeConstant) {\n        clearInterval(ticker);\n    }\n}, updateInterval);\n\n\n(If you want to have snap-to-grid feature, there is a subtle hint in the above code fragment!)\n\nShould you think that computing the exponent for every frame is too expensive, you can cache the values. If the time constant is 325 msec and the scrolling stops completely after ~2 seconds, with 60 fps animation you will only need an array with 120 values. Memoize this array based on the time constant and now you avoid calling Math.exp all the time. This comes at an expense, you won’t be able to adjust for degraded actual frame rate.\n\nThe online demo for mobile WebKit is available at ariya.github.com/js/kinetic (actually, it’s been there for a year!). The source code is easier to get from my code example repository (or the mirror), look at javascript/kinetic for the web and widget/kineticmodel for native (C++ and Qt). For the latter, there is a simple example widget/namelist. In both cases, the code should be generic enough and can be reused for other types of scrolling.\n\nFor the content of the web version, I pick the first four letters from Robert Walton in the famous Frankenstein novel. When viewed in portrait, the usual smartphone will render the text element as long as 4000 pixels, thus making it a nice stress test for the scroller.\n\nFor a good measure, I also included a primitive frame counter, measuring the amount of the handler for the timer is invoked averaged for the last few seconds. It’s likely not terribly accurate (depending on the platform, some rendering-related part may run asynchronously on a different thread), but it’s good to have a quantitative index of the performance. In addition, the scroll indicator on the left side is intentional, this is to avoid easy confusion with a native scroll bar (which would not appear if everything works properly). And even if you are going offline right after, the demo should still work since it leverages application cache.\n\nOn typical iOS devices, such as iPhone and iPad, scrolling very close to 60 fps is easily within reach. Nokia N9 or N950, due to its excellent browser, can get the same performance without any problem. As for Android phones, partially due to the lack of GPU compositing (a topic for another blog post), it does really depend on the hardware power, e.g. Nexus S won’t likely go beyond 25 fps. For your pleasure, enjoy the complete performance chart below (many thanks to my linguist friend Donald Carr and also Ronny and Espen for providing the results for Galaxy S II). Note that since rendering is always related to the number of pixels on the screen, be cautious when doing the comparison.\n\n\n\nObviously, if you really want the frame rate of 60 fps or more, adjust the timer update interval to be less than 16.7 msec. That way, there would be more processor time allocated for the computation part and thus the intended fluid scrolling is easier to achieve. For example, setting the update interval to 0 will push the speed to over 75 fps on those iOS devices.\n\nWhat about CSS3 animation? It’s fantastic to use this new animation system because (depending on the system) it can be composited (and thus, easily GPU accelerated). The performance is expected to be better because instead of calculating the position for every frame, we let the rendering engine (in its native code) to deal with it. Instead of using the built-in animation timing function (based on cubic Bézier curve), custom deceleration can be perfectly achieved using keyframes. This trick is used e.g. in Scrollability, read the blog post from Joe Hewitt for more detailed info.\n\nWhen I find some spare time, I’d like to discuss some follow-ups such as edge bouncing, snapping (which should be easy already), optimized keyframes generation, and other related topics. Till then, enjoy the momentum!\n\n(`_|_`)Oct 13, 2011(`_|_`)ariya.io(`_|_`)flick-list-with-its-momentum-scrolling-and-deceleration', 'flick-list-with-its-momentum-scrolling-and-deceleration'),
(253, 'hybrid native+web example: animator(`_|_`)\n\n\nJust released last week, Sencha Animator is a tool to create CSS3-based animation. The application itself is written in JavaScript (using ExtJS), though it runs as a normal desktop application (with native menu, file dialog, etc). The trick is simple: wrap the application using WebKit and create a hybrid solution. Because the wrapper is available for all major desktop platforms (Windows, Linux, Mac OS X), this also simplifies the build and deployment.\n\nThe user-interface of Animator leverages many advanced CSS features (it would be an irony if a CSS animation tool does look ugly). The interface itself is stunning, with a lot of subtle effects (shadow, gradient, animation) designed to make it really appealing. While the screenshot gives a rought idea, only playing with the application itself shows the actual feeling of the user experience. Recreating the interface without CSS would have been still possible, but it may push the limit of what native interface can do. Not too mention the effort.\n\nLights, Animator, Action!\n\n(`_|_`)Oct 11, 2011(`_|_`)ariya.io(`_|_`)hybrid-nativeweb-example-animator', 'hybrid-nativeweb-example-animator'),
(254, 'typical ofi #41(`_|_`)\n\n\nFor fans of id Software, post-apocalyptic RAGE was finally out, check out the official site rage.com and also the new TV spot (with a perfectly suited background music!). The engine behind this game is very capable, with lots of crazy visual effects. Will RAGE define a new era just like its predecessor DOOM and Quake? I guess we’ll find out some time soon. For all intents and purposes, it’s a new era, the RAGE era.\n\nApple finally announced the new iPhone 4S with some improvements: faster processors, voice control through Siri, better camera, etc. In the mean time, there was also a lot of coverage of Adobe MAX. Among others important stuff: the acquisition of Nitobi (PhoneGap maker) and TypeKit, more words about Adobe Edge.\n\nCSS shader could be another game changing. A lot of developers have been asking about precise control of compositing, rather than using magical spell like translate3d and such, shader is the right solution for this problem. CSS filter for simple effect, CSS shader for more cinematic impressions.\n\nAnd last week, all of us had to say good bye, Steve.\n\n(`_|_`)Oct 9, 2011(`_|_`)ariya.io(`_|_`)typical-ofi-41', 'typical-ofi-41'),
(255, 'post elements 2011(`_|_`)\n\n\nAs I mentioned before, my recent trip to Washington involved a premier event by Intel AppUp Elements in Bellevue. I had a presentation about web technologies (see the slide deck) straight after the opening keynote. It could not have been better, as the initial hours were filled with the excitement about Tizen, a new initiative to give a rebirth to MeeGo but with HTML5 and WAC as the foundations, along with the new partner, Samsung. More information about Tizen will be revealed in its official site tizen.org in the coming weeks.\n\nAs a nice touch, every participant also gets a bag of HTML5 Learning Kit, a collection of learning materials for web technologies. While the selection itself is quite good, I wish Intel would have included a good printed reference on the most important piece of the puzzle: JavaScript. A nice book like JavaScript: The Good Parts or Eloquent JavaScript or an equally decent one would have been an extremely nice complement to the kit.\n\nThe event itself was an excellent show. It was fun to meet again people I already know, make new friends, and get exposed to cool things I wasn’t aware of. Elements 2012? I’ll definitely keep an eye on it!\n\n\n\nAnd since Bellevue is next to Seattle, of course we did not miss it. While Bellevue feels like a typical beautiful modern place, Seattle is indeed a miniature of a metropolis. We managed to do almost all the common tourist things: Space Needle, Seattle’s Best Coffee, the first Starbucks store, Tully’s, Fisherman’s Restaurant, Pike Place Market, and even the disgusting Gum Wall. Getting some snacks at the library-looking Top Pot Doughnuts was memorable, also consider about a year ago President Obama dropped a visit and sampled the donuts there.\n\nOf course, riding the monorail and getting some rain completed the joyful experience!\n\nNow, how do I find an excuse to go back there?\n\n(`_|_`)Oct 7, 2011(`_|_`)ariya.io(`_|_`)post-elements-2011', 'post-elements-2011'),
(256, 'typical ofi #40(`_|_`)\n\n\nWeb technologies are not too much different than durian: either you love it or you hate it.\n\nAt AppUp Elements last week, Intel and Samsung announced Tizen, web-based system derived from MeeGo and LiMo. If Linux Foundation would succeed in running this project with open-governance, things could be interesting for its future.\n\nOther conferences taking place are JSConf EU in Berlin and jQuery conference in Boston. As predicted, the easiest and fastest way to follow what the hottest stuff in both events is by checking Twitter for #jsconfeu and #jqcon.\n\nAmazon finally announced the Android-based latest Kindle Fire. This is different than another iPad-wannabe in a way that it is marketed differently. Also, with $199 tag price, Fire is a tablet targeted at non-geeks (though I’m sure even a geek will not refuse to enjoy it) who conduct the business around Amazon ecosystem, anything from books to Amazon-own appstore.\n\nWhile Fire gets a welcoming response, controversy rises from its browser, Amazon Silk. Unlike traditional web browser, Silk can use server assistance (based on EC2, another Amazon infrastructure) to speed up the browser experience. Though this can be turned off, the sensitive term of proxy already triggers some privacy concerns.\n\nExpect this Tuesday to be another less-productive day. All attention would be given to Apple’s event, where the rumored two versions of iPhone will be finally revealed to the world, quite likely without the presence of Steve Jobs.\n\nFor most fans, durian is fantastic when it is served cold. Just like a revenge.\n\n(`_|_`)Oct 2, 2011(`_|_`)ariya.io(`_|_`)typical-ofi-40', 'typical-ofi-40'),
(257, 'water lily(`_|_`)\n\n\nBy Kazuyanagae (Own work), CC-BY-SA-3.0, via Wikimedia Commons\n\nLast Friday was an equinox. It also happened to be the scheduled release date for the latest version 1.3 of PhantomJS, the scriptable headless WebKit. Its code repository has been tagged so that you can build it from source. Alternatively, just use the source packages. Expect binary packages for major operating systems to catch up and become available in few days or weeks.\n\nFor a complete and detailed info of the new features and other changes in this version, I refer you to the official release notes. Most of you are probably excited with the filesystem module, originally championed by James and Ivan. This module has a lot of functions to deal with files and directories, modelled after CommonJS Filesystem proposal. Included in the examples folder is a short script demonstrating the API:\n\n// List all the files in a directory\n \nif (phantom.args.length !== 1) {\n    console.log(\"Usage: phantomjs scandir.js DIRECTORY_TO_SCAN\");\n    phantom.exit();\n}\n \nvar scanDirectory = function (path) {\n    var fs = require(\'fs\');\n    if (fs.exists(path) && fs.isFile(path)) {\n        console.log(path);\n    } else if (fs.isDirectory(path)) {\n        fs.list(path).forEach(function (e) {\n            if ( e !== \".\" && e !== \"..\" ) {\n                scanDirectory(path + \'/\' + e);\n            }\n        });\n    }\n};\nscanDirectory(phantom.args[]);\nphantom.exit();\n\n\nMy other favorite new weird feature is the callback for page initialization. It is triggered after the web page is created but right before any client code in the loaded URL is executed. This has a nice side effect: you can hijack and tweak the global objects that the web page will see. For example, this short code fragment effectively modifies the behavior of Math.random() to do something completely different:\n\npage.onInitialized = function() {\n    Math.random = function() {\n        return 0.42; // one-hundredth of \"The Answer\"\n    };\n};\n\n\nI’m confident there are other useful tricks you can achieve by employing this initialization callback.\n\nThere are also other nice new goodies as well as minor bug fixes which may be of interest to you. Again, details can be read in the release notes.\n\nSince the previous release, there have been more coverage of PhantomJS in various blogs. If you are curious to see the different use cases, have a look at the compiled list of those external articles. The number of related software projects and organizations which is known to use PhantomJS is also increasing rapidly.\n\nThis third minor update Water Lily follows the path of the previous two, Birds of Paradise and Cherry Blossom (there are of course the stories why the names are chosen that way). As for the future, the plan should reveal itself in the coming weeks. Expect a delightful beauty to pave the way for PhantomJS 1.4!\n\n(`_|_`)Sep 26, 2011(`_|_`)ariya.io(`_|_`)water-lily', 'water-lily'),
(258, 'hybrid native+web: interactive folder visualizer(`_|_`)\nTime for another example of mixing web technologies inside a native application (as I promised before). As usual, we start with a screenshot:\n\n\n\n(Since we always want to be cross-platform, Windows and Mac OS X users need not worry as this example will work exactly the same there, it would just look slightly different)\n\nThis is basically a tool, given a directory in the file system, to crawl and produce an interactive treemap showing the allocated size for files and subdirectories. The entire code is available in the usual X2 git repo (or the alternative repo), look under webkit/foldervis (you need Qt 4.6 or later versions). Keep in mind that the visualization is interactive. When you click on a certain block, it will expand (with some nice animation) and show what is underneath that block.\n\nFor the interface, we use the excellent webtreemap component from Evan Martin (try the live demo). It’s a treemap implementation using DOM, CSS, and JavaScript. Other treemap implementations exist, check for example Nicolas’ Canvas-based treemap demo based on his InfoVis toolkit.\n\nThe crawling process itself is carried out in a simple Qt-based class. Let’s have a look at this native world. First of all, we need a simple structure to hold the crawling result:\n\nstruct Entry {\n    QString name;\n    int size;\n    QList<entry> children;\n};\n</entry>\n\n\nAnd then let’s declare a class of the crawler implementation, conveniently called Crawler. The reason why it is a QObject (with some signals and slots) will be obvious soon:\n\nclass Crawler: public QObject\n{\n    Q_OBJECT\n    Q_PROPERTY(QString tree READ tree)\n \npublic:\n    Crawler(QObject *parent);\n    QString tree() const;\n \npublic slots:\n    void start(const QString &dir);\n \nsignals:\n    void progress(int count);\n    void finished();\n \nprivate:\n    QString m_dir;\n    int m_count;\n    Entry m_rootEntry;\n \nprotected:\n    Entry search(const QString &dir);\n};\n\n\nCrawling is triggered by calling its start() function, passing the name of the directory to be crawled. Surprisingly, the implementation of this function is really simple since it passes the flow to the search() function which does the actual heavy-duty crawling.\n\nvoid Crawler::start(const QString &dir)\n{\n    m_dir = dir;\n    m_count = ;\n    m_rootEntry = search(m_dir);\n    emit finished();\n}\n\n\nSince we want to traverse to all the subdirectories, this is a recursive process:\n\nEntry Crawler::search(const QString &path)\n{\n    QList<entry> children;\n \n    int total = ;\n \n    m_count++;\n    emit progress(m_count);\n    QApplication::processEvents();\n \n    QFileInfoList list = QDir(path).entryInfoList();\n    for (int i = ; i < list.count(); ++i) {\n        Entry entry;\n        QFileInfo fi = list.at(i);\n        if (fi.fileName() == \".\" || fi.fileName() == \"..\")\n            continue;\n        if (fi.isDir() && fi.baseName() != \".\") {\n            entry = search(fi.absoluteFilePath());\n        } else {\n            entry.name = fi.fileName();\n            entry.size = fi.size();\n        }\n        total += entry.size;\n        children.append(entry);\n    }\n \n    Entry entry;\n    entry.name = QFileInfo(path).fileName();\n    entry.children = children;\n    entry.size = total;\n \n    return entry;\n}\n\n\nIf you are familiar with Qt, nothing is mysterious about the above implementation. Note also that before processing every directory, we trigger the progress signal. We will find out soon how we can use that.\n\nAn important point I would like to make is the use of processEvents(). Since this is supposed to be an example, we keep the code as simple as possible, without the use of thread and synchronization and other similar magic. Thus, the call to processEvents is necessary to allow Qt main event loop to process all the events, including firing signals and invoking the corresponding slots.\n\nSo up till now, we are basically in the native side of the application. The web side is about the webtreemap component. We run this conveniently inside our own subclass of QWebView:\n\nclass Visualizer: public QWebView\n{\n    Q_OBJECT\n \npublic:\n    Visualizer(const QString &dir);\n \nprivate slots:\n    void setup();\n \nprivate:\n    QString m_dir;\n    Crawler *m_crawler;\n};\n\n\nwhich has the following setup:\n\nVisualizer::Visualizer(const QString &dir)\n    : QWebView()\n    , m_dir(dir)\n    , m_crawler(new Crawler(this))\n{\n    setFixedSize(600, 600);\n    frame->setScrollBarPolicy(Qt::Horizontal, Qt::ScrollBarAlwaysOff);\n    frame->setScrollBarPolicy(Qt::Vertical, Qt::ScrollBarAlwaysOff);\n \n    load(QUrl(\"qrc:/index.html\"));\n \n    QWebFrame *frame = page()->mainFrame();\n    frame->addToJavaScriptWindowObject(\"crawler\", m_crawler);\n \n    QFile file(\":/bootstrap.js\");\n    file.open(QFile::ReadOnly);\n    QString bootstrap = file.readAll();\n    file.close();\n    page()->mainFrame()->evaluateJavaScript(bootstrap);\n \n    QTimer::singleShot(250, this, SLOT(setup()));\n}\n\n\nLet’s analyze what happens there. First of all, for simplicity we set a fixed window size and therefore we can get away with no scrollbar at all. We also load the main HTML file which embeds webtreemap, right from the resource by using Qt’s compact resource system. Like in the previous CodeMirror demo, this eases the deployment since everything is packaged right with the executable.\n\nThis example’s resource contains the following files:\n\nindex.html\nwebtreemap.js\nbootstrap.js\n\n\nWe need webtreemap.js for the webtreemap implementation and the main index.html to be loaded right into the QWebView (or rather, our own subclass). The purpose of bootstrap.js is clear if we look at the contents:\n\ncrawler.progress.connect(function(count) {\n    document.getElementById(\'progress\').textContent = \'Crawling \' + count +\n        \' directories...\';\n});\n \ncrawler.finished.connect(function() {\n    document.getElementById(\'progress\').style.display = \'none\';\n    appendTreemap(document.getElementById(\'map\'), JSON.parse(crawler.tree));\n});\n\n\nThe first part connects the signal named progress from an object called crawler to the implemented function, which basically just updates the text of an element in the web page, serving as a nice feedback to the user that the crawling is still on going (in particular, if the folder contains thousands of files). If you recall Visualizer constructor, there is a line which calls QWebFrame’s addToJavaScriptWindowObject() with an instance of the Crawler class, thereby adding a new object to the web page. When that object’s progress is emitted (from the native C++ side), the given JavaScript function (in the web world) is invoked. This demonstrates the signal-slot connection from a native QObject to the other side of the bridge.\n\nThe same thing happens with the other signal, finished(), which got emitted when the crawler is completed. This time, we need to supply our webtreemap widget the data. crawler.tree actually comes from a property named tree of that Crawler class again. What it contains is the JSON formatted (in string) data of the entire directory tree which also holds the size of each entry.\n\nSurprisingly, that’s all the bridging you need!\n\nAll in all, the native part is pretty thin (sloccount gives around 150 lines), mostly the code to crawl the file system. By leveraging DOM-based webtreemap, in a short time we wrap the result in a nice and interactive visualization.\n\nWeb technologies are nice, aren’t they?\n\n(`_|_`)Sep 22, 2011(`_|_`)ariya.io(`_|_`)hybrid-nativeweb-interactive-folder-visualizer', 'hybrid-nativeweb-interactive-folder-visualizer'),
(259, 'one week to elements(`_|_`)\n\n\nNext week, Intel will host AppUp Elements in Bellevue, WA. There will be a lot of presentations covering AppUp introduction, technologies you can use to build your apps, and finally how to leverage the market and become successful on the business side.\n\nLike it was mentioned before, I myself will be there and scheduled to ramble about the use of web technologies to design, build, and deploy your applications. Of course, I plan to insert some myth busting as well, there is a lot of widespread confusion and misconception what web technologies can and can’t do.\n\nWith Intel new commitment to HTML5 and its related technologies, you don’t want miss a lot of web-related jam-packed discussions and panels at Elements!\n\nSee you there.\n\n(`_|_`)Sep 21, 2011(`_|_`)ariya.io(`_|_`)one-week-to-elements', 'one-week-to-elements'),
(260, 'a short date with anna and charlie (seven)(`_|_`)\n\n\nI spent some time with Symbian-powered Nokia C7. This is a collection of random notes once the date is over.\n\nA quick summary on the hardware. The phone itself is looking really good (but beware, beauty is in the eye of the beholder). Both the stainless body and the shiny glass display boost its cool factor. I feel confident holding it in my hand, it is certainly a different feeling to the Nexus S I’ve used for many many months. The moderate resolution of 640 × 360 pixels does not really compete with iPhone 4’s retina display, this is compensated nicely with the sharp and vivid AMOLED touch screen.\n\nOn the inside, it packs the standard goodies of modern smartphones: 8 megapixels rear-camera, VGA front-camera, Bluetooth, MicroUSB, 8 GB internal flash, MicroSD slot, WiFi, GPS, and a final nice touch: NFC. The processor is however underpowered: “just” 680 MHz ARM11. This is a far cry from the de-facto standard of dual-core SoC found in high-end phones these days. This lack of power would be evident as soon as you launch and use some applications.\n\nSpeaking about the software, by default it is shipped with Symbian^3 though it gets updated to Symbian Anna few weeks ago.\n\nSince my life evolves around e-mail, web browsing, and social network, that’s the first thing I tried to setup with C7. First of course, OTA (over-the-air) update, which does the job without any hiccup. Mail for Exchange works flawlessly, in just few minutes (surprisingly) I got my Google Mail, Contacts, and Calendar synchronized, all out of the box. For Twitter and Facebook, Nokia’s own Social application is not the most-performant application, but it is definitely usable enough for most people. On the other hand, the official Foursquare application and LinkedIn are hassle-free to install and to use.\n\nComing from Android, the lack of scrollable list of application icons requires some strategy to work around. Rather than using a third-party home screen app, I decide to dedicate two screens full of Shortcut widgets. Since each of this widget can contain 4 shortcuts, now every screen can host 24 icons. Two of them are more than sufficient for all the apps I’ve  tested.\n\nFor media usage, C7’s camera produces high-quality pictures and videos. It definitely shows that Nokia is still strong in this respect. However, being spoiled with the excellent photos taken from Nokia N8, I will still vouch for N8 if I am about to pick a replacement for a pocket camera. Music player is rather basic but it does the job. Testing Bluetooth streaming to my car audio, I can say that it has no problem. As usual, Nokia includes FM Radio and Transmitter feature, handy in some cases. A bunch of little apps to watch assorted online videos are not too disappointing as well.\n\nNow onto some annoyances.\n\nThe biggest problem I have is the on-screen virtual keypad. In the landscape mode, somehow the keypad is less usable for me unless I use Swype (which works great). What about portrait mode? No QWERTY, which is a showstopper. Fortunately, the firmware update Symbian Anna fixes that. Anna’s portrait QWERTY is pretty decent, it works surprisingly well given the screen estate.\n\nOvi Store, supposed to be the central point for app discovery and management, is still miles behind the competitor. For a start, the application itself is implemented in such a way that there is a noticeable delay/lag for every operation. Being a developer myself, I can’t stop asking why a certain strategies (like caching, just to mention one) are not in place. Sliding back and forth between different views is far from smooth, seems that the app just recreates the views every single time there is a navigation action. Combine with the lack of CPU power, you can witness the layout process and how the pixels fly here and there!\n\nThe browser has been and is (sadly) still a pain point. Fortunately, the brand-new browser in Symbian Anna kind of improves it. The updated browser still does not perform as fast as the competitor, getting SunSpider to run only 8.8 seconds. If we care only about DOM performance, Dromaeo DOM tests get 63 runs/s, which is the low end of various smartphones (see my previous blog post on smartphones web performance to get the full chart).\n\nHaving said that, the difference between Symbian browser and Harmattan browser in N9 (or N950) is still day and night. After a day using the built-in browser, I finally gave up and did what most Nokia users do: install Opera Mobile. Consider how good Harmattan browser is, I still have a faint hope that someday Nokia will bring the same technology and innovation to Symbian.\n\nApparently, Nokia Social app does not work if there is no SIM card active for the phone. This is quite mysterious, I would speculate that it has something to do with the legal ramification of using certain functionalities depending on the geographic location. The workaround is simple, just use any other apps. The famous Gravity is stellar, had I decided to stay with C7 for a longer time I don’t mind to shell out ten bucks for that.\n\nOvi Maps comes a long way since the last time I tried it (years ago). I still don’t put my faith 100% on it but it does a decent job at giving the navigation information. For some reason, the GPS system is only slightly faster than the old Nokia X6 or even Nokia N8. Lane-assist feature is also really helpful. Combined with turn-by-turn navigation and offline support, these features are fantastic for the price you pay ($0, aka free).\n\nBecause Symbian is not the #1 target for developers, there are tons of applications not available on this platform. I am disconnected from some services like Google Books, Yelp, Google Voice, Meetup, Google Plus etc since there is no official Symbian version of these applications yet. The typical workaround is usually by leveraging third-party applications or connectors, which sadly have a varying degree of quality.\n\nHow to get C7? In the US, C7 is better known as Nokia Astound sold via T-Mobile. At the time of this writing, it is available for the subsidized price of $50, with 2-year contract. Without the contract, you can get it (depending on assorted deals) for as low as $250 on various on-line shops. This is unlocked and perfect for prepaid customer.\n\nWhat’s the conclusion? I believe C7 is not suitable for tech junkies. If you are eager to try all different applications in iPhone App Store or Android Marketplace, this one is definitely not for you. Road warriors will be frustrated with the sluggish applications and lack of comprehensive business tools. Hardcore gamers would find that the selection of games (if they run at a decent speed at all) is not as crazy as other competing platforms.\n\nI reckon Nokia markets C7 for the first-time or casual smartphone users, those who stay connected occasionally, use Twitter or Facebook once a while, read and write email few times a day, check out some news on the web, take and share pictures. For this particular segment, the price and the features hit a nice sweet spot for the temptation.\n\n(`_|_`)Sep 20, 2011(`_|_`)ariya.io(`_|_`)a-short-date-with-anna-and-charlie-seven', 'a-short-date-with-anna-and-charlie-seven');
INSERT INTO `ariyaio` (`id`, `content`, `url`) VALUES
(261, 'hybrid web+native: desktop codemirror(`_|_`)\nHere is another proof that Qt is not as ubiqutious as I would like it to be. When I ask around what developers use to develop desktop apps using web technologies (HTML, JavaScript, CSS), the choice is either Adobe AIR or Titanium Desktop. Seems that a lot of people overlook Qt and its built-in WebKit integration.\n\nRather than ranting, I will start a bunch of blog posts which shows how to bring rich web apps into the desktop. This will be the first now. For branding purposes, we will call it hybrid approach because this literally brings web technologies and native solution in the same plate.\n\nI have talked about this hybrid stuff before at MeeGo Conf 2011 (see the video) and will do it again for Intel Elements 2011. However, for that matter, I think blog posts still serve as a better written reference. It also gives me a chance to clarify some prejudices, confusions, and myths that some people still have about web technologies.\n\nFor this post, I’ll show you how to implement something like this screenshot:\n\n\n\nIt’s a code editor (supporting JavaScript mode) based on CodeMirror, an excellent web-based editing widget written using JavaScript and DOM. There are other similar projects out there, for this example I found out that CodeMirror is the easiest to work with. Note that we will use CodeMirror2, a complete rewrite which is way better and faster than the old version of CodeMirror.\n\nThe entire code is available in the usual X2 git repo (or the alternative repo), look under webkit/codemirror (you need Qt 4.6 or later versions). It essentially contains of two major classes, Editor which is the main window representing the application and CodeMirror which is the wrapper around CodeMirror’s JavaScript implementation. The latter is just a subclass of QWebView where we host CodeMirror actual logic.\n\nBecause we do not want to run CodeMirror from the file system and we want the editor to work even without Internet connection, we use the technique of storing all the necessary content in the resource system provided by Qt. This is what assets.qrc all about, i.e. as a central location to find the following:\n\nindex.html\ncodemirror.js\ncodemirror.css\njavascript.js\ndefault.css\ncobalt.css\nelegant.css\nneat.css\nnight.css\n\n\nMany still mistakenly believe that using web technologies means that the app requires constant network connection. This is not necessarily anymore with the said packaging approach. It is important to note that now we can access any of the files stored inside the resource using the special qrc scheme. This is exactly what the constructor is doing, i.e. loading qrc:/index.html right into the web view:\n\nCodeMirror::CodeMirror(QWidget *parent)\n    : QWebView(parent)\n{\n    load(QUrl(\"qrc:/index.html\"));\n    changeTheme(\"default\");\n \n    m_external = new External(this);\n    page()->mainFrame()->addToJavaScriptWindowObject(\"External\", m_external);\n}\n\n\nThe main application class, Editor, has all the important code to setup native menu (we have three main menu items: File, Edit, Theme) and file dialog if the user opens a new file or save the text. Of course, when we save to a file, we need to get the text out of our hosted CodeMirror and write it using QFile. This is where we work with bridging the two different worlds: native and web. There is a whole section about QtWebKit bridge in the Qt documentation.\n\nLooking at index.html, you would find that the CodeMirror’s editor object is created as (surprise!) editor. Thus, in order to get the content we have to call editor.getValue (see CodeMirror manual for the details), hence effectively transferring the data from the web world to the native world:\n\nQString CodeMirror::text() const\n{\n    return page()->mainFrame()->evaluateJavaScript(\"editor.getValue()\").toString();\n}\n\n\nWhat about the other way around? We could simply evaluate a JavaScript code that sets the editor’s value, e.g. editor.setValue(content). Rather than passing content as a string (and thus we need to escape it properly), let’s use another nice feature of QtWebKit bridge: built-in integration with QObject. We setup a simple QObject subclass called as External whose purpose is only to hold a string property:\n\nclass External: public QObject\n{\n    Q_OBJECT\n    Q_PROPERTY(QString data READ data)\n \npublic:\n    External(QObject *parent = ): QObject(parent) {}\n \n    QString text;\n    QString data() const { return text; }\n};\n\n\nAn instance of this class is inserted into our web page during the construction of CodeMirror class (see the previous code fragment), under the name External. From now on, anytime in the web world we call window.External.data, we would get the same exact value as what we put into the data property of our instance. It is doing what we want to do: transferring the data from the native world to the web world.\n\nThis seems to be complicated but check out at how simple the function finally looks like:\n\nvoid CodeMirror::setText(const QString &text)\n{\n    m_external->text = text;\n    page()->mainFrame()->evaluateJavaScript(\"editor.setValue(External.data)\");\n}\n\n\nArguably, the special function evaluateJavaScript is really critical to this hybrid approach! In addition to assist the bridging, it is also useful to trigger some action in the web world from the native world:\n\nvoid CodeMirror::undo()\n{\n    page()->mainFrame()->evaluateJavaScript(\"editor.undo()\");\n}\n \nvoid CodeMirror::redo()\n{\n    page()->mainFrame()->evaluateJavaScript(\"editor.redo()\");\n}\n\n\nThis function is also necessary for the theming support. All the styles needed for the different themes are available from the resource (the last few CSS files in the previous list), but we need to activate it (bonus exercise, why the last line dealing with class name is necessary?):\n\nvoid CodeMirror::changeTheme(const QString &theme)\n{\n    QWebFrame *frame = page()->mainFrame();\n    frame->evaluateJavaScript(QString(\"editor.setOption(\'theme\', \'%1\')\").arg(theme));\n    frame->evaluateJavaScript(QString(\"document.body.className = \'cm-s-%1\'\").arg(theme));\n}\n\n\nOf course, since we use Qt, the same editor example runs beautifully on other platforms (also here showing different color schemes available for CodeMirror):\n\n \n\nWith a pretty thin wrapper (sloccount gives around 250 lines), we bring CodeMirror to the desktop and build a simple editor around it, with menu, file, editing, and theme support. Of course, credits should go to the brave WebKit team, Qt folks, and CodeMirror developers, whose hard work is leveraged in this demo.\n\nObviously, being an example, this hybrid editor still lacks a lot of standard features and hence can’t be really used as a killer application. However, if someone wants to pursue the path of productized hybrid app, don’t hesitate to use it as a starting basis.\n\nThis short demo highlights just two points. First, we can package the web content using the resource system, thus it does not need to reside as individual files on the disk or even a remote server. Second, transferring the data between the web world and the native world is possible by leveraging the bridge provided by QtWebKit.\n\nIn the coming installments, hopefully we can explore more about the bridging mechanism. Of course, feel free to propose a specific topic or concern that you want me to tackle first!\n\n(`_|_`)Sep 6, 2011(`_|_`)ariya.io(`_|_`)hybrid-webnative-desktop-codemirror', 'hybrid-webnative-desktop-codemirror'),
(262, 'tropical orchid(`_|_`)\n\n\n\nAccording to The Green Book:\n\n\n..if every U.S. household replaced a bottle of body wash with a bar of soap, roughly\n\n2.5 million pounds of plastic containers could be diverted from the waste stream.\n\n\nJust saying.\n\n(`_|_`)Sep 2, 2011(`_|_`)ariya.io(`_|_`)tropical-orchid', 'tropical-orchid'),
(263, 'countdown to the elements(`_|_`)\n\n\nIn few weeks, I am scheduled to talk at Intel AppUp(SM) Elements 2011 in Seattle (or rather more precisely, in Bellevue). My presentation would be about hybrid applications (native + web) using QtWebKit. The short abstract is as follows:\n\n\nAn army of web technologies in the HTML5 family, namely CSS3, JavaScript, and SVG, can dramatically improve the application development workflow. Along with its momentum, there are hundreds of rich frameworks and timesaving libraries that speed up the development cycle. When packaged with a web run-time such as QtWebKit*, which combines powerful WebKit features with the ease of use of Qt*, this set of technologies enables fast prototyping and easy deployment of even the most demanding applications. Learn the strategies, tools, and best practices in developing and testing good-looking, feature-rich, and hardware-accelerated applications using web technologies targeting Windows* and MeeGo*.\n\n\nFor more tracks related to web technologies, check out Kira’s blog post on Will HTML5 steal the show?\n\nIf you are around Bellevue and want to meet a bunch of us, shout out!\n\n(`_|_`)Sep 1, 2011(`_|_`)ariya.io(`_|_`)countdown-to-the-elements', 'countdown-to-the-elements'),
(264, 'Eid Mubarak(`_|_`)\nHappy Eid to all!\n\n(`_|_`)Aug 30, 2011(`_|_`)ariya.io(`_|_`)eid-mubarak-5', 'eid-mubarak-5'),
(265, 'expression evaluator in javascript: part 3 (interpreter)(`_|_`)\nThis is the final part of my weekly series on how to write a math expression evaluator in JavaScript. If you haven’t do so, it is recommended that you read the first part (on lexical analysis) and second part (on parsing and syntax tree) before digesting this blog post.\n\nNote: If you want a different take on this subject, have a look at Dmitry’s Essentials of Interpretation.\n\nFirst, let me show you again an exemplary syntax tree:\n\n\n\nIf you are about to compute the expression represented by the above syntax tree, it is actually as easy as walking through every node in the tree (depth-first traversal) while doing a certain operation associated with the node. For a binary operator, it means we just need to add (or substract or multiply or divide) the two values obtained from each child node. This is basically the so-called abstract syntax tree interpreter because we interpret the operation represented by each syntax node.\n\nBefore we move on, let’s see first the JSON version of the syntax tree depicted in the above picture:\n\n{\n    \"Expression\": {\n        \"Assignment\": {\n            \"name\": {\n                \"Identifier\": \"x\"\n            },\n            \"value\": {\n                \"Binary\": {\n                    \"operator\": \"*\",\n                    \"left\": {\n                        \"Unary\": {\n                            \"operator\": \"-\",\n                            \"expression\": {\n                                \"Number\": \"6\"\n                            }\n                        }\n                    },\n                    \"right\": {\n                        \"Number\": \"7\"\n                    }\n                }\n            }\n        }\n    }\n}\n\n\nThe code to interpret this JSON-formatted tree is quite straightforward. Let’s start from the leaf, such as a number (we assume from here onwards that node points to the current node we need to evaluate):\n\nif (node.hasOwnProperty(\'Number\')) {\n    return parseFloat(node.Number);\n}\n\n\nFor a unary operation node, we need to evaluate the child node first and then apply the unary operation, either + or -:\n\nif (node.hasOwnProperty(\'Unary\')) {\n    node = node.Unary;\n    expr = exec(node.expression);\n    switch (node.operator) {\n    case \'+\':\n        return expr;\n    case \'-\':\n        return -expr;\n    default:\n        throw new SyntaxError(\'Unknown operator \' + node.operator);\n    }\n}\n\n\nBinary node is handled similarly, we just need to process both child nodes for the left and right side of the operator:\n\nif (node.hasOwnProperty(\'Binary\')) {\n    node = node.Binary;\n    left = exec(node.left);\n    right = exec(node.right);\n    switch (node.operator) {\n    case \'+\':\n        return left + right;\n    case \'-\':\n        return left - right;\n    case \'*\':\n        return left * right;\n    case \'/\':\n        return left / right;\n    default:\n        throw new SyntaxError(\'Unknown operator \' + node.operator);\n    }\n}\n\n\nBefore we continue to tackle variable assignment, let’s take a step back and see the concept of evaluation context. For this purpose, we define the context as an object that holds the variables, constants, and function definitions. When we evaluate an expression, we also need to pass a context so that the evaluator knows where to fetch the value of a variable, store a value to a variable, and invoke a certain function. Keeping the context as a different object promotes the separation of logic: the interpreter knows nothing about the context and the context does not really care how the interpreter works.\n\nIn our evaluator, the simplest possible context is:\n\ncontext = {\n    Constants: {},\n    Functions: {},\n    Variables: {}\n}\n\n\nA slightly more useful context (and thus can be used as a default one):\n\ncontext = {\n \n    Constants: {\n        pi: 3.1415926535897932384,\n        phi: 1.6180339887498948482\n    },\n \n    Functions: {\n        abs: Math.abs,\n        acos: Math.acos,\n        asin: Math.asin,\n        atan: Math.atan,\n        ceil: Math.ceil,\n        cos: Math.cos,\n        exp: Math.exp,\n        floor: Math.floor,\n        ln: Math.ln,\n        random: Math.random,\n        sin: Math.sin,\n        sqrt: Math.sqrt,\n        tan: Math.tan\n    },\n \n    Variables: {}\n}\n\n\nWe still do not have any variables (because the context is freshly created), but there are two common constants ready to use. The difference between a constant and a variable in this example is very simple and obvious: you can not change a constant or create a new one, you can do both with a variable.\n\nWith the context and its variables and constants ready, now we can handle identifier lookup (e.g. in an expression like x + 2):\n\nif (node.hasOwnProperty(\'Identifier\')) {\n    if (context.Constants.hasOwnProperty(node.Identifier)) {\n        return context.Constants[node.Identifier];\n    }\n    if (context.Variables.hasOwnProperty(node.Identifier)) {\n        return context.Variables[node.Identifier];\n    }\n    throw new SyntaxError(\'Unknown identifier\');\n}\n\n\nAssignment (like x = 3) works the other way around, though we have to ensure that we only process variable assignment and not constant override:\n\nif (node.hasOwnProperty(\'Assignment\')) {\n    right = exec(node.Assignment.value);\n    context.Variables[node.Assignment.name.Identifier] = right;\n    return right;\n}\n\n\nFinally, the remaining function node is handled as follows. Basically the function arguments (if any) are prepared in an array and then passed to the actual function. Note that in our default context, we simply wire a bunch of functions to the methods of the built-in Math object.\n\nif (node.hasOwnProperty(\'FunctionCall\')) {\n    expr = node.FunctionCall;\n    if (context.Functions.hasOwnProperty(expr.name)) {\n        args = [];\n        for (i = ; i < expr.args.length; i += 1) {\n            args.push(exec(expr.args[i]));\n        }\n        return context.Functions[expr.name].apply(null, args);\n    }\n    throw new SyntaxError(\'Unknown function \' + expr.name);\n}\n\n\nWhat if we want to have a custom function, maybe because it is not supported by the Math object? It can not be easier than defining the function for the context. As an example, let’s implement sum which adds all the number passed in the argument. Since we deal with a function which may have a variable number of arguments, we use special arguments object instead of named parameters:\n\ncontext.Functions.sum = function () {\n    var i, total = ;\n    for (i = ; i < arguments.length; i += 1) {\n        total += arguments[i];\n    }\n    return total;\n}\n\n\nDead easy, isn’t it?\n\nAs with the previous parts, what presented above are various code fragment only, the full working code is available from my TapDigit project. Don’t be scared, the complete implementation of the evaluator is not even 100 lines.\n\nFinally, for the demo, visit tapdigit.googlecode.com/git/eval.htm with your favorite browser, smartphones, or tablets.\n\nAnd that is the end of our adventure! Of course I only cover the basics so far, hopefully now you have a foundation to go and explore the wonderful world of bytecode interpretation, code transpiling, and many more. Don’t forget to have some fun**!\n\n\n  \n\n\n\n  \n\n\n\n\n(`_|_`)Aug 29, 2011(`_|_`)ariya.io(`_|_`)math-expression-evaluator-in-javascript-part-3', 'math-expression-evaluator-in-javascript-part-3'),
(266, 'hall of api shame: boolean trap(`_|_`)\n\n\nUpdate: Read also the approach to detect Boolean traps (in JavaScript apps) using a simple script.\n\nThe nice thing working for Trolltech was (among others) learning the principles behind the good API. The article Designing Qt-Style C++ API from Matthias 6 years ago is still a good reading till today. The content itself is now expanded into the wiki page API Design Principles.\n\nThe major premise behind a good API is rather straightforward:\n\n\nthe code is usually written once but read many times.\n\n\nWhen writing the code, the developer has the time she needs to look at the API documentation and digest it. When someone else reads the code (for review or bug fix), she may not always have the API documentation handy. While this is just common sense, wait until you finish reading and see why this important fact is still overlooked these days.\n\nNote: Qt is in C++, but surprisingly the same API design principles apply to the (wonderful) world of JavaScript, which is the focus in this blog post.\n\n\n\nGeorge Boole, inventor of the Boolean logic.\n\nFor this particular discussion, I’ll pick my favorite API design mistake: boolean trap. On this topic, the above API Design Principle wiki page says that\n\n\nit’s almost invariably a mistake to add a bool parameter to an existing function\n\n\nLet’s start with the textbook example: guess what this code means?\n\nwidget.repaint(false);\n\n\nWithout looking at the documentation, the usual suspect is don’t repaint the widget. Then, you look at the documentation and it refers the function argument as immediate, which is true if you want immediate painting or false for deferred painting. Thus, the correct behavior implied by the above code is actually repaint this widget later, which is miles away from your initial guess.\n\nOne possible solution to this problem is to use explicit function argument. In the C++ world, this can be solved using enum, e.g. widget.repaint(WidgetClass::Deferred). In the JavaScript world, the alternative is using an object literal such as,\n\nwidget.repaint({ immediate: false });\n\n\nor the more verbose variant:\n\nwidget.repaint({ mode: \"immediate\" });\n\n\nor just create a different function for that purpose:\n\nwidget.repaintLater();\n\n\nThere will be a concern of performance since an object is more expensive than just a simple boolean literal. Thus, profile your code carefully and set a sensible compromise if this above line is in your hot path. On the other hand, I also do believe that modern future JavaScript engines would be smart enough to optimize such usages that the speed penalty is negligible.\n\nAnother classic is the confusion during construction. Your user interface needs a bunch of sliders to allow the user to choose some values. Here is one line in the code for you to review:\n\nvar opacitySlider = new Slider(true);\n\n\nMysteriously, there are also lines similar to:\n\nvar volumeSlider = new Slider(false);\n\n\nIt turns out that true there means a horizontal slider and false means a vertical slider. Of course, the easiest way to clear this confusion is to actually name the object HorizontalSlider and VerticalSlider and get rid of the boolean argument. Heck, who knows someday you’ll need a diagonal slider!\n\nYou may scream, “Of course, I won’t be too idiot to make those rookie mistakes!”. Well, in the following paragraphs I’ll give examples of actual boolean traps in the API of several well-known JavaScript libraries and frameworks out there (I try to be unbiased). Consider that there are millions of developers using the libraries in real-world web applications, imagine the exposure of the traps.\n\nFor each of this case, imagine you are doing a code review. Your amazing coworker wants to commit a patch and he consults you to check your opinion.\n\nto be or not to be\n\nThis is the same as the textbook example, but coming from a real framework:\n\nstackView.updateHeight(false);\n\n\nYes, that false again refers to immediate or not. To the untrained developer, the above line feels like don’t update the height. A real crazy one might even stretch it to update the width!\n\nHere is another one. To facilitate easy iteration of child widgets, you can use next() function which would get you the next sibling. But then, the code looks like:\n\nwidget.next(true);\n\n\nwhich actually does the extra magic (because of the true value) that the very first child widget will be returned if you hit the last one. In other words, true there stands for circular. An innocent value which does too much behind your back. Well, good luck trying to review that kind of code.\n\nAnother dangerous venture:\n\nwidget.destroy(false);\n\n\nwhich potentially leads you to think don’t destroy this widget. You can’t be more wrong, the function actually still destroys your widget, but it leaves the DOM associated with the widget intact. Only if the argument is true then actually every related DOM pieces is also tore torn down.\n\noptionally undecipherable\n\nNow that we have the slider for the UI, we need to preset the value:\n\nvolumeSlider.setValue(90, false);\n\n\nAnother boolean horror! The documentation reveals that false there indicates that the slider should not animate the movement of its indicator from the old value to the new value. By default, it will show the animation but since we want to set the initial value, the animation will be distracting and needs to be off. How about writing it like this instead?\n\nvolumeSlider.setValue(90, { animation: false } );\n\n\nThere is this list view of all your customers. We want to find out who live in a certain city. Can you guess what the last optional argument refers to?\n\ncustomerView.filter(\'address\', \'sunnyvale\', false);\n\n\nOh, apparently the API documentation refers it to caseSensitive! Just by looking at it, this is not obvious and it could mean an entirely different thing, anything from exactMatch to highlightMatchedLine. One possible workaround:\n\ncustomerView.filter(\'address\', \'sunnyvale\', { caseSensitive: false });\n\n\nthe more, the merrier\n\nWhile one boolean argument is already confusing, two boolean arguments can’t be more fun.\n\nTo handle layout, often there is a line of code that looks like:\n\ncmp.setCentered(true, false);\n\n\nAgain, a trip to the API doc enlightens the reviewer that the function signature is actually setCentered(centered, autoUpdate). This is confusing as setCentered(centered) only is probably fine, it’s just like a property setter, but the interplay of the autoUpdate argument forces the brain to think harder.\n\nNote that a pair of values like that, especially in the context of centering/geometry purpose, might provoke a different interpretation: center vertically and horizontally. This is arguably the most sensible one which comes to mind if one sees that code.\n\nHere is another one:\n\nmenu.stop(true, false);\n\n\nThe boolean values there refer to clear the animation queue or not and go to the animation or not, respectively. They are not even remotely related. What is your best educated guess if you did not know this beforehand?\n\nOf course, why stop at two if you can have more?\n\nevent.initKeyEvent(\"keypress\", true, true, null, null,\n    false, false, false, false, 9, );\n\n\ndouble negative\n\nNow, coming back to property setter, this is one valid use of boolean argument, e.g. dialogBox.setVisible(true). However, care must be taken so that there is no such double negative. Especially for non-native speakers, double negative requires an extra careful measure to make sure that the right meaning is communicated.\n\nIf I wake you at midnight and ask you this question “if invisible is false, does that mean my component is shown or hidden?”, there is a chance you answer it incorrectly.\n\nReal-world examples of double negative follow:\n\nvolumeSlider.setThumbsDisabled(false);\ncomponent.setDisabled(false);\nfilter.setCaseInsensitive(false);\n\n\nWould you be less confused if this is what you read instead?\n\nvolumeSlider.setThumbsEnabled(true);\ncomponent.setEnabled(true);\nfilter.setCaseSensitive(true);\n\n\nThe same principle applies to active vs inactive, modified vs unmodified, defined vs undefined, selected vs unselected, etc.\n\nBy now, hopefully you got the idea of various risky uses of boolean argument. Feel free to share your favorite freak-out moment as you encounter such a similar trap.\n\nMost importantly, next time you design an API function, remember George Boole and don’t let him down!\n\nUpdate: Some people on Reddit pointed out that they would not interpret widget.repaint(false) as do not repaint. First of all, it’s subjective. In some languages it can be understood as repaint not, which is effectively a negation. Also, the context might pollute, e.g. if there is fooWidget.show(false) (which means do not show) right before, then it may influence a similar conclusion for the repaint issue. I was also not clear that any crazy possible interpretations are just examples, substitute them with your own imaginations. The fact that everyone can propose a different interpretation is the premise: ambiguity begets insanity.\n\n(`_|_`)Aug 24, 2011(`_|_`)ariya.io(`_|_`)hall-of-api-shame-boolean-trap', 'hall-of-api-shame-boolean-trap'),
(267, 'math expression evaluator in javascript: part 2 (parser)(`_|_`)\nThis is the second part of my weekly series on how to write a math expression evaluator in JavaScript. If you miss the first part, which was about lexical analysis, go and read it first and come back later.\n\nIn this installment, we will see the actual parsing process. Based on a sequence of tokens obtained from the lexer, we shall be able to match these tokens to the expression grammar which describes the syntax of the expression. At the end of the process, we want to produce a syntax tree. This entire procedure is commonly known as syntactic analysis.\n\nAn abstract syntax tree (AST) represents the syntactic structure of the expression. Consider the following expression:\n\nx = -6 * 7\n\n\nThe associated syntax tree for the above expression should look like:\n\n\n\nThe above syntax tree matches our logic if we are supposed to evaluate the expression (if we handle every node in the tree using depth-first traversal): take 6, negate it, multiply the result with 7, put the result into x. Unless you don’t pass primary school math, your brain should magically gives -42 as the answer.\n\nOf course, the question is how to create the tree given a list of tokens associated with the expression? There are multiple strategies to analyze the expression’s syntax. The one which I illustrate below is commonly known recursive descent parser. It may not be the fast one in some cases, but it is very illustrative and quite easy to trace should you want to follow the parsing logic.\n\nAgain, the following paragraphs explain and discuss various code fragment only (error checkings may be omitted). The full code is available for your pleasure from the TapDigit project.\n\nThe main entry point for the parsing looks like this. The lexer itself comes from the implementation of the lexical analyzer discussed in part 1.\n\nfunction parse(expression) {\n    var expr;\n \n    lexer.reset(expression);\n    expr = parseExpression();\n \n    return {\n        \'Expression\': expr\n    };\n}\n\n\nFrom this, we go to the main parseExpression function which is surprisingly simple. This is because our syntax only implies a variable assignment as an expression. For other languages with more elaborate control flow (branching, loop, etc) or some form of domain-specific language (DSL), assignment may not be the only form of expression.\n\nfunction parseExpression() {\n    return parseAssignment();\n}\n\n\nFor the next subsequent parseFoo variants, we need a function which can match an operator. If the incoming operator is the same as the expected one, then it returns true.\n\nfunction matchOp(token, op) {\n    return (typeof token !== \'undefined\') &&\n        token.type === T.Operator &&\n        token.value === op;\n}\n\n\nAn example form of assignment is x = 42. However, we also want to tackle the case where the expression is also as plain as 42 or a nested assignment such as x = y = 42. See if you can understand how the implementation of parseAssignment below handles all the three cases (hint: recursive is a possibility).\n\nfunction parseAssignment() {\n    var token, expr;\n \n    expr = parseAdditive();\n \n    if (typeof expr !== \'undefined\' && expr.Identifier) {\n        token = lexer.peek();\n        if (matchOp(token, \'=\')) {\n            lexer.next();\n            return {\n                \'Assignment\': {\n                    name: expr,\n                    value: parseAssignment()\n                }\n            };\n        }\n        return expr;\n    }\n \n    return expr;\n}\n\n\nThe function parseAdditive processes both addition and subtraction, i.e. it creates a binary operator node. There will be two child nodes, the left and the right ones. They represent the two subexpression, further handled by parseMultiplicative, to be added or subtracted. Update: the previous version of the function was copied from a wrong implementation, this has been fixed since.\n\nfunction parseAdditive() {\n    var expr, token;\n \n    expr = parseMultiplicative();\n    token = lexer.peek();\n    while (matchOp(token, \'+\') || matchOp(token, \'-\')) {\n        token = lexer.next();\n        expr = {\n            \'Binary\': {\n                operator: token.value,\n                left: expr,\n                right: parseMultiplicative()\n            }\n        }\n        token = lexer.peek();\n    };\n    return expr;\n}\n\n\nThe same logic follows for parseMultiplicative below. It does handle both multiplication and division.\n\nfunction parseMultiplicative() {\n    var expr, token;\n \n    expr = parseUnary();\n    token = lexer.peek();\n    while (matchOp(token, \'*\') || matchOp(token, \'/\')) {\n        token = lexer.next();\n        expr = {\n            \'Binary\': {\n                operator: token.value,\n                left: expr,\n                right: parseUnary()\n            }\n        };\n        token = lexer.peek();\n    }\n    return expr;\n}\n\n\nBefore we go and check the details of parseUnary, you may wonder why parseAdditive is first called and then parseMultiplicative. This is done in order to satisfy the operator precedence requirement. Consider the expression 2 + 4 * 10 which actually evaluates to 42 (multiply 4 by 10, then add 2) rather than 60 (add 2 to 4, multiply by 10). This is only possible if the topmost node in syntax tree is binary operator + which has two child nodes, the left one is just the number 2 and the right node is actually another binary operator *. The latter holds two numbers as the corresponding child nodes, 4 and 10.\n\nTo handle a negation, like -42, we use the concept of unary operation. In the syntax tree, this is represented by a unary operator node and it has only one child node (hence the name). While negation is one form of unary operation, there is also a case such as +42 which we need to take into account. Thanks to the recursive nature, expression like ----42 or even -+-+42 can be handled without any problem as well. The code to handle the said unary operation is as simple as the following:\n\nfunction parseUnary() {\n    var token, expr;\n \n    token = lexer.peek();\n    if (matchOp(token, \'-\') || matchOp(token, \'+\')) {\n        token = lexer.next();\n        expr = parseUnary();\n        return {\n            \'Unary\': {\n                operator: token.value,\n                expression: expr\n            }\n        };\n    }\n \n    return parsePrimary();\n}\n\n\nNow here comes one of the most important function of all: parsePrimary. First of all, let’s see four possible forms of primary node:\n\n\nan identifier (basically referring to a variable in this context), e.g. x\na number, e.g. 3.14159\na function call, e.g. sin(0)\nanother expression enclosed in brackets, e.g. (4 + 5)\n\n\nFortunately, deciding whether the incoming tokens will form one of the above possibilities is rather easy as we just need to examine the token type. There is only ambiguity between an identifier and a function call, which can be solved if we peek at the next token, i.e. whether it is an open bracket or not. Without further ado, here is the code:\n\nfunction parsePrimary() {\n    var token, expr;\n \n    token = lexer.peek();\n \n    if (token.type === T.Identifier) {\n        token = lexer.next();\n        if (matchOp(lexer.peek(), \'(\')) {\n            return parseFunctionCall(token.value);\n        } else {\n            return {\n                \'Identifier\': token.value\n            };\n        }\n    }\n \n    if (token.type === T.Number) {\n        token = lexer.next();\n        return {\n            \'Number\': token.value\n        };\n    }\n \n    if (matchOp(token, \'(\')) {\n        lexer.next();\n        expr = parseAssignment();\n        token = lexer.next();\n        if (!matchOp(token, \')\')) {\n            throw new SyntaxError(\'Expecting )\');\n        }\n        return {\n            \'Expression\': expr\n        };\n    }\n \n    throw new SyntaxError(\'Parse error, can not process token \' + token.value);\n}\n\n\nNow the remaining part is parseFunctionCall. If we see an example of a function call like sin(0), it basically consists of a function name, open bracket, function argument, and close bracket. It is important to realize that there can be more than one arguments (foo(1, 2, 3)) or no argument at all (random()), depending on the function itself. For simplicity, we split the handling of function argument to parseArgumentList. Here are both functions for your pleasure:\n\nfunction parseArgumentList() {\n    var token, expr, args = [];\n \n    while (true) {\n        expr = parseExpression();\n        if (typeof expr === \'undefined\') {\n            break;\n        }\n        args.push(expr);\n        token = lexer.peek();\n        if (!matchOp(token, \',\')) {\n            break;\n        }\n        lexer.next();\n    }\n \n    return args;\n}\n \nfunction parseFunctionCall(name) {\n    var token, args = [];\n \n    token = lexer.next();\n    if (!matchOp(token, \'(\')) {\n        throw new SyntaxError(\'Expecting ( in a function call \"\' + name + \'\"\');\n    }\n \n    token = lexer.peek();\n    if (!matchOp(token, \')\')) {\n        args = parseArgumentList();\n    }\n \n    token = lexer.next();\n    if (!matchOp(token, \')\')) {\n        throw new SyntaxError(\'Expecting ) in a function call \"\' + name + \'\"\');\n    }\n \n    return {\n        \'FunctionCall\' : {\n            \'name\': name,\n            \'args\': args\n        }\n    };\n}\n\n\nVoila! That’s all our parser code. When combined properly into a functional object, it is just about 200 lines of code, supporting various math operations with proper precedences, brackets, variables, and function calls.\n\n\n\nLive demo is available at tapdigit.googlecode.com/git/parser.htm (most common desktop and mobile browsers are supported).\n\nFor the last part next week, we will see the final missing puzzle necessary to be able to evaluate the syntax tree. Update: the final part (on building the interpreter) has been published!\n\n(`_|_`)Aug 22, 2011(`_|_`)ariya.io(`_|_`)math-evaluator-in-javascript-part-2', 'math-evaluator-in-javascript-part-2'),
(268, 'math evaluator in javascript: part 1 (the tokenizer)(`_|_`)\nThis will be the first part of a series of weekly blog posts where I outline the steps necessary to create a math expression evaluator using ECMAScript. By the end of the series, you expect to know the magical machinery which can understand and compute the result of the following expression:\n\nsin(pi/4) * sqrt(2) + 41\n\n\nIt is not targeted for hard-core computer scientists who likely already passed Compiler Techniques 101 with flying colors. This is geared more towards those who have a strong interests in the world of parsing but can’t afford the time to complete a whole course.\n\nAs with any educational tutorial, don’t expect this stuff to be in the production grade. For clarity, sometimes I also choose the most illustrative way to achieve a certain thing, it may not be the most optimal and fastest approach. For a start, I intentionally avoid regular expressions although in some particular real-world cases that’s exactly what you should use.\n\nNote: if you are eager to know the entire code, head to my TapDigit project page. The project is rather unfinished and not documented well, thus I advise you to stick with this detailed explanation. The code in the project is however very useful since it is more complete than various simplified fragments presented here. For your reference, there is also a summary page describing the expression syntax.\n\nThis Part 1 is about lexical analysis, i.e. breaking down a math expression into a list of tokens. A function that does this is often called a lexer, a tokenizer, or a scanner.\n\nWe need to define the types of the tokens. Since we deal with simple math expression, all we really need are number, identifier, and operator. Before we are able to distinguish a short string as one of these token types, we need some helper functions (they are self-explained):\n\nfunction isWhiteSpace(ch) {\n    return (ch === \'u0009\') || (ch === \' \') || (ch === \'u00A0\');\n}\n \nfunction isLetter(ch) {\n    return (ch >= \'a\' && ch < = \'z\') || (ch >= \'A\' && ch < = \'Z\');\n}\n \nfunction isDecimalDigit(ch) {\n    return (ch >= \'0\') && (ch < = \'9\');\n}\n\n\nAnother very useful auxiliary function is the following createToken, mostly to avoid repetitive code at the later stage. It basically create an object for the given token type and value:\n\nfunction createToken(type, value) {\n    return {\n        type: type,\n        value: value\n    };\n}\n\n\nAs we iterate through the characters in the math expression, we shall have a way to advance to the next character and another method to have a peek at the next character without advancing our position.\n\nfunction getNextChar() {\n    var ch = \'x00\',\n        idx = index;\n    if (idx < length) {\n        ch = expression.charAt(idx);\n        index += 1;\n    }\n    return ch;\n}\n \nfunction peekNextChar() {\n    var idx = index;\n    return ((idx < length) ? expression.charAt(idx) : \'x00\');\n}\n\n\nIn our expression language, spaces do not matter: 40 + 2 is treated the same as 40+2. Thus, we need a function which ignore white spaces and continue move forward until there is no such white space anymore:\n\nfunction skipSpaces() {\n    var ch;\n \n    while (index < length) {\n        ch = peekNextChar();\n        if (!isWhiteSpace(ch)) {\n            break;\n        }\n        getNextChar();\n    }\n}\n\n\nSupposed we want to support standard arithmetic operations, brackets, and a simple assignment, then the operators which we need to support are + - * / = ( ). A method to scan such an operator can be constructed as follows. Note that rather than checking the character against all possible choices, we just use a simple trick utilizing String.indexOf method. By convention, if this scanOperator function is called but no operator is detected, it returns undefined.\n\nfunction scanOperator() {\n    var ch = peekNextChar();\n    if (\'+-*/()=\'.indexOf(ch) >= ) {\n        return createToken(\'Operator\', getNextChar());\n    }\n    return undefined;\n}\n\n\nDeciding whether a series of characters is an identifier or not is slightly more complex. Let’s assume we allow the first character to be a letter or an underscore. The second, third, and subsequent character can be another letter or a decimal digit. We disallow a decimal digit to start an identifier because it gives a confusion with a number. Let’s begin with two simple helper functions that do the above checks:\n\nfunction isIdentifierStart(ch) {\n    return (ch === \'_\') || isLetter(ch);\n}\n \nfunction isIdentifierPart(ch) {\n    return isIdentifierStart(ch) || isDecimalDigit(ch);\n}\n\n\nThe identifier check can now be written as a simple loop like this:\n\nfunction scanIdentifier() {\n    var ch, id;\n \n    ch = peekNextChar();\n    if (!isIdentifierStart(ch)) {\n        return undefined;\n    }\n \n    id = getNextChar();\n    while (true) {\n        ch = peekNextChar();\n        if (!isIdentifierPart(ch)) {\n            break;\n        }\n        id += getNextChar();\n    }\n \n    return createToken(\'Identifier\', id);\n}\n\n\nSince we want to process math expressions, it would be absurd not to be able to recognize numbers. We want to support a simple integer such as 42, a floating point like 3.14159, and also numbers written in scientific notation like 6.62606957e-34. A skeleton for such a function is:\n\nfunction scanNumber() {\n    // return a token representing a number\n    // or undefined if no number is recognized\n}\n\n\nAnd here is the breakdown of the function implementation.\n\nFirst and foremost, we need to detect the presence of a number. It’s rather easy, just check whether the next character is a decimal digit or a decimal point (because .1 is a valid number).\n\nch = peekNextChar();\n    if (!isDecimalDigit(ch) && (ch !== \'.\')) {\n        return undefined;\n    }\n\n\nAnd if that is the case, we need to process each following character as long as it is a decimal digit:\n\nnumber = \'\';\n    if (ch !== \'.\') {\n        number = getNextChar();\n        while (true) {\n            ch = peekNextChar();\n            if (!isDecimalDigit(ch)) {\n                break;\n            }\n            number += getNextChar();\n        }\n    }\n\n\nSince we want to support a floating-point number, potentially we will see a decimal point coming (for example, for 3.14159, up to now we still process 3 only). If that is the case, we need to loop again and process all the digits behind the decimal point:\n\nif (ch === \'.\') {\n        number += getNextChar();\n        while (true) {\n            ch = peekNextChar();\n            if (!isDecimalDigit(ch)) {\n                break;\n            }\n            number += getNextChar();\n        }\n    }\n\n\nScientific notation with exponent means we will see e right after. For example, if we are supposed to scan 6.62606957e-34, we are only up to 6.62606957 now. Thus, we need to process more digits after the exponent sign. Note that there can be a plus or a minus sign as well.\n\nif (ch === \'e\' || ch === \'E\') {\n        number += getNextChar();\n        ch = peekNextChar();\n        if (ch === \'+\' || ch === \'-\' || isDecimalDigit(ch)) {\n            number += getNextChar();\n            while (true) {\n                ch = peekNextChar();\n                if (!isDecimalDigit(ch)) {\n                    break;\n                }\n                number += getNextChar();\n            }\n        } else {\n            throw new SyntaxError(\'Unexpected character after the exponent sign\');\n        }\n    }\n\n\nThe exception is needed because we want to tackle invalid numbers such as 4e.2 (there can not be a decimal digit after the exponent sign) or even just 4e (there must be some digits after the exponent sign).\n\nWrapping up our number lexing yields (combining all the bits and pieces above into a complete scanNumber function is left as an exercise for the reader):\n\nreturn createToken(\'Number\', number);\n\n\nIf we want to consume a math expression and produce a list of tokens represented by the expression, we shall have a function which recognize and get the next token. This is rather easy now since we have three individual functions which can handle a number, an operator, or an identifier.\n\nfunction next() {\n    var token;\n \n    skipSpaces();\n    if (index >= length) {\n        return undefined;\n    }\n \n    token = scanNumber();\n    if (typeof token !== \'undefined\') {\n        return token;\n    }\n \n    token = scanOperator();\n    if (typeof token !== \'undefined\') {\n        return token;\n    }\n \n    token = scanIdentifier();\n    if (typeof token !== \'undefined\') {\n        return token;\n    }\n \n    throw new SyntaxError(\'Unknown token from character \' + peekNextChar());\n}\n\n\nAnd that’s about it!\n\nNote: a much improved variant of the above “let’s try each scan function one by one” is actually doing a look ahead and decide which scan function to pick. This is left as an exercise for the reader.\n\n\n\nFor a live demo, go to tapdigit.googlecode.com/git/lexer.htm (works also on most smartphone browsers). You can enter an arbitrary (but valid) math expression and the demo will break it down into tokens and present them in a table.\n\nIn the next installment, I’ll cover the next stage after this: parsing the expression to produce the syntax tree. Enjoy and see you next week!\n\nUpdate: The second part is now online! It’s about syntactic analysis, i.e. building the parser.\n\nAnother update: The final part, about the actual interpreter, is now available.\n\n(`_|_`)Aug 18, 2011(`_|_`)ariya.io(`_|_`)math-evaluator-in-javascript-part1', 'math-evaluator-in-javascript-part1'),
(269, 'dirgahayu(`_|_`)\n66 years have passed since the Proclamation of Indonesian Independence.\n\n(`_|_`)Aug 17, 2011(`_|_`)ariya.io(`_|_`)dirgahayu-4', 'dirgahayu-4');
INSERT INTO `ariyaio` (`id`, `content`, `url`) VALUES
(270, 'javascript minifier and variable renaming(`_|_`)\nThis is something I’ve already pointed out during my talk at SenchaCon 2010 last year as well as the recent Velocity 2011.\n\nWhen you build a JavaScript-heavy web application, usually the final code is passed through a special JavaScript minifier in order to reduce the size without altering the program flow. Notable popular minifiers are JSMin, YUI Compressor, Closure Compiler, UglifyJS, and many more. Some minification tools out there also go an extra mile to rename variables (among others) so as to shorten the code even further. Of course, it is done in a such a way that the program would still work.\n\nLet’s take a look at this trivial function:\n\nfunction add(firstNumber, secondNumber) {\n    return firstNumber + secondNumber;\n}\n\n\nUsing Google Closure Compiler, e.g. the online version, one would get the optimized version as follows (UglifyJS and YUI Compressor will give the same result):\n\nfunction add(a,b){return a+b};\n\n\nAs you can see, the new function does the same amazing job of adding two values passed to the function. The renaming of firstNumber to a and secondNumber to b, as well the extra whitespace elimination, does not have any effect whatsoever, but it does shorten the code.\n\nNow let’s step back and see what a JavaScript engine does when it is about to run a certain script. The first step is the so-called lexical analysis, i.e. breaking down the string representing the code into a list of tokens. Because of that, it’s also called tokenization and the part which carries it out is often referred as the tokenizer.\n\n\n\nHere we see that both function and return are keywords, our function arguments firstNumber and secondNumber are identifiers. There are also punctuators, shown above with the green highlight. The minified version will give the same exact list of tokens.\n\nWhen the tokenizer sees a sequence of characters, e.g. function or firstNumber, it has to decide whether that string is a keyword (the former) or an identifier (the latter). It is obvious that if the character sequence is very long and very similar to a keyword, the tokenizer will have a hard time. For example, deciding whether instanceComponent is an identifier or not is slightly more difficult than just the single-letter a, not only because it is longer but also there is a keyword called instanceof.\n\nNow here is my argument: we shall not blindly use the simple alphabet series (a, b, c, …) as the replacement names for the variables. The reason is as follows. If we have a string, whose first letter can never be the first of letter of any reserved words, then the tokenizer may know immediately that that string is an identifier (in this context). Thus, we save a few CPU cycles.\n\nIf we look at the latest ECMAScript language specification, in particular section 7.6.1, we see the list of keywords and future reserved keywords. The reserved words also include true, false, null, and we may want to throw undefined for the practical purpose.\n\nHere is a list of characters which never start a reserved word:\n\na g h j k l m o p q x y z\n\nIf you want to involve all future keywords, such as let (which actually already in Firefox), package, etc, then the choices are slightly restricted to:\n\na g h j k o q x z\n\nLet me know if I miss other keywords. Update: I removed m (for module), thanks to Rick and Thaddee!\n\nOf course, this is a micro optimization. In most cases, the speed-up is negligible. It also depends on the implementation details, some tokenization implementation (perfect hash? I’m not sure about it) may not be affected by this cheap trick at all.\n\nHaving said that, if I create my own JavaScript minifier, am I going to pick this technique? Definitely!\n\n(`_|_`)Aug 16, 2011(`_|_`)ariya.io(`_|_`)javascript-minifier-and-variable-renaming', 'javascript-minifier-and-variable-renaming'),
(271, 'first look at nokia n950 web browser(`_|_`)\nNokia N950 is essentially the developer version of Nokia N9 (see the side-by-side comparison), the software stack is the same, i.e. MeeGo 1.2 Harmattan. While N9 is way more polished since it is targeted as a consumer smartphone, N950 still feels solid and good-looking, a long overdue replacement for the aging N900. The addition of hardware keypad makes it even more suitable as a developer device.\n\nLet’s do a quick run of the hardware platform. The CPU is TI OMAP 3630 (ARM Cortex-A8) clocked at 1 GHz. The integrated GPU is from Imagination Technology, PowerVR SGX 530. The phone is equipped with at least 16 GB NAND drive and 1 GB RAM. The same SoC also powers various smart phones such as Motorola Droid X and Palm Pre 2.\n\nFor a start, being a fresh Qt smartphone in the market wins my heart. I’m sure those who still use Greenphone would not disagree with me here. Qt SDK has been updated to ease the development for this platform. If you are a seasoned Qt developer, you can literally start in minutes.\n\nIn this blog post, I’d focus mostly on the web browser. This Harmattan browser is based on WebKit2, a wrapper for WebKit code to have it in a split process model (this multiprocess approach was popularized by Google Chrome). There is a lot of confusion about WebKit2 in general, usually because people mistakenly think of it as a version number. To make it perfectly clear, WebKit2 is not the next-generation of WebKit. Its presence merely extends the possible use of WebKit outside the single-process containment. WebKit2 does not make any of the existing WebKit code obsolete any time soon.\n\nSo far, this Harmattan flavor of MeeGo 1.2 can claim itself as the first mobile platform to use this multiprocess WebKit. One of the obvious benefit is the fluid and smooth user experience when using the browser. As I explained in my backing store blog entry, decoupling the rendering process and the user interface process is the key to this success. Spend few hours playing with N950 browser and you’ll probably notice how fast it is!\n\n\n  \n\n\n\n  \n\n\n\n  \n\n\nPerformance is one thing, faithful rendering is another thing. Beside being fast, the browser does not show any problem rendering many popular web sites out there (at least the ones I throw at). Scrolling is easy, flicking is smooth, pinching works as expected. Even mobile Google Mail works reasonably well. Looking at the DOM access performance, a recent investigation with Dromaeo test suite (see the full chart) shows how close it is to the performance of iPhone 4.\n\nFor the browser freak out there, the browser’s user agent is (this may or may not change for the final version, though):\n\n\nMozilla/5.0 (MeeGo; NokiaN950-00/00) AppleWebKit/534.13 (KHTML, like Gecko) NokiaBrowser/8.5.0 Mobile Safari/534.13\n\n\nHowever, user agent itself is pretty useless and does not tell much about the browser capabilities (see my post on the theory behind WebKit ports”)). If we use HTML5 Test to check various features of the browser engine, it shows that the browser is getting the score of 283 + 14 bonus points. This is better than other smartphones in the market: iPhone 4 (217 + 7), Android-based Nexus S (184 + 1), and BlackBerry Torch (266 + 3). Of course by the time iOS 5 and/or next Android smartphone OS are out, the numbers may look entirely different.\n\n\n  \n\n\n\n  \n\n\n\n  \n\n\nTurning to Modernizr feature detection suite, we will get the report like this screenshot. It is quite comprehensive, the browser can handle pretty much the common variants of modern web technologies (lacking only WebGL, IndexedDB, and some variants of input types). CSS3, SVG, and Canvas are well supported. Even CSS 3-D transform works well. My favorite is of course blur shadow, something I have implemented ages ago. HTML5 media is also there, though I haven’t done the real homework of investigating the supported codecs and its quality.\n\n\n  \n\n\n\n  \n\n\n\n  \n\n\nLet’s enter the topic of GPU acceleration. As I described in details in Sencha blog Understanding Hardware Acceleration on Mobile Browsers, the use of hardware acceleration falls into three categories: primitive drawing, backing store, and layer compositing. It is safe to say that Harmattan browser does all of these three, beautifully even. As No’am informed us in the comments to my blog post about accelerated compositing, the browser uses the new texture-mapping strategy to composite the layers. We can witness how the browser has no problem handling various CSS3 animations.\n\n\n  \n\n\n\n  \n\n\n\n  \n\n\nThere are of course rough edges here and there. Since there is still some time until the software stack is finalized for the ultimate release (of Nokia N9), hopefully by then those annoyances will be fixed. With so much technology burst coming to this slab of magic device, it is a shame that N9(50) will be the last MeeGo phone from Nokia.\n\nMeanwhile, kudos to the QtWebKit folks and the team behind the browser!\n\n(`_|_`)Aug 11, 2011(`_|_`)ariya.io(`_|_`)first-look-at-nokia-n950-web-browser', 'first-look-at-nokia-n950-web-browser'),
(272, 'crossfading with canvas(`_|_`)\nDissolve effect from one image to another is easily achieved by varying the opacity properly. With CSS animation feature, this does not even require any extra JavaScript code.\n\nThe following blog post however discusses about dissolve implemented using HTML Canvas. This is not because of performance reason, only to show an example of pixel manipulation via canvas API.\n\nBasically given two images, called source and target, we compose a third image called result. Each pixel in result is just a linear combination of the pixel in the same position from source and target. By varying the coefficients as a function of time, we achieve the crossfading.\n\nSide note: Crossfading in RGB color space can yield a weird and unnatural result. Since usually the dissolve duration is very short, visually it does not matter much. In the future I will talk about crossfading in other color spaces.\n\nThe straightforward approach:\n\nfunction tween(factor) {\n    var i, p, q, compl;\n    p = source.data;\n    q = target.data;\n    r = result.data;\n    compl = 1 - factor;\n    for (i = ; i &lt; len; i += 1) {\n        r[i] = p[i] * factor + q[i] * compl;\n    }\n    context.putImageData(result, , );\n}\n\n\nWe can see some problems with the above code. First of all, it accesses three CanvasPixelArray objects inside the loop, namely of the source, target and result images. Since all three of them are live references, this loop becomes quite costly.\n\nA better approach would be to prepare the source and target pixels in two normal arrays. This is done as follows:\n\noffset = new Array(len);\ndelta = new Array(len);\nfor (i = ; i &lt; len; i += 1) {\n    offset[i] = target.data[i];\n    delta[i] = source.data[i] - target.data[i];\n}\n\n\nThe inner-loop of the tweening now looks like this:\n\nfunction tween(factor) {\n    var i, r;\n    r = result.data;\n    for (i = ; i &lt; len; i += 4) {\n        r[i] = offset[i] + delta[i] * factor;\n        r[i + 1] = offset[i + 1] + delta[i + 1] * factor;\n        r[i + 2] = offset[i + 2] + delta[i + 2] * factor;\n    }\n    context.putImageData(result, , );\n}\n\n\nNote that by storing the tweening information as a pair of (offset, delta) instead of (source, target), we can save one multiplication. In addition, the loop is unrolled a bit in order to skip the alpha channel, i.e. every 4th byte, which is always set to 255 (=opaque).\n\n\n\nIf you run this example with a modern browser on a powerful machine, likely you will hit the capped 60 fps. With a slower machine, we can still squeeze some more framerate by using Int32Array (wherever it is supported) instead of normal JavaScript array. A typed array has a fixed size and known static type, this makes it easier for a modern JavaScript engine to optimize the execution.\n\nif (typeof Int32Array !== \'undefined\') {\n    offset = new Int32Array(len);\n    delta = new Int32Array(len);\n}\n\n\nIn fact, with a typed array above, you can get away with the alpha channel exclusion, i.e. just blindly loop through every byte and combine the pixel values linearly. Nicolas (of PhiloGL fame) gave me the hint that other typed array, e.g. Int16Array should work as well and likely better in terms of memory consumption.\n\nThe code is available in the usual X2 repository, look under javascript/crossfading directory (you need to access it via a web server as opposed to local file system, due to the same origin limitation). To keep it simple, animation is triggered via the good old setInterval. For real-world use case, you may want to use requestAnimationFrame instead.\n\nFor a live demo, check out ariya.github.com/canvas/crossfading with your favorite browsers, in particular on mobile devices. It’s also a simple benchmark test, let it run for about 7 seconds. Due to the extensive pixel manipulation, don’t expect to get double-digit fps on most smartphones. Still, share your framerate!\n\n(`_|_`)Aug 8, 2011(`_|_`)ariya.io(`_|_`)crossfading-with-canvas', 'crossfading-with-canvas'),
(273, 'a blast from the past(`_|_`)\n\n\n(`_|_`)Aug 7, 2011(`_|_`)ariya.io(`_|_`)a-blast-from-the-past', 'a-blast-from-the-past'),
(274, 'three padawan mistakes(`_|_`)\nIf you live in the Bay Area, you would be familiar with the chatter on how difficult it is to hire talented engineers these days. Well, looking back at tons of interviews I have done, that comes hardly as a big surprise. Seems that our education system still produces generations and generations of engineers with below-average passion for solving problems.\n\n\n\nExtracting the traits of failed newbie developers, let me emphasize three of them which I have seen over and over again. To make it more vivid, I’ll relate this to the possible answers you might get if you are given the following problem (which I already blogged before and also discussed at Stack Overflow):\n\n\nYou have rand5() function at your disposal, it returns an integer number 1..5 with equal probability. Your job is to implement rand7() function, which returns an integer number 1…7, just by using rand5().\n\n\n(1) misunderstand the problem\n\nTypical rookie’s mistake is answering the problem with scaling the return value from rand7() so it fits the desired range 1…7. While this might be the obvious answer, it is an excellent way to show how sloppy you are. In fact, there is a reason the problem has the word integer in it. Also, do you think high-tech companies want to hire you for solving a problem with just high-school math?\n\nAnother variant of miss-the-point approach is by ignoring rand5() and just return another random number. Totally off the mark. The reason rand5() exists at the first place is so that you can show your analytical and problem solving expertise. In real life, the same verbatim problem will likely never show up in your job. However, the similar problem solving situation usually occurs again and again.\n\nPersonally I never realized the power of reading and understanding the problem statement, until I studied in Germany and I had to read the exercise questions over and over again (it’s in German!) till I finally got it. Even if the problem is described in your native language, carefully going from one word to another might reveal something important and critical for your upcoming amazing discovery.\n\n(2) only think one step ahead\n\nA very common answer to the problem is by producing a number greater than 7 and then taking the remainder when dividing it with 7. For example, one can call rand5() twice and add both numbers, which results in a new range outside 1..7. Facing with this answer, the interviewer usually asks you back: what is the distribution of rand7() implemented that way? And if you manage to figure it out, the challenge is bumped: now rand7() is required to have a uniform distribution.\n\nThis is a case where, when you try to solve a problem, your gaze is fixed to the gravity of the problem and forget to look around and think outside the box. Obviously, the goal of this interview question is to realize a uniformly distributed rand7(). Otherwise, you might as well return whatever rand5() returns (giving a completely skewed distribution since 6 and 7 will never show up).\n\nPlaying the devil’s advocate in your mind is a great way to anticipate what’s coming. Chess players know this very well. Even with tons and tons of practices, a grand master is still prone to make a serious blunder. Imagine if you never think ahead more than one step.\n\n(3) lack of basic training\n\nNow that the interviewer teases you that she wants uniformly distributed rand7() implementation, what do you do with your rand5() manipulation? A lot of bit fiddling and arithmetic operation, if you don’t think carefully, will not yield 1..7 with equal probability. If you scroll through the comments in my previous blog entry, most of the wrong ones falls into this category.\n\nYou might be stopped there forever, if you hardly grasp the math behind it. As with any technical question, the correct answer hardly matters. The purpose of the interview process is to follow your train of thoughts, to see how you would attack the problem with different angles and analytically converge to a solution. This is however only possible if all the basic concepts of logic and problem solving is imprinted in your brain.\n\nJust like Peter Norvig asked, why the rush?. In his Outliers book, Malcolm Gladwell popularizes the notion that expertise requires 10,000 hours (or roughly 10 years) of continuous practice. You may not completely subscribe to that theory, but there is some truth to it. Our instant culture does not really help if you want to push your career further. Everyone wants to get an executive summary version of everything (don’t you think there is a reason it’s called executive summary).\n\nIf you dream of solving real-world problems, start by doing your homework and doing it really really well. Code more, tweet less.\n\nAnd by the way, just buy the T-shirt if you like.\n\n(`_|_`)Aug 6, 2011(`_|_`)ariya.io(`_|_`)three-padawan-mistakes', 'three-padawan-mistakes'),
(275, 'Mobile Web: Logical Pixel vs Physical Pixel(`_|_`)\nUsually you don’t want to do this, but in a rare occasion, sometimes you want to be able to have a web page that is logically as wide as the physical pixels of the browser, especially on the mobile devices. In this situation, one CSS pixel (px) will be exactly one physical pixel as depicted on the screen.\n\nThe usual trick to fit the content into the viewport is by using the de-facto viewport meta tag, first popularized by iPhone and now widely support in many other mobile browsers. Those who design web sites optimized for mobile view are familiar with this technique. For example, the following will fix the width to the phone or tablet browser width and the user can’t scale (via pinching or menu buttons) at all:\n\n<meta name=\"viewport\" content=\"width=device-width initial-scale=1 maximum-scale=1 user-scalable=no\">\n\n\nAfter Apple introduces higher-density screen, widely hyped as the retina display, the situation slightly changes. For compatibility with existing sites, the above trick still works. However, the content is simply scaled (in this case, twice). This means, a web page with the above viewport setting will still report 320 (px) as the screen.width (and window.innerWidth, not surprisingly) even on iPhone 4. Note that iPhone 4’s screen resolution is 640 x 960.\n\nIn order to detect the ratio between the device pixels and the logical pixels, there is window.devicePixelRatio. In the context of iOS, the value is 2 for a device using retina display, otherwise it is 1.\n\nNow let’s consider Android. It does not come as a surprise that the above viewport meta is also supported. When Android-based phones with higher resolution started to be available in the market, compatibility with iPhone-targeted web sites via this trick needs to be retained. However, for phones with resolution like 480 × 800, it is not an integer multiple of 320 (for the width). In this case,  window.devicePixelRatio will have the value of 1.5.\n\nEffectively, to reach 1:1 ratio of CSS pixel and physical pixel, we just need to compute the actual device width by multiplying  window.devicePixelRatio with  window.innerWidth and then adjust the viewport dynamically. The goal I’ve set for my experiment is however slightly more challenging: how can I do that without dynamic viewport modification unless it is absolutely necessary?\n\nFortunately for Android, we can do that rather easily, i.e. by customizing the scaling via another new setting: target-densityDpi. This was something specifically implemented for Android (see the corresponding commit).\n\nNow let’s give it a try.\n\nFirst of all, since Apple devices with retina display are arguably the most popular ones, let’s optimize for that use-case. We do that by setting the scale upfront to 0.5:\n\n<meta name=\"viewport\" content=\"width=device-width initial-scale=0.5 maximum-scale=0.5 user-scalable=no\">\n\n\nFor Android, we apply the density DPI approach and now it becomes:\n\n<meta name=\"viewport\" content=\"width=device-width target-densityDpi=device-dpi\n  initial-scale=0.5 maximum-scale=0.5 user-scalable=no\">\n\n\nNon-retina display is somehow still popular, e.g. iPad and previous generation of iPhone. To cater those users, we need to reset the scale back to 1 so that the viewport is not falsified (i.e. twice as large). We would do that by a simple JavaScript code (executed via window.onload):\n\nif (window.devicePixelRatio === 1) {\n    if (window.innerWidth === 2 * screen.width ||\n        window.innerWidth === 2 * screen.height) {\n        el = document.getElementById(\'viewport\');\n        el.setAttribute(\'content\', \'width=device-width target-densityDpi=device-dpi \' +\n            \'initial-scale=1 maximum-scale=1 user-scalable=no\');\n        document.head.appendChild(el);\n        width = window.innerWidth;\n        height = window.innerHeight;\n        if (width === 2 * screen.width) {\n            width /= 2;\n            height /= 2;\n        }\n    }\n}\n\n\nIn the above, when checking the ratio between window.innerWidth and screen.width, apparently we need to check screen.height as well. This seems counterintuitive, however it is necessary because on iOS, screen.width and screen.height values are not swapped when the device switches orientation (landscape, portrait).\n\nThe Harmattan web browser in Nokia N9 (and N950) has this peculiar behavior where (after modifying the viewport)  window.innerWidth and screen.width are not properly updated. Hence, we need additional check for that and adjust the values (that division by 2) ourselves when necessary.\n\nFor an online test case, go to ariya.github.com/browser/viewport. If everything goes well, there should be two arrows (position:absolute) which point exactly to the left and right edge of the screen, respectively. It also shall report the screen width in physical pixels, something you can verify with the device specification. There is a perfectly square box, 100 × 100, which should be centered properly.\n\nUsing few devices I could test (iPhone, Nexus S, N950, iPad, Playbook, and TouchPad), the above strategy seems to work well. The proof lies in the following screenshots.\n\n\n  \n\n\n\n  \n\n\n\n  \n\n\nNote how this trick is still missing some tweaks. For example, switching orientation (portrait to landscape or vice versa) is not taken care of, it is left as an exercise for the brave reader. Even reloading the web page after orientation change does not always solve the issue (somehow the viewport settings are sticky in one way or another). Due to the complexity and different ways viewport is handling in different devices, bear in mind that this whole technique might not be 100% future-proof.\n\nThis is my endeavor so far and if you have a better alternative trick, please do share!\n\n(`_|_`)Aug 4, 2011(`_|_`)ariya.io(`_|_`)mobile-web-logical-pixel-vs-physical-pixel', 'mobile-web-logical-pixel-vs-physical-pixel'),
(276, 'smartphones and web performance(`_|_`)\nThis one is basically the logical next step after I did the analysis of various tablets with respect to its DOM performance. After testing tablets, now I am switching to smartphones. The methodology is the same: leveraging Dromaeo set of DOM tests.\n\nHere is the graph for the impatients:\n\n\n\nThe full breakdown is also available, left-to-right: iPhone 4, Nexus S, Nokia N950, Galaxy S II, Palm Pre 2.\n\n(Special thanks to my linguist friend and self-proclaimed professional penguin lover Donald Carr for providing Galaxy S II result, my favorite web designer Jay Robinson for letting me use his iPhone for few minutes, and a PreCentral forum member Matt Williams for sharing the Pre 2 data).\n\nIt is better not to trust the numbers as exact scientific results, but more like a traditional rough estimate (the noise was quite high than usual, maybe because it is a phone and not only a simple tablet) . In all cases, it is pretty obvious that Galaxy S II is screaming fast, possible due to its dual-core Exynos (aka Orion) CPU. The rest of the phones have comparable SoC: Cortex A8 at 1 GHz (just single core).\n\nGreat respect to the folks behind the Harmattan browser because N950 (the Qt phone) is in the same league as iPhone 4. Nexus S, once regarded as the best Android phone, quickly fades out, a proof that the Android world is moving at a crazy speed. Interesting to notice how Pre2 is better than Nexus S, though it does even have a lot of room of (software) improvements consider N950 can push the number by quite a margin.\n\nOf course, the fun part is now the extrapolated speculations we are obliged to make. There is no doubt that the upcoming iPhone 5 (or however it would be called) rumored to be announced in few months will likely raise the bar further. If you check previous tablet comparison, iPad 2 is the ultimate winner and there is no reason iPhone 5 can’t reach the same numbers. Having said that, an army of dual-core (and likely also quad-core) Android phones will force the numbers to march further, in a hope that this translates to a better user experience.\n\nFun time ahead!\n\n(`_|_`)Aug 1, 2011(`_|_`)ariya.io(`_|_`)smartphones-and-web-performance', 'smartphones-and-web-performance'),
(277, 'tablets and web performance(`_|_`)\nBenchmarks, and the results of running them, are attractive because they eliminate the need to digest an arbitrary complex machinery, reducing it into a meaningful and powerful number. Comparison is thereby made easier, as it is now a matter of playing who has the biggest gun game.\n\nIn the areas of web performance, every benchmark becomes more like durian, either you hate it or you love it. No matter how useful (or useless) a benchmark is, there are always folks who defend it and others who despise it. Signal-to-noise ratio changes dramatically when the discussion over some benchmark results is started.\n\nI still reckon that in the years to come, what makes a great experience while browsing the web depends on the performance of (surprise!) DOM access. Common JavaScript frameworks (like jQuery, Prototype, Ext JS, MooTools, YUI, Dojo, and many others) still form the basis for a lot of rich web sites and interactive web applications out there, at least for the time being and till the near future.\n\nWhile SunSpider and V8 benchmarks are geared towards pure JavaScript performance and Kraken is better suited for future heavyweight applications, Dromaeo becomes a solid candidate for DOM performance analysis. In particular, its set of DOM tests is very valuable because it presents a nice sample of the behavior of framework-based sites. In this context, butter-smooth DOM modification has a bigger impact than just blazing-fast trigonometric computation, at least for gajillions web pages out there.\n\nSince more and more people are accessing the web through mobile platforms these days, I decided to test several popular tablets out there and summarize the result in one graph below (updated):\n\n\n\nFor the detailed comparisons, check out the complete Dromaeo numbers of all tablets (left-to-right: Galaxy Tab, iPad 2, Playbook, TouchPad). If you find the above result is different that what you test yourself, shout out. I want to be careful not to propagate any discrepancies or misleading results. As usual, take the above beautiful collection of colored bars with a pinch of salt.\n\nSamsung Galaxy Tab 10.1 is powered by Android 3.1 (Honeycomb) Build HMJ37, iPad 2 is using iOS 4.3.3, RIM Playbook’s firmware is 1.0.7.2670, which the HP TouchPad has webOS 3.0. The choice of the devices represent a variety of fresh ARM-based tablet operating systems in the market as of this writing.\n\nWith Qt coming closer and closer to the become a good companion of the green robot, I wonder how would QtWebKit compete with those numbers. I think we will find out the answer in a couple of months, maybe even sooner.\n\n(`_|_`)Jul 26, 2011(`_|_`)ariya.io(`_|_`)tablets-and-web-performance', 'tablets-and-web-performance'),
(278, 'fluid animation with accelerated compositing(`_|_`)\nThose who work on web-based applications on mobile platforms often recall the advice, “Use translate3d to make sure it’s hardware accelerated”. This advice seems magical at first, and I seldom find anyone who explains (or wants to explain) the actual machinery behind such a practical tip.\n\n\nFor a while, Safari (and Mobile Safari) was the only WebKit-based browser which supports hardware-accelerated CSS animation. Google Chrome caught up, QtWebKit-powered browser (like the one in Nokia N9) also finally supported it. Such a situation often gave the wrong impression that Apple kept the hardware-acceleration code for themselves.\n\nThe above two are basically the reasons for this blog post.\n\nIn case you miss it (before we dive in further), please read what I wrote before about different WebKit ports (to get the idea of implementation + back-end approach) and tiled backing store (decoupling web page complexity with smooth UX). The GraphicsContext abstraction will be specially useful in this topic. In particular, because animation is tightly related to efficient graphics.\n\nImagine if you have to move an image (of a unicorn, for example) from one position to another. The pseudo-code for doing it would be:\n\nfor pos = startPosition to endPosition\ndraw unicorn at pos\n\n\nTo ensure smooth 60fps, your inner loop has only 16 ms to draw that unicorn image. Usually this is a piece of cake because all the CPU does is sending the pixels of the unicorn image once to the GPU (in the form of texture) and then just refer the texture inside the animation loop. No heavy work is needed on the CPU and GPU sides.\n\nIf, however, what you draw is very complicated, e.g. formatted text consisting of different font typefaces and sizes, this gets hairy. The “draw” part can take more than 16 ms and the animation is not butter-smooth anymore. Because your text does not really change during the animation, only the position changes, the usual trick is to cache the text, i.e. draw it onto a buffer and just move around the buffer as needed. Again, the CPU just needs to push the buffer the GPU once:\n\nprepare a temporary buffer\ndraw the text onto the buffer\nfor pos = startPosition and endPosition\nset a new transformation matrix for the buffer\n\n\nAs you can imagine, that’s exactly what happens when WebKit performs CSS animation. Instead of drawing your div (or whatever you animate) multiple times in different position, it prepares a layer and redirect the drawing there. After that, animation is a simple matter of manipulating the layer, e.g. moving it around. WebKit term for this (useful if you comb the source code) is accelerated compositing.\n\nSide note: Mozilla has the same concept, available since Firefox 4, called Layer.\n\nIf you understand immediate vs retain mode rendering, non-composited vs composited is just like that. The idea to treat the render tree more like a scene graph, a stack of layers with different depth value.\n\nBecause compositing reduces the computation burden (GPU can handle varying transformation matrix efficiently), the animation is smoother. This is not so noticeable if you have a modern machine. In the following video demo (http://youtu.be/KujWTTRkPkM), I have to use my slightly old Windows laptop to demonstrate the frames/second differences:\n\nThe excellent falling leaves animation is something you have seen before, back when WebKit support for CSS animation was announced.\n\nAccelerated compositing does not magically turn every WebKit ports capable of doing fluid animation. Analog to my previous rounded corner example, compositing requires the support from the underlying platform. On Mac OS X port of WebKit, compositing is mapped into CoreAnimation (part of CoreGraphics), the official API to have animated user interface. Same goes for iOS WebKit. On Chromium, it is hooked into sandboxed GPU process.\n\nWith QtWebKit, compositing is achieved via Graphics View framework (read Noam’s explanation for details). The previous video you have seen was created with QtWebKit, running without and with compositing, i.e. QGraphicsWebView with different AcceleratedCompositingEnabled run-time setting. If you want to check out the code and try it yourself, head to the usual X2 repository and look under webkit/composition. Use spacebar (or mouse click) to switch between composited and non-composited mode. If there is no significant frame rate improvement, increase NUMBER_OF_LEAVES in leaves.js and rebuild. When compositing is active, press D to draw thin yellow border around each layer. Since it’s all about Graphics View, this debugging is easy to implement. I just inject a custom BorderEffect, based on QGraphicsEffect (which I did prototype back when I was with Nokia):\n\n\n\nThus, there is nothing like hidden secret with respect to Safari hardware-accelerated CSS support. In fact, Safari is not different than other Mac apps. If you compile WebKit yourself and build an application with it, you would definitely get the animation with hardware acceleration support.\n\nAs the bonus, since Mac and iOS WebKit delegate the animation to CoreAnimation (CA), you can use various CA tweaks to debug it. CA_COLOR_OPAQUE=1 will emphasize each layer with red color overlay (as in the demo). While this applies to any CA-based apps (not limited to WebKit or Safari), it’s still very useful nevertheless. Chromium’s similar feature is –show-composited-layer-border command line option.\n\nHow does WebKit determine what to composited? Since the goal is to fully take advantage of the GPU, there are few particular operations which are suitable for such a compositing. Among others are transparency (opacity < 1.0) and transformation matrix. Ideally we would just use compositing for the entire web page. However, compositing implies a higher memory allocation and a quite capable graphics processor. On mobile platforms, these two translate into additional critical factor: power consumption. Thus, one just needs to draw a line somewhere and stick with it. Hence, that’s why currently (on iOS) translate3d and scale3d are using compositing and their 2-D counterparts are not. Addendum: on the desktop WebKit, all transformed element is accelerated, regardless whether it’s 2-D or 3-D.\n\nIf you make it this far, here are few final twists.\n\nFirst of all, just like the tiled backing store approach I explained before, accelerated compositing does not force you to use the graphics processor for everything. For efficiency, your layer (backing store) might be mapped to GPU textures. However, you are not obligated to prepare the layer, i.e. drawing onto it, using the GPU. As an example, you can use a software rasterizer to draw to a buffer which will be mapped to OpenGL texture.\n\nIn fact, a further variation of this would be not to use the GPU at all. This may come as a surprise to you but Android 2.2 (Froyo) added compositing support (see the commit), albeit doing everything with in software (via its Skia graphics engine). The advantage is of course not that great (compared to using OpenGL ES entirely), however the improvement is really obvious. If you have two Android phones (of the same hardware specification), one still running the outdated 2.1 (Eclair) and the other with Froyo, just open the Falling Leaves demo and watch the frame rate difference.\n\nWith the non-GPU compisiting-based CSS animation in Froyo, translate3d and other similar tricks do not speed-up anything significantly. In fact, it may haunt you with bugs. For example, placing form elements in a div could wreck the touch events accuracy, mainly because the hit test procedures forget to take into account that the composited layer has moved. Things which seem to work just fine Eclair may start behaving weird under Froyo and Gingerbread. If that happens to you, check your CSS properties.\n\nFortunately (or unfortunately, depending on your point of view), Android madness with accelerated compositing is getting better with Honeycomb and further upcoming releases. Meanwhile, just take it for granted that your magical translate3d spell has no effect on the green robots.\n\nLast but not least, I’m pretty excited with the lightweight scene graph direction in the upcoming Qt 5. If any, this will become a better match for QtWebKit accelerated compositing compared to the current Graphics View solution. This would totally destroy the myth (or misconception) that only native apps can take advantage of OpenGL (ES). Thus, if you decide to use web technologies via QtWebKit (possibly through the hybrid approach), your investment would be future-attractive!\n\nUpdate: The incorrect term composition has been changed to correct one, compositing.\n\n(`_|_`)Jul 6, 2011(`_|_`)ariya.io(`_|_`)fluid-animation-with-accelerated-composition', 'fluid-animation-with-accelerated-composition'),
(279, 'quaternion multiplication: two years later(`_|_`)\nSometime back I wrote (fun fact: it’s Google first hit for faster quaternion multiplication) about my favorite commit I did exactly two years ago to Qt :\n\ngit show cbc22908\ncommit cbc229081a9df67a577b4bea61ad6aac52d470cb\nAuthor: Ariya Hidayat \nDate:   Tue Jun 30 11:18:03 2009 +0200\n\n    Faster quaternion multiplications.\n    \n    Use the known factorization trick to speed-up quaternion multiplication.\n    Now we need only 9 floating-point multiplications, instead of 16 (but\n    at the cost of extra additions and subtractions).\n\n\nAges ago, during my Ph.D research, when I worked with a certain hardware platform (hint: it’s not generalized CPU), minimizing the needed number of hardware multipliers with a very little impact in the computation speed makes a huge different. With today’s advanced processor architecture armed with vectorized instructions and a really smart optimizing compiler, there is often no need to use the factorized version of the multiplication.\n\nSide note: if you want to like quaternion, see this simple rotatation quiz which can be solved quite easily once you know quaternion.\n\nI try to apply the same trick to PhiloGL, an excellent WebGL framework from Nicolas. Recently, to my delight, he added quaternion support to the accompanying math library in PhiloGL. I think this is a nice chance to try the old trick, as I had the expectation that reducing the number of multiplications from 16 to just 9 could give some slight performance advantage.\n\nIt turns out that it is not the case, at least based on the benchmark tests running on modern browsers with very capable JavaScript engine. You can try the test yourself at jsperf.com/quaternion-multiplication. I have no idea whether this is due to JSPerf (very unlikely) or it’s simply because the longer construct of the factorized version does not really speed-up anything. If any, seems that the amount of executed instruction matters more than whether addition is much faster than multiplication. And of course, we’re talking about modern CPU, the difference is then becoming more subtle.\n\nWith the help of Nicolas, I tried various other tricks to help the JavaScript engine, mainly around different ways to prepare the persistent temporary variables: using normal properties, using Array, using Float32Array (at the cost of precision). Nothing leads to any significant improvement.\n\nOf course if you have other tricks in your sleeve, I welcome you to try it with the benchmark. Meanwhile, let’s hope that someday some JavaScript engine will run the factorized version faster. It’s just a much cooler way to multiply quaternions!\n\n(`_|_`)Jun 30, 2011(`_|_`)ariya.io(`_|_`)quaternion-multiplication-two-years-later', 'quaternion-multiplication-two-years-later'),
(280, 'progressive rendering via tiled backing store(`_|_`)\nImagine you have to create a CAD-grade application, e.g. drawing the entire wireframe of a space shuttle or showing the intricacies of 9-layer printed circuit board. Basically something that involves a heavy work to display the result on the screen. On top of that, the application is still expected to perform smoothly in case the user wants to pan/scroll around and zoom in/out.\n\nThe usual known trick to achieve this is by employing a backing store, i.e. off-screen buffer that serves as the target for the drawing operations. The user interface then takes the backing store and displays it to the user. Now panning is a matter of translation and zooming is just scaling. The backing store can be updated asynchronously, thus making the user interaction decoupled from the complexity of the rendering.\n\nMoving to a higher ninja level, the backing store can be tiled. Instead of just one giant snapshot of the rendering output, it is broken down to small tiles, say 128×128 pixels. The nice thing is because each tile can be mapped as a texture in the GPU, e.g. via glTexImage2D. Drawing each textured tile is also a (tasty) piece of cake, GL_QUAD with glBindTexture.\n\nAnother common use-case for tiling is for online maps. You probably use it every day without realizing it in Google Maps, OpenStreetMap, or other similar services. In this case, the reason is to use tiles is mainly to ease the network aspect. Instead of sending a huge image representing the area seen by the user in the viewport, actually lots of small images are transported and stitched together by the client code in the web browser.\n\nHere is an illustration of the concept. The border of each tile is emphasized. The faded area is what you don’t see (outside the viewport). Of course every time you pan and zoom, new fresh tiles are fetched so as to cover the viewport as much as possible.\n\n\n\nWhen I started to use the first generation iPhone years ago, I realized that the browser (or rather, its WebKit implementation) uses the very similar trick. Instead of drawing the web page straight to the screen, it uses a tiled backing store. Zooming (via pinching) becomes really cheap, it’s a matter of scaling up and down. Flicking is the same case, translating textures does not bother any mobile GPU that much.\n\nEvery iOS users know that if you manage to beat the browser and flick fast enough, it tries to catch up and fills the screen as fast as possible but every now and then you’ll see some sort of checkerboard pattern. That is actually the placeholder for tiles which are not ready yet.\n\nSince all the geeks out there likely better understand the technique with a piece of code, I’ll not waste more paragraphs and present you this week’s X2 example: full-featured implementation of tiled backing store in < 500 lines of Qt and C++. You can get the code from the usualX2 git repository, look under graphics/backingstore. When you compile and launch it, use mouse dragging to pan around and mouse wheel to zoom in/out. For the impatient, see the following 50-second screencast (or watch directly on YouTube):\n\nFor this particular trick, what you render actually does not matter much (it could be anything). To simplify the code, I do not use WebKit and instead just focus on SVG rendering, in particular of that famous Tiger head. The code should be pretty self-explanatory, especially for the TextureBuffer class, but here is some random note for your pleasure.\n\nAt the beginning, every tile is invalid (=0). Every time the program needs to draw a tile, it checks first if the tile is valid or not. If yes, it substitutes it with the checkerboard pattern instead (also called the default texture) and triggers an asynchronous update process. During the update, the program looks for the most important tile which needs to be updated (usually the one closes to the viewport center). What is a tile update? It’s the actual rendering of the SVG, clipped exactly to the rectangular bounding box represented by the tile, into a texture.\n\nTo show the mix-n-match, I actually use Qt built-in software rasterizer to draw the SVG. That demonstrates that, even though each tile is essentially an OpenGL texture, you are not forced to use OpenGL to prepare the tile itself. This is essentially mixing rasterization done by the CPU with the texture management handled by the GPU.\n\nAs I mentioned before, panning is a matter of adjusting the translation offset. Zooming is tricky, it involves scaling up (or down) the textures appropriately. At the same time, it also triggers an asynchronous refresh. The refresh function is nothing but to reset all the tiles to invalid again, which in turns would update each one by one. This gives the following effect (illustrated in the screenshot below). If suddenly you zoom in, you would see pixelated rendering (left). After a certain refresh delay, the tile update makes the rendering crisp again (right).\n\n\n\nBecause we still need to have the outdated tiles scaled up/down (those pixelated ones), we have to keep them around for a while until the refresh process is completed. This is why there is another texture buffer called the secondary background buffer. Rest assured, when none of the tiles in the background buffer is needed anymore, the buffer is flushed.\n\nIf you really want to follow the update and refresh, try to uncomment the debug compiler define. Beside showing the individual tiles better, that flag would also intentionally slows down both update and refresh so your eyes can have more time to trace them.\n\nBTW how would you determine the tile dimension in pixels? Unfortunately this can vary from one hardware to another. Ideally it’s not too small because you’d enjoy the penalty of logical overdraw. If it’s too large, you might not be progressive enough. Trial and error, that can be your enlightenment process.\n\nBeing an example, this program has a lot of simplifications. First of all, usually you want the tile update to take place in a separate thread, and probably updating few tiles at once. With a proper thread affinity, this helps improving the overall perceptive smoothness. Also, in case you know upfront that it does not impact the performance that much, using texture filtering (instead of just GL_NEAREST) for the scaling would give a better zooming illusion.\n\nYou might also see that I decided not to use the tile cache approach in the texture buffer. This is again done for simplicity. The continuous pruning of unused textures ensures that we actually don’t grow the textures and kill the GPU. If you really insist on the absolutely minimal amount of overdraw and texture usage, then go for a slightly complicated cache system.\n\nSince I’m lazy, the example is using Open GL and quad drawing. If you want to run it on a mobile platform, you have patch it so that it works with Open GL ES. In all cases, converting it to use vertex and texture arrays is likely a wise initial step. While you are there, hook the touch events so you can also do the pinch-to-zoom effect.\n\nIf you are brave enough, here is another nice final finish (as suggested by Nicolas of InfoVis and PhiloGL fame). When you zoom in, the tiles in the center are prioritized. However, when you zoom out, the tiles nearby the viewport border should get the first priority, in order to fill the viewport as fast as possible.\n\nProgressive rendering via a tiled backing store is the easiest way to take advantage of graphics processor. It’s of course just one form, probably the simplest one, of hardware acceleration.\n\n(`_|_`)Jun 27, 2011(`_|_`)ariya.io(`_|_`)progressive-rendering-via-tiled-backing-store', 'progressive-rendering-via-tiled-backing-store');
INSERT INTO `ariyaio` (`id`, `content`, `url`) VALUES
(281, 'your webkit port is special (just like every other port)(`_|_`)\nOne of the most often question I got, “Since browser Foo and browser Bar are using the same WebKit engine, why do I get different feature set?“.\n\nLet’s step aside a bit. Boeing 747, a very popular airliner, uses Pratt & Whitney JT9D engine. So does Airbus A310. Do you expect both planes to have the same flight characteristics? Surely not, there are other bazillion factors which decide how that big piece of metal actually flies. In fact, you would not expect A310-certified pilot to just jump into 747 cockpit and land it.\n\n(Aviation fans, please forgive me if the above analogy is an oversimplification).\n\nWebKit, as a web rendering engine, is designed to use a lot of (semi)abstract interfaces. These interfaces obviously require (surprise) some implementation. Example of such interfaces are network stack, mouse + key handling, thread system, disk access, memory management, graphics pipeline, etc.\n\nWhat is the popular reference to WebKit is usually Apple’s own flavor of WebKit which runs on Mac OS X (the first and the original WebKit library). As you can guess, the various interfaces are implemented using different native libraries on Mac OS X, mostly centered around CoreFoundation. For example, if you specify a flat colored button with specific border radius, well WebKit knows where and how to draw that button. However, the final actual responsibility of drawing the button (as pixels on the user’s monitor) falls into CoreGraphics.\n\nWith time, WebKit was “ported” into different platform, both desktop and mobile. Such flavor is often called “WebKit port”. For Safari Windows, Apple themselves also ported WebKit to run on Windows, using the Windows version of its (limited implementation of) CoreFoundation library.\n\nBeside that, there were many other “ports” as well (see the full list). Via its Chrome browser (and the Chromium sister project), Google has created and continues to maintain its Chromium port. There is also WebKitGtk which is based on Gtk+. Nokia (through Trolltech, which it acquired) maintains the Qt port of WebKit, popular as its QtWebKit module.\n\n(This explains why any beginner scream like “Help! I can’t build WebKit on platform FooBar” would likely get an instant reply “Which port are you trying to build?”).\n\nConsider QtWebKit, it’s even possible (through customized QNetworkAccessManager, thanks to Qt network modularity) to hook a different network backend. This is for example what is being done for KDEWebKit module so that it becomes the Qt port of WebKit which actually uses KDE libraries to access the network.\n\nIf we come back to the rounded button example, again the real drawing is carried out in the actual graphics library used by the said WebKit port. Here is a simplified diagram that shows the mapping:\n\n\n\nGraphicsContext is the interface. All other code inside WebKit will not “speak” directly to e.g. CoreGraphics on Mac. In the above rounded button example, it will call GraphicsContext’s fillRoundedRect() function.\n\nThere are various implementation of GraphicsContext, depending on the port. For Qt, you can see how it is done in GraphicsContextQt.cpp file.\n\nShould you know a little bit about graphics, you would realize that there are different methods and algorithms to rasterize a filled rounded rectangle. A certain approach is to convert it to a fill polygon, another one is to scanline-convert the rounded corner directly. A fully GPU-based system may prefer working with tessellated triangle strips, or even with shader. Even the antialiasing level defines the outcome, too.\n\nIn short, different graphic stacks with different algorithm may not produce the same result down to the exact pixel colors. It all depends various factors, including the complexity of the drawing itself.\n\nNow the same concept applies to other interfaces. For example, there is no HTTP stack inside WebKit code base. All network-aware code calls specific function to get resources off the server, post some data, etc. However, the actual implementation is in system libraries. Thus, don’t bother trying to find SSL code inside WebKit.\n\nThis gets us to this question, “If browser X is using WebKit, why it does not have feature Z?”. You may be able to deduce the reason. Imagine a certain graphic stack which glues GraphicsContext for that platform does not implement fillRoundedRect() function, what would happen? Yes, your rounded button suddenly becomes a square button.\n\nAs a matter of fact, when someone ports WebKit to a new platform, she will need to implement all these interfaces one by one. Until it is complete, of course not everything would work 100% and most likely only the basics are there. That should feel like putting a jet engine into an airframe that can’t fly yet.\n\n“Can we have one de-facto graphics stack that powers WebKit so we always have pixel-perfect rendering expectation?” Technically yes, but practically no. In fact, while Boeing and Airbus may buy the same engine from Pratt & Whitney, they may not want to have the exact same landing gears. Everyone of us wants to be special. A certain system wants to use OpenGL ES, squeeze the best performance out of it and doesn’t really care if the selling price goes up. Others want to sacrifice the speed, trim the silicon floor and make the device more affordable. More often, you just have to live with diversity.\n\nAnd if you want to put aside all the differences, two WebKit ports of the same revision share tons of stuff, especially if they use the same JavaScript engine. They will parse HTML and CSS in the same way, produce the same DOM, yield the same render tree, have the same JavaScript host objects, and so on.\n\nThus, next time someone shouts “there is no two exact WebKit”, you know the story behind it.\n\n(`_|_`)Jun 10, 2011(`_|_`)ariya.io(`_|_`)your-webkit-port-is-special-just-like-every-other-port', 'your-webkit-port-is-special-just-like-every-other-port'),
(282, 'rectangular gradient(`_|_`)\nThorsten Zachmann, from Calligra (and previously KOffice) fame, asked me once on how to draw a different kind of gradient: a rectangular one. While Qt itself has built-in supports for linear, radial, and conical gradient types, apparently for office apps we may need more than that. In short, the goal is creating the following:\n\n\n\nIt turns out that this is not so difficult at all, about 50 lines of code. Check it out at the usual X2 repository and find it under graphics/rectgradient.\n\nBasically it boils down to a two-step process, as illustrated below. The first one is easy, just create a linear gradient from the center going north and south. The second one is similar, but now we are going east and west and clip it to two triangles. Once we combined both, we get the rectangular gradient.\n\n\n\nHave fun with the gradient!\n\n(`_|_`)Jun 6, 2011(`_|_`)ariya.io(`_|_`)rectangular-gradient', 'rectangular-gradient'),
(283, 'on the story of browser names(`_|_`)\n\n\nOne of the early graphical web browser that got really popular was Mosaic, developed at National Center for Supercomputing Applications (NCSA). Some folks from the team, along with SGI founder Jim Clark, decided that it’s worth a venture and formed a company, originally called Mosaic Communication and then later renamed to Netscape Communication.\n\nNetscape’s flagship desktop product was a much more advanced web browser than Mosaic. Jamie Zawinski coined the name “Mozilla”, as it was supposed to be Mosaic Killer (Mozilla = Mosaic + Godzilla). At the later stage, the final browser was widely known as Netscape Navigator. For browsing the web, obviously you need a navigator.\n\nParallel to that, another company called Spyglass licensed the technology from NCSA and produced a web browser, Spyglass Mosaic. It is fun to see the same theme here (probably even slightly coincidental), typical Hollywood movies always portray the naval ship’s navigator using his spyglass for some sort of observations.\n\nThen came along Microsoft. It licensed Spyglass Mosaic, called it Internet Explorer, and distributed with Windows. The browser war has just started. I mean of course, the name war. Why would you stop at navigating (and using spyglass) if you can continue exploring?\n\nOn the other side of the planet, KDE slowly emerged as the attractive supplement to the otherwise boring Unix desktop. Internet technologies became the centerpiece of the early version of KDE, thus its developers grew a set of applications from e-mail program, newsgroup reader, IRC client, and (surprise) a web browser. There was no free-software-friendly modern and capable web rendering engine back then, thus a bunch of brave young hackers initiated the adventure of (re)writing one, under the name KHTML (which was itself a replacement of the original attempt, khtmlw).\n\nFrom this KDE camp, the ultimate web browser (which actually could serve other tasks as well, e.g. file manager and document viewer) was popular as Konqueror (indeed, those were the days where KDE stuff was named K-this or K-that). History showed how Age of Discovery was not about navigation and exploration only. After all, who would not want to repeat the glory of “I came, I saw, I conquered“?\n\nWhen Apple decided that it must give the best browsing experience for Mac (and could not just rely on Microsoft for its Internet Explorer), they took KHTML, ported it to Mac, improved it, and later released it as an open-source project called WebKit. Apple’s proprietary web browser, which is powered by WebKit (till today), was announced by Steve Jobs as Safari. Already conquered a land? Might as well enjoy it with a little bit of safari and collect exotic pictures. Shall we?\n\nJust like in your favorite comic books, the world is however multiverse. Netscape lost the browser war, Mozilla became an open-source project and its Firefox browser (formerly Firebird, and formerly Phoenix) remains as the icon of freedom, independence, and community. Opera, originally a Telenor research project, was something that came all the way from Norway, has loyal followers and remains dominant in the embedded space. Google even joined the fun and launched WebKit-based Chrome (and Chromium). All these three are excellent web browsers, they just don’t have the names which fit the story of navigation, exploration, and so on.\n\nAs the closing, here is a side twist. In its early WebKit days, how did Apple engineers name the code branch of its ported Konqueror’s KHTML? Alexander.\n\n(`_|_`)May 31, 2011(`_|_`)ariya.io(`_|_`)on-the-story-of-browser-names', 'on-the-story-of-browser-names'),
(284, 'meego conf 2011 impressions(`_|_`)\n\n\nIt’s a mixed feeling. Personally it was (always) fun to meet my former coworkers from Qt, Nokia and other KDE folks and catch up and exchange tech gossips. I am also excited to get to know MeeGo team from Intel side as well. The conference itself is professionally organized. The Hacker Lounge idea is perfect, a basement to hang out 24 hours with free cold drinks, lots of games (from fussball to pingpong), superfast and reliable WiFi, and of course a bunch of comfy couches. Hyatt Regency itself proves to be a really really nice venue from such a developer conference.\n\nThe three-day program was packed with tons of sessions, anything from Qt 5, Wayland, Scene Graph, Media and IVI, and various other BoFs. Lots of exciting new technologies coming to the next version of MeeGo! Oh BTW, the releases will be every 6 months, expect MeeGo 1.3 in October 2011, along with its experimental Wayland support.\n\nFrom the device-give-away perspective, Intel threw a lot of ExoPC tablets (flashed with MeeGo 1.2 preview), as part of its AppUp program. I got one for a while, it’s really easy to port your existing Qt apps using its SDK (but that’s a separate blog post).\n\nBut that’s about it. LG was supposed to showcase its MeeGo-based LG GW990 (based on Intel Moorestown). There was even rumor that LG has also a tablet product, instead of only just a smartphone. And of course Nokia has its own N9 phone in the pipeline. None of this happened.\n\nWhen I remember back at Maemo Summit 2009 in Amsterdam, there was an accelerated momentum just because Nokia gave N900 to everyone. It was a top-of-the-line phone at that time, I still even use it for various demos. Back then I was still with Nokia and after all these years, it’s not funny to see that everyone is still using it. It’s fine and dandy to have millions of cars using MeeGo for its infotainment, smart TVs based on MeeGo, and so on. A refresh in this smartphone party however would have made a much more dramatic impact with respect to the momentum in the development community.\n\nSeems I still need to wait until I can use a MeeGo phone as my primary phone. Meanwhile, I’ll stick with ExoPC tablet to learn various bits of MeeGo. And hopefully nothing would exhaust my patience.\n\n(`_|_`)May 29, 2011(`_|_`)ariya.io(`_|_`)meego-conf-2011-impressions', 'meego-conf-2011-impressions'),
(285, 'meego conf 2011(`_|_`)\nIt’s MeeGo time! 2011 conference will be held in Hyatt Regency, San Francisco.\n\n\n\nThe complete program has been published. For topics related to Qt (among others), check what Thiago listed. In particular, of course yours truly be there, talking about Hybrid Apps (Native + Web) using WebKit.\n\nIf you will be around, see you there!\n\n(`_|_`)May 22, 2011(`_|_`)ariya.io(`_|_`)meego-conf-2011', 'meego-conf-2011'),
(286, 'tango papa echo, charlie golf kilo(`_|_`)\n\n\nCurrently stranded at TPE. Few minutes before leaving SFO I managed to tag 1.1.0 release for PhantomJS (lesson learned: never attempt a release few hours before boarding). Thanks to Ivan and Alessandro, few source tarballs and binaries are now ready.\n\nIt’s been hectic days. 2011 WebKit Contributors Meeting was just over, it was fantastic and I got to meet and talk to a lot of WebKit rockstars. Parallel to that, my fellow brave Sencha lads finally unleashed The Quattro!\n\nNext stop, also the final destination: CGK. Bracing for the impact of reverse culture shock…\n\n(`_|_`)Apr 28, 2011(`_|_`)ariya.io(`_|_`)tango-papa-echo-charlie-golf-kilo', 'tango-papa-echo-charlie-golf-kilo'),
(287, 'camp kde 2011(`_|_`)\nCamp KDE 2011 was a fabulous experience. First of all, there is definitely something with me and Camp KDE. The previous one was in San Diego and at that time I was there working for Qualcomm. This year it is San Francisco, right after I moved to the Bay Area.\n\nVideos of the sessions have been published. I contributed two talks there, one is about the (usual) graphics stuff with Qt (video, slides). The other one is a series of demos of web technologies (video, slides).\n\nThere are some interview videos as well. If you watch Wade and me, you can spot a little guy there. Pay attention to his shirt \n\nThe venue can’t be better, it’s in the center of Japantown. Even better, the weekend after is the Cherry Blossom Festival.\n\n\n\nSince I don’t live in a big city anymore, it’s also fascinating to be able to spot a cozy cafe right between all the big buildings. Right in Japantown, we found YakiniQ which serves a must-try sweet potato latte!\n\n\n\nAll in all, it was a blast for me. Beside catching up with the people I met before, finally I got to meet folks I only know through our online interaction.\n\nKudos to the Camp KDE organizers! See you in 2012.\n\n(`_|_`)Apr 23, 2011(`_|_`)ariya.io(`_|_`)camp-kde-2011', 'camp-kde-2011'),
(288, 'camp kde in 2 weeks(`_|_`)\nMy first Camp KDE experience was when it was held in San Diego, which was also interesting since at that time, I just moved there.\n\nJust like the planets align themselves, apparent my move to the Bay Area is matched with this year Camp KDE in San Francisco. This time, it is co-located with Linux Foundation Collaboration Summit. For more info, just check the official site: camp.kde.org.\n\nThe schedule for the tracks has been finalized, there will be various talks around KDE on Mobile, PIM, and of course Qt. I myself will have two presentations: Introduction to QtWebKit and Efficient Graphics with Qt: Beautiful and Blazing Fast.\n\nSee you there!\n\n(`_|_`)Mar 19, 2011(`_|_`)ariya.io(`_|_`)camp-kde-in-2-weeks', 'camp-kde-in-2-weeks'),
(289, 'SenchaCon 2010(`_|_`)\nAt the last successful, sold-out Sencha Conference 2010, I did two introductory talks about JavaScript and WebKit, mainly targeted for web application developers. Since a few weeks ago, the videos for these talks have been available for you to watch.\n\nJavaScript Engines: Under the Hood is 10,000-foot overview on how a typical JavaScript engine works. Watch it below or at vimeo.com/18783283, with the accompanying slides at http://slidesha.re/gGx9aA.\n\nThe other talk Compiling and Optimizing Your Own Browser with WebKit (vimeo.com/18780399 for the video, http://slidesha.re/fPSvXX for the slide deck), mostly showing few tricks you can leverage to understand how your web applications work. For example, by using QtWebKit and capturing all the drawing commands and the corresponding timestamp, it is very easy to have a slow-motion rendering of your web page. As I showed it in the talk, it is even possible to go back in time, i.e. rendering your web page backwards.\n\nMany other videos from SenchaCon 2010 have been published as well. Make sure you check them out.\n\nEnjoy!\n\n(`_|_`)Mar 12, 2011(`_|_`)ariya.io(`_|_`)senchacon-2010', 'senchacon-2010'),
(290, 'PhantomJS meets CoffeeScript(`_|_`)\n\n\nI did something related to CoffeeScript before, namely simple command-line compiler. For those who are not aware of CoffeeScript, it’s basically (from Wikipedia) JavaScript with “syntactic sugar inspired by Ruby and Python”.\n\nOn the hand, surprisingly PhantomJS generates more interest than I ever imagined before (with over 240 watching its repository), prompting me not to abandon it too soon  In fact, I decided to dump my tought on its roadmap since more and more people are willing to help.\n\nMy secret feature, which is not secret anymore, for the upcoming 1.1 release is to incorporate the CoffeeScript compiler so that PhantomJS scripts can be written in CoffeeScript. Since the intention of PhantomJS is for various scripting purpose utilizing headless QtWebKit, this is a perfect match.\n\nGone are the curly braces…\n\n(`_|_`)Mar 11, 2011(`_|_`)ariya.io(`_|_`)phantomjs-meets-coffeescript', 'phantomjs-meets-coffeescript'),
(291, 'vim: fast file navigation with Command-T(`_|_`)\nJudging from the hits, my blog post on lightning-fast project navigation in vim seems to be still popular. While the Project script is still my favorite these days, especially when dealing with hundreds of files, let me show you here another gem: Command-T script.\n\nSimilar to Command-T in TextMate, basically this Command-T script allows quick and incremental search for files. This works very well. The official site for Command-T has several good screencasts which demonstrate how to install and set it up.\n\n\n\nManual installation is fairly simple. In fact, if you use Janus (which what I strongly do recommend these days for vim lovers), you are already set.\n\nCommand-T’s documentation is quite extensive, make sure you read it. For the impatient, here are three important tidbits.\n\n(1) Command-T requires vim with Ruby support. One way to find this is:\n\nvim --version | grep \'+ruby\'\n\n(2) The default binding is Leader-t. For MacVim (or other GUI-based vim on Mac) and you’d like to have it on your Command-t (or D-T, in vim’s terminology), just insert the following in your .vimrc:\n\nif has(\"gui_macvim\")\n    macmenu &File.New; Tab key=<nop>\n    map <d -t> :CommandT<cr>\n  endif\n</cr></d></nop>\n\n(3) If you like to open the selected file in a new tab, hit Ctrl+T instead of just Enter.\n\nOne side note: if you have MacVim but don’t have the mvim shortcut, add this to your .profile (or .bash_profile):\n\nalias mvim=\'/Applications/MacVim.app/Contents/MacOS/Vim -g\'\n\nThis way, you can launch MacVim from terminal, e.g. mvim code.js.\n\nAnd in case you still want to use TextMate, why don’t you check out TextMate2 instead?\n\n(`_|_`)Feb 22, 2011(`_|_`)ariya.io(`_|_`)vim-fast-file-navigation-with-command-t', 'vim-fast-file-navigation-with-command-t'),
(292, 'color wheel on Canvas(`_|_`)\n\n\nWhile I played with HSV pie and color wheel before, usually I just use the excellent Qt graphics stack to try out various things. This days, I lean towards using web technologies and for that purpose, HTML Canvas suits me just fine. With PhantomJS, I even got the result rendered as PNG image.\n\nThe new example I added to PhantomJS is colorwheel.js which produces the above screenshot. The entire script code is as follows (if some parts look cryptic, read about HSL and HSV color space):\n\nif (phantom.state.length === ) {\n    phantom.state = 1;\n    phantom.viewportSize = { width: 400, height : 400 };\n    phantom.content = \'<html><body><canvas id=\"surface\">\' +\n        \'</canvas></body></html>\';\n} else {\n    var el = document.getElementById(\'surface\'),\n        context = el.getContext(\'2d\'),\n        width = window.innerWidth,\n        height = window.innerHeight,\n        cx = width / 2,\n        cy = height / 2,\n        radius = width  / 2.3,\n        imageData,\n        pixels,\n        hue, sat, value,\n        i = , x, y, rx, ry, d,\n        f, g, p, u, v, w, rgb;\n \n    el.width = width;\n    el.height = height;\n    imageData = context.createImageData(width, height);\n    pixels = imageData.data;\n \n    for (y = ; y &lt; height; y = y + 1) {\n        for (x = ; x &lt; width; x = x + 1, i = i + 4) {\n            rx = x - cx;\n            ry = y - cy;\n            d = rx * rx + ry * ry;\n            if (d < radius * radius) {\n                hue = 6 * (Math.atan2(ry, rx) + Math.PI) / (2 * Math.PI);\n                sat = Math.sqrt(d) / radius;\n                g = Math.floor(hue);\n                f = hue - g;\n                u = 255 * (1 - sat);\n                v = 255 * (1 - sat * f);\n                w = 255 * (1 - sat * (1 - f));\n                pixels[i] = [255, v, u, u, w, 255, 255][g];\n                pixels[i + 1] = [w, 255, 255, v, u, u, w][g];\n                pixels[i + 2] = [u, u, w, 255, 255, v, u][g];\n                pixels[i + 3] = 255;\n            }\n        }\n    }\n \n    context.putImageData(imageData, , );\n    document.body.style.backgroundColor = \'white\';\n    document.body.style.margin = \'0px\';\n \n    phantom.render(\'colorwheel.png\');\n    phantom.exit();\n}\n\n\nBeside the above example, there are few other things which you’ll get in the upcoming PhantomJS 1.1 release, among others support for Unix shebang, file upload for form submission, disable/enable images loading and plugins, as well as support for QUnit integration.\n\n(`_|_`)Feb 21, 2011(`_|_`)ariya.io(`_|_`)color-wheel-on-canvas', 'color-wheel-on-canvas'),
(293, 'virtual globe in the browser(`_|_`)\nLatest stable version of Chrome 9 now has built-in support for WebGL. Hopefully this would increase the amount of people trying out various cool 3-D stuff, from the infamous Aquarium demo to the fancy Jelly Fish animation, and many others.\n\nWhat excites me is the following: WebGL Earth, a free and open-source implementation of a virtual globe using WebGL. The live demo supports showing the map tiles from OpenStreetMap, MapQuest, and Bing. Just awesome!\n\n\n\n(`_|_`)Feb 4, 2011(`_|_`)ariya.io(`_|_`)virtual-globe-in-the-browser', 'virtual-globe-in-the-browser'),
(294, 'PhantomJS: minimalistic headless WebKit-based JavaScript-driven tool(`_|_`)\nPhantomJS is a headless WebKit packaged as a JavaScript-driven tool. It can be used in command-line utilities which requires web stack, or even as the basis for testing rich web application. It uses WebKit in a headless mode, so you get access to the real native and fast implementation (not a simulated environment) of various standards such as DOM, CSS selector, Canvas, SVG, and many others.\n\nThe project page contains a bunch of examples, from easy ones to some more complicated uses. Feel free to contribute more examples!\n\nLet’s look at one of the examples, the page rasterizer (yes, it’s only 16 lines!):\n\nif (phantom.state.length === ) {\n    if (phantom.args.length !== 2) {\n        console.log(\'Usage: rasterize.js URL filename\');\n        phantom.exit();\n    } else {\n        var address = phantom.args[];\n        phantom.state = \'rasterize\';\n        phantom.viewportSize = { width: 600, height: 600 };\n        phantom.open(address);\n    }\n} else {\n    var output = phantom.args[1];\n    phantom.sleep(200);\n    phantom.render(output);\n    phantom.exit();\n}\n\n\nIf I want to have the famous PostScript tiger from its SVG source, all I have to do is to run:\n\nphantomjs rasterize.js http://ariya.github.com/svg/tiger.svg tiger.png\n\nBut static vector graphic is boring. Replacing the above with\n\nphantomjs rasterize.js http://raphaeljs.com/polar-clock.html clock.png\n\ngives me Polar Clock, one notable example from RaphaelJS.\n\n\n\nShould you need to deal with JSONP, process XML, and integrate with YQL, that’s all easily done. Again, refer to the various service integration examples. Let me show one example, which is actually my favorite:\n\nif (phantom.state.length === ) {\n    var origin, dest;\n    if (phantom.args.length < 2) {\n        console.log(\'Usage: direction.js origin destination\');\n        console.log(\'Example: direction.js \"San Diego\" \"Palo Alto\"\');\n        phantom.exit(1);\n    }\n    origin = phantom.args[];\n    dest = phantom.args[1];\n    phantom.state = origin + \' to \' + dest;\n    phantom.open(encodeURI(\'http://maps.googleapis.com/maps/api/directions/xml?origin=\'\n        + origin +  \'&destination;=\' + dest + \n        \'&units;=imperial&mode;=driving&sensor;=false\'));\n} else {\n    if (phantom.loadStatus === \'fail\') {\n        console.log(\'Unable to access network\');\n    } else {\n        var steps;\n        steps = phantom.content.match(/<html_instructions>(.*)/ig);\n        if (steps == null) {\n            console.log(\'No data available for \' + phantom.state);\n        } else {\n            steps.forEach(function (ins) {\n                ins = ins.replace(/</ig, \'< \').replace(/>/ig, \'>\');\n                ins = ins.replace(/<div>ig, \'n<div \');\n                ins = ins.replace(</div>< .*?>/g, \'\');\n                console.log(ins);\n            });\n        }\n    }\n    phantom.exit();\n}</div></div>\n\n\nIf I run it like the following:\n\nphantomjs direction.js \'Redwood City\' \'Sunnyvale\'\n\nwhat I got is the complete driving direction:\n\nHead east on Broadway toward El Camino Real\nTake the 1st left onto El Camino Real\nTurn right at Whipple Ave\nSlight right to merge onto US-101 S toward San Jose\nTake exit 398B to merge onto CA-85 S toward Santa Cruz/Cupertino\nTake exit 22A to merge onto CA-82 S/E El Camino Real toward Sunnyvale\nDestination will be on the right\n\nMap data ©2011 Google\n\n\nMake sure you check out other examples, such as getting weather forecast conditions, finding pizza in New York, looking up approximate location based on IP address, pulling the list of seasonal food, displaying tweets, and many others.\n\nHeadless execution of any web content also enables fast unit testing. Obviously, the goal is not to replace comprehensive, cross-browser framework such as Selenium or Squish for Web. Rather, it serves a quick sanity check just before you check in some changes.\n\nSince this can happen automatically and does not need to launch any browser, even better, you can hook the test so that it executes right before a commit and actually prevents the commit if any of the test fails. It is easily done using git via its hook support. This is something I have written at Sencha blog. It demonstrated precommit hook with Jasmine, but technically it can work with any test framework.\n\nI have been working on and off on PhantomJS for the past few years. You may be already familiar with some of its inspiration (also involving headless WebKit): SVG rasterizer, page capture, visual Google, etc.\n\nFinally I managed to overcome my laziness, cleaned up the code, and published it for your pleasure. Obviously it’s not a surprise if you find out that PhantomJS uses QtWebKit.\n\nI got a few tasks for next PhantomJS version 1.1. You are encouraged to file bugs and feature requests in the said issue tracker.\n\nGet it while it is hot!\n\n(`_|_`)Jan 23, 2011(`_|_`)ariya.io(`_|_`)phantomjs-minimalistic-headless-webkit-based-javascript-driven-tool', 'phantomjs-minimalistic-headless-webkit-based-javascript-driven-tool'),
(295, 'command line CoffeeScript(`_|_`)\nCoffeeScript seems to be picking up some momentum these days. No doubt, it is very valuable to help writing cleaner code.\n\nThe command-line choices to run CoffeeScript compiler right now are either using Rhino (jcoffeescript) or using NodeJS. While I love NodeJS, seems that it is an overkill to require the entire NodeJS stack/infrastructure/package manager to invoke CoffeeScript compiler.\n\nThe solution is to use V8, the powerful JavaScript engine, with a little binding so that it can access file system. This is exactly filejs, something I have shown before, e.g. to invoke JSLint from command line.\n\n\n\nCombining filejs and CoffeeScript is terribly easy. Just follow these steps.\n\nNote: filejs does not support Windows yet. Sorry.\n\nFirst of all, if you have not done it, build filejs. Go to the X2 repository, it is under the javascript/filejs folder. Open the included README.TXT and follow the instructions on how to build V8 and filejs.\n\nAfter you build it, copy both filejs executable and coffee.js to somewhere in your PATH. Usually I stash that kind of stuff in ~/bin and ensure that ~/bin is in my PATH.\n\nNow get coffee-script.js (the CoffeeScript to JavaScript compiler) and store it somewhere, e.g. ~/bin again.\n\nCreate a new file called coffee, which has the following one-line content:\n\nfilejs ~/bin/coffee.js $1\n\nMake that file executable and then save it to ~/bin (again).\n\nOpen coffee.js and modify the value of the compiler variable to point to your coffee-script.js. Note: this must use the absolute path name.\n\nNow you can do the following:\n\ncoffee hello.coffee\n\nIf hello.coffee is your script written in CoffeeScript, the converted JavaScript version will be dumped to the standard output.\n\nFeel free to tweak coffee.js so that it understands and passes various CoffeeScript compiler options!\n\nFun, isn’t it?\n\n(`_|_`)Jan 8, 2011(`_|_`)ariya.io(`_|_`)command-line-coffeescript', 'command-line-coffeescript'),
(296, 'X2 from Ofi Labs: wrap-up 2010(`_|_`)\nIt got started when I needed a new home for my examples. It has even a nice logo.\n\nsensor\n\naccelerometer viewer for Maemo 5 (Nokia N900).\n\nbouncing ball, where the gravity affects the movement of the ball.\n\nbox of marbles, where the gravity affects a bunch of colored marbles.\n\ncombining accelerometer and network to do inter-device marbles transfer.\n\nmotion and orientation for web applications.\n\nweb-based version of marble box.\n\nwidgets\n\nmorphing clock, where the transition between the digital and analog version is a kind of morphing effect.\n\nqpalette viewer so you know which color is which one.\n\ngraphics\n\nfast approximation of Gaussian blur to create a blurry drop shadow.\n\ncommand-line capture tool to save maps from OpenStreetMap, MapQuest and Ovi Maps.\n\nsimple tool to list all chunks inside a PNG image.\n\nwebkit & javascript\n\nfile processing, including using jslint, in command-line using JavaScript.\n\nplay Canvas-based game as normal desktop app.\n\noffline, command line beautifier for JavaScript code, utilizing Qt Script.\n\nanother variant of the beautifier, this time using V8.\n\nminimalistic editing widget for JavaScript code, with custom syntax highlighting.\n\nwhite background is boring? just try some color inverted web pages.\n\ndetect the closest link to ease following it on a touch device.\n\nCanvas pixel manipulation for plasma effect.\n\nnetwork\n\nsimple proxy server for HTTP, in 100 lines.\n\ntracenet: trap all network requests+replies to show them with Speed Tracer.\n\nfilterproxy: another variant of the proxy server with added URL filtering feature.\n\n(`_|_`)Jan 1, 2011(`_|_`)ariya.io(`_|_`)x2-from-ofi-labs-wrap-up-2010', 'x2-from-ofi-labs-wrap-up-2010'),
(297, 'motion vs orientation(`_|_`)\nI already showed the use of device orientation in a fun game called Box of Marbles. Based on my experience trying out this API implementation, often it is easy to get confused by device motion vs device orientation. Thus, I created two web-based applications (using on Sencha Touch): Device Motion and Device Orientation. Each basically just visualizes the values of the data in a bunch of sliders:\n\n\n\nYou can find the code in the usual X2 repository, under the subdirectory javascript/devicemotion and javascript/deviceorientation, respectively. Obviously, the rest of Sencha Touch library is needed before you can deploy and run the examples. For the lazy, just run the live demo for Device Motion and Device Orientation (they support offline mode).\n\nWhile right now only iOS 4.2 on iPhone/iPad/iPod Touch implements this API, I have a strong hope that Android (post Gingerbread) and Nokia (thanks to QtWebKit and Qt Mobility) will support this cool API in the near future. Well, at least I do plan to revive my Symbian setup to custom compile QtWebKit and test it on Nokia N8.\n\nSide note: from my limited understanding, seems that both accelerometer and gyroscope are needed in order to supply the accurate data, much like in an inertial navigation system (“Inertial Phone”, anyone?).\n\n(`_|_`)Dec 16, 2010(`_|_`)ariya.io(`_|_`)motion-vs-orientation', 'motion-vs-orientation'),
(298, 'the art of repository access(`_|_`)\n\n\nWhat will occur when a software team is working on a project? How to tackle the change control?\n\nThe first and foremost obvious approach is simply giving full access for everyone. This is what typically happens in a group of friends working together on a cool project, a school assignment, a short hackathon, an early prototype, or any other collaborative efforts.\n\nWhile this approach is very democratic (all developers are created equal), it is not very scalable. It works on a small and agile team, mainly because everyone knows each other. Once the team grows beyond a certain limit, the overhead of the communication makes it impossible to continuously get a full picture of what is being work on by whom.\n\nUsually this problem is minimized by having somebody responsible for each module, essentially putting some organizational hierarchy in the project. However, a slight problem in the communication (which happens quickly, we’re talking about engineers here) is enough to provoke a situation where conflict occurs due to a certain check in which carries over the problems and bugs from one module to another (Law of Unintended Consequences).\n\nAnother approach, certainly an evolution from the first one, is limited commit access. This particularly works well if there is a dedicated army of maintainers, whose job is to review incoming patches, give feedback, check them in. Usually this approach is very beneficial for the new members of the team, because they can learn what works and what does not work (since they are indirectly guided by the maintainer).\n\nQuality control is definitely easier since all patches will be always filtered. Limiting the damage due to a broken commit is also not difficult since the repository can be frozen while the disaster mitigation team carries out the work.\n\nThis approach however falls apart if there is not enough maintainers and/or the rate of submitted patches increases. The symptoms are easy to spot: patches stay far too long in the queue, a maintainer has no time to do his own development, bad patches sneak in due to the time pressure, etc.\n\nKeep in mind that due to its implicit (often also explicit) social stratification, it is important to take into account what everyone thinks about the approach. There should not be someone who feels left behind because only certain chosen guardians have the ultimate privilege access the repository. When such a situation is not tackled early on, it would grow latently and explode at some point in the future.\n\nIf there is a worry like that, then another (slightly reversal) evolution is inevitable: full access to everyone, as long as the patch is reviewed. The gut of this approach is basically “Let’s trust each other, but let’s also watch each other’s back”. Thus, inherent code review becomes mandated as well. Everyone is free to check in his patch directly to the repository, as long as some other competent fellow has looked at it and gave the green light. In fact, this should be called “brotherhood repository access” except that it may sound too exclusive and mystical.\n\nSometimes the system is also setup as far as rejecting the commit (e.g. from the server-side) when the log does not contained something like Reviewed by: Joe Sixpack. This is of course not always necessary, it may even require a consensus from everyone, under the pretext of preventing accidental check in.\n\nThis last approach may still not work in some situations. For example, if the team is global and located in different time zones, then coordinating the review becomes challenging (distributed control system may alleviate the problem). When code review is not a encouraged culture, counterproductive dead lock can be depressing. Also, because it is based on mutual trust, it breaks down when some people do not play by the same rule. In short, the approach depends heavily on the strong and committed communication between the team members.\n\nIn the end, the repository access approach must be evaluated on a case by case basis. Of course, in some places, no approach will work to satisfy everyone. In that case, consider again that technology can’t and won’t solve every social problem.\n\nWhat kind of repository access do you have in your group? Which one do you prefer and why?\n\n(`_|_`)Dec 13, 2010(`_|_`)ariya.io(`_|_`)the-art-of-repository-access', 'the-art-of-repository-access'),
(299, 'ubiQt(`_|_`)\n \n\nSince coming back from Qt Developer Days 2010 in San Francisco (more precisely in Burlingame, near SF airport), one thought really bothered my mind: “when will Qt become ubiquitous?”.\n\nNow, if you are active in the KDE and Qt community, this seems like a strange question. But ubiquitous means omnipresence, in particular for the whole developer community.\n\nFlash back to ages ago. You wrote a cool Python script (could be also in Ruby, or Lua, pick your battle) to do FooBar, everyone you know was impressed, you wanted to share the love with the world and then some fellow hacker noticed, “That’s cool, man. But I don’t want to install Python, can you give me the executable?”. What would you think?\n\nThe situation is similar with Qt these days. You write a nice Qt-based utility, running on different platforms, somebody spots it and the first thing he asks is “Where is the binary?”; never mind he has just grabbed and installed hundreds MB worth of utilities.\n\nThese days, when you are developing some software, the first thing you’d do on a fresh machine is to download and install a gazillion tools (Xcode with iOS SDK weighs around 3.8 GB). With the initiative towards open governance, I hope Nokia and others will be able to steward Qt in that direction: being included in the de-facto standard of development tool sets. The most interesting challenge is to overcome the doubt, “Why do I need to install some Nokia SDK to use your cool app?”.\n\n(`_|_`)Dec 11, 2010(`_|_`)ariya.io(`_|_`)ubiqt', 'ubiqt'),
(300, 'calligra(`_|_`)\n\n\nLong live Calligra Suite!\n\n(`_|_`)Dec 7, 2010(`_|_`)ariya.io(`_|_`)calligra', 'calligra'),
(301, 'Box of Marbles meets Device Orientation(`_|_`)\nRemember my Box of Marble demo?. It was a native Qt/C++ application running on Maemo-powered Nokia N900.\n\nWith the wave of DeviceOrientation Event Specification implementation, now it’s possible to have the demo as a web app, running just inside the web browser. In fact, this is what you can see from this demo: ariya.github.com/js/marblebox.\n\nRight now, it works with iPhone or iPad or iPod Touch running the new iOS 4.2, due to the brand new DeviceMotionEvent support. If you own a MacBook with accelerometer and you use Google Chrome, that works as well (tilt your laptop to see the gravity effect). But fear not, with the recent support to hook the acceleration data from Qt Mobilty to QtWebKit, don’t be shocked if the next Nokia phone with built-in QtWebKit sports this feature as well.\n\n\n\nWhile my previous demo uses Chipmunk physics engine, this web version relies on box2d-js instead, mostly because I am too lazy to port Chipmunk to JavaScript and also I want to try something else. If you are curious about the code, check the usual X2 repository under javascript/marblebox directory. Enjoy!\n\n(`_|_`)Nov 27, 2010(`_|_`)ariya.io(`_|_`)box-of-marbles-meets-device-orientation', 'box-of-marbles-meets-device-orientation'),
(302, 'V8 + jslint + vim(`_|_`)\n\n\nUsually, you would want to use scripting solution, e.g. Perl/Python/whatever, to manipulate file contents. Somehow, it’s also fun to use JavaScript instead. After I did the V8-based jsbeautify, I was doing V8-based jslint as well. Then I realized, let’s just extend it to be generic. With API loosely modelled after CommonJS, filejs was born. Find it in the usual X2 repository under the javascript/filejs. There are two examples so far, ROT-13 and line counter. If you write more examples, feel free to pass them to me!\n\nOf course, the twist is: use filejs to drive a command-line jslint. This is one way to do it. First build filejs (follow the instructions in the included README), then place the executable in your PATH. Create a simple shell script, which contains one line filejs /path/to/filejs/jslint.js $1 and make it executable. That’s it! If you also store this shell script in your PATH, then you just need to run:\n\njslint source-code.js\n\nIf you use vim, jslint can be combined with Quickfix. First of all, associate *.js with the tool by putting this line in your personal .vimrc:\n\nau FileType javascript set makeprg=jslint %\n\nNow open a JavaScript file and run :make (or whatever shortcut you map this into), which will launch jslint with the current file. After a while, use :cope to open the quickfix little window, move up and down, and press Enter to bring you back to the main editor and set the cursor at the specified problem. Use standard window navigation, e.g. Ctrl+W W to switch to quickfix pane again. Check the quickfix documentation for details. All in all, you may want to map mostly used commands to some shortcuts for faster access.\n\nNote that since this is dynamic JavaScript, rather than matching errorformat, technically I just tweaked the tool to spit something similar to what a C/C++ compiler would do. Also, if you need different jslint options, simply edit the invocation to suit your needs.\n\nIt’s been a while since I blogged about vim. The last one was about the project plugin, which is surprisingly still quite popular. Hopefully this one also teaches you a trick or two, especially if you work a lot with JavaScript code.\n\nNote 1: It does not work on Windows yet. No idea if I would have the time to do it, patch is welcomed.\n\nNote 2: This is not a replacement for NodeJS, nor would it grow to include more functions.\n\nNote 3: For the sake of completeness, let me mention that there are already other countless solutions for command-line jslint (using Rhino, SpiderMonkey, JSC, etc), even with vim integration.\n\n(`_|_`)Nov 10, 2010(`_|_`)ariya.io(`_|_`)v8-jslint-vim', 'v8-jslint-vim'),
(303, 'chunks inside PNG(`_|_`)\nHere is a few minutes of hack which would hopefully help someone else:\n\npngchunks logo.png\nFile size: 5967 byte(s)\n\nOffset    Chunk    Size\n      8    IHDR      13\n     33    iCCP    2627\n   2672    IDAT    3271\n   5955    IEND       0\n\n\nUseful to quickly find out if we can further strip unnecessary chunks from the PNG image. Or even as a warming up before you fire your favorite hex viewer/editor.\n\nIt’s pure, stand-alone, self-contained C code (i.e. compile using gcc -o pngchunks pngchunks.c), available at the usual X2 repository, find it under graphics/pngchunks.\n\n(`_|_`)Nov 9, 2010(`_|_`)ariya.io(`_|_`)chunks-inside-png', 'chunks-inside-png'),
(304, 'the fun of remote JavaScript debugging(`_|_`)\n\n\nRemote feature of Web Inspector, whereby you use an instance of WebKit and debug another one in different machine, is one important feature (that is being worked on) of WebKit I can’t wait to start using. Till that day, remote debugging is always a challenge. There are of course assorted workarounds out there. At Sencha we decide to have and share with you a little tool that helps JavaScript remote debugging. It is available in two flavors: GUI-based (using Qt obviously) and Python-based for scripts and automation. Right now, the target is Android WebKit but there is no reason why we should not march to other platforms as well (e.g. QtWebKit on Symbian and MeeGo). Get it while it’s hot!\n\n(`_|_`)Nov 5, 2010(`_|_`)ariya.io(`_|_`)the-fun-of-remote-javascript-debugging', 'the-fun-of-remote-javascript-debugging'),
(305, 'morphing clock revisited(`_|_`)\nIf you can’t see the clock below, visit the stand alone demo.\n\nTechnically, I had wanted to wait till it can display the actual time and perhaps ask some designer to polish it. But rather than keeping this lunch-break hack in a safe deposit box forever, let me just release this ugly clock transition (since everyone is on the animation frenzy). So far it works only if you use latest version of Safari, Chrome, Opera, Firefox. Canvas and/or VML fallback (which sadly will require JavaScript) for other browser are in the pipeline.\n\nBasically it is another version of my previous morphing clock attempt (see the video). The principle is the same, except now I modified that C++ program to also output an HTML which renders the clock as above.\n\nAlso it morphs only once. Reload the page to enjoy the morphing once more. Maybe I’ll find the time (in another lunch break) to toggle the two clock modes. Update: morphing from/to both analog and digital mode is implemented.\n\nLike I said, it’s a creepy, machine-generated, ugly looking clock. You’ve been warned, but feel free to write me anything (should you need to vent your anger).\n\n(`_|_`)Oct 28, 2010(`_|_`)ariya.io(`_|_`)morphing-clock-revisited', 'morphing-clock-revisited'),
(306, 'Look ma, no JavaScript!(`_|_`)\nTake a look at the following CSS 3 demo. No Flash. No JavaScript. No image.\n\nHungry for more? Enjoy some other demos created using Sencha Animator.\n\n(`_|_`)Oct 27, 2010(`_|_`)ariya.io(`_|_`)look-ma-no-javascript', 'look-ma-no-javascript'),
(307, 'Qt Developer Days, Bay Area Mobile meetup(`_|_`)\n\n\nWe heard that Munich Qt Developer Days was an awesome event, which is why I look forward to the San Francisco Qt Developer Days, which will be held November 1-3.\n\nNow, if you are from outside US, drop me an email in case you fancy some quality tea/coffee time. Even better, on the next day (November 4), Sencha will host the first Meet the Sencha Team, the first Bay Area Mobile meetup. Our team will give an overview of Sencha and the mobile technologies we are developing. RSVP and drop by!\n\n\n\n(`_|_`)Oct 18, 2010(`_|_`)ariya.io(`_|_`)qt-developer-days-bay-area-mobile-meetup', 'qt-developer-days-bay-area-mobile-meetup'),
(308, 'sencha touch hackathon(`_|_`)\n\n\nAre you in the Bay Area? Don’t miss our Sencha Touch Hackathon this Saturday (Oct 16) in our Palo Alto Office, 1pm to 5pm. There will be food and drinks as well.\n\nDrop by and upgrade your Sencha Touch kungfu!\n\n(`_|_`)Oct 14, 2010(`_|_`)ariya.io(`_|_`)sencha-touch-hackathon', 'sencha-touch-hackathon'),
(309, 'yet another command-line JavaScript beautifier (based on V8)(`_|_`)\nWhile we’re still on the topic of JavaScript, I took the afternoon break to create a command-line runner for jsbeautifier.org . In case you miss it, I did the similar thing using Qt Script module. This time however, the command-line tool uses and exploits Google V8 instead.\n\nIf you update your clone of js-beautify repository, check out the fresh v8 subdirectory. I also mirror the code in the usual X2 repository, under the javascript/jsbeautify8 subdirectory. Also, grok the included README.txt first.\n\nUpdate: I added –overwrite option which (surprise!) will overwrite the original source file (and thus, use it with care). This is useful if you invoke the beautifier tool from your text editor. Nicolas also implemented various settings support so you can specify the indentation level, braces placement, etc.\n\nThis is probably the last thing the world needs now, but hey, it was a fun break.\n\n(`_|_`)Oct 14, 2010(`_|_`)ariya.io(`_|_`)yet-another-command-line-javascript-beautifier-based-on-v8', 'yet-another-command-line-javascript-beautifier-based-on-v8');
INSERT INTO `ariyaio` (`id`, `content`, `url`) VALUES
(310, 'on JavaScript engines(`_|_`)\nIf you are using a modern browser, likely you already have the (arguably) most widely deployed scripting environment: JavaScript engine (or ECMAScript, if you insist). There are many things you can do with it (just look at tons of cool web apps out there). However, since it is contained in the browser, there are also things the embedded JavaScript engine can not do for you.\n\nIf you are using KDE, you also have two excellent JavaScript engines: KJS and Qt Script. You can embed either of them (i.e. KJSEmbed) and make your application scriptable. In a not-so-strange twist, they both relate (distantly) to each other via JavaScriptCore, WebKit’s default JavaScript engine, because\n\nlong time ago Apple forked KJS and used it as the base for JavaScriptCore, and Qt Script (for version 4.6 and 4.7) also uses JavaScriptCore as the back-end.\n\nIf you are interested in learning, using, and/or dissecting other open-source JavaScript engines, have a look at JavaScript Engines: How to Compile Them I wrote for our Sencha blog, which covers Mozilla’s SpiderMonkey, WebKit’s JavaScriptCore, and Google V8. The instructions should work on the supported platforms, including ARM, in case (just like me) you want to have and carry around every JavaScript engines in this planet on your Maemo-powered Nokia N900. That is fun.\n\nAs the closing, just remember, “Ask not what the JavaScript engine can do for you — ask what you can do for the JavaScript engine”.\n\n(`_|_`)Oct 13, 2010(`_|_`)ariya.io(`_|_`)on-javascript-engines', 'on-javascript-engines'),
(311, 'cinquantamila(`_|_`)\n\n\n’nuff said, head to www.sencha.com/contest!\n\n(`_|_`)Oct 8, 2010(`_|_`)ariya.io(`_|_`)cinquantamila', 'cinquantamila'),
(312, 'color inversion for web pages(`_|_`)\nSomething I worked on during my last few weeks with Qualcomm was color inversion for the web browser in Android. The patch was then integrated by Enrico (see the diff) because I switched job.\n\nLater on this feature was also pulled into CyanogenMod. Thus, if you are running CyanogenMod 6 on your shiny Android device, you can try this feature already! In the web browser, just pick the Settings menu and then scroll a bit until you see a checkbox for Invert Color. You should get something like the captured screens below:\n\n\n\nThe idea behind this is to reduce the power consumption of Organic LED display, because on mostly-white web page, it hungrily grabs to 3x more power compared to LCD. This is similar to Jeff’s trick of applying color filter in SurfaceFlinger.\n\nDoing it at the user-space level gives one advantage: we can keep the embedded images non-inverted. Blindly inverting the entire screen would result in web pages look rather funky, especially those new sites with photos to accompany the articles. Of course, this hackish approach will not work 100%, (hint: double XOR?) since the web designer likely never intend the page to be color inverted. However it seems to work most of the time, at least with pages which do not have ueberartistic look-and-feel.\n\nFaithful followers of my blog know that I already played with the color inversion ages ago, in the form of giving night mode appearance for QWebView. Thus, it happened that in one afternoon break I played with QtWebKit to do something similar to this selective color inversion.\n\nNow, in the case of Android WebKit, the effect was rather easy to achieve. This is because Skia’s SkCanvas is basically an interface which can be subclassed easily, while none of the functions in QPainter is virtual. The trick using Skia was to use a proxy canvas (a slight variation of Skia’s built-in SkProxyCanvas) which I invented for this purpose but somehow also useful for another feature.\n\nFor QtWebKit however, we need to tweak it with some QPaintEngine voodoo. Check out the code at the usual X2 repository, find it under webkit/nightcapture (it still has some rooms for improvement, left as exercises for the adventurous readers). For simplicity, I made it as capturing tool so you need to pass a URL and the output filename. Unless you do something wrong, expect to get something like this:\n\n\n\nThe trick is the same as my approach for the Android patch: invert the colors of each image before drawing it, at the end invert the entire viewport. This seems like slow, but it’s the best compromise I found out working with most sites. Note how we skip inverting any brush pixmap as usually brush is for the tiled background (and thus we want to keep it that way, i.e. not inverted). You can do some fancy magic with clipping and whatnot, but I doubt the end result is much better. Again, this whole stuff is a hack anyway and there will be always corner cases which will not work, no matter what approach you pick, thus there is no need to make it more complicated that it should be.\n\nJust like they say, we code for life, i.e. the battery life.\n\n(`_|_`)Oct 6, 2010(`_|_`)ariya.io(`_|_`)color-inversion-for-web-pages', 'color-inversion-for-web-pages'),
(313, 'quattroporte and hummingbird(`_|_`)\n\n\nFermi problem of the day, anyone?\n\nAssume there is this large organization, say with over ten thousands employees. For some (legal) reason, each employee needs to write down what she has been doing for the week, usually by Friday afternoon. Some record everything in details (down to the hours), some prefer to just express “8 hours doing FooBar” for every working day.\n\nSince this is 2010, usually the system is web-based. To prevent abuse, some login/credential check and anti-bot system are also in place. It is often unheard that people use their beloved smartphones to do the job.\n\nLet us say it takes one minute to do this. With a really conservative $30/hour rate, this is worth 50 cents. Assume ten thousands do that, so it’s worth $5,000. This translates to $260,000 per year.\n\nOf course this is just a gross approximation. It does not even include/exclude the extra time the managers spend to double-check their staff’s entries, typically (much) higher hourly rates, non-working (also known as vacation time), wasted effort to setup (and forget) the reminders, occasional weekend shock at times you forgot it, and other similar (intangible) overhead. Or if you just need 5 seconds to accomplish the task. But you get the idea.\n\nNow, $260,000 is a lot of money. You can buy a decent house in San Diego. Or two shiny Maserati Quattroporte. Or several hundreds Hummingbird-powered phones. Or, in some parts of the world, access to fresh water for the entire city all year long.\n\nSurely for a quarter million per year some smart people will figure something out?\n\n(`_|_`)Oct 3, 2010(`_|_`)ariya.io(`_|_`)quattroporte-and-hummingbird', 'quattroporte-and-hummingbird'),
(314, 'invade & destroy(`_|_`)\nDeveloping games using HTML5 Canvas and JavaScript is simply the future. Something classic like Egor Balishev’s RGB Invader, an entry in the 10K Apart, is usually my favorite.\n\nIf for some reasons (which I would not elaborate in this post) you need to deploy the game as a desktop or a mobile application, using Canvas and JavaScript gives another advantage: just package it with WebKit, for example QtWebKit if you do not mind using Qt.\n\nHowever, since usually it is just about Canvas, often it is enough to run the game logic with a JavaScript interpreter and use some Canvas implementation for the display. This was something that I demonstrated before, i.e. running the Monster Evolution demo via JavaScriptCore and V8. Applying the same technique, and adjusting the shim so that it layers whatever RGB Invader requires, gives the following:\n\n\n\nBasically it is using Qt Script (also in attempt to popularize it even more) along with a mix of C++/QObject and JavaScript machinery to fool the game code to think it’s running in a browser environment. It was a nice afternoon fun project.\n\nThe code is in the X2 repository, find it under the javascript/invader directory. Get it while it’s hot, and save our Earth!\n\n(`_|_`)Sep 24, 2010(`_|_`)ariya.io(`_|_`)invade-destroy', 'invade-destroy'),
(315, 'offline, command-line beautifier for JavaScript code(`_|_`)\nThere are many different ways to autoformat JavaScript code, my favorite is always jsbeautifier.org. Apparently, you can also use it locally without a web browser since it supports running it with Rhino.\n\nIt took me just few minutes to reimplement the same functionality, but using Qt Script, the fantastic ECMAScript support built into Qt.\n\nThe code is in the usual X2 repository, under the javascript/jsbeautify. Note that this is just a convenient mirror as Einar’s js-beautify repository already includes this Qt Script driver.\n\nWith the rise of server-side JavaScript and desktop-esque JavaScript tools, I hope Qt Script will become more popular. It is sadly still “underrated” right now.\n\n(`_|_`)Sep 20, 2010(`_|_`)ariya.io(`_|_`)offline-command-line-beautifier-for-javascript-code', 'offline-command-line-beautifier-for-javascript-code'),
(316, 'san francisco(`_|_`)\n\n\nI have been in Qt Developer Days twice, in the previous two years. This year I am still going there, but only the San Francisco event, for the first time as a participant (as opposed to as a speaker). I’ll bring other new engineers at Sencha, too.\n\nSince I live in the Bay Area these days, feel free to email me should you want to meet for coffee/lunch/dinner. See you there!\n\n(`_|_`)Sep 18, 2010(`_|_`)ariya.io(`_|_`)san-francisco', 'san-francisco'),
(317, 'geocoding based on IP address(`_|_`)\nGiven an IP address, there are different ways to obtain the approximate location: online web service or offline database. It is far from perfect, but it is very useful to give some initial guess before locking into GPS signals or using WiFi-based tracking.\n\nToday’s example for X2 is actually an old code lying around which does the former: relying on IpInfoDB web service to guess where your computer is. Combined with the previous example, MapSnap, the guessed position is used to center the shown map (OpenStreetMap, of course).\n\n\n\nOf course, as with other examples, it works fine on Maemo-powered Nokia N900 as well. Feel free to give it a try on Symbian or other supported Qt platforms.\n\nThe code is found in the usual X2 repository, under the sensor/ipgeocoder subdirectory.\n\nFor completeness’ sake, let me mention also that Matteo did something similar, using hostip.info and Google Maps via QtWebKit.\n\n(`_|_`)Sep 13, 2010(`_|_`)ariya.io(`_|_`)geocoding-based-on-ip-address', 'geocoding-based-on-ip-address'),
(318, 'capture OpenStreetMap and MapQuest (and Ovi Maps)(`_|_`)\nOver a year ago, I showed how to render OpenStreetMap on your Qt application. While there were few follow-ups after that, I never found some time to clean it up. But worry no more, here is one OpenStreetMap-related example (at roughly 250 lines of code) I just made public, freshly available from X2 repository under the graphics/mapsnap. It’s operated from command line, basically you pass the center latitude and longitude, zoom level (1..17, with 17 is the detailed, street-level zoom), output filename (e.g. mymap.png), and the size.\n\nThe following image is the result of running:\n\nmapsnap 37.45108 -122.15917 12 sample.png 600 450\n\nThe tool will grab the tiles, more precisely Mapnik-rendered tile images, and stitch them for the final outcome:\n\n\n\nFew weeks ago I wrote about MapQuest embracing OpenStreetMap. One positive impact of this awesome move is that you can show OpenStreetMap-based MapQuest tiles in your application. It’s just the same map data but rendered using different styles. Running the previous example but with MapQuest flavor gives the following:\n\n\n\nWhen checking out Qt Mobility after its 1.1 TP announcement, I found out that its Maps/Navigation API actually uses the tile data from Ovi Maps. If you read the source code, the tile server encoding scheme is pretty obvious. Since it is also based on Mercator projection, changing this MapSnap example to use tiles from Ovi Maps is a breeze: it’s a matter of setting up the correct tileURL.\n\n\n\nI’m curious about the terms of such Ovi Maps tile usage, though. Although it is more or less “exposed” via Qt Mobility and there is no API key whatsoever, surely it should not mean the tiles are free for everyone, should it? As a comparison, Google Static Maps API specifically allows only browser-based application. Feel free to share your investigation!\n\n(`_|_`)Sep 13, 2010(`_|_`)ariya.io(`_|_`)capture-openstreetmap-and-mapquest-and-ovi-maps', 'capture-openstreetmap-and-mapquest-and-ovi-maps'),
(319, 'minimalistic JavaScript editing widget(`_|_`)\nIn the spirit of clean-up-and-publish, here is another code example of X2: a subclass of QPlainTextEdit which acts as a nice and minimalistic JavaScript editor. Basically it just adds a sidebar for the line number and a syntax highlighter. Thanks to QPlainTextEdit and QSyntaxHighlighter, this editing widget is quite performant. At just about 500 lines, think about it as another example on how to use these two classes.\n\n\n\nIt does support specifying different colors so you can have funky color scheme if you want:\n\n\n\nThe widget is BSD licensed. Find it out in the X2 repository under the javascript/jsedit subdirectory.\n\nIt does not have fancy features such as code folding or autocomplete (not sure I would have time to add them, so patches are welcomed!), but if you want feature packed editor, use QScintilla, KDE’s Kate, Qt Creator’s editor, or grab something else or even write your own.\n\n(`_|_`)Sep 11, 2010(`_|_`)ariya.io(`_|_`)minimalistic-javascript-editing-widget', 'minimalistic-javascript-editing-widget'),
(320, 'Eid Mubarak(`_|_`)\nHappy Eid Al-Fitr to all!\n\n(`_|_`)Sep 10, 2010(`_|_`)ariya.io(`_|_`)eid-mubarak', 'eid-mubarak'),
(321, 'the art of blurring the shadow(`_|_`)\nIn the recent weeks, sporadically I have been working on QtWebKit to fix the missing blur support for Canvas and CSS shadow (see the tracking bug 34479). This brings some good memory; before I left Nokia, I was involved in prototyping the special effect stuff, both for the low-level (non-public) QPixmapFilter and the high-level QGraphicsEffect.\n\nUsually blurring drop shadow for a shape is a very typical: grab the alpha channel of the shape, apply the blur filter, and finally tint it with the intended shadow color. The last step is trivial using the SourceIn composition mode. The blur filter is supposed to follow the SVG specification on feGaussianBlur. The said specification mentions one possible way to approximate the perfect Gaussian blur: three successive box blurs.\n\nSince QPixmapFilter is private anyway and QGraphicsEffect is not suitable for this task, an attempt to implement what the specification outlines became my hobby for a few evenings. This is basically what emerges as the shadow blur implementation in QtWebKit. For the sake of code reuse, I pushed the implementation to the X2 repository under the graphics/shadowblur subdirectory. The shadowBlur() function itself is BSD licensed, there is a demo program included for your pleasure:\n\n\n\nPerformance-wise, the code is as satisfactory (for such a portable implementation). Another good approach is to use stack blur, adopted among others by AGG. KHTML notably uses stack blur for its Canvas shadow blur support. Exponential blur is known to be very fast, although quality-wise it deviates farther from a true Gaussian one. The portable, raster version of QGraphicsDropShadowEffect (via QPixmapFilter) is using this algorithm.\n\nFor this particular use-case, namely blurring the shadow (as opposed to generic blur filter), I’m surprised that the Gaussian blur approximation is not necessary slower than KHTML’s stack blur approach or even QGraphicsDropShadowEffect’s exponential blur. I did a quick benchmark, measuring the time spent creating the shadow for two images (horizontal 149×13 and vertical 13×149) for different radii (small 4px and medium 17px), on a Core i7 machine. The outcome is shown in the following bar chart. The result was from several runs, with the overall confidence level observed to make sure it was statistically sound. Still, take it with a pinch of salt.\n\n\n\nWith a very large blur radius, e.g. 50, stack blur performance deteriorates quickly, probably because the pre-loop initial setup. Exponential blur is pretty much radius-agnostic, although I can’t find cases where it wins against my shadow blur code (which is BTW only 60 lines). Larger source images would highlight the performance difference even more. Maybe I am doing something wrong, or maybe that’s how it is. In any case, I insert a low-priority entry in my (already infinite) TODO list: spend some quality evenings with callgrind and examine those blur implementations.\n\nOn mobile devices however the situation is reversed. The approximated Gaussian blur is consistently slower, around 10%, compared to exponential or stack blur, when tested on 600 MHz Cortex A8-powered Nokia N900. Due to slower memory speed and smaller cache, the repetitive memory access for the successive box blurs cancels its fast processing benefit. Hopefully the 1 GHz generation CPU (like in Nokia N8) and improved memory bus will eliminate this minor slow down.\n\nAnyway, in all cases, just like Andreas mentioned, now you can enjoy the fancy Parcycle demo in its full glory:\n\n\n\n(`_|_`)Sep 9, 2010(`_|_`)ariya.io(`_|_`)the-art-of-blurring-the-shadow', 'the-art-of-blurring-the-shadow'),
(322, 'Sencha Touch and N900(`_|_`)\nBeing part of the awesome Sencha Team, I did shoot a quick attempt to run Sencha Touch, more precisely its Kitchen Sink demo, on Maemo-powered Nokia N900. Since Sencha Touch targets WebKit but Maemo default browser is Gecko/Firefox-based, I crafted a mini launcher which wraps Sencha Touch in QtWebKit. The screenshots below serve as the proof:\n\n\n\nMost of the stuff works just fine. There are some minor issues and performance problems, but I worry not. With the amazing amount of optimizations Qt+Nokia put in place for Qt 4.7 and QtWebKit 2.x, writing applications for Maemo/MeeGo will be fun (again).\n\n(`_|_`)Sep 8, 2010(`_|_`)ariya.io(`_|_`)sencha-touch-and-n900', 'sencha-touch-and-n900'),
(323, 'box of marbles redux(`_|_`)\nIf you enjoy the box of marbles demo, now we extend it to include some basic network support. The premise is simple, look at this short video first (or watch on YouTube):\n\n\n\nThe code to handle the physics of the marbles remains the same, i.e. we just use Chipmunk physics engine. However, I added a simple feature to transfer marbles from one place to another. To keep it simple, it is done using UDP. The Qt network module supports UDP quite well, making the datagram code short and readable.\n\n\n\nThe intended use of this example is easy: run the desktop version and then run the mobile version (tested with Nokia N900). Each instance should find each other and start communicating. Again, we simplify the situation here and handle only 2 (two) peers. To facilitate troubleshooting, the application window title will contain the network address information, if the two peers are fully connected. To avoid complicated setup, discovery is carried out automagically through broadcast. This makes such a demo runs only under the same subnet, which is not a big deal.\n\nIt would have been much more fun doing the transfer between two smartphones (instead of a phone and my laptop). However, I own only one Nokia N900. Hint: I will not refuse your donation of Nokia N8 or (preferably) MeeGo-powered  Nokia N9 (i.e. the N900’s successor, whatever the real name is).\n\nIf you want to give it a try, head to the usual X2 repository and look at demo/marblenet subdirectory. Again, have the patient to follow the README file before you start compiling it.\n\nOf course, feel free to extend this example to suit your (more wild) fantasy!\n\n(`_|_`)Aug 18, 2010(`_|_`)ariya.io(`_|_`)box-of-marbles-redux', 'box-of-marbles-redux'),
(324, 'adventure to the land of green tea(`_|_`)\n\n\nNow I work for Sencha, the company behind the leading JavaScript frameworks such as Sencha Touch, Ext JS, Ext GWT, Ext Designer, jQTouch, Raphaël, Connect, which empower developers to create, deploy and optimize application using web-standard technologies (HTML5, CSS, JavaScript). Beside, it’s a hot startup to work for.\n\n(`_|_`)Aug 11, 2010(`_|_`)ariya.io(`_|_`)adventure-to-the-land-of-green-tea', 'adventure-to-the-land-of-green-tea'),
(325, 'quattro cinque(`_|_`)\n\n\nIt’s released!\n\n(`_|_`)Aug 11, 2010(`_|_`)ariya.io(`_|_`)quattro-cinque', 'quattro-cinque'),
(326, 'box of marbles(`_|_`)\nThe next logical step after simple bouncing ball example is something which uses a real, full-featured physics engine. Box2D is usually the popular choice. Combining Box2D with Qt has been done by many people, recently demonstrated before by Andreas and Thorbjørn. I decided to pick something else, i.e. Chipmunk physics engine.\n\nBecause this is supposed to an example, I tried to make it as simple as possible (you’d be able to extend it, once you grab the basics). Basically we have a box full of colorful marbles (yes, I loved to play marbles when I was a kid, there was not any PlayStation back then). A mouse click, or a screen tap, will generated a new marble with a random color. If you run the example on Nokia N900, you can control how the marbles move and hit each other by tilting and shaking the phone.\n\n\n\nCheck the code yourself at the usual X2 repository under the demo/marblebox subdirectory. Make sure you open and follow the instructions in the included README file.\n\nFor a sneak peek, just watch this video (or enjoy on YouTube).\n\n\n\nThere is still a sequel to this marble box. And still with Chipmunk.\n\n(`_|_`)Aug 10, 2010(`_|_`)ariya.io(`_|_`)box-of-marbles', 'box-of-marbles'),
(327, 'what is it with this froyo obsession(`_|_`)\nEclair still rocks \n\n\n\n(`_|_`)Aug 10, 2010(`_|_`)ariya.io(`_|_`)what-is-it-with-this-froyo-obsession', 'what-is-it-with-this-froyo-obsession'),
(328, 'bouncing ball with accelerometer on N900(`_|_`)\nFirst of all, I apologize for my laziness in updating X2 with new code example. I have actually written quite a number of interesting examples, some of which have even been shown back in March, during my talk at Bossa Conference 10, though I did not find the time to clean up and polish them. Although I’d face new challenges in my upcoming adventure, I am quite confident I will reach the designated rate of new X2 example fortnightly.\n\nNow let’s focus on the newest example: a minor modification to the previous accelerometer code on Nokia N900 [1]. There has been confusion with my statement there: put this function is a separate thread. This is the alternative to a non-blocking D-Bus code. The main goal of course is not to be able to get faster acceleration values per second, it is only to prevent your code from being blocked by the synchronous D-Bus call.\n\nRather than just updating the code with the threaded version, I also added some high-school Newtonian physics. Instead of boring sliders, you’ll get a ball which moves based on the acceleration [2], i.e. it follows the gravity if you keep your N900 straight.\n\nHere is the obligatory video. Or watch directly on YouTube.\n\n\n\nThe code can be found in the X2 repository under the sensor/bouncingball subdirectory.\n\nIn the next installment, we will integrate a third-party real physics engine and make the example more alive!\n\n[1] Another approach is to use Qt Mobility. However, QTMOBILITY-381 (which was spawn from QTMOBILITY-326) has not been solved yet (as of today).\n\n[2] The overall math is not too scientifically correct, but hey, I always need to leave out something, for your homework \n\n(`_|_`)Aug 9, 2010(`_|_`)ariya.io(`_|_`)bouncing-ball-with-accelerometer-on-n900', 'bouncing-ball-with-accelerometer-on-n900'),
(329, 'even LOST has its season finale(`_|_`)\n\n\nToday is my last day at Qualcomm.\n\nIt still feels like yesterday when I set foot in this continent, started some fun with X2, enjoyed Brazil, had this meet-up in Cupertino, did little exploration around San Diego, and then got blessed with a cute boy. Time really flies. Now it’s already time to move on, again (though this time without a geeky resignation).\n\nI will miss Snapdragon (the pictured HTC EVO is powered by the said platform). Or any other dragons.\n\nThose who are annoyed by a certain obsession of mine probably can guess where I’m heading to. In the grand mission of inspiring and pushing developers to write better and more exciting applications, a particular productivity barrier needs to be broken. And I dropped enough (subtle) hints in my previous blog entries already.\n\nStay tuned.\n\n(`_|_`)Aug 6, 2010(`_|_`)ariya.io(`_|_`)even-lost-has-its-season-finale', 'even-lost-has-its-season-finale'),
(330, 'crowdsourcing for the win(`_|_`)\nIn some news, MapQuest embraces OpenStreetMap, launches the maps site at open.mapquest.co.uk using the data from OpenStreetMap, as well as sets aside $1 million funding to improve the maps situation in USA. Let’s see if other maps services will follow.\n\n\n\n(`_|_`)Aug 2, 2010(`_|_`)ariya.io(`_|_`)crowdsourcing-for-the-win', 'crowdsourcing-for-the-win'),
(331, 'var Adam = new Child(Ariya);(`_|_`)\n\nAdam.prototype Human > Adam.timestamp 1279148700 > Adam.length 50.17 > Adam.weight 3.4 > Adam.health Checking…. Good > Adam.mother.health Checking… Good > Adam.father.status “Happy”\n\n\n(`_|_`)Jul 16, 2010(`_|_`)ariya.io(`_|_`)var-adam-new-childariya', 'var-adam-new-childariya'),
(332, 'faster quaternion multiplication(`_|_`)\nSweet memories, it was fun to derive it.\n\nFaster here however must be taken with a grain of salt as the new code is not always guaranteed to be better pipelined.\n\nAnd of course, it’s trivial to beat this generic C code with architecture-specific hand-rolled assembly.\n\ngit show cbc22908\ncommit cbc229081a9df67a577b4bea61ad6aac52d470cb\nAuthor: Ariya Hidayat <ariya .hidayat>\nDate:   Tue Jun 30 11:18:03 2009 +0200\n\n    Faster quaternion multiplications.\n    \n    Use the known factorization trick to speed-up quaternion multiplication.\n    Now we need only 9 floating-point multiplications, instead of 16 (but\n    at the cost of extra additions and subtractions).\n    \n    Callgrind shows that the function now takes 299 instructions instead of\n    318 instructions, which is not a big win. However I assume the speed-up\n    has a better effect for mobile CPU, where multiplications are more\n    expensive.\n    \n    Reviewed-by: Rhys Weatherley\n\ndiff --git a/src/gui/math3d/qquaternion.h b/src/gui/math3d/qquaternion.h\nindex 55c871d..9a1b590 100644\n--- a/src/gui/math3d/qquaternion.h\n+++ b/src/gui/math3d/qquaternion.h\n@@ -198,24 +198,17 @@ inline QQuaternion &QQuaternion;::operator*=(qreal factor)\n \n inline const QQuaternion operator*(const QQuaternion &q1;, const QQuaternion& q2)\n {\n-    // Algorithm from:\n-    // http://www.j3d.org/matrix_faq/matrfaq_latest.html#Q53\n-    float x = q1.wp * q2.xp +\n-                    q1.xp * q2.wp +\n-                    q1.yp * q2.zp -\n-                    q1.zp * q2.yp;\n-    float y = q1.wp * q2.yp +\n-                    q1.yp * q2.wp +\n-                    q1.zp * q2.xp -\n-                    q1.xp * q2.zp;\n-    float z = q1.wp * q2.zp +\n-                    q1.zp * q2.wp +\n-                    q1.xp * q2.yp -\n-                    q1.yp * q2.xp;\n-    float w = q1.wp * q2.wp -\n-                    q1.xp * q2.xp -\n-                    q1.yp * q2.yp -\n-                    q1.zp * q2.zp;\n+    float ww = (q1.zp + q1.xp) * (q2.xp + q2.yp);\n+    float yy = (q1.wp - q1.yp) * (q2.wp + q2.zp);\n+    float zz = (q1.wp + q1.yp) * (q2.wp - q2.zp);\n+    float xx = ww + yy + zz;\n+    float qq = 0.5 * (xx + (q1.zp - q1.xp) * (q2.xp - q2.yp));\n+\n+    float w = qq - ww + (q1.zp - q1.yp) * (q2.yp - q2.zp);\n+    float x = qq - xx + (q1.xp + q1.wp) * (q2.xp + q2.wp);\n+    float y = qq - yy + (q1.wp - q1.xp) * (q2.yp + q2.zp);\n+    float z = qq - zz + (q1.zp + q1.yp) * (q2.wp - q2.xp);\n+\n     return QQuaternion(w, x, y, z, 1);\n }\n</ariya>\n\n(`_|_`)Jul 9, 2010(`_|_`)ariya.io(`_|_`)faster-quaternion-multiplication', 'faster-quaternion-multiplication'),
(333, 'proxy server with filtering feature(`_|_`)\nBeside exploring San Diego, I had done some coding intermittently only. My apology if I do not update X2 with fresh new examples often enough.\n\nHaving said that, here is one network-related example: a minor tweak to the previous example of Qt-based proxy server. Basically it adds a minimalistic URL filtering support, in the form of blacklisting certain URLs which start with some predefined strings. The code is available in the usual place, X2 repository, under the directory network/filterproxy.\n\nWhile major browsers support some variants of content blocking, be it via an extension like AdBlock or as a feature built-in into the browser itself, this new filterproxy should work with any browser that supports proxy. Alas, I did not bother to implement an AdBlock-compatible rule system because it would complicate the code. Again, consider this is a proof of concept only. A challenging exercise would be to fully support the most known subscription filters.\n\nIt is unheard that content filtering can dramatically improve your browsing experience. Because it cuts the bandwidth usage, it does translate to lower cost for those who are not lucky enough to get unlimited data plan. But most importantly, throwing garbage out of the web pages definitely speeds up the page loading. For this filterproxy example, I did a very unscientific benchmark and test it with Detik.com news site (now you get the answer why the included blacklist.txt contains only some basic advertisement-laden sites). The screenshots below (click to enlarge) show the unfiltered version (left) and the filtered version (right). Notice also the whopping 40% of bandwith saving!\n\n\n\nMy promise was to post two variations from that simple proxy example. This counts as one of them, and when the time allows me to clean-up to the other, you’ll know it. Stay tuned and happy proxying!\n\n(`_|_`)Jun 21, 2010(`_|_`)ariya.io(`_|_`)proxy-server-with-filtering-feature', 'proxy-server-with-filtering-feature'),
(334, 'spring-to-summer: photo blog(`_|_`)\nSince I’ve not been blogging for a while, let me do a post on some pictures (plus the stories) instead.\n\nOn a weekend, Balboa Park is a very nice attraction. Rather than explaining it in details, I suggest to just drop the park a visit. Beside a lot of different types of museum, there is also this Japanese Friendship Garden. A small cafe there, the Tea Pavillion, is a very nice place to relax and enjoy the surrounding. They serve sencha and other types of tea. Hungry? Get a rice bowl:\n\n\n\nIf you are more a beach person instead, then there is a plenty of choices, for example Silver Strand Beach. It is rather small, but it is always a nice spot to enjoy the sunset.\n\n\n\nWhen I was at Google IO, I took some pictures of the large overhang banners because I wanted to test the 8 megapixel camera of HTC EVO 4G that Google gave away (see more in the complete set):\n\n\n\nGetting a fantastic gift for the Father’s day? Thinking of something for the next Mother’s Day? What about a beautiful pendant (get one from LuShae Jewelry) like what my other better half elegantly captured below?\n\n\n\n(`_|_`)Jun 21, 2010(`_|_`)ariya.io(`_|_`)spring-to-summer-photo-blog', 'spring-to-summer-photo-blog'),
(335, 'google io 2010(`_|_`)\nIn few hours, I am scheduled to fly to San Francisco, bracing for the impact of Google I/O 2010!\n\n\n\n(`_|_`)May 18, 2010(`_|_`)ariya.io(`_|_`)google-io-2010', 'google-io-2010'),
(336, 'Quake and WebGL(`_|_`)\nWhile I’m there, let me just quickly blog about it. Using the developer version of Chromium on OpenSUSE, I just run it with the following arguments:\n\n/usr/bin/chromium --enable-webgl --in-process-webgl\n\nand then I have WebGL at my fingertip. You can test it with some O3D samples (the pool one is pretty cool).\n\nIn fact, just go ahead and play Quake II at http://playwebgl.com/games/quake-2-webgl/.\n\n\n\nI got bad FPS because I own a cheap laptop (8 FPS is more than what I expect from a $330 box). Obviously you can get 25 FPS or more on a much better machine!\n\n(`_|_`)May 18, 2010(`_|_`)ariya.io(`_|_`)quake-and-webgl', 'quake-and-webgl'),
(337, 'QNetworkAccessManager, tracenet, Speed Tracer(`_|_`)\nJust like Rich’s trick with QNetworkAccessManager, I have done something similar which I call tracenet (around 150 lines of code). Though I have committed this example to X2 some time ago, only now I have the chance to blog about it.\n\nThe idea is to subclass QNetworkAccessManager and reimplement its createRequest method so that we can keep track all the network responses and replies. This is useful for your network-based application, or even for e.g. QtWebKit. As a matter of fact, the tracenet example captures the network traffic as you load a URL into a web page.\n\nNow, the next step is how to visualize the result. While it’s certainly possible to craft a Qt-based fancy GUI for this (maybe using Qt Quick?), let’s think outside the box. Unless you live in a cave, I am sure you are aware that there is this nice tool called Speed Tracer, part of GWT, an extension for Google Chrome or Chromium. For this purpose, we won’t use the live profiling feature of Speed Tracer, but rather its ability to visualize network requests and replies (with nice timeline and so on). All we have to do is to carefully spit some JSON-formatted data that match the Speed Tracer data dump format. And that is exactly what tracenet does!\n\nThe screenshot below gives an exemplary result from running tracenet on my Nokia N900 when it accesses New York Times front website, a notoriously complicated web page. All I did was to execute “tracenet > nytimes.htm”, transfer back the HTML file to the laptop and then open it with Chromium on OpenSUSE, click on “Network (resources)” line, and voila! You can click on each entry to get detailed timing info, use zoom in/out, and many other features of Speed Tracer. Refer to some tutorials if you are new to Speed Tracer.\n\n\n\nIf you want some follow-up and challenging exercise, try to split Speed Tracer code so that the pure GWT-part can run on any browser. Then you can just package it with QtWebKit and use it to show the outcome of all your network sniffing. Have fun!\n\n(`_|_`)May 15, 2010(`_|_`)ariya.io(`_|_`)qnetworkaccessmanager-tracenet-speed-tracer', 'qnetworkaccessmanager-tracenet-speed-tracer'),
(338, 'vittoria: tiger in color(`_|_`)\nContinuing from the saga I started some time ago, at least now I got to the point where it’s rendered anti-aliased in full color:\n\n\n\nStay tuned, I’d clean-up and release the code soon-ish.\n\n(`_|_`)May 9, 2010(`_|_`)ariya.io(`_|_`)vittoria-tiger-in-color', 'vittoria-tiger-in-color'),
(339, 'vector graphics, tiger in wireframe(`_|_`)\nAt the risk of starting another yet-will-be-unmaintained project, sometime ago I decided to continue learning about graphics stuff in my spare time. I will not announce it of course until its code is better for public consumption. However, I really can’t contain my excitement when it reaches an important milestone:\n\n\n\nThis sounds like childish, but as a graphics n00b, the above screenshot means a lot to me.\n\nStay tuned!\n\n(`_|_`)May 6, 2010(`_|_`)ariya.io(`_|_`)vector-graphics-tiger-in-wireframe', 'vector-graphics-tiger-in-wireframe'),
(340, 'cupertino(`_|_`)\nTomorrow, we (a bunch of Qualcomm folks working on WebKit) will go up north. We’ll be at Apple HQ in Cupertino for the WebKit contributors meeting. I look forward to meeting all the great WebKit hackers (again) face-to-face!\n\n(`_|_`)Apr 10, 2010(`_|_`)ariya.io(`_|_`)cupertino', 'cupertino'),
(341, 'simple http proxy server in 100 lines(`_|_`)\nI guess a simple proxy server should have been an example in Qt Network module. What I mean of course a real proxy server based on Qt, not about using a proxy server via QNetworkProxy class. After all, there are other more complex examples like the torrent client and Google suggest (yeah, blame me for the latter). As a matter of fact, there are e.g. a gazillion proxy servers written in Python.\n\nLook no more. I posted an example in the X2 repository, under the directory network/webproxy. The code is written for clarity and not for performance. In fact, fancy error handling is even omitted (minimalism rulez!). There is no support for pipelining, or in-memory cache, or per-connection thread, or even secure connection via https. I leave them as exercises for the curious readers.\n\nIf we focus on things which work, here they are: asynchronous socket handling, different request methods (GET/PUT/POST/HEAD), persistent connection aka keep alive, and even Flash and HTML 5 video streaming. Yes, you can still watch YouTube or Vimeo if you hook your browser into this little proxy. For a few hours of hacking and 92 lines of code (as reported by sloccount) and certain ways to abuse QObject, I could not be more happier.\n\nThere will be two other offspring examples based on this one. So stay tuned. Meanwhile let’s just hope nobody would ask me for a colorful UML diagram for this snippet…\n\nPS: Special thanks to Jan Erik for his feedback and review.\n\n(`_|_`)Apr 5, 2010(`_|_`)ariya.io(`_|_`)simple-http-proxy-server-in-100-lines', 'simple-http-proxy-server-in-100-lines'),
(342, 'multiples of 3 or 5(`_|_`)\nOne day Helder showed me Project Euler, a collection of interesting math problems to be solved using computer programs.\n\nI took a look at the first problem: find the sum of all the multiples of 3 or 5 below 1000. Getting the linear time solution was trivial, the constant time solution was also not hard. However, I could not help it, I continued by applying some obfuscation voodoo and came up with this answer (of course, constant time as well):\n\nreturn \"uncopyrightable\"[n % 15] - \'a\' + 44 - \"xzoxy}pge]_LAKD\"[n% 15] +\n\'A\' - (!(n % 15)) * 9 + 15 * ((n / 15) * (4 + (\"aaabbcdddeffggg\"[n % 15] - \'a\')) +\n(n / 15) * (n / 15 - 1) * 7 / 2);\n\n\nHow did a word (“uncopyrightable”) end up in that solution? Believe me, it was (a lot of) fun! \n\n(`_|_`)Mar 26, 2010(`_|_`)ariya.io(`_|_`)multiples-of-3-or-5', 'multiples-of-3-or-5'),
(343, 'morphing clock(`_|_`)\nAs I promised before, here is a fresh X2 example. Those who attended Bossa Conference 10 and followed my talk are lucky to have seen it for the first time there. In fact, this example is ridiculously simple that I am not surprised at all if somebody has done this ages ago.\n\nLet’s start with a screen capture, or two:\n\n\n\nBasically the above shows an analog and digital clock running on my Nokia N900, hardly a shock. However, the fun part is when you switch the clock from analog to digital and vice versa. Check out this video, or watch directly on YouTube, courtesy of Signor Portale from Nokia/Qt, showing the morphing on Nokia 5800:\n\n\n\nThe trick is simple. Actually it’s not even generic enough, meaning that you can’t morph from an arbitrary path to another arbitrary path. However, for this clock use-case, the gross approximation is good enough. First, we need to convert the path into a polygon, which is done easily via QPainterPath::toFillPolygon() function. Then any line segment in the polygon longer than a certain tolerance is further split into smaller segments. As I claimed above, the result is not perfect, i.e. it does not approximate the original path into line segments with equal length. But hey, it is good enough for this animation purpose (unless your user has ueberhuman eyes).\n\nThe target path needs to be sliced into segments as well. Since we have only two types, circle (for the analog clock frame) and solid block (for the hour and minute hands), it is easier to special-case both. The secret is to have the same number of segments as the source path. The following figure shows the digit ‘7’ and a circle, each splitted to 28 line segments. Small dots indicate the start and end points of those segments. The animation is now a matter of doing tweening, or linear interpolation, between each segment.\n\n\n\nThe flaw of this trick is when the source path contains holes inside it, e.g. for digits like 0, 4, 6, 8, and 9. Again, we are cheating here for the sake of keeping the code simple, so I leave the code as it is. Doing a more advanced, better handling for those cases is left as a motivational exercise for the perfectionist readers. Another bonus puzzle: find out why 503 ms is the morphing time (hint: find the same number in Qt source tree).\n\nThe code is in the X2 repository, check the sub-directory widget/morphingclock. You need Qt 4.5 or later. It is not long at all (surprise!), sloccount reports 191 lines of code. A morphing-clock plasmoid is also underway, just be patient.\n\nFor the sake of completeness, let me mentioned Dali Clock (even in Canvas and JavaScript version) from the famous Jamie Zawinski (jwz). It is similar, however Dali Clock just morphs the digits of the digital clock.\n\nAlso, if you just prefer a normal (but old-fashioned!) digital clock with the flipping effect, check the digiflip example I did back then. You already have it if you install Qt 4.6 for Symbian.\n\nLast but not least, I’d like to mention my “special thanks to Delta Airlines for such a long (but safe) flight to Brazil so I had the chance to write this example while I was bored”, but then I was told by the Trolls that this kind of intro line can’t be funny anymore.\n\n(`_|_`)Mar 20, 2010(`_|_`)ariya.io(`_|_`)morphing-clock', 'morphing-clock'),
(344, 'new X2 logo(`_|_`)\nI got few proposed designs after I announced X2 project back then. It is tough to pick the winner cause they are all very good. In the end, the one from Elvis Stansvik becomes the new official logo of X2:\n\n\n\nThank you to everyone who has sent me the logo design!\n\n(`_|_`)Mar 11, 2010(`_|_`)ariya.io(`_|_`)new-x2-logo', 'new-x2-logo'),
(345, 'manaus and bossa conf(`_|_`)\n\n\nRight now I am in Manaus, in the middle of the Amazon, Brazil. Good weather, beautiful nature. Fresh tropical rain, feels just like home.\n\nYes, I am here for the (legendary) Bossa Conference ’10 from the awesome INdT folks. I had delivered my talk, Redefining Mobile Graphics Stack this morning. I used the chance to preview (and got feedback) some of upcoming graphics example for X2 from Ofi Labs (what’s X2? read the explanation), even straight from my N900, so just watch its git repository in the next few weeks. BTW, Radeon HD 3200 of my new toy and TV output of N900 worked out-the-box with the projector.\n\nIt is also nice to meet few INdT guys I knew, and get to know new folks as well. Since a few Trolls are also here, I also catch up (and share more jokes) with them. Gosh, feels like ages since I left Oslo.\n\nThis is my first visit to Brazil. Looks like it won’t be the last time!\n\n(`_|_`)Mar 8, 2010(`_|_`)ariya.io(`_|_`)manaus-and-bossa-conf', 'manaus-and-bossa-conf'),
(346, 'n900 and its accelerometer(`_|_`)\nThere is a bunch of code out there (which can be copied and pasted) to grab the acceleration values from Nokia N900. Here I contribute one more, it’s Qt-based and using the QtDBus module. The values in x, y, z will have the unit of G.\n\nQDBusConnection connection(QDBusConnection::systemBus());\n    QDBusInterface interface(\"com.nokia.mce\", \"/com/nokia/icd\", QString(), connection);\n    QDBusPendingReply<qstring> reply;\n    reply = interface.asyncCall(\"get_device_orientation\");\n    reply.waitForFinished();\n    x = static_cast<qreal>(reply.argumentAt<3>()) / 1000;\n    y = static_cast</qreal><qreal>(reply.argumentAt<4>()) / 1000;\n    z = static_cast</qreal><qreal>(reply.argumentAt<5>()) / 1000;\n</qreal></qstring>\n\nAs usual, error checking is omitted (left as an exercise for the reader). Like Star Wars, there is also a reason I skip the first 3 QStrings. Debug it yourself to see what you would get. In addition, I found out that at most it would take 25 ms to grab all three values. It means, if you run your application at > 40 fps, then better put this function is a separate thread. Actually, consider that you don’t want QDBusPendingReply::waitForFinished() to block your entire GUI, this is likely a good idea anyway.\n\nFor a full-version of an accelerometer tool, check out the X2 repository under the sub-directory sensor/accelview. Note that technically acceleration > 1 G is always possible, I clamp the values in this example to keep the UI simple.\n\n\n\n(`_|_`)Mar 5, 2010(`_|_`)ariya.io(`_|_`)n900-and-its-accelerometer', 'n900-and-its-accelerometer'),
(347, '(q)palette viewer(`_|_`)\nQt documentation mentions QPalette as the class that contains color groups, Active, Inactive, and Disabled, for each widget state. Knowing the color for many different color roles is important. For example, a style author might want to tweak the colors of each buttons depending on QPalette::Button, QPalette::ButtonText, QPalette::Highlight and likely play with the shades and the saturation. There are probably few different ways to get the RGB values of those colores, here I show one of them: using a small tool that display all the color roles for active, inactive and disabled states:\n\n \n\nAnd here how it looks like on Nokia N900:\n\n\n\nThe code is in the X2 repository, check the sub-directory widget/palview. A possible exercise for the brave reader: allow the user to choose other color spaces such as HSL or HSV.\n\nHave fun with the colors!\n\n(`_|_`)Feb 28, 2010(`_|_`)ariya.io(`_|_`)qpalette-viewer', 'qpalette-viewer'),
(348, 'web browser and touch device: problem with links(`_|_`)\nTime for X2 premier, like I promised before.\n\nLike what every interface designer would tell you, you can’t just reuse desktop user interface to your mobile version of the application and pray that the application will be useable. Here is an example. In a web browser designed for a mobile device armed with a touchscreen, the typical mapping the touch coordinate to the usual mouse event presents a problem because seems every screen has its own accuracy and precision problem. Sometimes it’s hard trying to visit a link, merely because it is not possible to hit the link properly with your finger.\n\nThe solution seems to be quite (ridiculously) easy. Instead of trying to find what is exactly under your finger (point of contact with the screen), let’s also probe the area in the nearby. If there is a link very close to it, then assume the user wants to go there, she just misses the link accidently by a few pixels. If there are multiple links, then pick the nearest one.\n\n\n\nI have written a very short example, using Qt 4.6 (or later), based on QtWebKit, to demonstrate this workaround. Check the code in the X2 repository under the directory webkit/probelink. It might not work on web pages with multiple frames, but at least you got the basic idea. The chosen link is even highlighted before the browser loads it, just like in the screenshot above.\n\nNext week, or the week after, let’s see another simple example which implements something like Opera Fingertouch.\n\n(`_|_`)Feb 23, 2010(`_|_`)ariya.io(`_|_`)web-browser-and-touch-device-problem-with-links', 'web-browser-and-touch-device-problem-with-links'),
(349, 'introducing X2(`_|_`)\nI know the number of Qt experts out there is growing (like crazy). Still, I believe we should do more to help people master this great framework. I am aware that I might bore you with few Qt code examples I did last year or even the year before, but somehow I feel that I won’t do no harm if I keep sharing new stuff I learn every now and then (especially since now I got a new toy). And maybe it’s not too bad if I change this blog tagline to “don’t code today what you can’t share tomorrow” \n\nSince I am not with Nokia/Qt anymore, I also left the Graphics Dojo corner behind. I decide to publish my new and upcoming Qt examples under a new moniker: X2 from Ofi Labs. The two Xs there stand technically for eXperiments and eXamples, though X2 only sounds cool (even if that X-Men movie would not exist) and I prefer it that way. The name “Ofi Labs” will require a longer explanation, which I rather not elaborate right now.\n\nThe git repository for X2 is at gitorious.org/ofi-labs/X2. In the next few days, watch this space for the first few examples.\n\nMeanwhile, enjoy the logo. If you are an artist, feel free to propose a new and better logo!\n\n\n\n(`_|_`)Feb 21, 2010(`_|_`)ariya.io(`_|_`)introducing-x2', 'introducing-x2');
INSERT INTO `ariyaio` (`id`, `content`, `url`) VALUES
(350, 'distcc, VirtualBox, NAT(`_|_`)\nThe following scenario is quite typical. Your family member, spouse, or coworker has this fantastic, powerful, brand-new multicore machine which, for some reasons, has to run Windows or Mac OS X. On the other hand, you probably have some el-cheapo laptop which is also wonderful but it lacks the processing power to do heavy-duty build and compile. Now, what if you can exploit the other box for a distributed compile? Especially if the powerful box seems to be idle once a while, doing nothing.\n\nMany of you already figure it out the solution: let’s install Linux on a virtual machine and use tools like distcc or icecream. In fact, this is quite easy to do. I managed to find out the details, even if I have only little idea about network stuff.\n\nSide note: I don’t see why icecream would not work. But since I did try distcc, that’s what I wrote below.\n\n\n\nFor the following explanation, refer to the above exemplary network setup. Basically I run virtualized openSUSE inside VirtualBox. You don’t even need a full-blown graphical system, you can create a customized openSUSE installation (no X11 but with some development tools like make, gcc, g++, etc) using SUSE Studio.\n\nFirst of all, we need to configure VirtualBox to do port forwarding. If you read the manual, you see that the default networking is NAT, which is what we use, along with extra forwarded ports. To do this, run the following on the command prompt (in your installation folder, e.g. C:Program FilesSunVirtualBox for Windows, tweak for Mac OS X), changing openSUSE with the name of your virtual machine:\n\nVBoxManage.exe setextradata \"openSUSE\" \"VBoxInternal/Devices/pcnet/0/LUN#0/Config/distcc/HostPort\" 3632\nVBoxManage.exe setextradata \"openSUSE\" \"VBoxInternal/Devices/pcnet/0/LUN#0/Config/distcc/GuestPort\" 3632\nVBoxManage.exe setextradata \"openSUSE\" \"VBoxInternal/Devices/pcnet/0/LUN#0/Config/distcc/Protocol\" TCP\nVBoxManage.exe setextradata \"openSUSE\" \"VBoxInternal/Devices/pcnet/0/LUN#0/Config/ssh/HostPort\" 2222\nVBoxManage.exe setextradata \"openSUSE\" \"VBoxInternal/Devices/pcnet/0/LUN#0/Config/ssh/GuestPort\" 22\nVBoxManage.exe setextradata \"openSUSE\" \"VBoxInternal/Devices/pcnet/0/LUN#0/Config/ssh/Protocol\" TCP\n\n\nThe last 3 lines are not important for distcc itself, however it’s quite handy since you will be able to ssh to the machine (on the port 2222, i.e. the forwarded one and not port 22) and start or stop distcc remotely.\n\nSide note: I was told that bridged networking mode should work as well (even without the hassle of port forwarding). However, I did not manage to make it working in my setup.\n\nIn addition, tweak the settings of your virtual machine so you get more than one CPU cores. For example, on a quad-core machine, giving the virtualized openSUSE two or three cores might be better, considered if the host system does not run need all that burning power.\n\nNext step is to install distcc both on the virtualized openSUSE (anjali) and your laptop (latika). The easiest way is to use the one click install feature, just go to software.opensuse.org, click on Package Search, type in distcc and press Enter and then install both distcc and distcc-server. To do it manually, add http://download.opensuse.org/repositories/home:/dbahi/openSUSE_11.2/ to your repositories and install using:\n\nsudo zypper in distcc distcc-server\n\nAfter that, on anjali, run the following (as normal user, no need to sudo/root):\n\n/usr/sbin/distccd --daemon --allow 192.168.1.0/24\n\nNow on your own machine, latika in the above example, set first where you want to distribute the compile:\n\nexport DISTCC_HOSTS=\'anjali,lzo\'\n\nIf you want, do this in your .bashrc or shell startup script for your convenient.\n\nCompiling and building a project is now as easy as replacing the plain make command with:\n\nmake -j4 CC=distcc CXX=distcc\n\nFor troubleshooting, run distccmon-text 3 (nice for static logging) or watch distccmon-text (useful for real-time view).\n\nSupposed another machine, e.g. naina, wants to join the party, just do the same steps. Don’t forget to adjust DISTCC_HOSTS so that the compile will be distributed also to naina.\n\nThat’s it! For more info (I barely scratch the surface) and better optimization, refer to the manpage of distcc and distccd.\n\nNow the (trivia) question is, the host that runs anjali, who do you think he is? \n\n(`_|_`)Feb 20, 2010(`_|_`)ariya.io(`_|_`)distcc-virtualbox-nat', 'distcc-virtualbox-nat'),
(351, 'new laptop, free yourself!(`_|_`)\nThe other day, I couldn’t resist buying the el-cheapo Athlon 1.6 GHz-powered Acer Aspire 5532 in BestBuy for $330. With its 15.6 inch screen, seems that it is quite a nice bargain. It comes (of course) with Windows 7 Home Premium, but after slapping openSUSE 11.2 DVD I got from the last Camp KDE (must be from Will, thanks dude!) and a bunch of keystrokes, a few hours later the machine happily runs the shiny KDE 4.4. Sound was not a problem, even WiFi was easy to get it working (hard to believe that after all these years, NetworkManager still does not work for me, maybe my bad karma). The included radeonhd driver is good enough for its Radeon HD 3200 (RS780M chipset), but for the sake of testing, I did install ATI fglrx 7.4 10.1 and, voila, I got flawless KWin desktop effects. Even proprietary stuff like Opera, Skype, and Flash plugin faced no serious problem as well.\n\nTime for some fun hacking! \n\nObligatory click-to-enlarge desktop snapshot follows:\n\n\n\n(`_|_`)Feb 15, 2010(`_|_`)ariya.io(`_|_`)new-laptop-free-yourself', 'new-laptop-free-yourself'),
(352, 'camp kde: day two (sunday)(`_|_`)\nAgain, just track all the tweets and blogs to know what happens in Camp KDE in almost real-time. For more pictures, check out KDE Events Pool at Flickr.\n\nIn one of the talks today, Romain “Frankenstein” Pokrzywka showcased KDE 4 on Windows. Though he blogged about it recently, it is definitely interesting to see a live demo, especially things like Plasma running (and crashing, occasionally) on Windows, and that some apps are really usable already. Well, who knows? In the not so distant future, it is definitely easier to convince Window users like Joe Sixpack to start using KDE apps.\n\n\n\n(`_|_`)Jan 18, 2010(`_|_`)ariya.io(`_|_`)camp-kde-day-two-sunday', 'camp-kde-day-two-sunday'),
(353, 'camp kde: day one (saturday)(`_|_`)\nShowing up at this year’s Camp KDE feels a bit weird. First of all, because I do not need to travel at all since I already moved to San Diego some time ago. In addition to that, while I was still with Nokia (Qt), usually I could only attend conferences only if I have something to present. It is a great relief not to worry about my own talks and just enjoy the event.\n\nThere were few talks today. As you can guess, you can pretty much follow them if you keep an eye on #campkde tweets and/or follow Planet KDE these days.\n\n\n\nThe keynote was from Professor Bourne, he had a presentation about open access to data, in particular in the field of science (in his example, pharmaceutical sciences), such as the initiatives with protein databank, Public Library of Science, SciVee. I fully agree with his opinions in this matter, especially since they resemble some of my observations when I was doing my graduate research years ago. In particular, “publish or perish” could potentially destroy the sharing spirit of researches. I do believe that competition is good, but I also do strongly believe that science is about sharing.\n\nI hope more people will show up tomorrow. The sunset here is so fantastic, you just have to experience it yourself.\n\n sunset at Lake Miramar by Ariya Hidayat, on Flickr”)\n\nTo be continued (to day 2).\n\n(`_|_`)Jan 17, 2010(`_|_`)ariya.io(`_|_`)camp-kde-day-one-saturday', 'camp-kde-day-one-saturday'),
(354, '\"i\" for innovate(`_|_`)\nAs I have hinted before, somehow I aimed to move to some sunny place in California. Well, lucky as we could be, after days of experiencing the transient stage (with tons of good and bad experiences, what a roller-coaster), we slowly settle in San Diego, (arguably) a beautiful place to live. The proof is the following picture, basically I can enjoy watching sunset from our balcony every day when the weather permits (it does usually).\n\n\n\nFew weeks ago, I started a new position within Qualcomm Innovation Center Inc., specifically in the new Web Technologies team. This center is a wholly-owned subsidiary of Qualcomm, one of the top 10 semiconductor sales leaders last year. The official party line of Qualcomm Innovation Center is best understood by what our president, Rob Chandhok, has expressed once: focus on such important open source initiatives as Linux and Webkit, and on open source operating systems such as Symbian, Android and Chrome.\n\n\n\nOf course, faithful followers of my blog can quickly point out that this whole thing is just a cover-up for the real motive: the strong desire to live in a perfect symmetry \n\n\n\nIn addition, to convince you that the alignment of the planet has been planned for this, surely you know (perfectly) where the upcoming Camp KDE will be held?\n\n\n\nSee you in 2 weeks. Happy 0x7da!\n\n(`_|_`)Dec 30, 2009(`_|_`)ariya.io(`_|_`)i-for-innovate', 'i-for-innovate'),
(355, 'putu, kelepon, terang bulan(`_|_`)\nWhile enjoying this vacation, I managed to steal few hours to do some fun coding. Nothing spectacular, but it yielded something I will surely share in the near future. However, since I am still in the mood of bombing the planet again, here is another post with food pictures.\n\nSomething else we were glad to taste during our extremely short visit to Bandung were Putu and Kelepon, typically sold at the price of 1 EUR for 25 pieces. They are basically rice cake filled with palm sugar and served with grated coconut. Putu is steamed, while kelepon is boiled. The latter is also colored using pandan leaves.\n\n\n\nWhile sampling culinary specialties means that we do not cook quite often, when the opportunity presents itself, it is of course a good feeling to eat something home-made once a while. Here is one: Terang Bulan (literally: bright moon). It is some sort of pancake, very similar to Martabak except Terang Bulan is filled with sugar, sprinkles, condensed milk, cheese, and the likes. Hence, it is also known as Martabak Manis (literally: sweet Martabak), a term that is somehow I dislike (because language-wise it is unnecessary as there exists a good name for that and thus it extends and pollutes the meaning of Martabak with a very weak reason).\n\nThe recipe? Check what this lady has posted. Terang Bulan is sweet and healthy (reduce the amount of sugar if in doubt), it makes for a good snack in the afternoon.\n\n\n\nLast but not least: Eid Mubarak to everyone!\n\n(`_|_`)Nov 28, 2009(`_|_`)ariya.io(`_|_`)putu-kelepon-terang-bulan', 'putu-kelepon-terang-bulan'),
(356, 'parijs van java(`_|_`)\nSomehow the wind finally leads me to Bandung, the place where I spent years studying at ITB. While still trying to absorb all the deja-vu sensations (last time I was here, when I left the place, was 6 years ago!), nothing beats having breakfast (and potentially also lunch and dinner later on) in one of those food stalls. Since I promised to write about my culinary excitement, here is one to pollute the planets (the aggregated blogs, not our blue marble): Kupat Tahu. Essentially it is fried tofu, bean sprouts, and lontong (compressed rice) served with peanut sauce and some crackers. That makes it for a good breakfast.\n\n\n\nI will be in Bandung today and tomorrow, mostly just around the university. If\n\nyou are around and want to have a chat, feel free to drop me an email!\n\n(`_|_`)Nov 24, 2009(`_|_`)ariya.io(`_|_`)parijs-van-java', 'parijs-van-java'),
(357, 'english vs indonesian(`_|_`)\nOne thing which recently made it into my reverse-culture-shock impact list is the widespread use of incomprehensible (read: broken), mixed-language expressions, potentially due to many reasons (to name a few: innocent show-off, following the mainstream, or just trying to look more “educated”). It starts with an easy one, like denoting the printer cartridge types as “black” and “color”, i.e. in English, although we have good Indonesian words for that (“hitam” and “warna”, in case you can’t recall). The worse part is yet to come, it kills me when someone starts to sprinkle English words in an otherwise perfect sentence, e.g. “tapi you mesti ngajak aku to follow your, ehm [can’t find the English words], kegiatan, which is sebenarnya quite interesting”. This wonderful fragment is ridiculously non-sense for both foreigners who never learned Indonesian and for my fellow countrymen who do not know English at all.\n\nOf course it won’t surprise you if I say that you can easily find flyers and\n\nother promotion materials exactly using the same pattern. Just today we found a\n\nstate-sponsored, free Shopping & Travelling Guide booklet featuring\n\ndozens of pages with English headings. Again, the contents are written in\n\nIndonesian. This leads to a number of striking typos and mistakes, one of which\n\nis shown here:\n\n\n\nI have nothing against foreign languages (I have my share by learning few of\n\nthem), but I also still love my wonderful mother tongue, Bahasa Indonesia.\n\n(`_|_`)Nov 4, 2009(`_|_`)ariya.io(`_|_`)english-vs-indonesian', 'english-vs-indonesian'),
(358, 'even QPainter has QPainter::end()(`_|_`)\nI came to Trolltech (then became Qt Software, then Qt Development Framework) early last year, at the time when the Trolls were busy stabilizing Qt 4.4. I was assigned to work on QtWebKit, so right from Day 0, I did carry out my best patching skills and committed my burst fixes as fast as I could. Qt 4.4.0 was released shortly after, followed by 4.4.1, and the remaining 4.4.x series.\n\nSummer was fun. I learned a lot about WebKit, git, development workflow, the art of backporting, and a lot of other stuff. Together with Samuel, we did resurrect Graphics Dojo. Ever since, I am sure you spotted a bunch of biweekly graphics and WebKit examples I posted: 27 examples this year and 12 examples last year. Autumn brought me to my first Qt Developer Days 2008, both in Munich and Redwood City. We also did a bit of tour to the east coast, back to around Mountain View, and most importantly I got to know the best juice in the world.\n\n\n\nI completely forgot to blog about this, probably because it was not worth mentioning, but during this time I rightfully obtained my Ph.D degree (or rather the official Dr. -Ing). My 70-page dissertation is available for download, still I suggest reading the summary in the 8-page paper. FWIW, I passed with magna cum laude.\n\nAfter the winter break (I did two trips to my home country), spring brought us the long-waited Qt 4.5 along with other blessings (LGPL, open repository, contribution model, S60 port). Qt for S60 was getting hot, I wrote a bunch of smaller examples, OpenStreetMap, ray casting, and some others, all of them showed up as new examples in Qt 4.6. After all, I am always thrilled to offer our valued customers some blue sky approaches and streamlined, breakthrough paradigm shifts so that they can better monetize their mission-critical, enterprise graphical applications in this quality-driven, business-focused Web 2.0 world \n\nIt also meant the traveling time (for doing talks) started again for me. For a lowly code monkey like me, I am proud (on Nokia’s behalf) that this year alone, I had delivered 5 (mostly successful) graphics-related presentations in open-source/developer conferences: Pycon Italia in Florence, LinuxTag in Berlin, and of course Akademy in Gran Canaria, Maemo Summit in Amsterdam and Qt Developer Days in Munich.\n\nAt this point, you can probably guess how it would end. Our last short, memorable vacation around Europe was enough hint. Yes, today is my last day in the office. Our flight back to Indonesia is due within few days. The parting is amicable and amiable. The Last Supper, for my (soon ex-) team mates has been served, too.\n\nSpare the tears, follows is the actual resignation e-mail I sent to our internal mailing-list (the “Foul Stench Officer” refers to the durian incident back then). Last note: my e-mails ariya.hidayat@trolltech.com and ariya.hidayat@nokia.com will soon RIP.\n\n\n\n_Subject: Even QPainter has a QPainter::end() function\n\nFrom: Ariya Hidayat _\n\nAfter being involved in the affair of “connecting people” (insert the jingle here) for some time, I decided that it is the time to move on. If everything goes smoothly, then starting from November 1st (which is a good day, since November is the 11th Gregorian month and 11 is the first double-digit prime number) I would not work for QtSW anymore. Going through a lengthy discussion, my other (better) half and I finally came to a conclusion that Oslo, as beautiful as it is, is not really the place where we want to settle down, at least for the near future.\n\nI still hesitate to definitely mention where I would be stationed by the end of this year. This is because many things depend on e.g. the visa process (as uncertain as the Schrödinger’s cat), and being a citizen of a country stamped in the “terrorism haven” list does not really help. In the worst case, I will take a short leave in my career and spend time with my family, in some sunny city (comparable, if not better, than Las Palmas) in our home country. In the best case (finger crossed!), it will be another sunny city, somewhere in California (to avoid speculation, I can safely say beforehand: no, right now I have zero interest to work for a search engine or a fruit company).\n\nI have been using Qt since my C++ skill was still a joke. Rest assured, I will be still using Qt in the future, at least for my personal pet projects and/or my spare-time joyful endeavor with KDE. And although it has nothing to do with Qt, I can proudly say that my coming professional activities will be still around open-source projects (surprise!).\n\nIt is an honor to serve with all of you, my fellow Trolls!\n\nYour Chief Foul Stench Officer\n\nEND OF TRANSMISSION\n\n\n\n(`_|_`)Oct 22, 2009(`_|_`)ariya.io(`_|_`)even-qpainter-has-qpainterend', 'even-qpainter-has-qpainterend'),
(359, 'graphics dojo in 2009: wrap-up(`_|_`)\nThat is, 2009 is coming to its end. Some parts in Central Europe already enjoy the snow although Oslo still has a touch of autumn feeling.\n\nHere is a list of biweekly Graphics Dojo examples that I managed to pull off this year. Most of them are available for Qt/C++ and PyQt.\n\nNote that although the examples are categorized (for your convenience), often it does not strictly belong to one category, e.g. night mode is both a graphics and WebKit example. Also, all S60 examples are designed with S60 mind but they still run well on the desktop, too.\n\nS60\n\n\nWolfenstein-like ray casting in your pocket.\nMaps solution using OpenStreetMap, of course running on the phone, too.\nFlight tracking utility, useful to check the status and time.\nWeather info on your pocket.\nStill about kinetic scrolling, now with a Flickable interface that works smooth also on a phone.\nSuitable for your S60 phone: flipping digital clock.\n\n\nGraphics\n\n\nReborn/recycled parallax effect for the home screen.\nSimplified magnifying glass trick.\nA simple trick to get the night-mode vision, just like in some navigation system.\nDragMove charm to allow widget moving by dragging\nsimple timeline demo along with a custom S-shape curve\nthumbnail preview via a fast cheat-scaling trick.\ncheap trick to half-scale ARGB32 image very fast.\n\n\nWebKit\n\n\nDoing a talk? Use a presentation tool purely based on web technologies.\nMagnifying glass trick with Google Maps.\nMake your QWebView transparent to achieve some interesting effect.\nsnap-scrolling in QWebView, useful for small-screen browser.\nNeed to do a visual web scraping? This little weather applet, which scraps the Google-provided page, might be a good start.\nUse jQuery, enjoy selector goodies with QtWebKit\nsimple example to integrate Google Suggest\nWYSIWYG HTML Editor using QtWebKit\nGoogle chat client made in 15 minutes\nweb capture, a tool to take a snapshot of web pages.\n\n\nJavaScript\n\n\nRun Monster Evolution demo with Qt and V8 (the JavaScript engine behind Google Chrome)\nStill about Monster, but now with JavaScriptCore of QtWebKit\nOr, just run this cool Monster Evolution demo with QtScript\nsimple bar chart using QtScript.\n\n\nNeed more goodies? See also last year (2008) graphics dojo wrap-up.\n\nUntil next time.\n\n(`_|_`)Oct 22, 2009(`_|_`)ariya.io(`_|_`)graphics-dojo-in-2009-wrap-up', 'graphics-dojo-in-2009-wrap-up'),
(360, 'kinetic scrolling: the state machine(`_|_`)\nSome of the slides from last Maemo Summit in Amsterdam have been made online. Here is the one from the Cross Platform with Qt talk that I held. It does not give much, though, since mostly what counts is the real live demo. Let us hope that at some point in time, the recorded videos will be online as well. Of course, there are also other interesting slides such as Harmattan highlights and its architecture, Web Runtime, Quake3, and many others.\n\n\n  Cross Platform Qt \n  \n  \n    View more presentations from Nokia, Qt Development Frameworks\n  \n\n\nWhile I am there, if you check the slides from my talk above, page 9 shows the secret behind kinetic scrolling code, which I featured before as Flick Charm or Flickable interface. Or, in another version as follows (click to enlarge):\n\n\n\nOf course, it is the simplified version and ignore some details, but that should be a good start to really digest the code. Since it was hacked in the old 4.4⁄4.5 time, I did not have the luxury of using the new state machine framework in Qt 4.6. As an exercise for you, the brave readers, convert the code to use the framework. In addition, it does not support yet bouncing-on-edge feature, something which can serve as another exercise, too.\n\nHave fun with scrolling \n\n(`_|_`)Oct 21, 2009(`_|_`)ariya.io(`_|_`)kinetic-scrolling-the-state-machine', 'kinetic-scrolling-the-state-machine'),
(361, 'Chromium on OpenSUSE(`_|_`)\nThough Google Chrome for Linux is not yet officially announced, people have been working to make Chromium, the open-source version thereof, available for different popular distributions. I wrote before about CrossOver Chromium, but not only this is just a hack, it is also not up-to-date at all. The easiest way for OpenSUSE 11.1 users is to use the package from Contrib.\n\nThough for veteran OpenSUSE fans, the steps to install Chromium are obvious, here I write down the idiot-proof version. Go to http://software.opensuse.org/search, type Chromium and click the Search button, wait for a moment, find the entry from openSUSE:Factory:Contrib/openSUSE_11.1, then well, click on the 1-Click Install button there. Follow the usual installation guides (mostly just agreeing and confirming some stuff), then in few minutes you will get:\n\n\n\nWho says installing software in Linux is difficult? \n\n(`_|_`)Oct 20, 2009(`_|_`)ariya.io(`_|_`)chromium-on-opensuse', 'chromium-on-opensuse'),
(362, 'from autumn to winter(`_|_`)\nThe wave of cold weather is approaching us, the nature’s way of saying Wind of Change. While some parts of Europe enjoy the snow already, Oslo is relative still calm and actually enjoyable, even in the afternoon, for a walk.\n\n\n\n(Picture was taken and shared to Flickr using Nokia N900 \n\n(`_|_`)Oct 18, 2009(`_|_`)ariya.io(`_|_`)from-autumn-to-winter', 'from-autumn-to-winter'),
(363, 'bye munich (and D2)(`_|_`)\nAfter kickstarted on Tuesday, Qt Developer Days 2009 Munich has ended. Some of us, the Trolls, are already back in Oslo, recovering from the intense adrenalin kicks within the last 72 hours (or more). The extra surprise was to experience the first snow in Munich (and this is still mid October!). Most must recharge pretty fast, considering the San Francisco version of the event is in about two weeks time.\n\nThere already a bunch of articles covering the event which show up in some sites, Aron has most of them in his wrap-up blog entry. More links are and will be available via qtbynokia twitter. Fancy some pictures instead? Search for qtdd09 tag on Flickr and enjoy them!\n\nAs for me, I am glad that this is finally over. It’s all about people: it was exciting to meet old friends and make new ones. In addition, my Special FX with Graphics View talk was well received (the room was jam-packed), I got some very interesting feedback and questions to follow-up. The other talk, Copy Your Favourite Nokia App with Qt, was a bit quiet (the typical problem of all presentations in the afternoon of the last day) but still, it was as interactive as it could be.\n\nThis mini wrap-up is not complete without food photos. While we were in Munich, we ventured some different possibilities for dinner. Let me just show you two of them: Low-carb Seafood and Biryani:\n\n by Ariya Hidayat, on Flickr”) \n\n(`_|_`)Oct 16, 2009(`_|_`)ariya.io(`_|_`)bye-munich-and-d2', 'bye-munich-and-d2'),
(364, 'Qt Developer Days 2009 - Live(`_|_`)\nLike I mentioned before, now I am in Munich for Qt Developer Days 2009. The training sessions started yesterday already, the plenary was initiated this morning as we had the keynotes from Sebastian, Lars, Walter, and Matthias. We are now in the middle of lunch break, the technical track will start very soon.\n\n\n\nThis is the biggest Qt Developer Days so far, we have over 650 participants (last year it was only around 400). Can you imagine now what happens during the lunch break? Hint: the queue. As a nice touch, we even show a coffee machine running Qt:\n\n\n\nI will have two talks tomorrow (Day 2) for the Innovate track: Special FX with Graphics View and Copy Your Favourite Nokia App with Qt. See you there!\n\n(`_|_`)Oct 13, 2009(`_|_`)ariya.io(`_|_`)qt-developer-days-2009-live', 'qt-developer-days-2009-live'),
(365, 'bye amsterdam. next stop: munich(`_|_`)\nToday is the last day of Maemo Summit 2009. I am sure the news spreads quickly; everyone and his uncle know already that Nokia lends around 300 shiny N900 (preproduction devices), worth 500 EUR, to the summit participants, excluding Nokia employees and contractors. It’s Christmas in Amsterdam!\n\nI had done my Cross Platform with Qt talk, I was quite content with it (that hopelessly small room was jam-packed). There were (and still will be) many other interesting tracks as well. For the detailed coverage, check out All About Maemo site, they are doing great jobs keeping the rest of the world up-to-date with the latest excitements from WesterGasFabriek.\n\nWhile waiting in Schiphol for my next flight to Munich (for Qt Developer Days 2009), I had a quick glance at some of photos taken in the last few days. Let me just post one:\n\n\n\nOne evening, we picked Restaurant Sari Citra for our dinner. It serves Indonesian cuisine, the proof is the picture above. You have the choice to mix your own rice dish, such Nasi Kuning (rice with coconut milk and turmeric) with Tempe Kering (slices of fried, crispy tempe mixed with peanuts), Perkedel Kentang (mashed potato fritters) along with a wide selection of vegetables. Authentic experience with a reasonable price. Everyone enjoyed the dinner; happy Trolls \n\nAnd see you in Munich!\n\n(`_|_`)Oct 11, 2009(`_|_`)ariya.io(`_|_`)bye-amsterdam-next-stop-munich', 'bye-amsterdam-next-stop-munich'),
(366, 'Maemo Summit 2009 - Live(`_|_`)\n\n\nLike mentioned before, with other few Trolls, we are now in Amsterdam for the Maemo Summit 2009. If you are there, don’t forget to look for us and/or drop us a visit!\n\n\n\n(`_|_`)Oct 9, 2009(`_|_`)ariya.io(`_|_`)maemo-summit-2009-live', 'maemo-summit-2009-live'),
(367, 'webkit dinner: gado-gado + nasi uduk(`_|_`)\n\n\nSomething I can always be proud of is to be part of the Nokia QtWebKit team. The fact that we are all the WebKit reviewers from Nokia (at the moment, surely the situation will improve in the future) is one thing, but most important is that the team is small and agile, and it comprises great hackers. You surely already hear a lot from Simon, Tor Arne, and Kent these days, and you will hear from the new blood pretty soon, too.\n\nThe least we can do for such great coworkers is to offer them a bit of culinary journey to our culture. Hence, the so-called WebKit dinner. As much as I love Italian food, such as pizza, it’s also time for a change.\n\nThe starter was Gado-gado, which is just vegetable salad served with peanut sauce as the dressing. The main dish consisted of fish curry (generously contributed by Kavindra) and Nasi Uduk. The latter, which is shown in the photo above, is rice cooked with (among others) coconut milk served with sliced omelette, fried tofu, chicken, fish, and vegetables. A lot of other slight variations also exist. Original (from Sidoarjo) prawn crackers, aka Krupuk, completed the experience.\n\nDessert? Not forgotten. It was basically just fresh waffles (like I blogged before) served with the sauce made from brown sugar and coconut milk. Let’s say it’s the European interpretation of Serabi.\n\nTasty. What else does a man want?\n\n(`_|_`)Oct 7, 2009(`_|_`)ariya.io(`_|_`)webkit-dinner-gado-gado-nasi-uduk', 'webkit-dinner-gado-gado-nasi-uduk'),
(368, 'paris lisbon madrid(`_|_`)\nFinally I had a real vacation, albeit short. Like many typical holidaymakers, I decided to do a little tour passing three selected cities in Europe, at the same time also using the chance to practice light, one-bag travelling (with a great success, mind you!).\n\n\n\nParis can always make a good start. The target at this second visit to Paris was to enjoy it at night. After all, it is supposed to be la Ville Lumière (City of Light). However, a long walking tour during the day was still inevitable, as evidenced from the picture of Église Saint-Eustache above.\n\n\n\nAs for the food, we decided to try non-local cuisine instead. We dined at the nicely-decorated Restaurant Indonesia, one of two restaurants in Paris (the other one is Djakarta-Bali) serving authentic culinary experience from my home country. If you happen to be nearby, give it a try as the dishes were good and reasonably priced.\n\n\n\nLisbon is fabulous and rich with history. We managed to explore the downtown area on foot, enjoying the busy Marquês de Pombal, even walking up to the Castelo de São Jorge. However I feel that exploring the surrounding would have been much better with a car. The view of Lisbon from the castle was majestic, also from the dozens of the short alleys on the way up there (the photo above). Of course, passing Ponte 25 de Abril – the sister bridge of San Francisco’s Golden Gate – both on the motorway and using the train, was also a wonderful experience. Due to our limited time, we had to skip some other tourist attractions. We already compiled a list of must-visit places for the future, in case we fly to Lisbon again.\n\n\n\nNevertheless we had the obligatory fantastic dinner with cod. In another occasion, a simplistic but enjoyable dinner buffet in a Churrascaria was also memorable. A short detour to the beach at midnight completed the unforgettable journey.\n\n\n\nMadrid was very vibrant and dynamic. It is also quite warm (as expected) with the heat at noon being close to unbearable. I like the fact that it was still possible, even convenient, to sit on a bench even somewhere in downtown as long as it is still in the shadow. Unfortunately Madrid was defeated by Rio in the race for the 2016 Summer Olympics host. Otherwise it would have been extremely fantastic as we were there after the last round.\n\n\n\nWe did the usual sightseeing (on foot) – including the compulsory visit to Palacio Real – and other usual rituals: having chocolate con churros for breakfast, drinking horchata to ease from the heat at midday, as well as eating traditional paella (and fidueà) for the (very!) late dinner.\n\nMadrid at night on the other hand is a bit problematic for me. Since I am not a nightlife type, I don’t drink, and I can’t stand the cigarette smoke, touring the city after sunset is practically a mild torture.\n\nNext to visit (due in few days): Amsterdam and Munich.\n\n(`_|_`)Oct 6, 2009(`_|_`)ariya.io(`_|_`)paris-lisbon-madrid', 'paris-lisbon-madrid'),
(369, 'Maemo Summit 2009, Amsterdam, 9-11 Oct(`_|_`)\n\n\nAnother exciting event coming up soon: Maemo Summit 2009! This time it will be in Amsterdam. My flight ticket is secured already, I look forward to it. And of course, since this will be also my first visit to Amsterdam.\n\nMy talk will be on Friday afternoon, see the schedule for details. Although the title “Cross-platform with Qt” is a bit boring, rest assured you will see showcases of many things (which I can pack in 25 minutes) Qt is capable of doing.\n\nA few other Trolls will be there as well so go there and find us. In all cases, if you are around and want to have a chat, drop me an email (ariya.hidayat AT gmail DOT com).\n\n(`_|_`)Sep 27, 2009(`_|_`)ariya.io(`_|_`)maemo-summit-2009-amsterdam-9-11-oct', 'maemo-summit-2009-amsterdam-9-11-oct'),
(370, 'a moment, a love, a dream, a laugh, a kiss, a cry(`_|_`)\n by Ariya Hidayat, on Flickr”)\n\nSeems autumn always calls for my service, hence the usual pizza-baking obligation, as evidenced from the photo. Recipe? Check what I have posted last year. A slight variation: slices of pineapples \n\n(`_|_`)Sep 27, 2009(`_|_`)ariya.io(`_|_`)a-moment-a-love-a-dream-a-laugh-a-kiss-a-cry', 'a-moment-a-love-a-dream-a-laugh-a-kiss-a-cry'),
(371, 'frozen in the headlights (have I made the final sacrifice?)(`_|_`)\n\n\nThis slick stuff is mostly educational (for the lazy, see the 30-second YouTube video courtesy of Alessandro). With all the accelerated graphics (with those alphabet soups) these days, who on earth uses ray casting for real-world apps? Nevertheless, since I still keep the piece of code (read: a function, literally) I wrote ages ago, why not giving it a try again?\n\nTesting it on Nokia E71 (powered by ARM 369 MHz processor), I am content to get a consistent 25 fps at QVGA resolution (and the code is still portable!). I reckon I need to resort to platform-specific, e.g. Anti Tearing API for S60, if I want to push the frame rate further.\n\nFor the code and the explanation, head to the S60 ray casting demo. You would need the Qt 4.5 Tower release to build it for your favorite phone. Also, you need a four-way controller as I haven’t bothered to let it run on a touch device.\n\nFinal (friendly) reminder: use sloccount and check yourself how long this example is. Why? Because usually people think I try to trick them when I reveal the size of the source code \n\n(`_|_`)Sep 23, 2009(`_|_`)ariya.io(`_|_`)frozen-in-the-headlights-have-i-made-the-final-sacrifice', 'frozen-in-the-headlights-have-i-made-the-final-sacrifice'),
(372, 'Eid Mubarak(`_|_`)\nHappy Eid Al-Fitr to all !\n\n(`_|_`)Sep 20, 2009(`_|_`)ariya.io(`_|_`)eid-mubarak-2', 'eid-mubarak-2'),
(373, 'SVG: parsing and content optimization(`_|_`)\nA few weeks ago, just for a change (between the usual QtWebKit bug-fixing and patches juggling), I did take a look at our QtSvg module. According to some internal reports, QtSvg is not fast enough when parsing a large and complicated SVG. Of course, slow is relative, slow to what. And arguably, parsing time is not as important as rendering time. But if you stash your user-interface elements in some sort of SVG theme, loading time becomes a factor (caching the pixmaps whenever possible also helps). Of course, reduced size served in a web server can decrease the bandwidth as well (think of all the SVGs in Wikipedia).\n\nStill, I decided to have a look, just in case there are low-hanging fruits I can grab. And I was right, far from being an SVG expert, with just two days of work I managed to squeeze its performance a bit, which you’d enjoy already in the recent 4.6 preview.\n\n\n\nThe chart above – shorter is better – represents the comparison of the time spent in QSvgRenderer::load(), measured using CPU tick counter (in millions of ticks), comparing Qt 4.5 and 4.6. I also tested some other files as well, see the bigger bar charts. In all measurements, the 95% confidence intervals were well below 1%. In-house Theme refers to an internal SVG that unfortunately I can’t share. Tiger is the SVG version of the famous head in PostScript (taken from GNU GhostScript), something I have shown before. Imperial Coat of Arms of France is another complex SVG, from Wikipedia Commons. World Map is the public domain blank grayscale world map from Wikipedia. There are a bunch of other test files I used, they mostly show the same improvements.\n\nAs you can see, Qt 4.6 would enjoy a bit of speed-up (in some cases up to 1.4x) when loading and parsing SVG.\n\nHowever, I did not stop there. For the fun of it, I quickly hacked a Qt-based, command line SVG minifier, dubbed SVGMin. More about it can be read in the detailed Quick Start, but basically it tries to eliminate redundant garbages which have no effect whatsoever in the final rendering.\n\nWhat follows is the chart showing the same type of measurement but I added the result with the minified SVG (see also the full comparison chart). The result should speak for itself:\n\n\n\nI plan some more improvements to the SVG minifier, for example collapsing a single grouped element ( makes no sense), group a bunch of nodes with similar attributes (no need to duplicate the same fill colors over 100 circles), remove useless attributes (why there is fill-* for fill:none?), and many others. Hold your breath.\n\n(`_|_`)Sep 11, 2009(`_|_`)ariya.io(`_|_`)svg-parsing-and-content-optimization', 'svg-parsing-and-content-optimization'),
(374, 'the game of escalation(`_|_`)\n\n\nOften I ask myself how long I would still want to stay in the software industry. Before I started my professional programming career, I never thought that this wonderful world of software craftsmanship is full of complaints, frustration, anger, and hostility. Perhaps that is just the reflection of people wanting to achieve the best things they can do. When you aim for a perfection, anything good enough will not be satisfactory.\n\nI can’t say for sure, but somehow I feel that I am still heavily influenced by the positive gratitude mentality, even in the case of calamity. When you have an accident and your right arm is amputated, someone reminds you, “You are lucky, you could have lost your legs!”. Losing an arm is considered lucky? This does not mean that we bury our head in the sand and forget the fact that one arm is gone already, it just means that we should not be blind to the fact that things could have been worse. By doing so hopefully we keep things in perspective and move forwards as positive and as best as we can.\n\nOne of the lessons I learned so far is the amount of extrapolated verdicts you would get from the users, the developers, and/or the customers. Any bugs, any annoyances, no matter how small it is, are sometimes blown out of proportion. I call this the Universal Rule of Blaming. A customer complains, the company desperately grabs a consultant to help, he finds the bug in the toolkit, the toolkit guy chains it further to the operating systems, and so on. Of course, for each stage, the amount of anger and loudness of the screams increase exponentially. Basically, nobody wants to be the escape goat.\n\nSadly, everyone in the business of doing software seems to forget that making a software is just like another engineering project. It has its constraints, the resources are limited, the time is the (common) enemy, priorities must be set, and practically it is impossible to achieve 100% perfectness. It is the classic optimization problems. Thus, the responsible people have to make some decisions and these decisions can’t please everyone. There will be people alienated with such decisions. Anyone ever done any kind of sensible business knows exactly what it does mean. Every customer feels that he is important (I mean, who does not?), yet a typical company has a lot of customers and such a company is always ready to disappoints 10% of the customers, rather than 90%. As you can guess, it is a matter of minimizing the loss. When a business guy asks his customers, “Hey, I need your feedback” and he really means it, he is not trying to be nice, he is trying to save his business.\n\nHowever, my concern is not on the technical matters, but rather the non-technical side. When you are angry, you may say some words that you may regret later. Unfortunately, getting mad because of software annoyances can trap you in the same, if not worse, situation. What I often witness is that people start guessing, accusing, throwing blames, up to the a point where it becomes counter-productive and getting personal. You all know what happens when a developer takes it personally: a cycle of violence is about to roll. Once a while I try to stand in the line of fire (a big mistake, I know) in order to bridge both parties. No luck, it is like being trapped in a DMZ and people will just release their steam and waste their bullets to me as if they are happy to find a new bandito to kill. Ever wonder why some developers take the holy vow of silence?\n\nThe most common case is the why-my-bug-is-not-fixed drama. For example if I do not fix the problem X on the platform Y, people might start rambling on anything from “you secretly plan to drop support for Y” to “you rather focus only on feature Z instead of fixing X”. There are various reasons I still do not manage to provide you the fix, but because of the frustration, people tend to invent and believe in some kind of conspiracy theory. Feel free to write a long Pulitzer-quality editorial on why the lack of the fix destroys your million dollar business, but no need to cross the line and start imagining things.\n\nThe drama can continue in a developer conference, where a guy might ask a simple, seemingly innocent question (even in a keynote speech) such as “Why don’t you fix (my) bug 123? Why do you work on feature 456 instead?”. Believe me, I saw that happened many many time. Those questions will put both the speaker and the audience in a awkward situation. While I fully agree that every bugs must be fixed, throwing such a question which only has the intention of embarrassing the developer in front of everyone is way too dirty for my taste (not to mention that, like often the case, our poor little developer never took any How to Deal with Angry Customers course). In fact, every time I encounter this kind of scene, I make a mental note to stay away from that guy. And I am sure I am not the only one who is doing that. Like I often expressed, we are not in the kindergarten anymore, screaming does not make the solution comes faster. Time to make a ThinkGeek T-shirt for that?\n\nThus, I reached a conclusion that there are two types of software guys: those who symphatize with the difficulties and problems of delivering a perfect product (because they are trying to do the same, “Welcome to the club!”) and those who just like to shift the blames to others (because they get customers banging their doors). Nobody likes to deal with angry customers so the choice is (not) hard: either you take the blame (after all, you are the one who is doing the direct business to your customers) or you pass it along (every one of us is a customer of someone else’s product). In the latter case, you just become yet another angry customer.\n\nNoblesse oblige.\n\n(`_|_`)Sep 8, 2009(`_|_`)ariya.io(`_|_`)the-game-of-escalation', 'the-game-of-escalation'),
(375, 'wanna curve away? it\'s such a perfect day(`_|_`)\nIf you were at my Special F/X talk, Desktop Summit in Las Palmas, or if you watched the recorded video (135 MB Ogg), you might notice the tongue-in-cheek gratitudes to Lufthansa dan SpanAir I expressed at the beginning of the talk. The story goes as follows. As all of us, the Trolls, left Oslo to fly to Las Palmas, our flight got delayed twice, in Oslo (by Lufthansa) and Madrid (by SpanAir). Like every other dedicated (read: foolish) hackers, I took advantage of the delay to fulfill my dream (read: obsession): writing my own presentation tool. Hence, the special thanks.\n\n\n\nOf course, like every other dedicated hackers, I cheated (after all, great artists steal). Inspired from the previous discussion with Simon (and Holger), I just took S5 and wrapped it with QtWebKit. The result is something I called s5runner. The 200-lines Qt/C++ code (and PyQt, thanks to David) is best demonstrated by watching the following short screencast:\n\n\n\nFew extra features added on top S5 are screen blanking (white or black), night mode (just for the fun of it), syntax highlighting (useful for code snippet), countdown timer (because my laptop has 100x computing power vs my wristwatch), and (my favorite) live editing.\n\nI will definitely reuse this for my upcoming talks.\n\n(`_|_`)Sep 1, 2009(`_|_`)ariya.io(`_|_`)wanna-curve-away-its-such-a-perfect-day', 'wanna-curve-away-its-such-a-perfect-day'),
(376, 'light beams(`_|_`)\n \n\nSome kind of midnight light attractions a week ago in Bremen was a good opportunity, a better one than just in the physics class, to remember that light beams are actually invisible, except when the beams get scattered by some particles or other objects. Hence the fog machines operating in the same space and time as the powerful headlights.\n\n(`_|_`)Aug 30, 2009(`_|_`)ariya.io(`_|_`)light-beams', 'light-beams'),
(377, 'mails I wish I could skip(`_|_`)\n\n\nDon’t get me wrong, I love to get emails. In fact, as long as the emails are not nuked by the spam filter, I read each and every one of them. I might not give a response immediately, but I seldom skip an email. However, there are few types of e-mails that I wish I could just skip, thereby saving my and the everyone else’s time.\n\nthat starts with “Dear Sir/Madam”. Nothing wrong with it of course. But if someone knows my email address, a little check with Google would reveal my gender and my full name. However, with that Sir/Madam thing, I cast a suspicion upon the content of the email (likely a spam anyway).\n\nthat asks “how to download FooBar”. Maybe s/he reads one of my articles or a post in my blog. But normally I always state the web site of that particularly interesting program so that people can try it. Usually I give her/him the benefit of doubt and send the first few links I find by googling (or lmgify-ing) on “download FooBar”.\n\nthat only says “I tried to do X and it did not work”. Unless I have a crystal ball, how on earth could I possibly know the problems? Shall I forward this email to Uri Geller, or any of his successors, then?\n\nthat requests suggestions for a (final) project. If I do not know the sender (what s/he’s studying, what the interests are, etc), well what would I say then? I can mention anything, e.g. create a rocket that flies us to Jupiter, but that wastes more of our time.\n\nthat ends with “Please help, it’s urgent” or something similar. As much as I would like to help, I also have a life, and I have my own sets of problems, too. And so does everyone else. True, urgency requires a delicate handling but I am not in business of waving a magic hand. Beside, we are not in the kindergarten anymore, screaming does not make the solution comes faster.\n\nthat asks for some architectural diagram of my example code. It’s soooo “corporate”. Seriously, do you expect me to fire up Rational Rose and draw colorful charts (flying arrows included) for a 300-lines example program? Some people fail to see that an example, just as the name implies, is meant to be taken as an example.\n\nthat is closed with a very long signature. It’s fine for the legalese purpose, but isn’t it ironic when the mail signature is ridiculously long, sometimes up to 4x longer, than the content of the mail itself? And when the email is basically a set of some of the points above, the signature is like adding an insult (a terrible one even) to the injury.\n\nDo you ever get other types of annoyances like that?\n\n(`_|_`)Aug 28, 2009(`_|_`)ariya.io(`_|_`)mails-i-wish-i-could-skip', 'mails-i-wish-i-could-skip'),
(378, 'Nokia N900: Linux-based mobile phone(`_|_`)\nFinally it’s out. N900 is the first Linux-based 3G/HSPA phone from Nokia, powered by Maemo. There are already some high-quality awesome pictures of the phone, or just enjoy the following taken by my countryman who is working for Maemo. Or watch its 75-second promo video clip. Price is not set yet, but seems to be in the EUR 500 range. The geek side of you might want to glance at the specifications (and mark that OpenGL ES 2.0!).\n\n\n  Paling gress dan paling canggih: N900Originally uploaded by mdamt\n\n\n\n\n(`_|_`)Aug 27, 2009(`_|_`)ariya.io(`_|_`)nokia-n900-linux-based-mobile-phone', 'nokia-n900-linux-based-mobile-phone'),
(379, 'oslo mela(`_|_`)\n\n\nJust like last year, Oslo Mela Festival few days ago was something we did not miss, in particular because of the food.\n\n(`_|_`)Aug 24, 2009(`_|_`)ariya.io(`_|_`)oslo-mela', 'oslo-mela'),
(380, 'q-o-t-w(`_|_`)\n\nPeople who succeed in life are rarely reflective. Their gaze is always on the future: that’s why they succeed.\n\n\n\n— “Ghost”, Robert Harris\n\n(`_|_`)Aug 20, 2009(`_|_`)ariya.io(`_|_`)q-o-t-w', 'q-o-t-w'),
(381, '0x40 dirgahayu(`_|_`)\nToday is our Independence Day. Merdeka!.\n\n(`_|_`)Aug 17, 2009(`_|_`)ariya.io(`_|_`)0x40-dirgahayu', '0x40-dirgahayu');
INSERT INTO `ariyaio` (`id`, `content`, `url`) VALUES
(382, '(again) the map of my world gets smaller as I sit here(`_|_`)\nI always wanted to help Marble, but I am guilty because until now I can’t afford any time to play with it. All these years, I used to compile bleeding-edge Marble from time and time, use it, and basically that is it. Although since a long time ago I promised Torsten that I was willing to help Marble, actually only right after Gran Canaria Desktop Summit finally I devoted some time to study its code. The three of us, Torsten, Andrew and I also had a short but fascinating discussion during the summit.\n\nNow, I still don’t manage to contribute anything to Marble yet, but I already have something in my pipeline. You will likely hear from me in the coming weeks, so stay tuned.\n\nSince I reckon I enter the wonderful territory of mapping world, I thought, well, let’s familiarize myself a bit with the technology. I took a look at the interesting experimental Google Maps API v3 (which BTW does not require an API key). Using QtWebKit, I wrote a simple 300-lines example that shows a magnifying glass over the map (see the screencast). Of course, the area under is the zoomed version of the map.\n\n\n\nSince I am flirting with Qt for S60 these days, I thought about bringing that example to the phone. However, instead of relying on Google Maps, I decided to leave the dark side and jumped to use OpenStreetMap instead. The result is effectively an example of how to render the tiles from OpenStreetMap using Qt, which also runs on S60. It does even have the night-mode feature.\n\n\n\nVideo, you asked? Thanks to Alessandro, here is the 52-second videocast that demonstrates it (or watch on YouTube), running on Nokia 5800:\n\n\n\n(`_|_`)Aug 11, 2009(`_|_`)ariya.io(`_|_`)again-the-map-of-my-world-gets-smaller-as-i-sit-here', 'again-the-map-of-my-world-gets-smaller-as-i-sit-here'),
(383, 'how far is that plane(`_|_`)\n\n\nThis did happen in my last flight. I consider making it a quick math quiz for any candidate I have to interview in the future (to see whether it takes him 5 minutes or 5 hours to analyze).\n\nA few minutes after the captain announced that we were flying at forty thousand feet above the sea level, cruising at the speed of 900 km/h, through the window we saw another airplane flying at roughly the opposite direction, but at a slightly lower altitude. Of course, the obvious question was asked: How far is the other plane from us? This is better than the typical Fermi problem. Assuming that that airplane was visible in our 90 degrees field of view for 4 seconds and it flew just as fast as our plane, I did a quick calculation and came up with an answer, the flight trajectory of that plane was 1 km apart from ours.\n\nThe other guy was impressed, but he was not convinced. Now, since my math skills are rusty, I am sure I missed a thing or two. Now, what is your take?\n\n(Picture rendered from Jarno’s public-domain vectorized aircraft).\n\n(`_|_`)Aug 9, 2009(`_|_`)ariya.io(`_|_`)how-far-is-that-plane', 'how-far-is-that-plane'),
(384, 'the power of definition(`_|_`)\nHave you ever got a simple question from a non-techie person, like “What is Java”?\n\nHere is a portion of what you get from wikipedia on Java:\n\nJava refers to a number of computer software products and specifications from Sun Microsystems that together provide a system for developing application software and deploying it in a cross-platform environment\n\nHere is what you’d enjoy from its official site:\n\n_Java allows you to play online games, chat with people around the world, calculate your mortgage interest, and view images in 3D, just to name a few.\n\n_\n\nThat really makes my day.\n\n(`_|_`)Aug 8, 2009(`_|_`)ariya.io(`_|_`)the-power-of-definition', 'the-power-of-definition'),
(385, 'like a startling sign that fate had finally found me(`_|_`)\nWhat follows is a list of three Qt examples, designed with Qt/S60 in mind, but works fine on the desktop as well. Hopefully this will attract^Wprovoke more people to create, write, port apps to S60, especially since the Tower release makes our life much easier already.\n\nFor each example, the picture shows how it does look like both on an actual phone and on the desktop. The code is available from the usual Graphics Dojo repository. All of them runs on the desktop, too (of course). Afterall, they are just normal Qt/C++ programs. Thanks to my fellow Troll, dboddie, some of them are already available (or being converted as we speak) to PyQt, for all the Python fans out there. Also, screenshots are so prehistoric and we are the YouTube generation, so another fellow Troll, aportale, agreed to spend few minutes of his precious lifetime to play the Producer, Cameraman, Propman, Editor roles (all at the same time) and publish the Director’s Cut versions of all videocasts mentioned here. Long live the Trolls!\n\nWithout further ado, here they are.\n\nThe first is the easiest one: flipping digital clock, where the digits flip as they change. There are probably tons of implementations out there (do we have one for KDE 4?), but if you are ever so curious to find out how useful QTransform could be, the check it out. For the lazy, watch the 23-second YouTube video.\n\n\n\nNext is yet-another-weather tool. This time I relied on the unoffical Google Weather API. Nothing too fancy here, just a bit of SVG and Graphics View here and there, along with a bit of animation. The lazy side of you can go straight to stare at the 34-second demonstration videocast.\n\n\n\nThe last one is (just the next logical step to the second one): flight tracking tool. Based on flightview.com, the video can be checked on YouTube, too. It looks a bit ugly and it’s also pretty limited, but hey, dogfooding your own app on your phone is also not bad.\n\n\n\nNow, who’s next?\n\n(`_|_`)Jul 28, 2009(`_|_`)ariya.io(`_|_`)like-a-startling-sign-that-fate-had-finally-found-me', 'like-a-startling-sign-that-fate-had-finally-found-me'),
(386, 'the price of ignorance(`_|_`)\nThis blog entry from Hallvord really makes my day.\n\nUnfortunately seems that this page is listed on Digg or reddit (hence the off-topic, bashing, and/or childish comments). Otherwise, I would expect some more cheeky yet insightful and thoughtful remarks.\n\n(`_|_`)Jul 21, 2009(`_|_`)ariya.io(`_|_`)the-price-of-ignorance', 'the-price-of-ignorance'),
(387, 'towards a better talk(`_|_`)\nEvery now and then, when I attend a conference, I try to analyze the way the best talks are delivered (and not only the contents). After that, I make a mental note of certain points of the important skills that the speakers successfully demonstrated.\n\n\n\nWhat I list below however is something difference. It’s the exact opposite. I write down few minus points of my own talks (and from others, too) which do not match to those good traits of an excellent talk.\n\nFirst thing first: the accent. For me and others non-native speakers, it is difficult to speak English without any accents. In the best case, a presentation delivered with a strong accent would mean few parts here and there are not understood by the audience. This is usually not a big problem as (most of the time) our brain can interpolate the missing part. In the worst case, the audience can not understand the talk at all. Even worse if the presenter talks very fast like a machine gun.\n\nStill language-related: the unnecessary pause. This is best illustrated with an example: “Akademy is … ehm … a conference for … ehm … KDE developers and .. ehm also contributors.“. The flow of the talk becomes weird, the speaker seems to think more about the literal sentence rather than the overall idea. The best advice I got to reduce this problem to practice a lot. In addition, pretend that you are having a water-cooler chat with your fellow coworkers instead of addressing thousands of people.\n\nSpending time looking at the laptop and/or the big screen. The irony is that we usually do it when we are stuck with the same slide for few minutes. The slide does not change, yet we are just staring at it as if we expect some magic will happen. The audience is our friend, so we’d better look at them as we talk.\n\nForgetting to engage the audience. Especially for a long talk, the presentation’s attractiveness quickly wears off once we start doing the one-way conversation for more than 10 minutes. Usually this is easy to notice, just check if they start concentrating more to the laptops instead of paying an attention or watching the slides. In that case, some kind of a question or a quick informal poll typically helps to get the audience back on track again.\n\nMonotonic speech, something still closely related to the above point. In such a conference, the audience does not intend to enjoy a bed-time story, hence the importance of inserting surprises when appropriate, provoking some thrills, triggering a bit of drama, throwing jokes, and such other related acts. Never afraid to show some emotion, be it a frustration or an excitement.\n\nLetting the slides dictate the talk. We often forget that the slides are there to help us to convey the messages. It’s not the actual presentation. It’s just the outline of the book, it’s not the book itself. Thus, the talk must not be as rigid as the prepared slides. Not seldom we need to carry out adjustments according to the situation, e.g. skipping some parts or elaborating points not detailed in the slides.\n\nLack of passion. We definitely need to show that we are having fun doing the talk! How could we expect the audience to enjoy it if we do not express and shared the joy?\n\nTo counter the above points, the key is the rehearsal, or rather tons of rehearsals. Often, checking out the video of your own talks helps a lot. Of course, there are the usual advices of studying Presentation Zen, watching TED talks, keynotes from His Steveness, and many other online-available materials.\n\nLast but not least, regardless the way the talk is carried out, I still always thumb-up and respect those who have the courage to stand in front of many people and present their ideas. It’s easy to give remarks on how good (or bad) a football player is, however it’s far more difficult to actually play football in the real field under the scrutiny of millions of eyes.\n\n(`_|_`)Jul 12, 2009(`_|_`)ariya.io(`_|_`)towards-a-better-talk', 'towards-a-better-talk'),
(388, 'paella de marisco(`_|_`)\n\n\nAlso known as seafood paella, something we tried when we were in Las Palmas, Gran Canaria. Now I am motivated to cook it myself, sometime in the near future, in particular since I am also a fan of mussels.\n\n(`_|_`)Jul 11, 2009(`_|_`)ariya.io(`_|_`)paella-de-marisco', 'paella-de-marisco'),
(389, 'who would have thought it would end up like this?(`_|_`)\nComing back to Oslo (from LinuxTag in Berlin), apparently the heat wave which hits Europe was its peak, at least here in Oslo. To add insult to the injury, it does not really help if the ventilation system acts strangely, which it usually does right when you need it. We sort of enjoy the rare moment when Oslo is warmer than most other places.\n\nIn any case, Berlin was fantastic. There were already few blog posts (e.g. from Lydia, Chani, Sebas, Frederik) about LinuxTag so I won’t write too much about it. I was very content with my talk since the room was quite filled when I was doing my presentation. The Qt booth was fun as well, I managed to have short chats here and there with the fellow Berlin trolls, KDAB guys, KDE people, and some other new contacts.\n\n\n\n\n\nAs it was nicely planned long time ago (except a little glitch with some kind of a desktop suite program :-), we did manage a cuisine-exchange program (and it was not about pizza). Hmm, I still need to find those pictures…\n\n(`_|_`)Jul 3, 2009(`_|_`)ariya.io(`_|_`)who-would-have-thought-it-would-end-up-like-this', 'who-would-have-thought-it-would-end-up-like-this'),
(390, '2009 developer days(`_|_`)\n\n\nJust like last year, this fall we will have another Qt Developer Days. Europeans might want to visit Munich, Americans are better served with San Francisco.\n\nWill I go there? Well, unless there is something wrong, yes I will. Note that a little information about the sessions is already available. I leave it as an exercise to the reader, which talks in the Innovate track I will hold \n\n(`_|_`)Jul 2, 2009(`_|_`)ariya.io(`_|_`)2009-developer-days', '2009-developer-days'),
(391, 'save me from being confused, show me what I\'m looking for(`_|_`)\nSince three brings the luck and it is the first Mersenne prime, I am glad to list three QWebView tricks for your pleasure:\n\nNight-mode\n\n\n\nSnap scrolling:\n\n\n\nTransparency, something you have also seen before:\n\n\n\n(`_|_`)Jul 2, 2009(`_|_`)ariya.io(`_|_`)save-me-from-being-confused-show-me-what-im-looking-for', 'save-me-from-being-confused-show-me-what-im-looking-for'),
(392, 'ivory tower? I\'d pick one of the anomalies of water(`_|_`)\nThe Qt/S60 team continues to make some progresses. After Pyramid, Temple, and Garden, finally Tower came out of its cage. For a quick intro of what is inside Tower, check out the video. In particular, QtWebKit is included in this prerelease (yay!), thanks to the hard work of Simon, Norbert, Laszlo, Janne, Kristian, and other great hackers. My little contribution improves from only the basic engine behind the infamous Fluid Launcher (remember PictureFlow?) to a tech-demo QtWebKit-based web browser (created quickly in 1.5 days, cause I needed to rush to LinuxTag) dubbed Anomaly (Mobile). Once I am free again (now we’re busy preparing for Akademy), I will put some more efforts to add more polishes to Anomaly Mobile. Imagine having visual bookmarks, flick support, Google suggest, optimized disk cache, double-tap-to-zoom, of course also smooth zooming in and out, snap scrolling, perhaps even night mode for your Nokia 5800, Nokia N97, and other Nokia touch devices, all implemented with Qt? /me just drools \n\n\n\n(`_|_`)Jun 29, 2009(`_|_`)ariya.io(`_|_`)ivory-tower-id-pick-one-of-the-anomalies-of-water', 'ivory-tower-id-pick-one-of-the-anomalies-of-water'),
(393, 'quattro cinque due(`_|_`)\nAgain the freshly baked: Qt 4.5.2.\n\nDetails on the changes in this release is available in the changes-4.5.2 file. As for QtWebKit, some weeks ago I played the patch monkey role and did backport and test a number of critical fixes from WebKit trunk, among others stuff related to canvas, memory access and leaks, rendering painting and performance, JavaScript, plugin handling, clipboard, SVG, and many others. In addition Simon also tackled the backporting of various security fixes.\n\nOverall, 4.5.2 seems to be a solid patch release. An upgrade from 4.5.x is highly recommended.\n\nIn a related note, Qt Creator 1.2 was also out. It brings a better fakevim plugin, regex search/replace, and numerous other improvements. Grab it while it’s hot.\n\n(`_|_`)Jun 29, 2009(`_|_`)ariya.io(`_|_`)quattro-cinque-due', 'quattro-cinque-due'),
(394, 'and the only chance we have of moving on(`_|_`)\n\n\nLike I wrote before, an exciting event is coming up soon: LinuxTag. I am still polishing the slides for my Advanced Graphics Programming with Qt. In few hours I will be flying to Berlin.\n\nIf you are around, drop Qt Software stand #108 in hall 7.2b a visit!\n\n(`_|_`)Jun 24, 2009(`_|_`)ariya.io(`_|_`)and-the-only-chance-we-have-of-moving-on', 'and-the-only-chance-we-have-of-moving-on'),
(395, 'there was a time that we\'d stay up all night, best friends, talking til the daylight(`_|_`)\n\n\nJust like last year, I took again the picture of the horizon from my apartment, in the early few seconds of Monday. Last Sunday was summer solstice (for the northern hemisphere), the day was 2 seconds longer (in Oslo) compared to Saturday.\n\n(`_|_`)Jun 24, 2009(`_|_`)ariya.io(`_|_`)there-was-a-time-that-wed-stay-up-all-night-best-friends-talking-til-the-daylight', 'there-was-a-time-that-wed-stay-up-all-night-best-friends-talking-til-the-daylight'),
(396, 'Please, I\'ll be strong, I\'m finding it hard to resist(`_|_`)\n\n\nThings are always exciting.\n\nWithin three weeks, I will be in Gran Canaria for the Desktop Summit, specifically for Akademy 2009. The summit is also sponsored by Nokia, via Qt Software and Maemo.\n\nMy talk, Special F/X with Graphics View will be on Tuesday afternoon. There will be some graphics demo which will be shown for time there, so show up if you are interested in. Check also an array of other fabulous presentations.\n\nI can’t wait to finally meet many fellow KDE hackers face to face. And yes, this will be my first Akademy. Afterall, there is always a first time for everything…\n\n\n\n(`_|_`)Jun 10, 2009(`_|_`)ariya.io(`_|_`)please-ill-be-strong-im-finding-it-hard-to-resist', 'please-ill-be-strong-im-finding-it-hard-to-resist'),
(397, 'Wait, I\'m wrong, should have done better than this(`_|_`)\n Things are always exciting.\n\nWithin two weeks, I will be in Berlin for LinuxTag, “Where .COM meets .ORG”, one of the important FOSS shows in Europe. We (as in Qt Software) will have a stand, just check stand #108 in hall 7.2b. Drop us a visit!\n\nAnd if you stay until Saturday, feel free to show up at my short talk (as in 30 minutes) Advanced Graphics Programming with Qt. Nothing fancy there, but if you want to kick-start doing cool stuff with Qt, try not to miss it. Of course, there is a whole stack of attractive presentations at the KDE track (and other tracks, too) on Saturday.\n\nI can’t wait to see Berlin again. And of course, since our very own Mr. Portale lives in Berlin, we would not miss the chance to exchange our cuisine experiences, just like the last time. This time however, I will make sure it’s not only about pizza!\n\nIn all cases, if you are around and want to have a chat, drop me an email (ariya.hidayat AT gmail DOT com).\n\n(`_|_`)Jun 10, 2009(`_|_`)ariya.io(`_|_`)wait-im-wrong-should-have-done-better-than-this', 'wait-im-wrong-should-have-done-better-than-this'),
(398, 'QS_BIND macro magic(`_|_`)\nAt my request, Kent kindly changed the initialization of the Qt bindings (from the binding generator project) so that the class wrappers are populated in a single function for every module. This also means, you don’t have to compile everything as plugins and then deploy them with your scripted application. You can just include the appropriate .pri file (e.g. generated_cpp/com_trolltech_qt_gui/com_trolltech_qt_gui.pri for Qt Gui bindings) and then build together with your project (or compiled to non-shipped, project-wide static library, if you wish).\n\nAnother gem: for each module you will have a source file, e.g. qt_gui_init.cpp for Qt Gui, that is responsible to create the wrapper classes. This means, the two macro tricks would work:\n\n// example: QS_BIND_MODULE(new QScriptEngine, core)\n#define QS_BIND_MODULE(engine, modulename) \nextern void qtscript_initialize_com_trolltech_qt_##modulename##_bindings(QScriptValue &extensionObject;); \n  { QScriptValue extensionObject = (engine)->globalObject(); \n  qtscript_initialize_com_trolltech_qt_##modulename##_bindings(extensionObject); }\n\n// example: QS_BIND_CLASS(new QScriptEngine, QPushButton)\n#define QS_BIND_CLASS(engine, classname) \nextern QScriptValue qtscript_create_##classname##_class(QScriptEngine*); \n  (engine)->globalObject().setProperty(#classname, \n      qtscript_create_##classname##_class((engine)), \n      QScriptValue::SkipInEnumeration);\n\n\n(or download/git-clone it from gist.github.com/125487)\n\nWhile the first is arguable already useful, the second one is interesting because it allows you to limit the bindings to certain classes only. For example, if you want to extend the look-and-feel of some GUI elements in your cool applications, just offer the user the bindings for QPainter, QBrush, QPen, and other related classes. Neat, isn’t it?\n\nOn a related note, you should also perform some kind of dance that our QtScript hero has also created the bindings for the Animation and State Machine frameworks slated for Qt 4.6.\n\nIsn’t the Qt Script world wonderful?\n\n(`_|_`)Jun 7, 2009(`_|_`)ariya.io(`_|_`)qs_bind-macro-magic', 'qs_bind-macro-magic'),
(399, 'how to get Spotify running on OpenSUSE(`_|_`)\nSince there is no native Linux client yet, we have to use Spotify via Wine. On my OpenSUSE 11.1 (32-bit) machine, installing Wine (I got version 1.1.9) is as easy as:\n\nsudo zypper install wine\n\nNow, since I am using KDE 4 with PulseAudio, the step to configure Wine must be modified a bit (after Paul Betts’ hint):\n\npadsp winecfg\n\nThen choose OSS Driver (not ALSA Driver) in the Audio tab. Follow the other steps, i.e. closing it, run winecfg again, choose the right settings for DirectSound.\n\nAfter that, download Spotify for Windows. Open Dolphin, find the download file, click on it. Wine will be automatically launched and the installation will start. After a while, you can enjoy Spotify (even with systray integration).\n\n\n\n(`_|_`)Jun 7, 2009(`_|_`)ariya.io(`_|_`)how-to-get-spotify-running-on-opensuse', 'how-to-get-spotify-running-on-opensuse'),
(400, 'Martabak(`_|_`)\n\n\nMartabak – a popular snack in some places, including my home country, Indonesia – is actually easy to prepare. Basically it is just crepe (but potentially with many eggs for the batter), stuffed with vegetables and (if you wish) minced meat, deep fried for 3 minutes. Typically it is served with a dipping sauce that is a combination of shallots, chili pepper, palm sugar, soy bean, vinegar, and often cucumber slices.\n\n(`_|_`)Jun 7, 2009(`_|_`)ariya.io(`_|_`)martabak', 'martabak'),
(401, 'it got cold and then dark so suddenly and rained(`_|_`)\nCutting a long story short, check out my latest example of a less-than-150-lines code (pick your battle: C++ version or Python version) to show the weather status and day forecasts for almost all places in this blue planet, powered by Google, based on QtWebKit. As always, let’s start with the screenshot (aka the proof):\n\n\n\nI doubt there is a need for this to be a plasmoid, as it will just clutter Plasma with yet another weather applet. But hey, if people like it, I (or someone else, preferably) can make it.\n\n(`_|_`)Jun 3, 2009(`_|_`)ariya.io(`_|_`)it-got-cold-and-then-dark-so-suddenly-and-rained', 'it-got-cold-and-then-dark-so-suddenly-and-rained'),
(402, 'all the blessings in May(`_|_`)\nI was sadly too lazy to update this blog. My only excuse is because there were many good things happened last month. The context here is of course Qt Software and Qt in general.\n\nFirst thing first: we just open our source code repository. It’s git, and it is hosted at http://qt.gitorious.org/. You can track every single commit from the engineers inside Qt Software, fantastic to see how certain bug is fixed and to localize regression breakage. For more goodies in the repository, check out what Benjamin, an ex-troll, has written.\n\nBut the beauty does not stop here. Now we are also accepting external contributions to Qt. It means that you can help us fixing bugs and implementing features. Read and digest the Contribution Guidelines to find out how. Since the repository was opened, every cool kid and his dogs have cloned it like crazy and we even have merged some of the contributions.\n\nThe domino effect. Since now we have the infrastructure on Gitorious, the project repository for Qt/S60 was going public, too. The repository is at www.gitorious.org/+qt-s60-developers/qt/qt-s60. I can imagine that this will be valuable for all the S60 fans out there, not only for Nokia platforms, but for other S60 devices e.g. for Samsung. If you see their video, you realize now what my PictureFlow Everywhere vision all about \n\nIt does not stop there. Some research projects are moving towards more openness. Check for example the really cool multi-touch support being worked on by Brad. Also, the brand-new Declarative User Interface project, a concept of making good looking, fluid user interface via a non-imperative description of the interface. Both projects can be tracked from the repositories at qt.gitorious.org/+qt-developers/qt/multitouch-and-gestures and qt.gitorious.org/qt/kinetic/trees/kinetic-declarativeui, respectively.\n\nTwo bleeding-edges frameworks slated for Qt 4.6, Animation and State Machine, were finally merged into qt/master. If you love to compile Qt on a daily basis, you can really start to use both frameworks for your upcoming cool applications.\n\nLast but not least, do not miss the Qt Mobility project announcement. The project aims to offer good API to access mobile functionalities, both for Nokia and non-Nokia platforms. The first set of API for Service Framework was going public already. Check its repository at qt.gitorious.org/qt-mobility/serviceframework.\n\nAlong with our successful visit to Pycon Tre Italia, can you see now how last month I got adrenalin kicks on a daily basis?\n\nI of course do not abandon Graphics Dojo corner. Expect few cool things coming out in the next few weeks. Stay tuned!\n\n(`_|_`)Jun 1, 2009(`_|_`)ariya.io(`_|_`)all-the-blessings-in-may', 'all-the-blessings-in-may'),
(403, 'traffic jams? no sweat!(`_|_`)\n\n\nRonald and I were doing podcast whose topic is about programming and other related things. We tried not to dive too much into the technical details, though. Check out the first two episodes with me at temanmacet.com.\n\nWe will plan to have this on a regular basis. Who knows this becomes yet-another-Jeff-and-Joel clone?  Feedbacks are warmly welcomed.\n\nNote: skip this if you don’t understand Indonesian. There are tons of similar podcasts in English, so we pick our own lovely language!\n\nAgain, kudos to Ronald!\n\n(`_|_`)Jun 1, 2009(`_|_`)ariya.io(`_|_`)traffic-jams-no-sweat', 'traffic-jams-no-sweat'),
(404, 'Chrome Experiments, Flash-killer, Monster Evolution(`_|_`)\nThese days I am juggling balls. Beside fixing QtWebKit-related bugs, writing more examples on using QtWebKit, I am helping the Kinetic guys with Graphics View optimizations, and working on new Graphics View feature I still can’t elaborate (sorry for the teaser :-). On top of that, I already started to work on Qt Script, learning the intricacies of JavaScript along the way, stress-testing Kent’s Qt Script binding generators, and surely also playing around with the brand-new Qt Script debugger in Qt 4.5. For the latter, even if you are not really into Qt Script, I highly recommend giving it a try, at least watch the screencast from Kent for a start.\n\nUnless you stayed under the rock for the last few weeks, you already heard about Chrome Experiments. These are some extremely cool demos designed to run in a web browser. Of course, there are already tons of demos out there. Chrome Experiments are however different. It relies on a high-performance browser. The reason: the demo is JavaScript intensive and thus a blazing-fast JavaScript engine will make a different. Coupled with the use of HTML 5 Canvas, some of demos simply show many things which are not possible before. Flash will be still here to stay (due to its authoring tools, advanced features, libraries collections, and so on). But I won’t be too surprised if this is going to be a Flash-killer technology. There is O3D but I reckon it tackles a different market segment.\n\n\n\nMy favorite Chrome Experiment is Monster Evolution, an fantastic demo written by Dean McNamee. Try to launch it in your browser (warning: extremely slow if you don’t use state-of-the-art browser). Or just watch the YouTube video. Impressive, isn’t it?\n\nWhen I saw Monster demo for the time, I thought it would be cool to be able to run it as a Qt application. Porting the demo from JavaScript to C++/Qt is one way to do it, but to make the challenge even more painful, I decided to run the monster.js code directly (warning: it’s minified, better check Dean’s open-source 3-D engine behind the demo). There are tons of ways to do, I almost tried every possible permutations. In the end, I managed to run Monster Evolution smoothly, at more than 25 fps on a fairly modern machine. What was to be just a quick hack turned into a struggling but delirious adventure, resulting in a three-installment series.\n\nFor the YouTube generation, here is the time-lapsed screencast (if you prefer, grab the 3 MB AVI).\n\n\n\nIn the first part, The QtScript Menace, I used Qt’s built-in ECMAScript interpreter to run the demo. The performance was not my main concern (though it gave me the chance of using our work-in-progress Qt Script version that uses JavaScriptCore as the back-end), rather the trick on how to run it with as little code as possible. I ended up with a hackish pure JavaScript implementation of the canvas object, along with few lines of glue code, using Qt Script’s feature of making a QObject instance available to the script engine. Surprisingly, it works pretty well. It downloads the JavaScript code from the Internet, setups some stuff and then runs it. For a program comprises 240 lines of C++ and 140 line of JavaScript, I am pretty happy.\n\nFor the second attempt, Attack of the SquirrelFish, JavaScriptCore was chosen as the engine that powers the demo, used via QtWebKit. Again the same trick was employed, with the glue code now relies on QWebFrame’s addToJavaScriptWindowObject and evaluateJavaScript. This requires only minimal changes, with an improved performance as the result (significant and noticeable), especially when JIT is available.\n\nThe saga was closed with the third episode, Revenge of the Cylinders. This time the victim was V8, the JavaScript engine which powers Google Chrome. Again, the code change was minimal, consider that V8 glue code to this little Qt application needs to be written manually. Of course this requires you to build V8, I have included the instructions (works on Linux, Mac, Windows) in the accompanying README on how to do that.\n\nFeel free to try all three methods and let us know the frame-per-second speed-up that you get!\n\n(`_|_`)May 20, 2009(`_|_`)ariya.io(`_|_`)chrome-experiments-flash-killer-monster-evolution', 'chrome-experiments-flash-killer-monster-evolution'),
(405, 'the daylight seems to want you just as much as I want you(`_|_`)\nLike I wrote before, last week I was in Florence for the third installment of Pycon Italia.\n\nI must admit, it was absolutely a fantastic event, so kudos to the the organizer! Everything went without glitches, the auditorium was spacious, coffee breaks and lunch were without compromise. And thanks to our lovely translators, we have on-the-fly, quasi real-time translations both English-to-Italian and Italian-to-English. I guess this is something any others non-English conferences need to copy, it was definitely awesome to be able to follow few talks presented in Italian. Of course, I need to say that it gives a different feeling (for a Python conference) when some VIPs like Guido von Rossum and Alex Martelli were there.\n\nBoth my Advanced Graphics Programming with PyQt and David’s PyQt for Desktop and Embedded Devices were well received. Things could still have been better, for example I had this funny voice due to my hay fever (which was fortunately cured faster thanks to the Italian warm weather) and I did not realize that I packed too much stuff in the talks. Still, we are pretty content with the way it went. Before you ask, according to the organizer, some time in the future the slides and the video will be available online.\n\nNeedless to say, the conference participants were friendly and very passionate. And it was good to meet Enrico again. I also met Matteo whose Qt examples show up from time to time on Planet Qt. We also finally got to know Giovanni and his colleagues from Develer, which was the main drive behind the conference organization. We met a lot of other fellows as well, including KDE evangelists from Salerno. It is still a shame I forgot almost all of my basic Italian, I need to ensure I must polish it before I go to Pycon Quattro.\n\nBeside the conference, Florence proves to be as good as what people say about it. It is beautiful. Amazingly beautiful. And of course, the most important of it, the food was great, as great as it could be. Being a fan of Italian culinary I did sample few excellent dishes, like Pappa al pomodoro and spaghetti frutti di mare. Having dinner outside, in a narrow passage, with happy children running around you, did indeed give a surrealistic atmosphere.\n\nThe obligatory picture of the grandeur facade of the Basilica di Santa Maria del Fiore, the central tourist attraction in Florence, follows:\n\n\n\nBut nothing is more breath-taking than walking next to the river, reaching Ponte Vecchio, enjoying its stunning beauty at night, just on last Saturday when it was exactly full moon!\n\nFor more conference-related pictures, check out PyCon Tre Flickr group.\n\n(`_|_`)May 18, 2009(`_|_`)ariya.io(`_|_`)the-daylight-seems-to-want-you-just-as-much-as-i-want-you', 'the-daylight-seems-to-want-you-just-as-much-as-i-want-you'),
(406, 'PyCon Italia Tre, Firenze(`_|_`)\n \n\nLike I mentioned before, I will spend the next few days in Florence (Italy) for PyCon Italia. I’m preparing my slides and demos, including few things I never posted before (premier show, yay!), for the Advanced Graphics Programming with PyQt talk.\n\nAccording to our flight schedule, tomorrow afternoon David and I shall be in Florence already; so anyone who want to have a chat, drop me an email (ariya.hidayat AT gmail DOT com).\n\n(`_|_`)May 6, 2009(`_|_`)ariya.io(`_|_`)pycon-italia-tre-firenze', 'pycon-italia-tre-firenze'),
(407, 'transparent QWebView and QWebPage(`_|_`)\nSeems that the trick to make a transparent QWebView or QWebPage is not very well known. So here is the magic incantation:\n\nview = new QWebView(this);\n    QPalette palette = view->palette();\n    palette.setBrush(QPalette::Base, Qt::transparent);\n    view->page()->setPalette(palette);\n    view->setAttribute(Qt::WA_OpaquePaintEvent, false);\n\n\nOr grab it at http://gist.github.com/103126.\n\nHere is the result (click to zoom). I put the famous TuxKiller wallpaper as the background for the main window. The central widget is set to a QWebView instance, using the transparent trick. As everyone loves Cube these days, that is the URL I am loading:\n\n\n\nNote 1: of course this does not work if the web page explicitly sets the background color. For example, google.com (see its HTML source) forces a white background.\n\nNote 2: with Qt 4.4’s QtWebKit, you have to use the background brush instead of the base brush. This is changed in Qt 4.5 for consistency with the rest of Qt (it is mentioned in Qt 4.5.0 changes file).\n\n(`_|_`)Apr 28, 2009(`_|_`)ariya.io(`_|_`)transparent-qwebview-and-qwebpage', 'transparent-qwebview-and-qwebpage'),
(408, 'quattro cinque uno(`_|_`)\nFresh from the oven: Qt 4.5.1, Qt Creator 1.1, new SDK.\n\nDetails on what has changed can be examined in the changes file. Now that the release is out, the QtWebKit team is busy again fixing bugs and backporting important fixes for the next patch release (4.5.2). Expect to see more extensive changes there. Few QtWebkit-related examples which I have written are also being cleaned-up and imported as new Qt examples, as we speak.\n\n\n\n(`_|_`)Apr 24, 2009(`_|_`)ariya.io(`_|_`)quattro-cinque-uno', 'quattro-cinque-uno'),
(409, 'Still about color wheel(`_|_`)\nThis is the follow-up to what I wrote before: hue subdivision for mortals.\n\nSeems everyone echoes my sentiment: increasing the coverage area of green is not the right way to go. The easiest explanation is as follows. Since this is an additive color model, due to the higher sensitivity of green, its contribution to other primary colors should be reduced. Effectively, this means we should shrink the green region in the color wheel:\n\n\n\nFor the “Mortal” version in the above picture, I modified the conversion from hue to RGB (assuming fully saturated color), because I discarded the idea of curve-fitting to map the angle to the hue value. Another change is that I gave up keeping the triangle of the primaries, i.e. while 0 is still red (as an arbitrary reference), 0.333 is not green anymore. The actual position of a color component is now determined by the inverse proportion of its part to the grayscale function. I arrive at 26% red, 17% green, and 57% blue. Unsuprisingly, it means blue now occupies most of the space.\n\nUnder each wheel, shown also colors taken from the color wheel, if it is equally divided into eight parts. The result for “Droid” is probably familiar for a lot of people. Comparing it to the “Mortal” version gives an interesting insight. As can be predicted, now the contribution of green is less dominant. Indeed, blue shades are apparent in few more colors. In fact, this arises a problem. The light and dark blue colors (in “Mortal”) look too similar. Compare to the light and dark green (in “Droid”). Maybe this is because the weighting factors of 26:17:57 are completely busted? But then, how shall I come up with nice weighting factors?\n\nSeriously, maybe I should just stop trying all this with an additive color model…\n\n(`_|_`)Apr 22, 2009(`_|_`)ariya.io(`_|_`)still-about-color-wheel', 'still-about-color-wheel'),
(410, 'On hue subdividision for mortals(`_|_`)\nThe use of HSV/HSL color space is obvious when we need to have several colors distributed in an optimal way, colors as unique as possible. For example, SpeedCrunch uses it to autogenerate the colors used for the syntax highlighting feature. The details behind its algorithm was already described by Helder in his Qt Quarterly article Adaptive Coloring for Syntax Highlighting. Basically we use the color wheel and subdivide the hue into equal parts. Primary additive color components are red, green, and blue. This distributes the colors in maximum angular distance with respect to the hue values.\n\nSo far so good. However, it was known that human eyes are generally more sensitive to green than other colors. In computer graphics, this is often manifested in the grayscale function, i.e. the function that converts RGB to a grayscale value. Take a peek at Qt’s qGray(), it gives the red, green, and blue the weighting factors of 11, 16, and 5, respectively. Shall we take this into account when we subdivide the hue?\n\nIf this theory holds, it actually means that a change of shade in the green region should give more perception of change to our eyes then e.g. the same change of shade in the blue region. Another way to say it: the same amount of color difference (to our eyes) corresponds to different angular distances (in the hue component, in HSV/HSL color space) in the green and blue region. Hence, if we want to subdivide green, we can have a smaller spacing there compared to the case where we want to subdivide blue. A simpler way to do it would be to stretch the green region so that it is wider than blue. That way, we just subdivide the color wheels with equal spacings and overall we still get more contributions from green than other components. This is illustrated in the following picture. It will be more “human-friendly”, won’t it?\n\n\n\nHere is a detailed explanation. Suppose a (in the range 0..1) denotes the angular distance relative to a reference. For the purpose of this analysis, assume a=0 means red, 0.333 means green, and 0.667 means blue. This is a 1:1 mapping to the the normalized hue value (in HSL/HSV color space). It is exactly what is shown in the “Machine” version of the color ring in the above picture. On the right, the “Human” version, a=0.333 still means green, same for 0 (red) and 0.667 (blue). However, we see that the yellow color (roughly marks the transition between red and green) is in a different position, same for cyan and magenta. Overall, the coverage area of green is larger, analog to (like previously described) 50% contribution of the green component to the grayscale value. This means that the mapping between a and hue gets more complicated.\n\nA simple solution is to have a custom interpolation between red and green, green and blue, and blue and red. In the case of “Machine”, any value a between 0 and 0.333 corresponds to a linear combination between red and green, and thus the middle point (yellow) sits at a=0.167. For the “Human” version, this is not the case anymore. The distance between yellow-red and yellow-green has a proportion of 11 and 16. Thus, yellow sits at a=0.136. If we continue for green to blue and blue to red in a similar fashion, we will arrive at the complete mapping between a and hue.\n\nI decided to take another route. After few minutes experiment with different curve fitting methods, here is an interesting mapping function:\n\nhue = (1.39 - a * (4.6 - a * 4.04)) / (1 / a - 2.44 + a * (0.5 + a * 1.77));\n\nthat is exactly the one I used to produce the image of the color rings above. You still need to take care of avoiding divide-by-zero (or rewrite it to avoid division: left as a 5-minute exercise to the curious reader), but otherwise the function is smooth and fast enough to execute on modern machine. Isn’t math cool?\n\nOf course, take this with a pinch of salt: likely I make a lot of gross approximation and model simplification.\n\nPersonally I still doubt that this will make a big difference. Afterall, you can hardly distinguish two saturated colors when they have a hue distance less than 0.1. They just look the same, unless we play with the saturation and value. We can even attack it from a different point view: since a bit of shade of green provokes our eyes more than blue and red, should not we shrink the green region instead, and thus effectively reducing its contribution? Or maybe we need to use the concept with a different approach? Or let us just forget it and use subtractive color model instead?\n\nComments? Ideas? Flames?\n\n(`_|_`)Apr 21, 2009(`_|_`)ariya.io(`_|_`)on-hue-subdividision-for-mortals', 'on-hue-subdividision-for-mortals'),
(411, 'this is the world that we live in, the Python world!(`_|_`)\n \n\nIt’s been one year I work for Qt Software (nee Trolltech). Two big releases: Qt 4.4 and Qt 4.5. Qt for S60. LGPL-ed Qt. Graphics Dojo. Going to Munich and Redwood City for DevDays. Things are exciting as ever.\n\nIn one month, I will be in Florence (Italy) for PyCon Italia. I’d have one technical talk: Advanced Graphics Programming with PyQt, see the abstract for details.\n\nCheck also other interesting talks in the schedule. For example, don’t miss PyQt for Desktop and Embedded Devices by our Python+Qt guru, David Boddie. And yes, I would not dare to skip Guido von Rossum’s keynote on Python 3.0.\n\nIf you will be around and want to have a snack or a chat, just let me know!\n\n(`_|_`)Apr 4, 2009(`_|_`)ariya.io(`_|_`)this-is-the-world-that-we-live-in-the-python-world', 'this-is-the-world-that-we-live-in-the-python-world'),
(412, 'what you see is important, how you see it is even more(`_|_`)\nIn case you miss it, Benjamin just added Google Suggest to Arora, within hours after I showed how to do it in Qt Labs. His BSD-licensed Google Suggest implementation is very lightweight, it is pretty trivial to integrate it to most common applications.\n\nScreenshot follows (click to enlarge):\n\n\n\n(`_|_`)Mar 23, 2009(`_|_`)ariya.io(`_|_`)what-you-see-is-important-how-you-see-it-is-even-more', 'what-you-see-is-important-how-you-see-it-is-even-more'),
(413, 'I was blindfolded but now I\'m seeing(`_|_`)\nTwo (old) tricks for the price of one. Well, since it takes two to Tango anyway.\n\nThe first is to make your window movable by dragging, especially if the window does not have a title bar (remember the classic WinAmp?) or use a custom-drawn one (Google Chrome is the prominent example here). To make the challenge more difficult, no change to the main window code is allowed. To reveal the secret (which is a matter of using event filtering properly), go to my Qt Labs blog entry: Moving top-level window by dragging.\n\nTo see it in action, peek at the following screencast (alternatives: YouTube, blip.tv, 3.7 MB Ogg Theora).\n\n\n\nThe second is about Google Suggest. Almost all browsers have supported it. For a minimalistic example on how to do it, check out my other Qt Labs blog on Google Suggest made easy. The demo launches your default browser with the chosen search term, with or without autocompletion.\n\nThe proof lies in this short screencast (alternatives: YouTube, blip.tv, 450 KB Ogg Theora).\n\n\n\n(It is evident that my default browser is Konqueror. I told you I am not that biased \n\nNow just like last time, who is going to turn this into a plasmoid?\n\n(`_|_`)Mar 20, 2009(`_|_`)ariya.io(`_|_`)i-was-blindfolded-but-now-im-seeing', 'i-was-blindfolded-but-now-im-seeing'),
(414, 'it takes two to tango(`_|_`)\n\n\n(`_|_`)Mar 20, 2009(`_|_`)ariya.io(`_|_`)it-takes-two-to-tango', 'it-takes-two-to-tango'),
(415, 'I can see it\'s coming, like a serenade of sound(`_|_`)\nThe initial version of WYSIWYG editor based on QtWebKit (see my post on Qt Labs for details) apparently works pretty well. There are rough edges here and there, something which need fixing, but overall I am quite happy. Live editing a web page opens a whole new possibilty. For an HTML-based help system, you can offer annotation feature, where the user can add his own note right inside the documentation (you may want enable editing on certain parts, not the whole document). You can make a note-taking system that copies something from the web (in HTML) and then the user can touch the content to adjust it to his need. Translate web pages easily, with all the formatting and whatnot intact, and without the need to scare the translators with raw HTML black magic. Any more useful examples?\n\nScreenshots follow. Click on each image to enlarge.\n\n\n\n\n\n(`_|_`)Mar 12, 2009(`_|_`)ariya.io(`_|_`)i-can-see-its-coming-like-a-serenade-of-sound', 'i-can-see-its-coming-like-a-serenade-of-sound'),
(416, 'bias(`_|_`)\nReaders of my blogs might notice the remark “heavy corporate bias” [1] which was the most interesting comment after I showed the result of JavaScript benchmark test. Interesting? Because I work for Nokia [2] and none of the product shown in that benchmark result is from Nokia.\n\n\nOf course I am not stupid. It is just because I am paid to hack on QtWebKit [3], right? It does not matter if I never pushed QtWebKit to replace KHTML or KJS. It does not matter if I never (God forbid) bad-mouthed or insulted KHTML, KJS, KOffice, or any other KDE sub-projects, or any of its developers. It does not matter if I (and other KDE developers and ex-developers here in Qt Software) give our best [4] to ensure that the latest Qt release plays well with KDE 4.x.\n\nI guess some people are just hostile, not matter what I do. The greatest lessons of it are (1) I try to be active again in KDE, despite Real Life ™ would make it a difficult task (2) I will post more food pictures, apparently these did not annoy people enough \n\nOn a slightly unrelated side note: after all these (tough) years, “biased” is probably not really my thing (those who know me well, please speak up!). I use all major browsers on an almost equal basis. Of all three phones I use since I start working for Nokia, none of them are Nokia ones. I enjoy working on QtWebKit, yet I like the simplicity and easy-to-follow KHTML. My home machine runs (the beautiful) KDE 4, my work desktop is still with (the trusted) KDE 3. I am a proud vim user but hardly recommend it to novices. My main debugging tool is still gdb but everyone knows how I praise VS integrated debugging. I like and use git (rebase) with passion, still I believe mercurial patch-queue rocks. I contributed a lot to KOffice but I am a great fan of Jody Goldberg and Michael Meeks’ work on Gnumeric and OpenOffice.org.\n\nIf you come to me [5] and tell me how bad my code is, likely I will buy you a drink. And I am usually still the one who hates my code most.\n\n[1] The phrase “heavy corporate bias” starts to become an insider joke here among my fellow Trolls  [2] The disclaimer in my blog explicitly states do not necessarily represent the official view of my employer. [3] If you fail to see the connection, Chrome and Safari are powered by WebKit as well. [4] We are still human^Troll, and there are only 7 days a week. [5] Nokia employees may not enter the contest. \n\n(`_|_`)Mar 12, 2009(`_|_`)ariya.io(`_|_`)bias', 'bias'),
(417, 'sate kelapa(`_|_`)\nA dish that is on the prominent position of my must-eat list (when I am on vacation) is sate kelapa (or in its local variant known as sate kelopo). This is like the usual satay, except that it is sprinkled with coconut rasp (hence the name, kelapa is coconut) before being grilled, thus giving its distinctive, wonderful and appetizing smell.\n\nYou can find sate kelapa if you travel around Surabaya and perhaps other places in East Java. A portion of 10 pieces typically costs only 50 Eurocents. Served with lontong (bite-size compressed rice), with peanut-mixed-with-soy-bean sauce, you would never stop eating it. There was a time I had a double portion for breakfast, every single day in a week!\n\n\n\n(`_|_`)Mar 12, 2009(`_|_`)ariya.io(`_|_`)sate-kelapa', 'sate-kelapa'),
(418, 'won\'t you take me where the streetlights glow(`_|_`)\nLet’s start with the screenshot (aka the proof):\n\n\n\nFor the full explanation, read what I wrote in our Qt Labs. Basically we just use Google Talk web app for iPhone, which is 100 percent HTML and JS. There is seldom an uglier hack than this.\n\nNow, who is going to turn this into a plasmoid?\n\n(`_|_`)Mar 8, 2009(`_|_`)ariya.io(`_|_`)wont-you-take-me-where-the-streetlights-glow', 'wont-you-take-me-where-the-streetlights-glow');
INSERT INTO `ariyaio` (`id`, `content`, `url`) VALUES
(419, 'chocolate brownies(`_|_`)\nIt is cold. It is snowing outside. It is weekend time. What would be better than baking something delicious?\n\n by Ariya Hidayat, on Flickr”)\n\nBy popular demand, here is the recipe for home-made chocolate brownies. It is so easy, it would never fail. Think about this: last summer, after I was injured in a football match, I had a surgery on my left hand. Effectively for weeks I could use only my right hand. Guess what? I still baked brownies when I was in the mood!\n\nIngredients: 4 eggs, 200 gr sugar, 100 gr flour, 100 gr butter, 100 gr bitter chocolate.\n\nPreheat your oven to 450 K (OK, it’s around 180 C or 360 F). Melt the chocolate. Melt the butter. In a bowl, stir together everything. Grease a pan and pour the mix. Bake for 30 minutes. Enjoy!\n\nFor a variant, add slices of fruit to the mix. My favorite is mango, but banana and orange apparently work pretty well. Usually I also spice it up with a bit of ginger and/or cinnamon.\n\n(`_|_`)Mar 8, 2009(`_|_`)ariya.io(`_|_`)chocolate-brownies', 'chocolate-brownies'),
(420, 'quattro cinque zero(`_|_`)\nToday (three-three-nine, no conspiracy about the chosen date, please!) Qt Software releases Qt 4.5.0!\n\nThere are a number of interesting things about this particular release: lots of performance improvements, simultaneous release of Qt Creator 1.0 which enables the Qt SDK package, LGPL as the new license option, and plenty of new and improved features.\n\nPersonally this is an exciting release for me, since it contains some of my work since I joined Qt Software (nee Trolltech). Among others, I did a bit of optimizations for Graphics View, touched the low-level graphics stuff at times where I understood it, and of course – my main task – integrated a lot of WebKit features into the QtWebKit module.\n\nDownload Qt 4.5 (or via torrents) while it is fresh. Especially with the SDK package, there is no excuse not to learn C++ and Qt anymore.\n\nPS: can you spot me in the group picture? \n\n(`_|_`)Mar 3, 2009(`_|_`)ariya.io(`_|_`)quattro-cinque-zero', 'quattro-cinque-zero'),
(421, 'didn\'t have a choice but to lift you up(`_|_`)\nQTimeLine is a nice class to control animation [1], used among others in Plasma::Animator. There are some curve shapes available for the timeline, from a linear one to some easing combinations. Though linear gives a rather standard movement effect, using easing often can give a better touch. This makes sense, as everything is our daily life usually moves not in a linear movement, due to e.g. inertia and gravity.\n\nWhich brings me to another point. At least for me, the ease in and out curve shapes do not feel as natural as they could be. The solution is to create a custom timeline. This becomes the latest graphics example in our Qt Labs blogs. Basically I use the logistic function (again [2]) for a nice S-shape curve. You can even adjust the sharpness of the S-shape. From the animation (click the Show Panel or Hide Panel button), you might see that the starting part of the curve gives you the feeling of overcoming the inertia of the panel and the friction of the panel to the desktop, while the last part of the curve makes you think as if you release the push force and let the panel slides by itself.\n\nTime to make this as the default curve shape for Plasma? \n\n\n\n[1] For Qt 4.6, a new animation framework is planned which is supposed to give a much more flexible animation control. [2] I used it for the genie effect before. \n\n(`_|_`)Mar 3, 2009(`_|_`)ariya.io(`_|_`)didnt-have-a-choice-but-to-lift-you-up', 'didnt-have-a-choice-but-to-lift-you-up'),
(422, 'For the Glorious Nation(`_|_`)\nApproaching the Qt 4.5 release, in order to relax the atmosphere a bit, and while I was just back from vacation in Indonesia, last week I brought nice goodies to the office. Read what I posted to our internal list:\n\n\nSubject: durian, for the glorious nation of Indonesia\n\nDate: Tuesday 24 February 2009\n\nFrom: Ariya Hidayat\n\nExecutive summary: try durian candies I brought, find them on the desk in the 5th floor, next to the stairs.\n\nDurian [1], an arguably very nutritious and delicious fruit, my all-time favorite snack, best things before sliced bread and LISP, is unfortunately forbidden to be carried in the flight, placing it in the same category as guns and drugs. Since I am not a brave as our Chief Troll (with his cheese adventure), instead of smuggling a large quantity of durians, cowardly I fall back to a simpler solution: durian (flavored) candies. For me, they taste fantastic (albeit not as heavenly as the fresh fruit, or when made into mixed drink [2,3]), but for most people, they stink, smell horribly, and taste disgusting.\n\nWhen you start the losing fight with your stomach, when you count the minutes in the toilet, when your days in Emergency Room are almost over, now think about it: how do most Asian feel about European cheese? [4]\n\nNow I am back on completing my patent application on “Method and Apparatus of Information Extraction from Combatants Using Exotic Tropical Fruit”, before someone ratifies the counterpoint as an addendum to the Geneva Convention.\n\nEnjoy the ride!\n\n[1] http://en.wikipedia.org/wiki/Durian\n\n[2] http://flickr.com/photos/ariyahidayat/3293814359/\n\n[3] http://flickr.com/photos/ariyahidayat/3294638128/\n\n[4] Surprisingly, durian and revenge share a general theme: they are best served cold\n\n\nThese candies of course can not reach the real taste of the fruit itself, especially when made into fresh drink like the picture here:\n\n\n\n(`_|_`)Mar 3, 2009(`_|_`)ariya.io(`_|_`)for-the-glorious-nation', 'for-the-glorious-nation'),
(423, 'JavaScript speed race: reloaded(`_|_`)\nAfter the recent public beta release of Safari 4, it is time to do another round of JavaScript performance testing (see the last one I did). Here I compare the unstable/development releases of different web browsers, when running SunSpider benchmark (runs/minute) and V8 benchmark (raw score). The test machine is Lenovo T61 laptop armed with Intel Core2 Duo 2 GHz, 2 GB RAM running Windows XP Professional SP2. The results follow (longer is better):\n\n \n\nGoogle Chrome 2.0 is the unstable version from the developer channel, where Chrome 1.0 is the stable one. Opera 10.0 Alpha unfortunately still does not include Carakan, the brand-new fast JavaScript engine from Opera. Firefox 3.1 is tested with TraceMonkey enabled, i.e. via javascript.options.jit.chrome set to true in about:config. Konqueror 4.2 is installed from the KDE Windows project (MSVC 2005 built), the latest stable version because its latest unstable still points to 4.1.96. For safety reason, Internet Explorer 8 runs inside Xenocode browser sandbox as the sandboxing overhead was found to be negligible. The laptop’s power manager tool is set to give maximum performance, thus forcing the laptop to always runs at its maximum speed.\n\n(`_|_`)Feb 27, 2009(`_|_`)ariya.io(`_|_`)javascript-speed-race-reloaded', 'javascript-speed-race-reloaded'),
(424, 'bravo bravo quebec(`_|_`)\nTravelling around Sidoarjo, East Java? Drop Steak Liana a visit (located across the train station) and enjoy its rather well-known roasted ribs (Indonesian: iga bakar) for less than EUR 2 per portion.\n\n\n\n(`_|_`)Feb 23, 2009(`_|_`)ariya.io(`_|_`)bravo-bravo-quebec', 'bravo-bravo-quebec'),
(425, 'sweet potato vs steamed sponge cake(`_|_`)\nIf you happen to visit Malang (East Java), do not skip the chance to visit Bakpao Telo right in Lawang, a small city just before Malang. The shopping complex is located conveniently on the main street, its enormous size makes it impossible to miss. What is unique there? A lot of assorted snacks (cakes, cookies, chips, and many more), made of highly-nutritious sweet potatoes, known here as ubi jalar or ketela rambat, often shortened to tela or telo, hence the name.\n\nNeedless to say, the following delicious steamed sponge cake (bolu kukus), which costs me a fortune (20 Eurocents or a quarter dollar), is my favorite.\n\n\n\n(`_|_`)Feb 23, 2009(`_|_`)ariya.io(`_|_`)sweet-potato-vs-steamed-sponge-cake', 'sweet-potato-vs-steamed-sponge-cake'),
(426, 'the ultimate answer to life, the universe, and everything(`_|_`)\n\n\nRemember what I wrote about Qt 4.2 back then? Well now KDE 4.2 also reached it.\n\n\nRock on!\n\n(`_|_`)Jan 27, 2009(`_|_`)ariya.io(`_|_`)the-ultimate-answer-to-life-the-universe-and-everything', 'the-ultimate-answer-to-life-the-universe-and-everything'),
(427, 'Qt, not QT(`_|_`)\nQt, the application framework from Qt Software is written as Qt (capital Q). It is not written as QT (capital Q, capital T). QT can refer to a lot of other things, e.g. Apple QuickTime.\n\nThe official pronunciation of Qt is “cute”. It is not pronounced as “cue tea”.\n\n(`_|_`)Jan 27, 2009(`_|_`)ariya.io(`_|_`)qt-not-qt', 'qt-not-qt'),
(428, 'Qt::CheatTransform(`_|_`)\nQt::CheatTransform was supposed to be a joke in Qt Developer Days graphics talk (though some people took it seriously). It still resembles the idea of blazing-fast by cheating whenever you can. Basically this is about creating a thumbnail preview of a large image in an optimized way. Downscaling an image is usually done using QImage::scaled() function. You have two choices: Qt::SmoothTransformation gives the best quality but very slow or Qt::FastTransformation is extremely fast at the expense of the quality. But what if there is a compromise: not too slow but the quality is still acceptable? Well, apparently it is possible to do. Check out my latest Qt Labs blog which exactly exposes the trick.\n\n\n\nIn the above screenshot, the result of downscaling a 10-megapixel picture is depicted. There are three images, each for Qt::FastTransformation, Qt::SmoothTransformation and one “cheat scaling” method. Use the key 1 to 3 to switch the scaling method and watch out the bottom right image. If you flip back and forth using 2 (for Qt::SmoothTransformation) and 3 (using the cheat method), can you spot the different pixels immediately? Do you think the cheat downscaled image is good enough?\n\nHow about the speed? Check out the following chart (longer is better), which speaks for itself:\n\n\n\nOf course your milage may vary. The above comparison is for downscaling a 10-megapixel image to something like 200×150 pixels. You may gain less for smaller source images, though.\n\n(`_|_`)Jan 26, 2009(`_|_`)ariya.io(`_|_`)qtcheattransform', 'qtcheattransform'),
(429, 'wisdom of the week(`_|_`)\n\nKlug zu reden ist doch schwer, klug zu schweigen noch viel mehr.\n\n\n\nEnglish: To talk cleverly is difficult, to hold the tongue cleverly is even more.\n\n\n\n(`_|_`)Jan 24, 2009(`_|_`)ariya.io(`_|_`)wisdom-of-the-week', 'wisdom-of-the-week'),
(430, 'secrets, a sign, a reason(`_|_`)\nLet us start with a comparison (longer is better):\n\n\n\nIf you see the my latest graphics example: 50% scaling of (A)RGB32 image, you will find a 10x faster way (compared to QImage::scaled() function) to downscale an image to the half its original size, of course with (approximately) the same visual quality as when you use Qt::SmoothTransformation.\n\nFor the readers who also did listened to my Qt Developer Days graphics talk, you can have an idea why I make so much fuss just for image halfscaling  Bear with me and we will reach that point.\n\n\n\n(`_|_`)Jan 20, 2009(`_|_`)ariya.io(`_|_`)secrets-a-sign-a-reason', 'secrets-a-sign-a-reason'),
(431, 'enlightment of the week(`_|_`)\n\nYou would know someone better, not from the way he treats his friends, but rather the way he deals with his enemies.\n\n\n\n(`_|_`)Jan 16, 2009(`_|_`)ariya.io(`_|_`)enlightment-of-the-week', 'enlightment-of-the-week'),
(432, 'capture the idea, before it is long gone(`_|_`)\nUsing WebKit, it is quite trivial to create a tool that grabs the contents of a web page and then saves everything as an image. Together with the new full page zoom feature, we can have the zoomed in or zoomed out version of the page, even at different viewport sizes (which may simulate different screen resolutions). In fact, that is what I describe in Qt Labs on the topic of Capturing web pages.\n\n\n\nJust imagine you can have that small utility and you can run something like (web address, zoom factor in percent, output filename, optionally also the viewport width):\n\nwebcapture www.trolltech.com 50 trolltech.png\n\nwhat would you do then?\n\n(`_|_`)Jan 15, 2009(`_|_`)ariya.io(`_|_`)capture-the-idea-before-it-is-long-gone', 'capture-the-idea-before-it-is-long-gone'),
(433, 'lima golf papa lima(`_|_`)\n\n\nSebastian just announced that Qt 4.5 will be also available under LGPL 2.1. Yes, it’s the Lesser General Public License (check the FAQ). It means a good change for KDE as well.\n\nOne small step for Qt Software, one giant leap for mankind…\n\n(`_|_`)Jan 14, 2009(`_|_`)ariya.io(`_|_`)lima-golf-papa-lima', 'lima-golf-papa-lima'),
(434, 'bleeding-edge ioquake3 to play Quake III: Arena(`_|_`)\n\n\nHere is step by step short instructions if you want to play Quake III: Arena using the bleeding-edge version of ioquake3. Reasons to do this (instead of using the vanilla Q3A executable): ioquake is still actively developed and maintained and it has new fancy features like in-game VoIP, SDL backend, OpenAL support, x86-64 JIT, MinGW build, and many others.\n\nGet ioquake3 source code using subversion, git, or a normal plain web browser.\n\nTo get the source code using Subversion:\n\nsvn co svn://svn.icculus.org/quake3/trunk ioquake3\n\nWindows users might want to use something like TortoiseSVN and enter svn://svn.icculus.org/quake3/trunk to check it out.\n\nSince cool kids are using git these days, I set up an unofficial git mirror of the repository at github.com/ariya/ioquake3/. It is synchronized with the subversion repository. To get the code:\n\ngit clone git://github.com/ariya/ioquake3.git\n\nWindows users might want to use something like msysgit.\n\nIf you are allergic to subversion and git, grab the most up-to-date source code as ZIP or tar.gz package. Use a web browser or tool like wget. How is the last one possible? Hint: download button at the github page.\n\nBuild ioquake3, which is quite easy.\n\nOn Windows, you need MinGW, MSYS, along with typical development packages (gcc, make, etc). Run MSYS, go to the ioquake3 source directory (e.g. C:ioquake3), and just type make. If everything is OK, you will get the executable (e.g. at C:ioquake3buildrelease-mingw32-x86ioquake3.x86.exe). After that, grab SDL 1.2.11 (try to match it with ioquake3, see e.g. C:ioquake3codeSDL12includeSDL_version.h) development package for MinGW, extract it and put it in your MinGW directory (e.g. C:MinGW).\n\nOn Linux/Unix, you need SDL and OpenAL development packages. Then go to the ioquake3 source (e.g. ~/ioquake3) directory and type make. You will find the executables at the build subdirectory (e.g. ~/ioquake/build/release-linux-i386/ioquake3.i386)\n\nStart to play, since the executable is now ready. Before that, we need to copy the Q3A game data.\n\nOn Windows, get the pak0.pk3 from your Q3A CD. Afterwards, find and install Q3A point release 1.32 and then locate its additional data files (e.g. C:Program FilesQuake III Arenabaseq3). Place all these *.pk3 files to your user Q3 directory (e.g. C:Document and SettingsusernameApplication DataQuake3baseq3). Launch ioquake3 and you are set.\n\nOn Linux/Unix, copy all pk3 files to the baseq3 directory (e.g. ~/.q3a/baseq3). Again, if you have installed 1.32 point release, there will be 9 pk3 files needed. Now just launch the ioquake.i386 executable and have some fun.\n\nRelated note: if you don’t own Quake 3, then just download and install OpenArena. Of course, it is not an exact 1:1 copy of Quake 3, but enough to have some fraggin’ fun. You don’t even need to bother with building ioquake3 at all because OpenArena already packages it. If you are bored with Q3A, there are other similar free and good games, like Warsow, Nexuiz, Tremulous, Urban Terror, and many others.\n\n(`_|_`)Jan 13, 2009(`_|_`)ariya.io(`_|_`)bleeding-edge-ioquake3-to-play-quake-iii-arena', 'bleeding-edge-ioquake3-to-play-quake-iii-arena'),
(435, 'white is not the new color(`_|_`)\nLet us start with a screenshot:\n\n\n\nThe graph itself is not something new, since I just recreated SquirrelFish Extreme comparison (against its predecessors). The focus is actually the tool which was used to generate that bar chart.\n\nFor the code and a little explanation, check out what I wrote on Qt Labs on the topic of\n\nQtScript-based bar chart.\n\n(`_|_`)Jan 6, 2009(`_|_`)ariya.io(`_|_`)white-is-not-the-new-color', 'white-is-not-the-new-color'),
(436, 'I could sit for hours finding new ways to be awed each minute(`_|_`)\nJust like Jim Rohn said: Miss a meal if you have to, but don’t miss a book, these days I force myself to read more books more often than before. Here is a list of English fictions that I managed to read fortnightly, in the order of my preference, just in case you are looking for good books and want to read some of them as well.\n\n\nPaulo Coelho’s The Alchemist. I always wanted to finish this one and finally I did. Needless, it is only one of its kind. At one point in your life, you simply need to read and digest this book, because there is just Santiago in each and everyone of us.\nThe Kite Runner by Khaled Hosseini. I wrote the short review before. I also watched the movie, but the movie was not even close to the book.\nThe Curious Incident of the Dog in the Night-time, an award winning book from Mark Haddon. You may finish this small book in a day, but that day will be the day that changes your life. The story is about an intelligent (lots of excellent math references in the book) but autistic young boy who tried to find the villain that murdered a dog. However, the story unfolds into something a lot bigger than that, something that changed his life significantly.\nThe Witch of Portobello, again from Paulo Coelho.The witch, who was murdered, was a woman named Athena. She was very special and her life story was narrated by her relatives and friends. A trivia: find a sentence that exists both in this book and The Alchemist.\nConn Iggulden’s Emperor series: The Gates of Rome, The Death of Kings, The Fields of Swords, The Gods of War. A heavily fictionalized story of arguably the greatest leader ever in the whole Roman Empire, Julius Caesar. I really like these books and want to write a separate short review for this series.\nMarina Lewycka’s very funny A Short History of Tractors in Ukrainian. Both entertaining and educating. I wish someday it will be made into a movie. Set in modern day England, the story of the tractors is told by one of the protagonists, a brilliant old immigrant from Ukraina.\nA Thousand Splendid Sun by Khaled Hosseini (again). A sad story about Mariam and Laila, two Afghan women. It is a very nice read, especially after The Kite Runner. I am, however, a bit spoiled because fews of the plots become more predictable once you recognize The Kite Runner’s patterns.\nThe Book Thief, an award-winning bestseller, written by Markus Zusak. A sad but vivid story of a young German girl’s experience during the second world war. She was closed to Death several times, and it was Death who narrated her story of life.\nThe Last Templar by Raymond Khoury, that draws the commonly used theme: the adventure to find out hundred years old relic, supposed to be guarded by the Templar knight in the old time, which may change the foundation of the religion.\nSandstorm, a wonderful thriller from ex-SAS Michael Asher. George Sterling, upon a hint that his son who was missing in the desert some time ago, mounted a journey to try to find back the lost son. Right from the beginning, it was not smooth at all and soon he would be involved in a mystery larger than just a family reunion.\nA collection of short stories, The Veteran by Frederick Forsyth. The highlight is the short story of the same title, a detective investigation of a murder that looked boring and usual at the beginning but then revealed a much larger matter in the end.\nCaptain Corelli’s Mandolin. Everyone knows the Nicholas Cage version (of the movie), but trust me, the book is much much better. Set in the second world war, the story is about the struggle of an Italian captain in an island in Greece.\nAnother one from Raymond Khoury: The Sanctuary. Again about a secret, a centuries-old relic, that was supposed to change the way we look at the life and the universe.\nThe Apocalypse Watch, written by Robert Ludlum. A top-notch agent disappeared after successfully sneaked into a supersecret military facility. What did happen to him? His brother was set to find that out.\nWith a backdrop of second world war, The Black Order, a spy-thriller by James Rollins, is a story of the search for the cause of life. Introducing the concept of quantum evolution, apparently it was also possible to abuse the technology to “modify” the life itself.\nA reporter was missing and someone was supposed to find him. All of sudden, a mystery and a big conspiracy were the stake. Andy McNab’s Crossfire.\nEast of The City by Grant Sutherland. Yet another thriller (albeit with a slow start) about an underwriter which, when doing an investigation, was dragged into his dark past.\nWhat if you try to trace the mysterious girl who lived in your place before? That is what Michael Connelly wrote in the tech-thriller Chasing the Dime. At first, it looked just normal, but soon it became an important part of a dangerous game.\nUltimate Weapon from Chris Ryan. A story of two men fighting in war-time Iraq to find their loved one.\n\n\nI may forget some other books. But maybe those are not really important after all.\n\n(`_|_`)Jan 3, 2009(`_|_`)ariya.io(`_|_`)i-could-sit-for-hours-finding-new-ways-to-be-awed-each-minute', 'i-could-sit-for-hours-finding-new-ways-to-be-awed-each-minute'),
(437, 'on coincidence(`_|_`)\n\nKein Sieger glaubt an den Zufall.\n\n\n\n— Friedrich Nietzsche\n\n(English translation: No winner believes in coincidence)\n\n\n\nPhoto by this girl.\n\n(`_|_`)Jan 3, 2009(`_|_`)ariya.io(`_|_`)on-coincidence', 'on-coincidence'),
(438, 'graphics dojo in 2008: a wrap-up(`_|_`)\nIf you show some friends an ancient trick to multiply two numbers in your head within seconds, typically you would either get a dismissal (“Fast? A calculator or Google is faster!”) or an excitement (“How useful!”). Each response is justified. In our daily activities, we seldom face the situation that force us to only multiply two numbers and right at that moment you don’t have a calculator (or Google) at your disposal. However, knowing such an art can help you to improve your overall math skill, cast away the unnecessary fear, build your passion for math, and makes you ready for the next level. As Louis Pasteur once expressed, “In the field of observation, chance favors the prepared mind”.\n\nThe same goes for some of the graphics examples I have written for that Labs Graphics Dojo corner, and also what I have shown in my Developer Days talk. The most common comment is “Blazing-fast? Just use OpenGL!” That is very true, and I could not agree more. However, googling for 27*31, which gives the answer one second faster than my brain, will not make me fall in love with math. The concern of the talk was more about the tricks and the passion behind them. It could be only me, but I feel that developers start to lose passion for graphics, even though they have to deal with lots of user interface stuff. We are practical enough already, we know when to use Google or when to do it ourselves, but we can not afford to let the passion goes away. After all, Zack started it under the name Graphics Dojo not e.g. Graphics Oracle, as it is merely a training place rather than a collection of solutions.\n\nAlthough it is implicitly stated, if I were Louis Pasteur, I would have gone further and said “chance favors the prepared and passionate mind”.\n\nThat is, 2008 is coming to its end. Around mid 2008 Samuel and I agreed to resurrect our beloved Graphics Dojo corner. I hope our attempt did not fail (miserably), in particular since I was new to this wonderful world of graphics.\n\nSqueezing a couple minutes here and there, making the best out of rainy weekends, firing vim to code during some sleepless nights (instead of browsing the web aimlessly), redirecting my passion to graphics between fixing WebKit bugs, here is a list of biweekly Dojo examples that I managed to pull off this half-year:\n\n\nGenie effect, after the similar one made popular in Mac OS X.\nFlick charm to make any scroll area flickable.\nCustom web view with panning support, useful for touch device.\nImage colorizer using painter composition.\nA simple image viewer with support for remote URL drag-and-drop.\nVisual Google, where your search result is accompanied by the thumbnail previews of the hits.\nSmall tool called websnap, given a web page it will create the preview.\nParallax sliding effect for, say, a home screen in a mobile platform (phone, portable device, you name it).\nSVG rasterizer using WebKit as the rendering back end.\nQuake-like underwater effect. Simple old school trick.\nHSV pie with QImage pixel manipulation.\nDreamy feeling by bloom effect, as some sort of composition example.\n\n\nAnd while you are there, check out examples written by my fellow Trolls:\n\n\nWolfenQt, a Qt version of Wolfenstein 3-D along with embedded Qt widgets.\nBloom filter as an example of the new pixmap filter feature.\nTranslucent widget, for X11.\nText zooming through painter scaling.\nRadial blur like in the nineties.\nMix widgets and Graphics View to have widget acceleration with OpenGL.\n\n\nHappy New Year!\n\n(`_|_`)Dec 27, 2008(`_|_`)ariya.io(`_|_`)graphics-dojo-in-2008-a-wrap-up', 'graphics-dojo-in-2008-a-wrap-up'),
(439, 'oh, Clifford(`_|_`)\n“You could not live without quaternion, could you?”, so was the impression of my advisor.\n\nWilliam Hamilton and William Clifford are my heroes. I fell in love with quaternion some time ago and used it with passion in my dissertation (check the summary). Those who had done extensive polarization analysis using matrix and quaternion would come to the usual conclusion: for this context, quaternion and polarization analysis is a marriage made in heaven.\n\nNow I realize that few days left until 2008 is gone. This would mark my biggest failure for this year. Sadly, I fail (again) to learn Clifford algebra in depth.\n\n(`_|_`)Dec 21, 2008(`_|_`)ariya.io(`_|_`)oh-clifford', 'oh-clifford'),
(440, 'fragrances(`_|_`)\nI decided to ask her. “Sorry if I’m rude, but isn’t your perfume Escada Moon Sparkle For Men?”\n\nShe smiled. “Yes, and it is wonderful. ” She continued smiling. “I got it from a customer, I work in a bank.”\n\n“Ah, I see.”\n\n“Don’t you also use Bruno Banani Pure Woman?“, her turn now to ask me.\n\n“Oh, yes I do. So I feel that my other half is always there.”\n\nOne second passed. Then we shared a laugh.\n\n(`_|_`)Dec 20, 2008(`_|_`)ariya.io(`_|_`)fragrances', 'fragrances'),
(441, 'code less. create more. with Qt Creator.(`_|_`)\nCongratulations to the Qt Creator team for the Beta release! In case you live under the rock, Qt Creator is the new-IDE-on-the-block. It is now open source and it has just reached beta, so just download it (Windows, Mac, Linux) or learn more about it. For the braves, check also its shiny new open repository, start git cloning and hack on it!\n\n\n\n(`_|_`)Dec 18, 2008(`_|_`)ariya.io(`_|_`)code-less-create-more-with-qt-creator', 'code-less-create-more-with-qt-creator'),
(442, 'happy holidays (from Qt Software)(`_|_`)\n\n\n(Or see the video on YouTube)\n\n(`_|_`)Dec 17, 2008(`_|_`)ariya.io(`_|_`)happy-holidays-from-qt-software', 'happy-holidays-from-qt-software'),
(443, 'genie in a bottle(`_|_`)\nLet us start with a screenshot:\n\n\n\nFor the code, the hack behind it, and a screencast/video, check out\n\nmy Qt Labs blog entry.\n\n(`_|_`)Dec 15, 2008(`_|_`)ariya.io(`_|_`)genie-in-a-bottle', 'genie-in-a-bottle'),
(444, 'every day a false start and it burns my heart(`_|_`)\nThis week in Oslo we have visitors, as evidenced from this picture:\n\n\n\n(Zoltan, Holger, Simon, another Zoltan, Enrico, Tor Arne, Ariya).\n\nBasically we are doing a QtWebKit hackfest. Beside the usual three musketeers of us (Guardians of QtWebKit here in Oslo), we have also two Zoltans and Akos (not in the picture) coming from University of Szeged, as well as Holger (WebKit open-source developer) and Enrico (Italian ueber-hacker).\n\nWe managed to nail down a lots of stuff, among other the discussion about development workflow using git, a heavy round of final API review, brainstorming on the DOM API, ACID3 patches merge and some, font, handlings, lots of bug fixes and touches such as fix for annoying focus problem, cursor flashing, proper non SVG build, multiple file chooser support, state save and restore signals, native plugins, instance lifetime, file extension for images, autogenerated inspector qrc, fix for Enter does not work, missing plugin icon, and many other stuff, including non-technical ones.\n\nIt is a fun hackfest and we certainly need to do this more often \n\n(`_|_`)Dec 13, 2008(`_|_`)ariya.io(`_|_`)every-day-a-false-start-and-it-burns-my-heart', 'every-day-a-false-start-and-it-burns-my-heart'),
(445, 'knocked out(`_|_`)\nThe beauty of taking a trip from/to South East Asia is simply its ridiculous journey. In the last 72 hours, I have been in 6 different airports, gone through 7 hours timeshifting, trapped 3 times in inhuman traffic jams, exposed to 40 Kelvin temperature drop, and of course enjoyed only sporadic in-flight sleeps and food.\n\nFor my aging, weak body, it hardly comes as a surprise that I am K.O.\n\n(`_|_`)Dec 8, 2008(`_|_`)ariya.io(`_|_`)knocked-out', 'knocked-out'),
(446, 'scrolling through the paragraphs, clicking through the photographs(`_|_`)\nI heard that seven is a magic number. I am seeing the seventh winter in my life. How magical.\n\nFor roughly 300 weeks I stay in Europe already. And I will still be here for some time to come. But after reaching some of my goals, missing many others, I decided I will pay my home country a visit.\n\nBracing for the impact of reverse culture shock.\n\n(`_|_`)Nov 18, 2008(`_|_`)ariya.io(`_|_`)scrolling-through-the-paragraphs-clicking-through-the-photographs', 'scrolling-through-the-paragraphs-clicking-through-the-photographs'),
(447, 'the sky will be my shroud, a monument of cloud(`_|_`)\nThings are still exciting as ever. In two weeks, I will be in Bali. Yes, I will be there for the Workshop on Open Source and Open Content (WOSOC) that is held in conjuction with IEEE Conference on Signal-Image Technology and Internet-based Systems.\n\nCheck out the full schedule, find the invited talk: Qt for Rapid Mobile Application Development, and enjoy some demos that I will premiere there. Update: the talk is actually one of the keynotes.\n\nSo, if you are around and want to have a snack or a chat, just let me know! Mail me at ariya.hidayat@gmail.com.\n\n(`_|_`)Nov 16, 2008(`_|_`)ariya.io(`_|_`)the-sky-will-be-my-shroud-a-monument-of-cloud', 'the-sky-will-be-my-shroud-a-monument-of-cloud'),
(448, 'everything is better when you hear that shout(`_|_`)\nIn Oslo? Don’t miss Mithas The Sweethouse (Grønland 2A Oslo)!\n\n\n\nPhoto by this girl.\n\n(`_|_`)Nov 16, 2008(`_|_`)ariya.io(`_|_`)everything-is-better-when-you-hear-that-shout', 'everything-is-better-when-you-hear-that-shout'),
(449, 'Flickify!(`_|_`)\nAs Harry entered the room, he saw Ron hopelessly fighting with his magic tablet. Ron was desperately trying to look for something using the tablet. Harry pulled his wand and then “Flickify!”\n\nThe Qt Everywhere mantra means that Qt will be available in more and more platform,\n\nincluding of course mobile devices. For example, the recently announced\n\nQt S60\n\nmeans that 80 million devices can become the target market for Qt application developers.\n\nIn another front, touch screen seems to be the future direction.\n\nNokia 5800 XpressMusic (better known\n\nas Tube) starts the new generation of S60 devices with touch screen. As introduced\n\nby Apple on iPhone, navigating a long list in a device with touch screen is best\n\ndone using flickable list. The scrolling effect is also often known as\n\nkinetic scrolling.\n\nThough up to now Qt does not offer an official mean to flick-enable your list,\n\napparently it can be done without too much effort. Heck, you do not even\n\nneed to modify your code.\n\nFlick Charm,\n\nmy latest graphics example exactly demonstrates the idea. The trick is to use\n\nan event filter to hijack the mouse events and then to scroll the widget\n\nproperly. This simple charm apparently works on any\n\nQAbstractScrollArea\n\nsubclasses, including all the ItemViews and of course\n\nQGraphicsView as well as\n\nQWebView.\n\nCheck out the following screencast for the proof:\n\n\n\n(Screencast is also available for direct watch at\n\nblip.tv or\n\nYouTube).\n\n(`_|_`)Nov 15, 2008(`_|_`)ariya.io(`_|_`)flickify', 'flickify'),
(450, 'Scrolling QWebFrame programmatically(`_|_`)\nHere is a challenge: how to scroll QWebFrame programmatically, if the scroll bars are invisible? At first you might think: Aha, let us just set the value of the scroll bars! The idea looks great, however it does not work that way (since QWebView is not a scroll area). Though you can change the value of the scroll bars, they are not reflected in a scrolled view. Because the need for this, in Qt 4.5 there will be functions to get and set the scroll offset, regardless whether the scroll bars are hidden or visible. But then, what about the customers for Qt 4.4?\n\nJavaScript to the rescue. Using the rather infamous hook\n\nQWebFrame::evaluateJavaScript,\n\ndoing the task is rather trivial:\n\nQWebFrame *frame = page()->mainFrame();\nframe->evaluateJavaScript(QString(\"window.scrollTo(%1,%2);\").arg(x).arg(y));\n\n\nFor a more complete example, see what I show in our graphics corner lately:\n\nWebView and panning support.\n\n(`_|_`)Nov 14, 2008(`_|_`)ariya.io(`_|_`)scrolling-qwebframe-programmatically', 'scrolling-qwebframe-programmatically'),
(451, 'Tinting through composition(`_|_`)\nAnother example that I showed in Developer Days was an alternative way to tint an image. Suppose you want to have a little feedback to the user when s/he puts the mouse on an icon, what you can do is to colorize the icon while the cursor is still on top of it. Changing the overall tone of the color of an image can be done in different ways. One obvious way is to convert every pixels from RGB to HSV, perform some manipulations on the hue and perhaps also saturation, then convert back the result to RGB, which will be the final color of those pixels. A rather different and less correct approach (though the result is still visually good) is to convert the image to grayscale and then overdraw a big rectangle with certain composition modes, check out my latest entry on Qt Labs Blogs exactly on that matter: Colorize an image via painter composition.\n\nThe included example can also take an image from the web, e.g. drag and drop from Flickr. In case you want to know the trick and/or look for a simple example of QNetworkAccessManager, then follow the simpler code for image viewer with support for remote URL.\n\n\n\n(`_|_`)Nov 13, 2008(`_|_`)ariya.io(`_|_`)tinting-through-composition', 'tinting-through-composition'),
(452, 'Gmail video chat(`_|_`)\nIt does not work on Linux (yet), but this video and voice chat right inside Google Mail will be definitely a killer!\n\n(`_|_`)Nov 12, 2008(`_|_`)ariya.io(`_|_`)gmail-video-chat', 'gmail-video-chat'),
(453, 'visual google(`_|_`)\nRemember the tradition that I started in Redwood City? Well, the parallax sliding demo was for the graphics talk. For my QtWebKit presentation, the challenge was different. Basically it boils down to a visual version of Google Search. Instead only getting the hits and some text snippet, you should also get the web snapshot of the hits. There are apparently browser extensions out there which implement this kind of functionality.\n\nBefore going further, let us see first how we can get a preview of any web page. With QtWebKit, it is as easy as creating a QWebPage and using it to render the content to a painter that operates on an image. Check out websnap example, if you think this is not easy enough. Running websnap to several popular web sites gives the following:\n\n\n\nComing back to visual search. So while rehearsing my talk in the night before, I created the search and snap demo. What is presented as the next dojo example is however a slightly better version (afterall, I have more than just one night to polish it), as I added some text snippet to make it more attractive. The result is as follows, the code can be checkout from the usual graphics corner. As you can see, a third of the code is just reusing the WebSnap class.\n\n\n\nA screencast is worth a thousand screenshots. Thus, for your pleasure, check the following 1-minute video, too. Or view it on blip.tv (high quality), YouTube (low quality, more bandwidth-friendly), or download the Ogg Theora file (3.3 MB).\n\n\n\nSo who is going to turn it into a plasmoid?\n\n(`_|_`)Nov 4, 2008(`_|_`)ariya.io(`_|_`)visual-google', 'visual-google'),
(454, 'World Fastest Optical Polarization Tracking(`_|_`)\nOnce a while, somebody asked me about my dissertation. Since I am working in software industry these days, it is a bit awkward to mention my previous physics and electrical-engineering related work. Now the job becomes easier. I can point those curious guys to the following paper:\n\n\nHigh-speed endless optical polarization stabilization using calibrated waveplates\nand field-programmable gate array-based digital controller\n\n\nThis 8-page text is basically a condensed version of my dissertation, the 2.5 MB PDF file is available for download (free). It would appear in the upcoming Vol. 16, Issue 23 of Optics Express, one of the leading peer-reviewed journal in optics (impact factor last year: 3.709).\n\n\n\nIn a nutshell, the paper consists of two parts: optical retarder characterization and implementation of FPGA-based controller. The first part deals with modelling and estimation of characteristics of off-the-shelf lithium-niobate polarization transformers, then the characterization result is used to calibrate the respective retarders. It uses a new approach based on quaternion analysis. Learning quaternion is a life-changing experience for me, and it seems natural to use it in this context. Unfortunately, as a footnote in my dissertation says “Although, rather surprisingly, quaternion is hardly employed in literature on polarization analysis”.\n\nThe second part is a bit about the controller itself. It comprises an FPGA, some peripherals, and few optical components. The implementation employs a lot of tricks that were imaginable at that time so that the controller can run as fast as possible (control iteration time of 2 us) and in limited resources available on Xilinx Spartan 3. It was a hard task for the few of us. Finally we pulled it off and made it work reliably in a series of experiments. To date, the 15 krad/s stabilization experiment that is reported in that paper is still the fastest endless optical polarization tracking ever recorded on this planet.\n\nEven these days, I often ask myself, what was in my mind when I decided to pick up this challenge back then?\n\n(`_|_`)Nov 4, 2008(`_|_`)ariya.io(`_|_`)world-fastest-optical-polarization-tracking', 'world-fastest-optical-polarization-tracking'),
(455, 'Android-like parallax sliding(`_|_`)\nAt Redwood City Qt Developer Days (also where, BTW, a bunch of KDE geeks made a funny group photo), I started a tradition: throw an idea for a demo and I will implement it for the talk. The challenge for my graphics talk was the subtle effect in the Android‘s home screen. We saw T-Mobile G1 the night before and recalled again the good old games in the eighties. So the next morning I waked up earlier both to rehearse my talk (again) and to implement this parallax sliding. It turned out to be almost trivial to implement (200 lines of code) so just check it out!\n\nFor the lazy, do enjoy the screen capture below, or\n\nsee also the screencast\n\non YouTube\n\nor blip.tv or just grab the\n\nOgg Theora video (4.2 MB).\n\n\n\nHappy parallaxing!\n\n(`_|_`)Nov 3, 2008(`_|_`)ariya.io(`_|_`)android-like-parallax-sliding', 'android-like-parallax-sliding'),
(456, 'Summer of Code 2008 Mentor Summit(`_|_`)\n\nGroup Photo – AndroidOriginally uploaded by Austin Ziegler\n\n\n\nGroup Photo – Main Staircase Building 43Originally uploaded by Austin Ziegler\n\n\nSqueezing the time between the busy schedule, with other three Trolls (Simon, Thiago, Olivier), I attended the Google Summer of Code 2008 Mentor Summit at Googleplex in Mountain View. On the KDE side, we also met Jason and Leo. On the second day, the mentors and the organizers had two group pictures, one in the staircase and one in front of the big Android statue. The six of us from KDE also took a nice picture with the Android background.\n\nMy general impression of the summit: it was awesome! The venue was great, the talks were interesting, the food was nice, the snacks were abundant,\n\nand of course the opportunity to try out Toto E200 – the infamous 14-button toilet – was priceless. Surely the organizers did a very good job!\n\nWhat is also great from Mentor Summit is the chance to meet great people. Since at Qt Software we switched from Perforce to Git, it was nice to be able to talk and discuss matters with Shawn Pearce. He happens to work on Google Android these days, unsurprisingly Android project is of course using git. Still related to Android, there were two talks about it: the story behind and the application development. Also of a great interest is\n\nGerrit, the Python-based code review tool used Android development. According to Shawn, Gerrit is an improved fork of Rietveld, a similar tool written by Guido von Rossum. The mystery of both names is solved if you check out this Dutch architect.\n\nI myself was so glad to be able to have a short chat with one of my personal legends, Sam Lantinga, the man behind the fantastic libsdl. He works for Blizzard and likely you know the game he is working on, as it is called World of Warcraft. As for libsdl itself, the new adventure is SDL for iPhone (which is one of its SoC projects). When finally it is released, I can’t wait to see how many SDL-based games will be then available on iPhone. Plus, if you write an SDL-based application, now you have an interesting fast-growing target market as well.\n\nI also followed a discussion from the 12-year old Dmitri Gaskin. He is the youngest mentor, he is actually too young to participate as a student (the age cut-off is 18). If you are a fan of Google Tech Talks, surely you are aware of his jQuery talk. So we discussed about JavaScript unit test, it involved a lot of coding from his side. I am not a jQuery expert so I just gave my opinions based on my little knowledge on the JavaScript engine in WebKit. I am eager to see how the unit test framework would evolve.\n\nAt the end of the summit, many of us were exhausted. But of course, we look forward to having the next-year mentor summit!\n\n(`_|_`)Nov 3, 2008(`_|_`)ariya.io(`_|_`)summer-of-code-2008-mentor-summit', 'summer-of-code-2008-mentor-summit'),
(457, 'Android meets KDE guys(`_|_`)\n\nKDE and Qt Developers Meet AndroidOriginally uploaded by vanRijn\n\n\n\n\n\n\n\n\n\n\n(`_|_`)Nov 3, 2008(`_|_`)ariya.io(`_|_`)android-meets-kde-guys', 'android-meets-kde-guys'),
(458, 'I chose this mortal life(`_|_`)\n\n\nI wonder if this juice is available somewhere in Oslo, or even Norway, or even Scandinavia, or even mainland Europe…\n\n(`_|_`)Nov 2, 2008(`_|_`)ariya.io(`_|_`)i-chose-this-mortal-life', 'i-chose-this-mortal-life'),
(459, 'KDE + Qt(`_|_`)\n\n\nFor details, check out Jason’s post on KDE/Qt California People Sightings.\n\n(`_|_`)Oct 30, 2008(`_|_`)ariya.io(`_|_`)kde-qt', 'kde-qt'),
(460, 'breaking new ground(`_|_`)\n\n\nCredit: picture by this guy.\n\n(`_|_`)Oct 22, 2008(`_|_`)ariya.io(`_|_`)breaking-new-ground', 'breaking-new-ground'),
(461, 'lamb pizza(`_|_`)\nBy popular demand, here is a quick and easy recipe to make a home-made, fresh, delicious lamb pizza. For faithful Planet KDE readers who are sick of my occasional food ramblings, please skip this one (again).\n\n\n\nA little story about this pizza. Signor Portale (better known as Alessandro), our beloved Italian-German Troll who was in Oslo for a visit, once wisely described the typical pizza sold in the common pizzeria as a bread with homeopathic tomato sauce, simply because the crust is so thick (like a bread) and is not even covered properly by those few accidental tiny drops of the tomato sauce. And let us not even talk about the toppings, usually so thin it is more a bread spread then the well-deserved pizza toppings. Hence, the subsequent real-pizza-making sessions with him. BTW, the result of the following recipe has been surely tested by some Trolls, including Signor Portale himself. As a matter of fact, only from him I could complete my amateurish skill by having to learn the magical charms of love and passion, the two most important cooking ingredients ever!\n\nIngredients\n\nFor the dough:\n\n400 gr all-purpose flour\n\n1 small-pack of yeast\n\n300 ml warm water\n\na few drops of olive oil\n\na pinch of salt\n\nFor the meat:\n\n500 gr minced lamb\n\n1 tbsp garam masala\n\n1⁄4 tbsp curry powder\n\nfew drops of vinegar\n\n1 tbsp lime juice\n\n2 tbsp olive oil\n\n1 large onion\n\n2 shallots\n\n3 cloves of garlic\n\n2 well-beaten eggs\n\n4 tbsp sweet soy sauce\n\n4 stems lemon grass\n\n10cm piece ginger\n\n2 tbsp tomato ketchup\n\n4 basil leaves\n\n1 coriander leave\n\n40gr dried or chopped parsley\n\nsalt and black pepper to taste\n\nchili pepper (optional)\n\nFor the toppings:\n\n200 ml tomato sauce\n\n1 medium aubergine\n\n400 gr ripe tomatoes\n\n1 bunch basil\n\n200 gr corn kernels\n\na handful of oregano\n\nsome pizza cheese\n\n200 gr fresh rocket leaves\n\nIt always start with the cooperation between human and microorganisms. Mix the yeast with warm water. Then mix with the flour and some salt and form a dough. Occasionally drop the olive oil. Set it aside, e.g. for one hour, in a warm place until it doubles its size. For the lazy (who isn’t?), just place the dough in a warm (but not too hot) oven and after few minutes, pull it when it already grows.\n\nTo prepare the meat, sprinkle a generous amount of salt and pepper to the minced meat. Mix garam masala and curry powder, pour in the vinegar and lime juice and then set aside the meat for 1-2 hours. Crush the garlic and chop the onion and shallots, sautee them with olive oil. Mix the eggs as if you would make a scrambled egg. Then finally put the meat. Next are sweet (not salty) soy sauce, tomato ketchup, sliced basil and coriander leaves, bruised lemon grass, ginger cubes. Continue to cook everything with a low heat for one more hour. If necessary, pour in a glass of water and let the water vapors slowly with the heat. You know you are successful when it does not have the typical often-annoying smell (of lamb meat) anymore. Add chopped chili pepper if you like it hot and spicy. Taste and correct seasoning.\n\nFor the toppings, first of all you need around a glass of thick tomato sauce. If you’re lazy or in a hurry, use a ready-made one. Otherwise make it yourself: peel fresh tomatoes, chop them in a food processor, mix the result with sauteed onion and garlic with olive oil, blend some basil, chopped spring onion, and of course salt and pepper to taste. Give another few seconds in the food processor. While waiting for the sauce to blend its taste, slice the aubergine, rub each piece with a drop of olive oil, spray some salt and then bake it (e.g. 5 minutes at 200 C) until it softens.\n\nNow knead the dough. Roll the dough into a pizza base. My preference is usually a very thin one (after all, we’re making a pizza here, not a bread) but some favor to have a thicker crust on the side. Lay the base on a baking sheet, then spread the tomato sauce and sliced fresh tomatoes as well. After that, add chopped basil, already-prepared-and-well-cooked minced lamb, oregano, baked aubergine slices, corn kernels, and the cheese. As with any other pizza, you are of course free to experiment with your own favorite toppings. For example, olive halves, fine-sliced tuna, pepperoni, sliced onion, mushrooms, preboiled shrimps, or cubes of tofu could be a very nice extra. Never hesitate to build your pizza vertically!\n\nBake your pizza, say at 250 C for 10 minutes. It really depends on your oven, so check it every now and then quickly pull the pizza when the cheese completely melts and the crust looks ready. Serve with few rocket leaves (in some places, better know as rucola) and you are done!\n\nLegal notice: You are free to copy, alter, and/or distribute the verbatim or modified copies of this recipe. In fact, do whatever you like with it. This recipe is also provided without any expressed or implied warranties, including if your pizza is burnt or you experience any other casualties.\n\nCredit: the gorgeous picture is thanks to this girl and her Sony Alpha.\n\n(`_|_`)Oct 18, 2008(`_|_`)ariya.io(`_|_`)lamb-pizza', 'lamb-pizza');
INSERT INTO `ariyaio` (`id`, `content`, `url`) VALUES
(462, 'bye, Munich. see you in US!(`_|_`)\n I am back in Oslo for a short rest before flying again to US. Of course, I am still having symptoms of sleep deprivation, in the last 5 days in Munich I managed to accumulate only 19 hours of sleep. Though the schedule was tight, I could squeeze few hours of sight-seeing, among others to visit Castle Neuschwanstein and Viktualienmarkt.\n\nAt least in my opinion, Qt Developer Days 2008 in Munich was a success. Our fellow Trolls who organized this event did a great job. We announced a fresh Qt IDE called Greenhouse and also the first Pimp My Widgets contest (the pimp himself was there on-stage), ate a piece of the 5-years DevDays cake, had a wonderful dinner with the partners and customers, and of course enjoyed a lot of talks and discussions with them as well.\n\nI was quite content with my technical talks: QtWebKit: Present and Future and Beautiful and Blazing-Fast Graphics with Qt. The room was jam-packed for both of them. Lots of questions in the QA session, even more after the talks.\n\nIn about 10 days I will be in Redwood City for US Qt Developer Days 2008. Looks like I will be in around in San Francisco even from the weekend before. In addition, next week I will be in Boston for another business trip. Thus, if you are around and want to have a snack or a chat, just mail me at ariya.hidayat@gmail.com!\n\n(`_|_`)Oct 18, 2008(`_|_`)ariya.io(`_|_`)bye-munich-see-you-in-us', 'bye-munich-see-you-in-us'),
(463, 'message from the pumpkins(`_|_`)\n\n\nDon’t skip Viktualienmarkt, a 200-years-old food market in a square in Munich downtown (Viktualien apparently means food, or rather Lebensmittel in German). In those hundreds of stalls, you can find a lot of things, from fresh organic vegetables (and pumpkins, see above) to a wide selection of ready-to-eat seafood.\n\n(`_|_`)Oct 17, 2008(`_|_`)ariya.io(`_|_`)message-from-the-pumpkins', 'message-from-the-pumpkins'),
(464, 'Pimp My Widgets(`_|_`)\n\n\nYou think you are good? Why don’t you try to win a Segway or some N810. Head straight to:\n\nhttp://trolltech.com/pimpmywidgets!\n\n\n\nUpdate: our pimp announced the contest right after dinner here at DevDays 2008:\n\n\n\n(`_|_`)Oct 14, 2008(`_|_`)ariya.io(`_|_`)pimp-my-widgets', 'pimp-my-widgets'),
(465, 'through my fingers into cold sunlight(`_|_`)\n\n\n“The view from up above is enchanting, especially the view from the Marienbrücke of the castle,…“\n\n— King Ludwig II\n\n\n\n(`_|_`)Oct 13, 2008(`_|_`)ariya.io(`_|_`)through-my-fingers-into-cold-sunlight', 'through-my-fingers-into-cold-sunlight'),
(466, 'the map of my world gets smaller as I sit here(`_|_`)\n\n\nLast weekend, when the weather was just about perfect, there was “Norwegian food in the streets” (official website is www.matstreif.no). It comprised quite a number of stalls that sell (and offer you to sample) products such as honey, fresh organic vegetables, crabs, organic salmon and many others.\n\n(`_|_`)Oct 13, 2008(`_|_`)ariya.io(`_|_`)the-map-of-my-world-gets-smaller-as-i-sit-here', 'the-map-of-my-world-gets-smaller-as-i-sit-here'),
(467, 'magnificent skyline out of my reach(`_|_`)\n As I mentioned before, few hours more until Qt Developer Days 2008 at Hilton Munich Park. Feel free to contact me at ariya.hidayat@gmail.com if you are around!\n\n/me is getting ready for the flight.\n\n(`_|_`)Oct 12, 2008(`_|_`)ariya.io(`_|_`)magnificent-skyline-out-of-my-reach', 'magnificent-skyline-out-of-my-reach'),
(468, 'I fashioned you from jewels and stone(`_|_`)\nThese days, here at Qt Software (nee Trolltech) we are as busy as working bees. Not only due to a point release, but also because the exciting, upcoming Qt 4.5 is in the horizon. Some of us have blogged about its new features, such as Cocoa support and Qt Falcon. As part of the QtWebKit team, we integrated a fresh version of QtWebKit into 4.5, which you might notice already when you monitor our snapshots. In the past few months, we wrote a bit about QtWebKit development, but hopefully we can still present an overall summary once time permits.\n\n\n\nFrom my side, I just completed the first 6-month period in Trolltech. Things are exciting as ever. In one week, I will be in Munich. In three weeks, Redwood City is the next stop. Yes, I will be there for the Qt Developer Days 2008. I’d have two talks in the technical tracks: QtWebKit: Present and Future and Beautiful and Blazing-Fast Graphics with Qt. See the abstracts for details. Actually, just skip the abstracts and enjoy some demos that I will premiere there.\n\nSo, if you are around and want to have a snack or a chat, just let me know!\n\n(`_|_`)Oct 7, 2008(`_|_`)ariya.io(`_|_`)i-fashioned-you-from-jewels-and-stone', 'i-fashioned-you-from-jewels-and-stone'),
(469, 'waiting for a revelation, for someone to count me in(`_|_`)\nJust welcoming the autumn equinox, several things happened in Oslo. Some worth noticing were river walk by torchlight along Akerselva, the 8 km river in Oslo, Culture Night with its closing fireworks, and of course Oslo Marathon right at Aker Brygge.\n\n \n\nAlso, check out the photo sets for torches and fireworks.\n\n(Credit: photos are taken by this girl)\n\n(`_|_`)Oct 4, 2008(`_|_`)ariya.io(`_|_`)waiting-for-a-revelation-for-someone-to-count-me-in', 'waiting-for-a-revelation-for-someone-to-count-me-in'),
(470, 'Eid Mubarak(`_|_`)\nHappy Eid Al-Fitr to all!\n\n(`_|_`)Oct 1, 2008(`_|_`)ariya.io(`_|_`)eid-mubarak-3', 'eid-mubarak-3'),
(471, 'fresh waffle(`_|_`)\n\n\nBy popular request, here is a quick and easy recipe for making waffles. It is so easy, it would never fail.\n\nIngredients:\n\n2 whole eggs, beaten\n\n300 gr all-purpose flour\n\n160 gr butter\n\n140 gr sugar\n\n1 teaspoon baking powder\n\n100 ml milk\n\nvanilla, to taste\n\nOf course, you also need a waffle iron.\n\n(Photo is taken by this girl)\n\n(`_|_`)Sep 24, 2008(`_|_`)ariya.io(`_|_`)fresh-waffle', 'fresh-waffle'),
(472, 'on passion and reason(`_|_`)\n\nIf passion drives you, let reason hold the reins.\n\n\n\n— Benjamin Franklin\n\n\n\n(`_|_`)Sep 22, 2008(`_|_`)ariya.io(`_|_`)on-passion-and-reason', 'on-passion-and-reason'),
(473, 'on CrossOver Chromium (a way for Chrome on Linux)(`_|_`)\nCrossOver Chromium is a nice and easy approach to run the famous Google Chrome browser under Linux (while waiting for the official Linux version and if you don’t want to mess around with Wine). I tried it on my OpenSUSE machine, it works pretty well. There are minor glitches, like maximized window could not be restored anymore (because Chrome skips normal window management), a status bar that does not appear and disappear properly, the omnibox rendering problem, and similar other small annoyances. But all in all, for 11 days of work, it is an amazing achievement.\n\n\n\nChecking its JavaScript performance using SunSpider, it is only up to 40% slower. However, it still feels smooth and fast. Definitely worth a try.\n\n(`_|_`)Sep 16, 2008(`_|_`)ariya.io(`_|_`)on-crossover-chromium-a-way-for-chrome-on-linux', 'on-crossover-chromium-a-way-for-chrome-on-linux'),
(474, 'curiosity kills the cat(`_|_`)\nThe unverified reason Irn-Bru is not available in Germany is because the ingredients label and so on are only English, not in German. Usually this is remedied by sticking another label in whatever language it should be. No idea why it doesn’t work out.\n\nApparently, this famous Scottish soda is available in Norway.\n\n\n\n(`_|_`)Sep 13, 2008(`_|_`)ariya.io(`_|_`)curiosity-kills-the-cat', 'curiosity-kills-the-cat'),
(475, 'on karma (in this zen-like moment...)(`_|_`)\n\nHow people treat you is their karma; how you react is yours.\n\n\n\n— Wayne Dyer\n\n\n\n(`_|_`)Sep 7, 2008(`_|_`)ariya.io(`_|_`)on-karma-in-this-zen-like-moment', 'on-karma-in-this-zen-like-moment'),
(476, 'sushi (again)(`_|_`)\nStill in the same Sushi Factory. As usual, the fried prawn rolls quickly become my all-time favorites.\n\n\n\n(`_|_`)Aug 29, 2008(`_|_`)ariya.io(`_|_`)sushi-again', 'sushi-again'),
(477, 'Mela Festival, Oslo(`_|_`)\nThere is Mela Festival this weekend in Oslo. Lots of food, dance, music, fashion, stalls, as well as some interesting children activities. Too good to miss!\n\n \n\n(see some more pictures)\n\n(`_|_`)Aug 24, 2008(`_|_`)ariya.io(`_|_`)mela-festival-oslo', 'mela-festival-oslo'),
(478, 'Qt 4.4 and Maemo(`_|_`)\nAfter playing a while with Qt 4.4 on my N800 (will be the same for N810), the impression of “slow” (like latest Adam’s latest post) is something that I predicted will soon come out. So far, my very brief investigation reveals that the cause for this is both simple and sad: the Maemo’s X is running 16-bit visual (N8xx’s display is Highcolor only, not Truecolor). Thus, if you do something fancy with 32-bit stuff, like running a QPainter on a Format_ARGB32 or Format_ARGB32_Premultiplied QImage, then basically you force a 32-to-16 conversion every time you blit the image.\n\nTake a look at PictureFlow, the infamous clone of Cover Flow. You can just checkout it, run qmake and make as usual and start to have some fun (all inside Scratchbox, and after that transfer it to the N8xx).\n\n\n\nSurprisingly, it runs horribly slow, probably less than 5 fps. Consider than PictureFlow does its magic by straight pixel manipulation and then just blit the result, this looks really weird. However, it was found out that Qt needs to perform the conversion from 32-bit image to 16-bit pixmap for every single frame, hence the terrible slow down. In short, there is more CPU power wasted for the blitting vs for the rendering. Check your callgrind output to confirm this.\n\nGood news: this is something that can be fixed (both in the application level and probably inside Qt). Personally this one is my favorite aim for Qt 4.5. Once we start to see ported Qt apps for Maemo, we can’t afford to allow a potential performance penalty like this, it would just give a wrong impression of Qt. Don’t you agree?\n\nSidenote: 16-bit can be useful because (on a non-accelerated graphics system), you can perform faster full-screen update (less transferred bytes). 32-bit is however easier to handle because each color component lives in a separate byte.\n\n(`_|_`)Aug 23, 2008(`_|_`)ariya.io(`_|_`)qt-4-4-and-maemo', 'qt-4-4-and-maemo'),
(479, 'Yes, honey (or the beauty of double meaning)(`_|_`)\nA sunny morning in a small coffee shop.\n\n“Hi!”\n\n“Hi!”\n\n“I’d like one chai latte, please”.\n\n“OK.”\n\nThe girl went on to prepare the order. After a while,\n\n“Do you want honey or sugar?”\n\n“Yes.”\n\n“Yes what?”\n\n“Yes, honey.”\n\nOne second passed. Then we shared a laugh.\n\n(Just like in a [HB]ollywood movie)\n\n(`_|_`)Aug 17, 2008(`_|_`)ariya.io(`_|_`)yes-honey-or-the-beauty-of-double-meaning', 'yes-honey-or-the-beauty-of-double-meaning'),
(480, 'dirgahayu(`_|_`)\nAugust 17th is Indonesia’s independence day. Merdeka!\n\n(`_|_`)Aug 17, 2008(`_|_`)ariya.io(`_|_`)dirgahayu', 'dirgahayu'),
(481, 'svg-to-png using (Qt)WebKit(`_|_`)\nRelated to the recent discussion on some problems of Qt SVG renderer when drawing the Oxygen icons, I decided to sit down and wrote an example of yet-another SVG renderer by using QtWebKit (available since Qt 4.4.0). Check out the code if you’re interested, it is part of the Graphics Dojo examples.\n\nThe major difference between this WebKit-based tool compared to QSvgRenderer is that it should handle SVG features which are supported by WebKit. Note that QtSvg limits itself only to SVG Tiny 1.2 without DOM API and scripting (due to various reasons). On the other hand, SVG support in WebKit will be improved over the time. Yes, fancy stuff like filter effects are not fully implemented yet (at least, in QtWebKit), but we are working towards that.\n\nFor those who can’t wait for the DOM API in QtWebKit, you can see the example of poor man’s way of doing it, i.e. by (ab)using evaluateJavaScript() of a web frame. Here it is used to get the SVG width and height attributes. As a hint, if you are unsure about the DOM tree, its elements and/or their attributes, then open the SVG in e.g. Arora or the Demo Browser and use the Web Inspector to check it. The JS console is also helpful to try out various thing right when you view the SVG.\n\nObligatory screenshot follows:\n\n\n\nAnd while you are there, check out also other fresh dojo examples: zooming text and old-school radial blur.\n\n(`_|_`)Aug 6, 2008(`_|_`)ariya.io(`_|_`)svg-to-png-using-qtwebkit', 'svg-to-png-using-qtwebkit'),
(482, 'quattro quattro uno(`_|_`)\nIn case you live under the rock and miss Thiago’s latest blog post, Qt 4.4.1 was just released. This is just a few days after KDE 4.1 was announced and close to three months after Qt 4.4.0 was out.\n\nThis patch release adds tons of bug fixes to the 4.4.0 release. For the WebKit team inside Trolltech Nokia’s Qt Software Unit (by team here it means a group of developers you can count with one of your hand, and still not everyone works full-time on WebKit), beside the usual feature development (like Phonon-based media and Netscape plugin support), we did spend a lot of time fixing important bugs, as evidenced from the 4.4.1 changes.\n\nOn to Qt 4.4.2 and KDE 4.2. The latter would be ten percent of the ultimate answer to life, the universe, and everything…\n\n(`_|_`)Aug 2, 2008(`_|_`)ariya.io(`_|_`)quattro-quattro-uno', 'quattro-quattro-uno'),
(483, 'seas would rise when I gave the words(`_|_`)\nIn the context of improving the user experience (read: wasting more CPU cycles), I couldn’t resist to add a bunch of random and experimental improvements to the experimental feature of live preview in Arora.\n\nFirst of all, I gave up the idea of having a top-level widget, like a QToolTip’s label, to display the preview and this would already wipe half of the annoyances that might show up. Bonus, this makes it easy to have a non-rectangular, translucent tab preview without the need to rely on composite support. Look at the shot below:\n\n\n\nThe callout shape, along with its subtle shadow, is very easy to do with QPolygon. Readers with sharp eyes might notice that the preview is not opaque, you can set the opacity as you like. In addition to that, a simple #define will make the tab preview to use OpenGL for scaling. This is obviously faster on graphics cards with proper, non-buggy accelerated drivers.\n\nSo far everything is done with only around 250 lines of code. I suggest you to give it a try (check out the live-preview branch). Be careful, as this live preview feature is very addictive! Opera and Firefox-with-Tab-Scope-extension users know for sure what I mean.\n\nAnother thing that I’m still undecided is a simple and subtle animation. With QTimeLine, again it would be quite easy. I have another 20-second screencast (watch on YouTube or blip.tv or get the 1.4 MB Ogg Theora video) that demonstrates this:\n\n\n\nMaybe this should be disabled by default. Here I would also like to mention that right now there is no plan from my side to push this to upstream. In plain English: you won’t see this feature in any official release of Arora in the near future. When, at a certain point in the future, I feel confident enough with this feature, then thing might change. But right now, if you want to try it, just pull my branch and compile it.\n\nAnd yeah, I watched The Dark Knight the other day and it’s simply magnificent!\n\n(`_|_`)Aug 1, 2008(`_|_`)ariya.io(`_|_`)seas-would-rise-when-i-gave-the-words', 'seas-would-rise-when-i-gave-the-words'),
(484, 'Be my mirror, my sword and shield(`_|_`)\nThe real blog title should be: experimental live tab (thumbnail) preview in Arora.\n\nThe nice thing about hacking on WebKit is, whenever you feel you want to experiment with some whacky web browser features, you can just go ahead and implement it. The code base is clean and easy to understand. For example, I always wonder how difficult it is to have a tab thumbnail preview like in Opera, where you hover the cursor on a tab and it displays the preview of the web page in that tab. This makes it easy for you to work with dozens of tabs (I know someone in Trolltech who opens at least 30 tabs in a browser :-), because often you can have a glance of the tab before really switch to that tab.\n\nToday [1] I decided to give it a try, of course with QtWebKit. The victim is Arora, the famous lightweight QtWebKit-based web browser. Giving it a thought, there are surely million ways to do it, from QPainter redirection, grabWidget() abuse, Widgets-on-Canvas with GraphicsView, scaled painting even to a GLWidget, you name it. As a starting point, I picked the simplest one [2]: ask the web view to render to a pixmap and scale the pixmap. After an hour or so, I got to put Arora on par with Opera, in terms of tab thumbnail preview [3].\n\n\n\nHowever, the fun just starts now. Remember video with CSS reflection and HTML 5 video support? If you open a tab and plays a video there, then you switch to another tab, then hover the cursor on the previous tab, you can see that the preview is live! [4] The video even plays in that tiny little window.\n\nSince it is impossible to show this live preview feature in a completely static screenshot, I made a 133-second screencast and put it on YouTube. See the video or watch it here:\n\n\n\nAs you can see, basically I opened three tabs: Google (0:04), a web page that plays Transformer trailer video (0:09), and another page that plays the same trailer but with added reflection effect (0:24). Then I switched back to the Google page (0:34) and placed the mouse cursor on the trailer tab (0:38). There you can see the minified trailer running nicely. Whacky? You bet \n\nThere is a big room for improvement, though. For starter, I just did a hack and repainted the preview at 10 fps even though nothing has been changed in the web page (e.g. the page contains no video or animation). This needs to be optimized, say by finding out a way to update only when it is absolutely necessary. Also, the preview scaling could be better, maybe using a QGLWidget for the preview viewport so the graphics card does the scaling for use. Once real full-page zoom is landed for QtWebKit, it is also interesting to explore it for painting the preview. I’m open for more ideas, especially tricks that can push the performance.\n\n[1] After few days only focusing on bug fixing and other usual stuff. Yes, even QtWebKit in Qt 4.4.2 will receive some love and a bunch of bug fixes. [2] The method of course can be improved later on. [3] The code can be found in my cloned Arora repository, under the live-preview branch. [4] Quite a coincidence, but the radio just plays I used to roll the dice, ….. But I reckon you assume that already. \n\n(`_|_`)Jul 30, 2008(`_|_`)ariya.io(`_|_`)be-my-mirror-my-sword-and-shield', 'be-my-mirror-my-sword-and-shield'),
(485, 'vim: lightning fast navigation in a large software project(`_|_`)\nLove vim but need to work with a large software project that spans a dozen subdirectories and a bazillion source files? There are plenty of solutions, vim scripts or external tools, for this particular problem. Here is one that I’ve used for years: using the marvelous project script.\n\n\n\nIt comprises one .vim file (the script) and .txt file (the documentation), thus dead easy to install. After that, just launch vim using: vim +Project (replace vim with gvim if you favor the GUI version), the side pane will be visible. There is where the project tree will be displayed.\n\nFor a quick start, type C and you will be prompted to answer 4 questions, as the example below (my answers are in bold)\n\nEnter the Name of the Entry: KOffice\n\nEnter the Absolute Directory to Load:/home/ariya/koffice/source\n\nEnter the CD parameter:\n\nEnter the File Filter: *.cpp *.h *.c\n\nwhich, as you might guess, create an entry with the given name from all C/C++ headers and sources from the specified directory. Wait a few seconds (or minutes, depending on the project size) for the script to scan files in your disk, at last it will show the tree (as in the screenshot above) in the project window.\n\nYou can, of course, add as many entries as you want.\n\nNote: for optimal usage, do not forget to put this on your .vimrc file:\n\n:let g:proj_flags=\"imstvcg\"\n\nFor details on the meaning, see the script documentation.\n\nNavigating the project tree is easy, if you are familiar with the vim folding. In principle, use zo and zc to open and close the fold right where the cursor is located, or zO and zC to apply it recursively, i.e. for the whole entry.\n\nHow to open a file? Just place a cursor in a file name and press Enter. Since the project window is just a normal window, switching back and forth between the project window and main editing window is as easy as Ctrl+W w. Or you can use F12 to quickly show and hide the project pane. In addition, pressing Space toggle the wide and small version of project pane.\n\nSome more tricks. Because the project window is just a normal vim window, use the blazing fast incremental search (along with n or N) to spot the file that you want. It even does allow you to jump between different matches quickly. Again, if the project window is too narrow, hit Space to make it wider and another Space will return the width back to normal. If you press Enter on a filename to open it, a wide project window is toggled to the usual width automagically. Master this technique and you will open any file you need in an instant.\n\nBecause I love tabbed editing, I also have this in my .vimrc:\n\n:map <c -t> <esc>:tabnew<cr></cr></esc></c>\n\nso that Ctrl+T opens a new empty tab. Wherever I am, I can open KSpread’s Cell.cpp (to have a quick look, hence in a new tab) as fast as hitting Ctrl+T, F12, /Cell.cpp, Enter. Try to beat that.\n\nBut that is not all. You might ask: what’s the use of a big file list if I don’t know which file I need to open? Right, because everyone (and his dog) just needs grep. Use G (which will use vimgrep) and type in your search string. After a while, all the matches are listed in another small window. Choose one that you want and hit Enter, all the magic ensures that the corresponding file will be opened and the cursor is right located in the matched line.\n\nFor more features, e.g. rescan the files from disk, adjust the pane width, execute a command on a file, non-global project tree, etc., refer to the script documentation.\n\nUntap the potential of this wonderful vim script and a 3000-files project is not a burden anymore!\n\n(`_|_`)Jul 16, 2008(`_|_`)ariya.io(`_|_`)vim-lightning-fast-navigation-in-a-large-software-project', 'vim-lightning-fast-navigation-in-a-large-software-project'),
(486, 'from SDL to Qt: the underwater effect(`_|_`)\nDoing a real underwater after effect would involve creating a believable water caustics plus some vertex shader incantations, both are far away from my expertise and it would even have taken more than an hour I would like to spend on the rainy Sunday morning preparing an example for this week’s Graphics Dojo corner. Instead, I just cheated and ported my previous SDL version of Quake-like underwater effect to use QImage, and that became the example. Since this is an animation effect, the still photo below could not really depict the idea. So, just grab the code, build it, drag-and-drop your favorite photo and stare at the result for few seconds.\n\n\n\n(`_|_`)Jul 13, 2008(`_|_`)ariya.io(`_|_`)from-sdl-to-qt-the-underwater-effect', 'from-sdl-to-qt-the-underwater-effect'),
(487, 'Lucky to have been where I have been(`_|_`)\n by Ariya Hidayat, on Flickr”)\n\nThis is Indonesian-style meatballs (but made from lamb instead of beef) served with noodles, soy sauce, chilli sauce and fried onions. It involved mixing mashed lamb with tapioca flour, egg white, garlic, salt, pepper, other herbs to taste and then boiling in hot water.\n\n(`_|_`)Jul 13, 2008(`_|_`)ariya.io(`_|_`)lucky-to-have-been-where-i-have-been', 'lucky-to-have-been-where-i-have-been'),
(488, 'dojo this week: HSV pie(`_|_`)\nUpdate: Fabian Jakobs has ported the Qt/C++ code to HTML Canvas and JavaScript, runnable inside a web browser.\n\nI was having headache fiddling with some fragment programs when Helder (of SpeedCrunch fame) asked me an innocent question that eventually triggered me to write the Graphics Dojo example for this week: rendering the well-known HSV cylinder in 3-D. At first, I thought using a fragment program is the perfect solution, but considering that we are Trolls, let us write a pure Qt solution that works everywhere. So check out the code!\n\n\n\nUnfortunately, in its current state, the code is not really optimized for (near) real-time rendering. If it would have been fast enough (which I guess not really feasible with a non-OpenGL solution), we could have used it for a fancy color picker. Why use a 2-D color picker/dialog when you can have a 3-D one? I’m sure once the 3-D version is introduced, the 2-D version quickly becomes confusing for any creature on this planet.\n\nThe question now: shall I do the HSL sphere?</p\n\n(`_|_`)Jul 5, 2008(`_|_`)ariya.io(`_|_`)dojo-this-week-hsv-pie', 'dojo-this-week-hsv-pie'),
(489, 'Converting between HSL and HSV(`_|_`)\nAmazingly, tons of code fragments on how to convert between RGB and HSV as well as between RGB and HSL do exist (in any imagineable programming languages). However, googling for HSL to HSV conversion did not reveal anything useful. Maybe I was blind, but there is really no point wasting minutes for something that (should be trivial). A quick glance at the wikipedia article on HSL and HSV gave me the following code:\n\nvoid hsv_to_hsl(double h, double s, double v,\ndouble* hh, double* ss, double *ll)\n{\n    *hh = h;\n    *ll = (2 - s) * v;\n    *ss = s * v;\n    *ss /= (*ll < = 1) ? (*ll) : 2 - (*ll);\n    *ll /= 2;\n}\n \nvoid hsl_to_hsv(double hh, double ss, double ll,\ndouble* h, double* s, double *v)\n{\n    *h = hh;\n    ll *= 2;\n    ss *= (ll <= 1) ? ll : 2 - ll;\n    *v = (ll + ss) / 2;\n    *s = (2 * ss) / (ll + ss);\n}\n\n\nError checking is left as an exercise to the reader, corrections are welcomed. If the code seems to be cryptic, then there is a reason to take a napkin and jot some stuff there…\n\n(`_|_`)Jul 2, 2008(`_|_`)ariya.io(`_|_`)converting-between-hsl-and-hsv', 'converting-between-hsl-and-hsv'),
(490, 'return of the graphics dojo: OpenGL-accelerated widgets and Bloom effect(`_|_`)\nAfter almost a year without any sign of life, Samuel and I decide that we should resurrect the Graphics Dojo, i.e. by populating it with some new fresh examples.\n\nBeing a graphics ninja, Samuel’s first example is on how to (finally) put widgets on OpenGL viewport. This is now made possible thanks to Qt 4.4‘s new feature of adding widgets to the graphics scene. Check out his example code, it looks awesome and you can play with it for hours!\n\n\n\nSince I’m new to all this magical graphics world, my first example is however fairly simple: Bloom effect (with pure Qt of course). If you are an avid gamer, you know what I am talking about here. And just for the fun of it, I coded it so that you can drag-and-drop an image right from the web browser, e.g. Blooming your favorite Flickr photo easily.\n\nFeedback is warmly welcomed. Enjoy!\n\n\n\n(`_|_`)Jun 29, 2008(`_|_`)ariya.io(`_|_`)return-of-the-graphics-dojo-opengl-accelerated-widgets-and-bloom-effect', 'return-of-the-graphics-dojo-opengl-accelerated-widgets-and-bloom-effect'),
(491, 'on Jim Rohn quotes(`_|_`)\nJim Rohn quotes have been always my favorites. Here are my picks:\n\n\nSuccess is doing ordinary things extraordinarily well\nMaturity is the ability to reap without apology and not complain when things don’t go well\nMiss a meal if you have to, but don’t miss a book\nLet others lead small lives, but not you. Let others argue over small things, but not you. Let others cry over small hurts, but not you. Let others leave their future in someone else’s hands, but not you\n\n\n(`_|_`)Jun 22, 2008(`_|_`)ariya.io(`_|_`)on-jim-rohn-quotes', 'on-jim-rohn-quotes'),
(492, 'midnight in Oslo(`_|_`)\n\n\nTaken today, half an hour past midnight, where the night lasts for only roughly 5 hours 10 minutes. And Oslo is only at 59° 56′ North. I wish I would have gone further north.\n\n(`_|_`)Jun 22, 2008(`_|_`)ariya.io(`_|_`)midnight-in-oslo', 'midnight-in-oslo'),
(493, 'JavaScript speed race(`_|_`)\nJust for fun, I tested JavaScript performance of several web browsers, using the well-known SunSpider benchmark tool. The test machine is a fairly old Fujitsu-Siemens Amilo notebook with AMD Turion64 1.8 GHz processor and 1 GB RAM, running Microsoft Windows XP SP2.\n\n\n\nThe result is not surprising. Internet Explorer is notoriously slow but there is hope with IE8. Mozilla developers have done a great job optimizing Firefox. WebKit with SquirrelFish (and surely the upcoming Safari 4) really shines in speed.\n\n(`_|_`)Jun 15, 2008(`_|_`)ariya.io(`_|_`)javascript-speed-race', 'javascript-speed-race'),
(494, 'creating fancy screenshots with Screenie(`_|_`)\n\n\nThere are tons of open-source projects, on SourceForge, Google Code, etc. If you check a project, most likely you see the screenshots first (don’t be ashamed, to look at a screenshot is human). And there lies the problem. There is a fairly small amount of coders that are both very good at writing codes and composing good-looking screenshots.\n\nSo we had a terribly hot weekend in Oslo. Too hot to be outside the whole day. So after populating the wonderful weekend with banana brownies (I still favor the one with mango, though), fresh chocolate waffles (let’s see if I can still continue the Sunday morning waffle tradition), huge delicious pizza (as usual I underestimated the size), pasta bolognese ala myself (but still can’t beat the best one, so I was told), every now and then my own interpretation of alcohol-free SOTB (guess what it is. hint: a cocktail of course), and finally some of the worse sushi rolls I ever made (they got it right when they say practice makes perfect), I still have some free time. Then…\n\nI sat down and checked again this old piece of code, Screenie, that I never had time to finish (note to self: do that more often and clean up the junk). It was a tool to compose a screenshot with some style. By style here I mean of course just copy Apple. Why? If you check e.g. Apple Keynote site, you see the proof that simple transformation and effects can make a big difference. What Screenie can do for you should be predictable: to create a screenshot like that.\n\nAssuming you have Qt 4.4 and git, here are the steps:\n\ngit clone git://github.com/ariya/screenie.git\ncd screenie && qmake && make\n\n\n(Likely you need qmake-qt4 for (K)ubuntu and Debian).\n\nBasically you have a window where you can drag-and-drop an image from Konqueror (either local file or from the Internet) and place it there. You have three spots on the screen to fill. Tweak the parameters to achieve the 3-D goodness and translucent reflection that you want. Finally right-click to save the result.\n\nAs some Apple web pages show, there are certain cases where you want two images instead of three. So use your imagination and the check boxes are at your disposal. In the following example, I just drag-and-drop the two Plasma screenshots (one, two) I have on my Flickr straight from Konqueror. Don’t you agree that visually it does make a difference?\n\n\n\nBenjamin was  already playing with that. Helder was using it for SpeedCrunch. Who else wants to join the club?\n\n(`_|_`)Jun 3, 2008(`_|_`)ariya.io(`_|_`)creating-fancy-screenshots-with-screenie', 'creating-fancy-screenshots-with-screenie'),
(495, 'Web Inspector under Linux(`_|_`)\nAre you a web developer, using Linux, and still running Safari under Wine to use its lovely Web Inspector? How about an alternative: use Web Inspector natively under Linux, e.g. inside Arora. Check out my blog post on Trolltech Labs for details.\n\nThe obligatory screenshot for your pleasure:\n\n\n\n(`_|_`)Jun 2, 2008(`_|_`)ariya.io(`_|_`)web-inspector-under-linux', 'web-inspector-under-linux'),
(496, 'learning git the easy way: gitcasts(`_|_`)\n\n\n Think you have problem understanding git? Want to fast-forward your git skills? Just follow Scott Chacon’s excellent and newbie-friendly GitCasts, a collection of screencasts on how to use git.\n\n(`_|_`)Jun 1, 2008(`_|_`)ariya.io(`_|_`)learning-git-the-easy-way-gitcasts', 'learning-git-the-easy-way-gitcasts'),
(497, 'on teamwork(`_|_`)\n\nGood coders solve problems. Great teams make history.\n\n\n\n— tagline of Microsoft Visual Studio ad\n\n(`_|_`)May 19, 2008(`_|_`)ariya.io(`_|_`)on-teamwork', 'on-teamwork'),
(498, 'HTML5 video with reflection(`_|_`)\nPoor Tor Arne. After his super-secret project is leaked, our HTML5 Media ninja has no other choice but to reveal all his cards. HTML5 video/audio, important for next-gen web content, will be available in Firefox, Opera, and Safari, is finally supported in QtWebKit, thanks to Tor Arne. As he wrote there, basically we use Phonon, the multimedia API available from Qt 4.4 onwards.\n\nSince WebKit (thus also QtWebKit) already supports CSS reflections, I decided to combine both the video and the reflection effect. Of course, it just works (click-to-enlarge):\n\n\n\n(As a new WebKit hacker, my skill is only at cranking HTML+CSS like this. Credits should go to Tor Arne and other WebKit chaps for doing the real work).\n\nIf you have sharp eyes, you can see that the following HTML snippet is all you need:\n\n<video src=\'\"videofile.ogg\"\' controls=\'\"true\"\' style=\'\"-webkit-box-reflect:below\'></video>\n\nMore info on the video tag is available elsewhere. Bear in mind that this probably does not work in many common browsers like Firefox 2. You need the next-gen web browsers, try Safari 3.1. You can even use Arora, if you build it against WebKit trunk.\n\nNote that all the bleeding-edge features are available only in WebKit trunk. Unless you want to experience the hassle of building QtWebKit yourself (hint: it is not that difficult actually), the best bet is of course to wait for the Qt 4.5. With the recent addition of NSAPI plugin support (yes, you can watch YouTube using QtWebKit) and now HTML5 Media element, I am excited to see the what kind of plasmoids will show up. But likely within the frame of KDE 4.2, if not 4.3. So, yes, it will take time. Once it is there, however, the sky is the limit. Using both Flash and Media element, imagine all the QtWebKit-based plasmoids deliver the best of YouTube videos, the highest rated movie trailers from the theaters in your neighborhood, some webcam views from your upcoming holiday destination, hand-picked favorite Internet radios and podcasts, etc etc to your desktop.\n\n(`_|_`)May 13, 2008(`_|_`)ariya.io(`_|_`)html5-video-with-reflection', 'html5-video-with-reflection'),
(499, 'the ninja made a movement(`_|_`)\nSo you think Ken Lee is the best Internet meme? Hold on, you haven’t seen Benny Lava yet!\n\n(`_|_`)May 11, 2008(`_|_`)ariya.io(`_|_`)the-ninja-made-a-movement', 'the-ninja-made-a-movement'),
(500, 'before you know it you\'re frozen(`_|_`)\nScreenshot of AccuWeather.com just now (to those who said “Gee, it is cold up there!” the moment they knew I was about to move to Oslo):\n\n\n\n(`_|_`)May 10, 2008(`_|_`)ariya.io(`_|_`)before-you-know-it-youre-frozen', 'before-you-know-it-youre-frozen'),
(501, 'quattro quattro zero(`_|_`)\nIn case you live under the rock and miss Thiago’s latest blog post, Qt 4.4.0 is just released. This latest release packs a lot of exciting new features such as Phonon for multimedia stuff, integration of WebKit (open-source web rendering engine), powerful XML processing  with XQuery and XPath, the famous Widgets on Canvas and Alien Widget, concurrent programming support for multithreaded processing, Qt for Windows CE, and tons of other enhancements.\n\nSurely you wouldn’t want to miss this one!\n\n(`_|_`)May 6, 2008(`_|_`)ariya.io(`_|_`)quattro-quattro-zero', 'quattro-quattro-zero'),
(502, 'I\'ll walk the seven seas when I believe that...(`_|_`)\n\n\nFinally the weather permits some wonderful sightseeing! The above is Holmenkollen ski jump, with its 60 meter high tower.\n\n(`_|_`)May 4, 2008(`_|_`)ariya.io(`_|_`)ill-walk-the-seven-seas-when-i-believe-that', 'ill-walk-the-seven-seas-when-i-believe-that'),
(503, 'SpeedCrunch and git(`_|_`)\n\n\nI have shown before how to use git to manage your code hosted in Google Code Project Hosting and how to synchronize it (automatically) with a public git repository hosted in github. SpeedCrunch, your lovely desktop calculator, is an example of all this.\n\nFlash back first. Due to an increasing demand, some time ago we (=Johan and I) decided that we should provide public Subversion repository for SpeedCrunch. Google Code was new but quickly became the popular choice, so Johan pulled the plug and imported the then latest version of the code. This happened 840 days ago. Fast forward to today. As of now, you can also get SpeedCrunch source code from github, it is available from http://github.com/ariya/speedcrunch/. It means you need as short as:\n\ngit clone git://github.com/ariya/speedcrunch.git\n\nand voila! You get all commits since the first time the code was imported. For fun, try git log e3cddb :-). For practical reasons, right now I only push master and 0.10 branches, which correspond to the trunk and branches/0.10 in its Google Code subversion repository. The .git directory weighs at around 5 MB.\n\nOf course, if you decide to fix bugs and make changes, just push your SpeedCrunch repository somewhere and (if Helder, the current maintainer, has no objection), I can merge into my github repository (if necessary, I would even cherry pick your changes). Think you can do better? Go ahead, sign up for github if you haven’t done so (it’s free!), then you can “fork” the repository easily. Just click on the button labeled fork. When you are happy with your own tree, use the pull request button (in your github repository) to notify me and we’ll see what would happen.\n\nNote: this public git repository is by no means the official one, as the official repository is still hosted in Google Code. It is fully synchronized, though. And by using git, I hope this can spark more contributions in term of new features, bug fixes, translations, etc.\n\nDon’t you just love choices?\n\n(`_|_`)Apr 27, 2008(`_|_`)ariya.io(`_|_`)speedcrunch-and-git', 'speedcrunch-and-git'),
(504, 'vim color gallery(`_|_`)\nFrom vim tip 693: the lovely vim color scheme test. There are even nice preview pages, e.g. for C/C++ highlighting.\n\nIf your choice of color scheme is not shipped with your vim, don’t panic. Just click on the color scheme name, download the .vim file and save it to your vimfiles/colors directory (e.g. for typical Windows users: C:Program FilesVimvimfilescolors).\n\n(`_|_`)Apr 22, 2008(`_|_`)ariya.io(`_|_`)vim-color-gallery', 'vim-color-gallery'),
(505, 'dancing between github and subversion repository(`_|_`)\nAs the next logical step after I wrote about easily using git to work with the subversion repository in Google Code Project Hosting, here is an idea to make your git repository available and still keep it synchronized (in both directions). The use case for my previous blog post is when your partners in crime still stick with subversion but you prefer to use git. Here it is extended further: some (not all) of your contributors start to realize how beautiful git is, try to use it, can’t get rid of it and finally decide it to use only git from now on. It would be a crime to ask them to sync to the subversion repository themselves, hence the following dancing. Basically it works like this. In a Unix/Windows machine, do the usual cloning  of a remote subversion repository and then push it to github. Your new git fans then clone the fresh git repository. It is amazingly simple, obvious and fast to do it this way.\n\nFirst of all, register at github. You don’t need anything except an email address.\n\nNext, prepare your SSH key which will be used for authentication, this can be carried out in one minute, just follow the instructions. Go back to your account page, copy your public key and paste it there in the SSH Public Keys area. Then, use ssh-agent trick to skip typing your password every single time.\n\nTip: if you are on a Windows box and your msysgit does not come with the ssh-keygen tool, use the famous PuTTY (known as the terminal emulation with SSH support). In the package, there is a tool called PuTTYgen (PuTTY Key Generator). Simply launch this tool. Click on Generate button and move your mouse randomly for a few second. After that, type in a secret password in the Key passphrase and Confirm passphrase fields. Click the button Save public key and name the file as id_rsa.pub. Choose menu Conversion, Export OpenSSH key and name the file as id_rsa (without any extension). After that, navigate to your user directory, this is typically C:Document and SettingsUsername. Create a new directory named .ssh, if it does not exist yet. Move both id_rsa and id_rsa.pub to this .ssh directory. Now you are set. File id_rsa.pub contains your public key, so copy and paste it into your SSH Key in the github account page.\n\nNow here comes the fun part: create a new repository. Just fill out a few fields and it is ready. Couldn’t be simpler, could it?\n\nAt this stage, go to your local git working directory (i.e. the one cloned from a subversion repository) and do the following:\n\ngit remote add origin git@github.com:joesixpack/coolproject.git\ngit push origin master\n\nby substituting joesixpack and coolproject with your github login name and the freshly created git repository. Wait a couple of seconds (or minutes), then basically your git repository, which is a clone of the remote subversion repository, is successfully pushed to github. Well done!\n\nTo keep both repositories synchronized, you can run a cron job that does the following:\n\ngit checkout master\ngit svn rebase\ngit svn dcommit\ngit push origin master\n\n\nIf you have branch(es) in the subversion repository, you still can do that. Just add few more commands and substitute master with your branch(es) name.\n\nTip: If accidently you push your local branch to github and now you want to remove it, use:\n\ngit push repository :heads/branchname\n\nOK. So far so good. Now of course you do not work on a single machine, e.g. you may do the above steps in a Linux server but you would like to work on your Windows laptop. At this moment, you need to prepare another SSH key or just use the same key (e.g. copy the previous id_rsa and id_rsa.pub). Then it is a no-brainer to clone your repository:\n\ngit clone git@github.com:joesixpack/coolproject.git\n\nNote: don’t be surprised with the amazing speed of doing a git clone. Essentially, you get the whole repository (which contains the full history of the project) in a short period time, probably comparable to the time needed to check out from the subversion repository (which however gives you only some part of the changes history).\n\nAwesome. In just few minutes, you have a git repository which can be synchronized with a remote repository (e.g. in Google Code project hosting). In addition, you can push this repository to github. And still, you can clone the repository in another machine for your pleasure. Now if you want other people to clone your repository, just tell them to do:\n\ngit clone git://github.com/joesixpack/coolproject.git\ncd coolproject\n\n\nOnce they send patches to you or push their branches, you can do the merge into your git repository and push it to github. Due to the said cron job, the subversion repository (e.g. in Google Code) will get the changes as well. Every now and then, when other contributors commit some changes to the subversion repository, the changes will be also propagated to github. Both parties are happy.\n\nHappy gitting!\n\n(`_|_`)Apr 16, 2008(`_|_`)ariya.io(`_|_`)dancing-between-github-and-subversion-repository', 'dancing-between-github-and-subversion-repository');
INSERT INTO `ariyaio` (`id`, `content`, `url`) VALUES
(506, 'Quick Start: using git (for Windows) with Google Code Project Hosting(`_|_`)\nIdeally everyone uses git, because just as Linus once wrote: Centralized works. It is just inferior.\n\nAnd like what I expressed before, the project hosting feature of Google Code is a nice choice (much better than SourceForge) for doing collaborative works on open source projects. You have a project page, a wiki, a download space, an issue tracker, integrated statistics and mailing-list features, and of course a repository. However, up to now only subversion repository is offered. Likely because of the 80% folks reason.\n\nThat is surely not the end of the world. You can try to polish your growing git skills with that subversion repository by using git-svn. The idea is that you use git and then, once a while, you place the code in the subversion repository. This has several extra advantages than doing git only. First, there is a backup done by Google to your repository. In addition, other developers that know only how to use friendly GUI tools, e.g. TortoiseSVN, can get the code easily. And if they are the project members and contribute some code (through Subversion because that is what those poor guys are using), you can still merge their changes without pain to your master working branch. Also, your code is searchable with Google Code Search and this gives more exposure and promotes code sharing and reuse.\n\nThis short instruction is mainly targeted to “average” Windows developers who wants to use work offline using git and still are not afraid to use command-line, but not for the usual hard-core Linux geeks (who can easily recall the manpage of git even if you suddenly wake them in the middle of the night). For the latter, there are many posts that already cover it. Just so that you are aware, what is written below is not a replacement for the git-svn manual{#baqa}. In addition, suitably adjusted, it should also work with other types of subversion repositories beside Google Code Project Hosting’s one, e.g. your company internal repository.\n\nTo get git, visit the msysgit project (which is, unsurprisingly, hosted on google code). Download the latest version that also includes git-svn, e.g. Git-preview20080301.exe at the time I write this. After that, double click the .exe file to install it. You will be presented with the installation wizard, just accept the default and continue clicking the Next button a couple of times until you finish. Usually it means you’ll get git on C:Program FilesGit and also you can right-click on Windows Explorer window to start doing some git magic from that active folder.\n\nTo initialize the git repository, from Windows Explorer folder tree, right click on a folder and choose the menu item Git Bash here. A console will open, here where you have type in the following:\n\ngit svn clone -s --username=joe.sixpack https://coolproject.googlecode.com/svn git\n\nOf course, substitute joe.sixpack and coolproject with your Google Code user name and project name. The following message will show up:\n\nInitialized empty Git repository in .git/\nAuthentication realm: <https:> Google Code Subversion Repository\nPassword for \'joe.sixpack\':</https:>\n\nand then just enter the generated Google Code password for the subversion repository. If everything is fine, all the revisions in the remote Subversion repository of your project are being pulled to your local git repository. This may take a while, especially if your repository has years of history.\n\nNote: On Windows, git-svn performance is just so-so. Maybe this will be improved in the future version. If suddenly you see git-svn fails at some point with the following error message:\n\nCannot commit config file!\n config svn-remote.svn.branches-maxRev 116: command returned error: 4\n\nthen just retype your last clone command as git-svn would happily continue from where it stops (i.e. no need to pull from revision 1 again).\n\nNow what you get is a subfolder called git (the last argument in the clone command that you typed before) which is your working folder and which contains the git repository (evidenced by a subfolder .git inside it). Switch to this git folder and you are ready for the subsequent steps.\n\nTo compact your git repository, run:\n\ngit gc\n\nIn principle, you need to do this only once a while. Here it is a good idea to do it because you just imported your whole subversion repository.\n\nTip: Because git repository is very compact, don’t bother with disk space when you do the initial step of cloning. This is usually a point that is always repeated by your nearest git evangelist. To give an example, after cloning over 1300 revisions of SpeedCrunch source code, my git repository is only around 7 MB. On the other hand, a single subversion checkout (including all the branches) is already 51 MB. Mind you, that 7 MB contains all changes that have been committed during the history of the project vs 51 MB which is associated only with few subversion revisions only (trunk and several branches).\n\nTo start using git for your brand new cool feature, usually it is best to create a new branch for that particular feature. First, check all the branches that you might have using:\n\ngit branch -a\n\nwhich gives something like:\n\n* master\n  0.6\n  0.7\n  0.8\n  0.9\n  tags/0.7\n  tags/0.7-beta2\n  tags/0.8\n  tags/0.8-alpha\n  tags/0.9\n  trunk\n\n\nwhere the star sign (*) indicates the current branch. The branch called master is created for you automatically, it is basically the local git branch to track the trunk version of the remote subversion repository.\n\nNow create a new branch, e.g. joe/feature1, from master with the command:\n\ngit checkout -b joe/feature1 master\n\nThe name joe/feature1 is arbitrary. It won’t be visible to the outside world because it is your local branch. So feel free use a naming scheme that suits you.\n\nTime to have fun! In this branch, implement the feature that you love and do some coding there. Once you are happy, just commit it (to this branch) using:\n\ngit commit -a\n\nContinue hacking on it until you are satisfied. Make as many commits as you like. The sky is the limit.\n\nFinally, when you think the feature is rock-solid, to merge back your changes to master, do the following:\n\ngit checkout master\ngit merge joe/feature1\n\nwhich means switching back again to the master branch and the apply all the changes that have been done in joe/feature1 branch. Simple and lovely, isn’t it?\n\nNow, what about the poor souls that still need to check out or update the code through the subversion repository in Google Code? Well, you still can push your changes there. To synchronize the remote subversion repository with your git master you need to do:\n\ngit svn dcommit\n\nThe other way around is perfectly possible as well. If your collaborators change something in the remote subversion repository, to keep your git master up to date just use:\n\ngit svn rebase\n\nThat is all. For more advanced techniques, refer to the git-svn manual. Don’t forget to polish your git skills by reading the manual and tutorials as well as (of course) doing a lot of practices.\n\nTip: An alternative to the very first stage of cloning is just to populate the new git repository only with some latest revisions of remote Subversion repository. Use the following commands:\n\ngit svn init -s –username=joe.sixpack https://coolproject.googlecode.com/svn\ngit svn fetch -r 1300:HEAD\ngit gc\n\nwhich will just give all the changes starting from revision 1300 to the last one (HEAD). This is of course not really recommended because you won’t get access to the whole history of your Subversion repository, but it is still useful if your project is very large and you do not care with all those changes made in its prehistoric time. If you use this init+fetch method instead of clone, there is no subfolder created. Your working folder (and git repository) is where you did the init and fetch. Now you can continue the usual steps of creating a local branch, implementing your feature, synchronizing, and so on.\n\nDon’t you just love git?\n\n(`_|_`)Apr 13, 2008(`_|_`)ariya.io(`_|_`)quick-start-using-git-for-windows-with-google-code-project-hosting', 'quick-start-using-git-for-windows-with-google-code-project-hosting'),
(507, 'I think I\'m moving but I got nowhere(`_|_`)\nFortunately, that is not what happens to me (anymore). I moved to Oslo a week ago. It is nice to come back to the place I have shortly visited months ago.\n\nFrom now on, I am working for Trolltech, the best company to work for \n\n(`_|_`)Apr 1, 2008(`_|_`)ariya.io(`_|_`)i-think-im-moving-but-i-got-nowhere', 'i-think-im-moving-but-i-got-nowhere'),
(508, 'accident waiting to happen(`_|_`)\n\n\nWell, given a wonderful kitchen, a new city to explore and a quite amount of free time, never been before I am involved in making assorted pizza variants (mini-pizza, lamb, tuna, tofu), tika scampi, plenty of sushi rolls, fried rice, naan bread, fried noodles, brownies, baked banana, cranberry rolls (the picture above), and some others (that I can’t possibly remember) in just a few days!\n\n(`_|_`)Mar 30, 2008(`_|_`)ariya.io(`_|_`)accident-waiting-to-happen', 'accident-waiting-to-happen'),
(509, 'Guitar Hero for C64(`_|_`)\nWell, ray tracing into a sparse voxel octree might be inspiring, but for the time being, Toni’s Shredz64, which is essentially the Commodore 64 version of Guitar Hero, is tantalizing!\n\n\n\n(`_|_`)Mar 13, 2008(`_|_`)ariya.io(`_|_`)guitar-hero-for-c64', 'guitar-hero-for-c64'),
(510, 'Common characteristics of failed open-sourced projects(`_|_`)\nWho am I to write this one? But, really, it is what I observe in the last couple of years watching some open-sourced projects die slowly.\n\nStart with something big. Imagine you want to create a next-gen music player, sort of Amarok-killer. Don’t worry about skinning, lastfm integration, support for Oracle DB, automation with infrared remote control etc. One step at a time. Just make your player plays MP3 files (or Ogg, pick anything you like) and continue from there. Keep the horizon in your vicinity so that the journey does not look like an impossible intergalactic travel.\n\nBlind design. Don’t get me wrong, design phase is a very important one. However, if you are new to the field, don’t bother too much with the design because your project will need a rewrite anyway. If you never study physics/electrical engineering before and your boss asks you to build a transatlantic fiber optic transmission system, I bet you would need to redesign your system several times so at first no need to talk about transmission impairments, price, modularity, and other issues. If your first serious project is supposed to be a new revolutionary spreadsheet program, never mind about its scalability, multicore CPU support, and Excel interoperability, until you get the core spreadsheet functionalities right first. Design is important, and so is experience.\n\nSmoke without fire. Unless your project is about a web application, then there is little point of discussing which CMS to use, where to host the website, how can we get the artists, etc etc. Sure, good looking web site, developers blog, and maintained forum can give more exposures to the project. But if you are only at the early stage, then just focus on the important part: the application. If you place your project on the host service like Google Code (avoid SourceForge), then the basic tools like subversion/wiki/issue tracker are already at your disposal. No need to show up your PHP skills there or to argue which artwork should be chosen for the logo, that can be done when finally your project has enough users. Spend your precious time doing something more helpful to the project’s important lifecycle.\n\nLack of passion. This is not work, this is supposed to be fun. Nobody holds a gun and tells you to do something. If you want to create a web browser but you hardly browse the web, forget it right away. Think twice: even if you are flamed and criticized, are you still going to love your new baby or not?\n\nToo many mock-ups (will kill you). Yes, mock-ups are wonderful, they help people to visualize the end result of the project. But mock-up only without any code will not drive the project to success. You can’t post hundreds of mock-ups and hope that one or two real coders would step in and implement everything for you. In the open-source world, it is close to impossible to ask people to do what you want (unless you have billions to spare).\n\nFollow the fashion. If you want the fame, do not waste your time doing software and do something more sensible (e.g. practice a lot for the next year’s Idol program). The problem with cool stuff is, when it is not the trend anymore, you are deserted. So stick with common sense and do what you think you can do best, not always what others think must be urgently done. Imagine if we have a dozen of PointCast clones…\n\nReinvent the wheels. Yes, this is so obvious. But let us talk about the components here. For example, even if you hate STL, just use it while you are kickstarting your project. If your design is correct, you can replace it later on (often not trivial, but still better than wasting time creating another library). When you need scripting support, just pick Lua/JavaScript/Python/etc at first. If finally it is absolutely necessary, you can hook your own script interpreter. Focus on building the application, not all the nitpicky details which can be improved with time.\n\nUnderestimate the maintenance. Just check SF, how many projects did become orphaned in the last years? You can create two dozens open-source projects if you want, but if you think you won’t be able to maintain them, then think about it again. Most of the time, we always hope that someone will take over the maintenance, but only a handful projects manage this. I assume, partly because maintaining something is not the fun part of the game. You may get slashdotted when magically you create something out of nothing, while when you fix a bug it is often (sometimes not at all) noticed only by the bug reporter.\n\nWanna add some other points?\n\n(Don’t be trapped in the fallacy: if you see these signs on the project you are working on, it does not mean that your project is bound to fail).\n\n(`_|_`)Mar 12, 2008(`_|_`)ariya.io(`_|_`)common-characteristics-of-failed-open-sourced-projects', 'common-characteristics-of-failed-open-sourced-projects'),
(511, 'Say all I need is the air I breathe(`_|_`)\nIf AIR is supposed to mean Adobe Integrated Runtime, calling it Adobe AIR sounds a bit awkward, right?\n\n(`_|_`)Mar 12, 2008(`_|_`)ariya.io(`_|_`)say-all-i-need-is-the-air-i-breathe', 'say-all-i-need-is-the-air-i-breathe'),
(512, 'who understands this boring blog(`_|_`)\n\n\nAt the time I check Planet KDE, it is for high school while Planet GNOME requires junior high school level. Strangely, my website is only for genius (no wonder I myself could not understand it).\n\nSomeone knows the algorithm behind that detector?\n\n(`_|_`)Mar 11, 2008(`_|_`)ariya.io(`_|_`)who-understands-this-boring-blog', 'who-understands-this-boring-blog'),
(513, 'The Forbidden Kingdom(`_|_`)\n\n\nFinally the long wait is over! In The Forbidden Kingdom, for the first time we are going to see the fantastic Jet Li and Jacky Chan together. Not so much about the story has been revealed. The plot might not be that unusual and even it is likely quite predictable (but who knows until we all watch it). From the trailer, it is mostly about a young bloke that travelled back in time. With a girl and two warriors, he was doing some sort of “prophecy fulfilling” adventure.\n\nFew weeks to go.\n\n(`_|_`)Mar 7, 2008(`_|_`)ariya.io(`_|_`)the-forbidden-kingdom', 'the-forbidden-kingdom'),
(514, 'PhotoFlow as a plasmoid(`_|_`)\n\n\nPhotoFlow, which I introduced less than 48 hours ago, can also be realized as a plasmoid. It is the top left applet in the screenshot above. I have never written a plasma applet in my life before, so it took me quite a while to figure out how the mechanism works. And frankly, I am still not sure whether such a kind of widget can be really useful at all.\n\nI guess I will wait until KDE 4.1 before I place this stuff in KDE’s playground. By that time, Plasma itself should already stabilize. Probably it is even better to integrate it with the Picture of the Day data engine. Or even with the slideshow plasmoid. Or perhaps do you have any other idea?\n\n(`_|_`)Mar 4, 2008(`_|_`)ariya.io(`_|_`)photoflow-as-a-plasmoid', 'photoflow-as-a-plasmoid'),
(515, 'chasing of the day(`_|_`)\n\nWe don’t believe improving your OS should be like chasing Tigers or Leopards.\n\n\n\n— gOS, on its free updates for life feature\n\n(`_|_`)Mar 3, 2008(`_|_`)ariya.io(`_|_`)chasing-of-the-day', 'chasing-of-the-day'),
(516, 'introducing PhotoFlow(`_|_`)\nAs I wrote before, the obvious complaints people are having after trying out Chad’s precompiled PictureFlow for Windows Mobile are (1) slow start-up and (2) memory footprint. These stem from the fact that the example demo program that I included was written for clarity so that you can get your feet wet quickly. To overcome the initial loading and memory consumption problem, of course you have to attack the problem from a different point of view.\n\n\n\nSo here it comes: PhotoFlow. It is a small application for view images and photos, designed to run on mobile devices –like those HTC smartphones, other Windows Mobile phones, Qtopia-based handsets etc– although you can test it of course on the desktop (but I will focus on the intended target platform only). The usual trick employed here is the so-called “delayed loading”. PhotoFlow never attempts to load, resize, and prepare an image to be rendered if that image is not in the vicinity of the user’s view. Thus, it starts rather instantly and won’t suck hundred of MBs of the precious memory space. This is even done without changing anything in the original PictureFlow widget, we just need to subclass it and handle several things smartly.\n\nBecause I am (still) insane, PhotoFlow supports both Qt/Qtopia 4 and the old Qt/Embedded 2.3 (actually also Qt 3, for which there isn’t any embedded version) with a single code base. Also the delayed loading part has two versions: with and without QThread. Of course the former is better but some platforms with Qt/E (or even Qtopia, if you want) might not support threading at all, hence the latter.\n\nGet it while it’s hot and flood my inbox with your flames.\n\n(`_|_`)Mar 3, 2008(`_|_`)ariya.io(`_|_`)introducing-photoflow', 'introducing-photoflow'),
(517, 'to examine and to protect(`_|_`)\n\n\n(`_|_`)Mar 2, 2008(`_|_`)ariya.io(`_|_`)to-examine-and-to-protect', 'to-examine-and-to-protect'),
(518, 'sushi factory bremen(`_|_`)\nIf you happen to be in Bremen, give Sushi Factory a try. It is located right in downtown (see on Google Maps) and easily reachable. The soy sauce is a bit salty for me, but otherwise everything else if fine. The place is cozy. The atmosphere is relaxing. The rolls are of course tasty although they are rather not so cheap. Still, there is a nice bargain for a lunch pack.\n\n\n\n(`_|_`)Mar 1, 2008(`_|_`)ariya.io(`_|_`)sushi-factory-bremen', 'sushi-factory-bremen'),
(519, 'Why are DOC/XLS/PPT so complicated?(`_|_`)\nStill related to the b2xtranslator and the direct availability of Microsoft Office binary (doc, xls, ppt) file formats, the question that is often raised is why are they so complicated? Of course, office suite developers know the likely reasons behind this. But in case you miss the interesting part, read Joel on Software’s insight on this matter.\n\n(`_|_`)Feb 27, 2008(`_|_`)ariya.io(`_|_`)why-are-docxlsppt-so-complicated', 'why-are-docxlsppt-so-complicated'),
(520, 'every night has its dawn(`_|_`)\nYou learn that you can be friends with those who do not always share your thoughts, because differences are not obstacles to a mutual respect. But you get to know others who, for whatever reason it might be, always try to convince every soul in this planet that their opinions are the best. You learn the magical meaning behind loyalty, for you go along with those with whom you can trust your life. Yet you uncover the secret of betrayal and meet those who do not hesitate to stab you in the back when an opportunity present itself.\n\nYou know those who do many different things for the sake of the humanity. You also meet those who tend to keep everything, often not only their belongings, for themselves. You learn that sharing your knowledge is the best way to advance the human civilization. However, some prefer to keep the charms and spells in their own vault as if they are not aware that great minds think alike.\n\nYou learn that your good intentions are sometimes misunderstood – and that sometimes you wonder ‘where did I go wrong’. But somehow, there are still some others who are always full of mercy, as giving a benefit of doubt is more challenging than simply blaming someone. You know few which genuinely pay attention to you and patiently listen to your tales. And there are some who have the knack to say something about anything and just keep bombarding you with their rants and ramblings, as if these do really matter.\n\nYou know people which have great passions and love for what they do (and that really inspires you). However, infrequently you are stuck with some others who do things as if their spirit is not completely in their body. You work with those who are exciting with all the challenges and on the other hand you also meet those who just drain your brain endlessly.\n\nEverything is just like Hollywood stories. Someone finds salvation in everyone, another only pain. And life won’t let you understand.\n\nFive years. Time to move on.\n\n \n\n \n\nP.S: This is my last official day at the university, though I still need to go back one more time for the final exam.\n\n(`_|_`)Feb 27, 2008(`_|_`)ariya.io(`_|_`)every-night-has-its-dawn', 'every-night-has-its-dawn'),
(521, 'laugh of the day(`_|_`)\nWhat will you get if you google for deutsche telekom hotline ?\n\n(`_|_`)Feb 24, 2008(`_|_`)ariya.io(`_|_`)laugh-of-the-day', 'laugh-of-the-day'),
(522, 'Microsoft Office binary format to Open XML(`_|_`)\nAs promised by Brian Jones, finally the project (under a liberal BSD-like license) to convert Microsoft Office binary format (doc, xls, ppt) to the Open XML format (used since Office 2007), named b2xtranslator, has been initiated on SourceForge. As I wrote before (on Google Code Project Hosting vs SourceForge), it’d be fantastic if Microsoft would have placed the project on Google Code instead of SourceForge (but it is Microsoft we are talking about). As of now, download is not yet available as the project is still in its very early stage.\n\nMany office suite developers have an interest on Microsoft Office file format because it is widely used. The description of the format itself can be obtained from Microsoft{#zw0z} since quite some time, however only with the b2xtranslator we will start to see an implementation which is “blessed” by Microsoft.\n\nTechnically, there are two slightly disappointing points with this b2xtranslator project. First, it is not an implementation used by Microsoft itself in its office suite but rather an independent one. Second, it requires .NET framework (exactly as I have predicted{#y9jy}). For the former, again it means playing the same cat-and-mouse game since there is no guarantee that the translation is fully compatible with the code in the real Microsoft Office. For the latter, well I leave to you, the readers, to reach your own conclusion. Of course there is Mono (which, by the way, is used to integrate odf-converter in Novell edition of OpenOffice.org), but you know well where the discussion would lead.\n\nAs usual, let’s wait and see.\n\n(`_|_`)Feb 16, 2008(`_|_`)ariya.io(`_|_`)microsoft-office-binary-format-to-open-xml', 'microsoft-office-binary-format-to-open-xml'),
(523, 'Karbon and WPG(`_|_`)\nAfter Inkscape, OpenOffice.org (Novell edition, ooo-build), and Abiword, Karbon in the next KOffice 2.x joins the array of open-source software which is, by using libwpg, able to import clip-arts in WordPerfect Graphics (WPG) formats. Since any Karbon drawings can be embedded in a document, of course this means you can attach and insert WPG clip-arts in a text document, a spreadsheet, or a presentation.\n\n\n\n(There is still a rendering problem in Karbon as seen in the comparison screenshot. Hopefully will be fixed as it is approaching the release).\n\n(`_|_`)Feb 15, 2008(`_|_`)ariya.io(`_|_`)karbon-and-wpg', 'karbon-and-wpg'),
(524, 'Google Docs goes pink(`_|_`)\nLikely only today. And even the star becomes a heart.\n\n\n\n(`_|_`)Feb 14, 2008(`_|_`)ariya.io(`_|_`)google-docs-goes-pink', 'google-docs-goes-pink'),
(525, 'Sun VirtualBox(`_|_`)\nSeems that the trend still continues, Sun is to acquire Innotek, a German company known for its open-source virtualization software, VirtualBox. Recently VirtualBox becomes my favorite virtualizer because it is dead-easy to install on OpenSUSE. I hope Sun will continue to improve and enhance VirtualBox, it is a pity if such a great product disappears from the virtualization radar.\n\n(`_|_`)Feb 13, 2008(`_|_`)ariya.io(`_|_`)sun-virtualbox', 'sun-virtualbox'),
(526, 'Landungsbrücken Hamburg(`_|_`)\n\n\n(`_|_`)Feb 10, 2008(`_|_`)ariya.io(`_|_`)landungsbrucken-hamburg', 'landungsbrucken-hamburg'),
(527, 'for you a thousand times over(`_|_`)\n\n\nThe film The Kite Runner (German: Drachenläufer) is adapted from the book with the same title. I have read the book and it is very enjoyable. The film is, however, something different. It is obvious that it is not possible to include every single scene from the book, and thus the film can not touch the major characters in the same depth as the book. I would say, read first the book before going to watch it and then try to fill out the missing episodes in your own mind.\n\nI also find it is pity to see that not so many are interested in this film. I can’t claim I was the youngest in the cinema, but it was clear that most of people are at least thirty something. On the other hand, it is indeed a bit hard to catch some attention when it must compete head to head against blockbusters e.g. I Am Legend. I hope the DVD will be better received.\n\n(`_|_`)Feb 5, 2008(`_|_`)ariya.io(`_|_`)for-you-a-thousand-times-over', 'for-you-a-thousand-times-over'),
(528, 'frozen Grand Central(`_|_`)\nThis is so awesome!\n\nNote: I wonder if it is legal to carry out that prank in EU.\n\n(`_|_`)Feb 3, 2008(`_|_`)ariya.io(`_|_`)frozen-grand-central', 'frozen-grand-central'),
(529, '2008 tech trend(`_|_`)\nSun MySQL\n\nNokia Trolltech\n\nMicrosoft Yahoo\n\n(`_|_`)Feb 1, 2008(`_|_`)ariya.io(`_|_`)2008-tech-trend', '2008-tech-trend'),
(530, 'KDE and KOffice on N800(`_|_`)\nThanks to the efforts of our hero Matthew Lewis (aka penguinbait), KDE 3.5.8 with KOffice can be enjoyed on both Nokia N800 and N810 (read also the step-by-step instructions). One of the screenshots from him:\n\n\n\nOnce I finally get OS2008 sorted out on my N800, I’ll definitely give it a try.\n\n(`_|_`)Feb 1, 2008(`_|_`)ariya.io(`_|_`)kde-and-koffice-on-n800', 'kde-and-koffice-on-n800'),
(531, 'why Google Code Project Hosting rocks(`_|_`)\nLet’s compare. Google Code Project Hosting (GCPJ) vs SourceForge.net (SF).\n\nYou can start using GCPJ in <1 minute. With SF, you have to provide all those tax-forms-like details and wait until your request for the project is approved.\n\nThe project front page in GCPJ is cleaner than that in SF. Don’t even bother thinking about the old version of SF.\n\nGCPJ’s label-based issues tracker is much more usable than the complicated SF’s one. Everyone hates a bug tracker anyway, somehow GCPJ is still humanly managaeble.\n\nOften you want to put some information quickly and the GCPJ wiki is fantastic for that. No need to create some web pages, upload them, and so on. Yes there is also the wiki support for SF but how many of you use it or even are aware of it?\n\nThe download page in GCPJ is easier for eyes.\n\nOptional goodies are not packed within GCPJ. If you want to display some screenshots, redirect to Picasa Web Album. Need some mailing-lists? Connect the project to Google Groups.\n\nTracking the statistics (visits, hits, referrers) is easy because it is integrated with Google Analytics, which btw provides more useful information compared to the limited SF’s stat tool.\n\nAdministering your project in SF can make you scream (aloud!). It’s however dead simple in GCPJ.\n\nSF’s subversion access is known to be flaky from time to time. GCPJ’s might not be the fastest, but so far it works smoothly.\n\nGCPJ’s subversion viewer (the very latest feature of GCPJ) is a way way better than SF’s traditional one. Try both and prove it yourself.\n\nIn short: GCPJ is designed with Pareto Principle in mind. Most of the core features which the open-source developers (who, BTW, do not have so much free time) really need are made very easy to handle. It’s rather minimalist, it’s not perfect, but it improves over the time. SF is so dull and not for mortals.\n\n(`_|_`)Feb 1, 2008(`_|_`)ariya.io(`_|_`)why-google-code-project-hosting-rocks', 'why-google-code-project-hosting-rocks'),
(532, 'to blur or not to blur(`_|_`)\nBlur is an interesting effect, mainly because it lets us enjoy the main object yet the out-of-focus parts add something to the realism. Like in the default KDE 4.0’s splash screen:\n\n\n\nFor PictureFlow, I decided to add the support for optional blur effect for the reflection, as shown in the following comparison:\n\n\n\nIt is even more enjoyable when you run the demo program and see those book covers sliding, as if they are ice skating. Shader guru can quickly point out the fakeness of the blur. Rather than blurring the “floor” after the reflection is painted there, I choose to blur the reflection for each image beforehand. Fake but fast and fun enough. As for the algorithm, it is the famous blazing-fast exponential blur from Jani Huhtanen, used among others in KDE 4’s Plasma.\n\nAnother improvement is that the background color can be customized, not limited to black. In fact, black is particularly suitable to do fast reflection illusion cause blending a specific color with black can be approximated by multiplying its RGB components with a decreasing factor. But since I saw that Cover Flow for iPod nano is with white background, I thought I just let you use your favorite color for PictureFlow.\n\nIn addition, I refactored the code so that it is more maintainable. For simplicity, the horribly long look-up sine/cosine table has been reduced with the help of simple interpolation. Even better, PictureFlow now supports Qt 4 (Win32, Linux, Mac, Qtopia, Windows Mobile), Qt 3 (tested on Linux only), and Qt 2 (for Qt/Embedded platform) with a single code base. Maybe even Symbian in the future \n\n(`_|_`)Feb 1, 2008(`_|_`)ariya.io(`_|_`)to-blur-or-not-to-blur', 'to-blur-or-not-to-blur'),
(533, 'qt embedded 2.3.x with gcc 4.x(`_|_`)\nIn case you want to build Qt Embedded 2.3.x — I know it’s old but who knows — with gcc 4.x which is what modern distributions (like the latest OpenSUSE) offer, you might get error messages like this:\n\nIn destructor ‘QSortedList<type>::~QSortedList()’:\nerror: there are no arguments to ‘clear’ that depend on a template parameter, so a declaration of ‘clear’ must be available\nerror: (if you use ‘-fpermissive’, G++ will accept your code, but allowing the use of an undeclared name is deprecated)\n</type>\n\nor something similar, because g++ 4.x (actually since 3.4) is stricter than the previous versions with respect to name lookup.\n\nTo solve the problem, get my patch: http://pastebin.com/f474708b6. It is tested only for Qt Embedded 2.3.8.\n\n(`_|_`)Jan 31, 2008(`_|_`)ariya.io(`_|_`)qt-embedded-2-3-x-with-gcc-4-x', 'qt-embedded-2-3-x-with-gcc-4-x'),
(534, 'KDE cookies(`_|_`)\nIt just came to mind. What if for the next KDE release events, parties, or any other get-together occasions, we should prepare cookies, something like the Warsaw Almond cookies (Warschauer Mandelgebäck)? It will be a challenge, though, to bake them for more than a dozen hungry mortals….\n\n\n\n(`_|_`)Jan 25, 2008(`_|_`)ariya.io(`_|_`)kde-cookies', 'kde-cookies'),
(535, 'EOS 450D(`_|_`)\nFor those who were waiting for this Canon EOS 450D, finally it’s out! There is a nice overview in dpreview.com, comparing 450D and 400D. Basically, it sports a 12 megapixel CMOS sensor, a SecureDigital card slot (instead of CompactFlash), larger viewfinder, large (3″) display, 14-bit ADC, personalized menu, and many other interesting goodies.\n\nTime to start hunting for the best bargains. So far, the EOS 450D body is available starting at EUR 649 and with 18-55mm lens kit starting at EUR 829.\n\n(the image is a slightly modified version of flomar’s DSLR camera)\n\n(`_|_`)Jan 25, 2008(`_|_`)ariya.io(`_|_`)eos-450d', 'eos-450d'),
(536, 'spamming the planet(`_|_`)\nSo, for the n-th time, I managed to spam PlanetKDE \n\nSorry for the annoyances!\n\n(`_|_`)Jan 25, 2008(`_|_`)ariya.io(`_|_`)spamming-the-planet', 'spamming-the-planet'),
(537, 'HTC and Motorola(`_|_`)\nJust over these two weeks, over 5 thousands came to my humble blog from XDA-developer’s forum. It turned out that Chad “thundershadow14”, based on the HTC Touch port, set to create a PictureFlow-based image viewer and release it as Windows Mobile executables. And seems that people like it, there are already 290 posts in that thread as I write this. It was reported to work on a wide range of HTC smartphones, among others Touch, Trinity, Herald, Hermes, Kaiser, Atlas, Prophet, Himalaya, Wizard, as well as other Windows Mobile devices like Treo 750, LG KS20, Asus P535, Axim X51v, and a bunch others. So if you have an HTC gadget (preferably with WM6), give it a shot. Looks like it quickly becomes one of the first popular Qt/WinCE-based application, this is considering that (as of now) the final official Qt/WinCE is not even released yet!\n\nOn the other side of the world, my countryman Ketut “blackhawk” Kumajaya brought PictureFlow to Linux-based Motorola phones (BTW, he is also the one who ports Rockbox to EZX). It runs smoothly on some Motorola phones like A1200, A780, E680i, ROKR E2, and ROKR E6. He kindly sent me the following screenshot:\n\n\n\nThere is even a short clip showing it on A1200:\n\n\n\nFrom these two exciting developments, and since the response is overwhelming (I can’t still believe people *do* really bother to mess around with such a weekend project), I want to be a bit more serious and plan to create a specialized image viewer with that lovely CoverFlow effect, designed with mobile device in mind (and targeting Qt/WinCE and Qtopia). From what I read in the forum, people are not happy with the loading time and memory consumption. Of course, this is definitely the case since the example I include with PictureFlow source code is not optimized for speed or memory footprint. It is a typical example program, meant to show how to use PictureFlow only, not as a basis of a real-world application. Thus, a really usable viewer must be implemented differently.\n\nSo, folks, stay tuned. Of course you can send me a smartphone, something like HTC Kaiser, if you want. I’ll be glad to take it \n\n(`_|_`)Jan 23, 2008(`_|_`)ariya.io(`_|_`)htc-and-motorola', 'htc-and-motorola'),
(538, 'proverb(`_|_`)\nHe who begins many things finishes but few. — Italian proverb\n\nBTW can anyone quote the original Italian version (if it does really exist)?\n\n(`_|_`)Jan 22, 2008(`_|_`)ariya.io(`_|_`)proverb', 'proverb'),
(539, 'Khaled Hosseini\'s The Kite Runner(`_|_`)\n What if your life is built upon stacks of lies? What if your past mistake haunts you until this very second? What if the handful people that know about your sin try to help you but they are facing death as time closes by? What if there is a dark side in each and every one of us, but somehow there is still also one last chance to make everything good again?\n\nThe Kite Runner is a heart-breaking story about friendship and loyalty, betrayal and treachery, happiness and misery, told in a beautiful, unforgettable way by the author, Khaled Hosseini. It is about what happens to two childhood friends, Amir and Hassan, and their families, all living in Kabul. They shared the same fate: never got the love of a mother. Amir’s father, Baba, was a successful Pasthun businessman while Hassan’s, Ali, was only Baba’s servant. Ali and therefore also his son Hassan were Hazara, often depicted as an inferior race. Ali and Baba grew up together, Hassan was always treated as his own son by Baba and this fatherly affection became a mystery to Amir day by day. Hassan was extremely loyal to Amir, he never disappointed nor harmed Amir during his lifetime.\n\nKite flying was a popular thing at their time and it quickly became one of their hobbies. Amir always flew the kite, Hassan was the one who run to catch the defeated kites. They were perfect as a team, everything was full of joy and happiness. Or it seemed to. Baba was tough on Amir, often too tough, and this made Amir trying hard to impress his father. He set to win the upcoming major kite tournament and to get the last kite that he would beat. Of course with the help of Hassan. But for the sake of making his Baba proud of him, Amir made a terrible mistake due to his cowardice that he would regret in the next three decades. Even worse, Hassan never wanted to take any revenge, which put more shame to Amir.\n\nPolitical turmoil (the invasion of Russia) forced Baba and Amir to move to California. They left behind their past, Baba took a simple job in a gas station, Amir continued his education. Soon he found the woman of his life and they got married. The happiness however did not last long. One tragedy came after another. At one time, he received a call from Pakistan, with the remark There is a way to be good again as it was made in passing but somehow this troubled Amir’s mind. He flew back, not to realize that it became the start of another big chapter in his life: to face things he ran away from before.\n\nAlthough one might think the central theme here is a classic, The Kite Runner is quite different. It is somehow remarkable because, not only it’s beautifully written and easy to understand at the same time, it’s also provocative, emotional and compulsive. Afghanistan political and social situations are wonderfully depicted, they make the story more believable and convincing. Amir is the sole narrator, you can feel his depth of feeling when he cries and when he smiles. And by the time you reach for you a thousand times over, don’t expect you can put the book down.\n\nP.S: The Kite Runner is the debut novel of Khaled Hosseini but it was on New York Times best-seller list for two years and sold four million copies. I can’t wait to see his next one: One Thousand Splendid Sun. A movie based on The Kite Runner (with the same title), which is out already or will be out soon, is definitely also a must for me.\n\n(`_|_`)Jan 21, 2008(`_|_`)ariya.io(`_|_`)khaled-hosseinis-the-kite-runner', 'khaled-hosseinis-the-kite-runner'),
(540, 'picking up where Apple has left off(`_|_`)\n\n\nIn the third generation of iPod nano, Apple has included the famous Cover Flow feature. But what if your iPod belongs to the generation before this? Well, AFAIK Cover Flow is not available. Either Apple would like the owners to upgrade or the hardware is simply not powerful enough. Pick your battle.\n\nThe solution: use Rockbox. It is a firmware replacement not only for Apple iPods but for a wide range of other popular music players. Since some time ago, it sports the PictureFlow plugin (still in continous development) which has the same idea as Cover Flow. This plugin is based on my PictureFlow Qt widget, something that I have mentioned before. The obligatory screenshot (courtesy of Jonas):\n\n\n\nThe good thing is, it is not limited to those iPods. At least, in the wiki page, it is reported that this PictureFlow plugin works for (among others) Sandisk Sansa e200/c200, Toshiba Gigabeat, Cowon iAudio X5, and iriver H300. For proofs, you can check some YouTube clips related to PictureFlow, for example:\n\n\n\n(`_|_`)Jan 14, 2008(`_|_`)ariya.io(`_|_`)picking-up-where-apple-has-left-off', 'picking-up-where-apple-has-left-off'),
(541, 'KDE 4.0 on OpenSUSE 10.3(`_|_`)\nKDE 4.0 is doubtlessly the most discussed KDE release at the moment. Some praise it, some don’t really favor it. But whether you’re going to like it or not, it’s worth to, at least, give it a try.\n\nIf you use OpenSUSE 10.3, installing KDE 4.0 is very easy, it’s just one-click away! Simply click on the following icon:\n\n\n\nWait few minutes (or hours), then you’ll get the desktop:\n\n\n\nUpdate: and add some plasmoids to get something like\n\n\n\n(`_|_`)Jan 13, 2008(`_|_`)ariya.io(`_|_`)kde-4-0-on-opensuse-10-3', 'kde-4-0-on-opensuse-10-3'),
(542, 'let\'s get it started(`_|_`)\n\n\n(`_|_`)Jan 11, 2008(`_|_`)ariya.io(`_|_`)lets-get-it-started', 'lets-get-it-started'),
(543, 'hamburg(`_|_`)\n\n\n(`_|_`)Jan 6, 2008(`_|_`)ariya.io(`_|_`)hamburg', 'hamburg'),
(544, 'aubergine meets fusilli(`_|_`)\n \n\nI love aubergine (or eggplant, for the Americans). I love pasta. Imagine how exciting I was when I stumbled upon Pasta alla Norma recipe from Jamie’s Italy (which is also a great book, BTW). It is simply a crime not to try this fabulous Sicilian dish. For my experiment, I substituted spaghetti with fusilli (I hope it isn’t an offense to do that) and added few more fresh vegetables. I could also just do with extra chilli for a good decoration and additional wonderful taste.\n\n(`_|_`)Dec 26, 2007(`_|_`)ariya.io(`_|_`)aubergine-meets-fusilli', 'aubergine-meets-fusilli'),
(545, 'chicken tandoori masala(`_|_`)\n\n\nWalking around in Weihnachtsmarkt, we noticed someone selling spices. It looks convincing, actually they sell products from Dudel. Among others, there was Tandoori masala so we bought it and gave it a try. It is more expensive that a spice bag found in typical Asian shop, but according to Dudel’s website, their spices are 100% natural and without any additives or flavorings.\n\nThis tandoori masala, according to the descriptions, comprises of coriander, cumin, ginger, garlic, chili, and salt. Sounds good. The poor man’s way to prepare it is by marinate the chicken with the spices and leave it overnight. Adding extra fresh garlic and ginger in pieces will do no harm. After then, cook everyhing with a pressure cooker. Halfway, let it cool and add yoghurt. You can add coconut milk, but personally I think yoghurt gives better look. Add some vegetables and enjoy!\n\nP.S: sorry for the quality of the picture, my Nikon camera gets older and its picture gets worse.\n\n(`_|_`)Dec 9, 2007(`_|_`)ariya.io(`_|_`)chicken-tandoori-masala', 'chicken-tandoori-masala'),
(546, 'Breach(`_|_`)\nBreach is a film adapated from the story of O’Neill vs Hanssen. O’Neill is an FBI agent wannabe, given an assignment to watch every single step of Hanssen, an FBI senior agent. FBI believes Hanssen is a double-agent, working for the Soviet but there is no proof. They want to catch Hanssen red-handed, hence the need for constant surveillance. But the fact that Hanssen does so many useful things and goes to church every day casts a doubt to O’Neill. Can he accomplish that task?\n\n\n\nBreach is a type of thriller that is quite rare nowadays. Granted, there is almost no puzzle to solve, the plot is pretty much predictable and likely not as cat-and-mouse as one would expect; but it is not polluted with unnecessary explosion-type actions. Sure, it would definitely bore Bourne’s fans, but Breach just has different targets. Chris Cooper’s performance (as Hannsen) is pretty convincing, he says more with his face and gestures than just his lines. He’s supposed to be traitor, yet we can have a feel of his intimate plays running in his mind. Not that it matters, but I wouldn’t hesitate to nominate him for an Oscar.\n\nIn short: Breach is too good to skip.\n\n(`_|_`)Dec 9, 2007(`_|_`)ariya.io(`_|_`)breach', 'breach'),
(547, 'attack of the clones (or PictureFlow-ing a phone, a set-top box, and an iPod)(`_|_`)\nCover Flow effect for Greenphone\n\nTrolltech Greenphone is a smartphone for Qtopia-based mobile-platform development. Although not available anymore, developing Greenphone is useful to learn Qtopia, and vice versa. You can still learn Qtopia/Greenphone without the real device using the\n\nGreenphone SDK within VMWare trick, which what I used to test my PictureFlow code some time ago.\n\nBut of course running a program inside an emulator is different than in a real 3-d device. Seeing is believing. Jonas Hurrelmann was very nice to check PictureFlow on Greenphone, as evidenced from his YouTube video. As expected, the performance is quite satisfactory. Kudos to Jonas!\n\n\n\nCover Flow effect for Dreambox\n\nDreambox is a satellite set-top box running Linux. Because it runs Linux and can be modified, it is popular among hackers. In case you miss it, few weeks ago Brad Hughes compiled and built Qt for his Dreambox DM 7000. Check his demo video…\n\n\n\n…and wait 41 seconds and see what is shown. Does that look familiar to you? (Hint: read this blog post again from top)\n\nCover Flow effect for iPod\n\nHuh? Doesn’t “Cover Flow for iPod” sounds too Zen-like? Didn’t His Steveness show it before?\n\nWell, this one is different. Jonas Hurrelmann (yes, the same Jonas, kudos to him again) ported the PictureFlow code to Rockbox and then ran it on the iPod 5.5G. The obligatory video is his YouTube clip:\n\n\n\nCareful readers might notice that it should be a Rockbox plugin (for those who live under the rock, Rockbox is the ultimate firmware replacement for many music players and it is completely open-source). Since Rockbox can support not only Apple iPod, but also Archos Jukebox, Sandisk Sansa, Cowon and many other popular MP3 players, this opens the possibility that those devices might enjoy CoverFlow-effect as well. Let’s wait for Jonas (and perhaps others) for further development.\n\nMore attacks are still needed….\n\nUpdate: check also PictureFlow attacking other mobile devices.\n\n(`_|_`)Dec 5, 2007(`_|_`)ariya.io(`_|_`)attack-of-the-clones-or-pictureflow-ing-a-phone-a-set-top-box-and-an-ipod', 'attack-of-the-clones-or-pictureflow-ing-a-phone-a-set-top-box-and-an-ipod'),
(548, 'looking for simple but fast 32-bit microcontroller(`_|_`)\nDear Lazyweb,\n\nIt’s been a while since I have been doing microcontroller-related projects. Now it’s time to get my feet wet again. For an exciting new project, I’m a looking for an evaluation/development kit for an affordable but high-performance (best-bang-for-the-buck) microcontroller. Preferred is 32-bit, but 16-bit is manageable. Important here is the availability of the I/O ports, I don’t care much for USB or Ethernet or even wireless support. Power is also not important. Built-in ADC will be a bonus, but not necessary. The program will be lightweight enough so no need for megabytes of memory.\n\nSurprisingly, I have difficulties finding such a board/microcontroller. Seems that 32-bit microcontrollers todays are geared more toward multimedia solution (image+audio processing), portable networked device, or automotive/industrial applications with different (and confusing) bus types. All I want to do is relatively simple but fast processing of some data. Unfortunately, I can’t stick with 8-bit system anymore because of the nature of the application. So what I am searching is rather a bare-bone, blazing-fast microcontroller with tons of digital I/O. The good old 8051 on steroids.\n\nThe closest I could find so far is Microchip PIC32 (though I wish it had more input output pins) with its $50 Starter Kit. However, I’m sure there are loads of similar stuff. Where are they?\n\nPS: I’m quite proficient with FPGA so I guess the fallback solution will be a soft-processor in an FPGA, but I would like to stay with the plain microcontroller if I have the choice.\n\n(`_|_`)Dec 5, 2007(`_|_`)ariya.io(`_|_`)looking-for-simple-but-fast-32-bit-microcontroller', 'looking-for-simple-but-fast-32-bit-microcontroller'),
(549, 'q.o.t.d(`_|_`)\n\n\n\nOpen source is a radical idea itself. I think you either get open source or you don’t.\n\n\n\n\n\n\n\n— Donald Rosenberg, on The secret to Red Hat\'s success\n\n\n\n\n\n\n(`_|_`)Dec 4, 2007(`_|_`)ariya.io(`_|_`)q-o-t-d', 'q-o-t-d');
INSERT INTO `ariyaio` (`id`, `content`, `url`) VALUES
(550, 'Fun with rotations(`_|_`)\nThe following puzzle might be trivial if you study physics and deal with lots of optics. Or, if you are simply good enough with math, especially with geometry.\n\nFirst, visualize a 3-d Euclidean space where x-y plane is the “floor” and z points “upward”. You are somewhere in this space.\n\nNow assume you have two rotation operators denoted as Q and H.\n\nThe idea is: both have fixed rotation angle but freely chosen rotation axis.\n\nThe common thing of both operators is that the rotation axis can be anything but it must lie on the x-y plane (i.e. the floor), so you can have [1 0 0]T or [0 1 0]T as the rotation vector but not [0 0 1]T. This way, the rotation vector can also be specified by its angle with the x axis. If we denote the angles as a and b for the rotation vectors of Q and H, we write the rotation operators as Q(a) and H(b). Hint: the rotation vector of Q(a) is thus [cos(a) sin(a) 0]T.\n\nNext comes the difference. The rotation angle for Q is 90 degrees, while the rotation angle for H is 180 degrees.\n\nHere is the quiz. Supposed you have a point at [0 0 1]T. This point is first rotated by Q(a). The result is then rotated again by H(b). The questions are:\n\n\nWhat will be the locus of the final result?\n\n\n\n(Hint: find the result as function of a and b).\n\n\nCan you replace the whole transformation (for the point at [0 0 1]T only) by just one Q operator? If yes, determine the rotation vector of this Q.\n\n\n\n(Hint: compare the answer to first question with the transformation result by only one Q).\n\nSpoiler Warning: if you have passion for puzzles, go away and solve this one by yourself first. Then come back again here and compare it with the following analysis.\n\nRemark\n\nAlthough at a glance it looks complicated, the questions are quite easy to solve. It is a matter of doing rotation (couldn’t be simpler!). The standard 3×3 transformation matrix will do the job, but usually you can do it much faster if you are familiar with quaternion. For convenience, here are the quaternions for Q and H:\n\n\nQ(a) = 1 + i*cos(a) + j*sin(a)\n\nH(b) = i*cos(b) + j*sin(b)\n\n\n(Exercise: normalize the above quarternions)\n\nThen, use the quarternions to find the rotation result with the usual quaternion algebra.\n\nAnswer to question #1\n\nAfter rotated by Q(a), the point [0 0 1]T will become [sin(a) -cos(a) 0]. Transform it with H(b) and you will get [-sin(2*b-a) cos(2*b-a) 0]T.\n\nNote: what you get is actually [x y 0]T with:\n\n\nx = cos(b)*sin(a-b) – sin(b)*cos(a-b)\n\ny = cos(b)*cos(a-b) + sin(b)*sin(a-b)\n\n\nwhich could be simplified using some trigonometric relations.\n\nFor the trained eyes, [-sin(2*b-a) cos(2*b-a) 0]T is the equation for a circle because sin(2*b-a)^2+cos(2*b-a)^2 = 1. The z coordinate is 0, means the circle is on the floor.\n\nSo, the answer to the first question: the locus will be a unit circle on the x-y plane.\n\nAnswer to question #2\n\nAfter rotated by Q(p), the point [0 0 1]T will become [sin(p) -cos(p) 0]T. This is also a unit circle. It means, direct transformation of [0 0 1]T by Q(p) will also give a circle. That’s the answer: yes, rotation by Q(a) followed by H(b), for the point at [0 0 1]T, can be replaced by one Q operator.\n\nBut how to find p in Q(p)? Recall [-sin(2*b-a) cos(2*b-a) 0]T from the answer to the first question. Comparing it with [sin(p) -cos(p) 0]T yields p = pi – a + 2*b.\n\nOr, you can specify the rotation vector of Q(p) directly as [-cos(2*b-a) -sin(2*b-a) 0]T.\n\nNot too difficult, isn’t it?\n\n(`_|_`)Nov 26, 2007(`_|_`)ariya.io(`_|_`)fun-with-rotations', 'fun-with-rotations'),
(551, 'three is the magic number(`_|_`)\nThe best thing about cooking is: there is no right or wrong. It means, you will not make any mistake.\n\nAfter some experiments, I found that adding some extra stuff when preparing mie goreng (a.k.a fried noodles) gives it a distinctive and unique taste. It’s not like the common fried noodles anymore. Here I share the secret: basil leaves cut into pieces, few slices of ginger, and a bit of curry powder. Like a charm.\n\nAller guten Dinge sind drei.\n\n(`_|_`)Nov 26, 2007(`_|_`)ariya.io(`_|_`)three-is-the-magic-number', 'three-is-the-magic-number'),
(552, 'iPhone in Germany(`_|_`)\nIn Germany, iPhone is sold with a price tag of 399 euros. But then you must sign a 24 months exclusive contract with T-Mobile, with a minimum plan of 49 euros monthly fee. This means (ignoring depreciation) at least you’ll lose 1575 euros in total. With one time activation fee, that makes it 1600 euros. On top of that, if you want to actually make a call, be ready to face the 39 cents/minute rate, which is (insanely) expensive compared to other offers. The fact that it is T-Mobile is also interesting, I don’t know whether it means a bless or a disaster.\n\nDue to a move from Vodafone, T-Mobile is also forced to sell an unlocked iPhone. So you can pick your favorite provider but only if you’re ready to shell out 999 euros for that. Might be better, but 999 euros? You can get 21 Motorola w205 with that amount of money  Or do/buy other sensible stuff.\n\nUsually I am not that skeptical. But this does not sound like a success recipe at all.\n\n(`_|_`)Nov 22, 2007(`_|_`)ariya.io(`_|_`)iphone-in-germany', 'iphone-in-germany'),
(553, 'SpeedCrunch: \"Nona\" edition(`_|_`)\nSpeedCrunch version 0.9 has just been released. The improvements are not really user visible, but check the ChangeLog and fixed bugs, nevertheless. Also, this release is available in 17 languages (and contributions are welcomed).\n\nSource tarball and Windows installer are ready for consumption. Go to http://code.google.com/p/speedcrunch/ and get it while it’s hot. Binary packages for major Linux distributions usually follow soon.\n\nAnd now that the first ever release of KDE 4 is on the horizon, it’s time to think to start enabling KDE integration in SpeedCrunch.\n\nNote: Nona is nine ninth in Portuguese.\n\n(`_|_`)Nov 19, 2007(`_|_`)ariya.io(`_|_`)speedcrunch-nona-edition', 'speedcrunch-nona-edition'),
(554, 'extraordinary(`_|_`)\n\nThe only extraordinary thing about me is that I am just an ordinary man.\n\n\n\n(on thinking about myself)\n\n(`_|_`)Nov 18, 2007(`_|_`)ariya.io(`_|_`)extraordinary', 'extraordinary'),
(555, 'Random number 1..5 to 1..7(`_|_`)\nThe task is to solve this puzzle:\n\n\n_Given a function which produces a random day Kliwon, Legi, Paing,\n\nPon, Wage, write a function which produces a random day Sunday to\n\nSaturday_\n\n\nOK, I modified the question a bit. Read about Anno Javanico if the names of the day sound strange to you. Originally, it says:\n\n\n_Given a function which produces a random integer in the range of 1 to 5,\n\nwrite a function which produces a random integer in the range of 1 to 7_\n\n\nThis is well-known as one of the so called Microsoft/Google interview questions. There are million ways to solve it. Here is my take. Bear in my mind that my math skill is mediocre and I never studied computer science, so don’t be surprised if the next few paragraphs look bogus and stupid.\n\nSpoiler warning: If you have passion for puzzles, go away and solve it and then come back again later. Don’t let this blog entry spoils the fun for you.\n\nFirst, let’s assume the random number 1..5 is generated by the following (the randomness, or lack thereof, of stdlib’s rand() doesn’t play any significant role here):\n\n#include <stdlib .h>\nint rand5()\n{\n return 1 + rand() % 5;\n}\n</stdlib>\n\n\nNow we must write rand7() which gives an integer between 1 and 7 and which is allowed to call only the above rand5().\n\nThe trivial solution, which you should have in mind in a fraction of seconds, is:\n\nint rand7()\n{\n  return rand5();\n}\n\n\nbecause nowhere it says that the original nor the new function must give a random number following a specific distribution, e.g. uniform distribution. Of course this can or can’t be the real answer, depends on how you look at it.\n\nThe next logical step is assuming that the return value of rand7() must have a uniform distribution. The probability to get one of the number in the range of 1..7 is therefore approximately 0.143.\n\nSo what comes to mind is to reduce 1⁄5 probability from rand5() to 1⁄35, then increase it again to 5⁄35, which equals to 1⁄7. The former can be done by calling rand5() several times and treating the first result as 1..5, the second as 6..11 and so on until 31..35. The latter is easier, it’s just a modulus operator. The code for this idea (which is shorter than the explanation above):\n\nint rand7()\n{\n static int c = ;\n int x = rand5() + c;\n c = (c + 5) % 35;\n \n return (x % 7)+1;\n}\n\n\n(I know static variables can be evil, but that’s another chapter…)\n\nThe disadvantage is obvious, the result is not completely random. For example, the first call will not yield 1 or 7 at all. Another variant is then by making c a bit random, though now that requires two calls to rand():\n\nint rand7()\n{\n static int c = ;\n int x = rand5() + c;\n c = (c + 5*rand5()) % 35;\n \n return (x % 7)+1;\n}\n\n\nAnother nice solution is by using rejection sampling, similar to the famous Box-Muller transform. Here we expand the range of 1…5 to 1..25 and reject anything larger than 7. The code is:\n\nint rand7()\n{\n int x = 8;\n while( x > 7)\n  x = rand5() + 5*rand5() - 5;\n return x;\n}\n\n\nPity that we throw away 8..25. It can be improved by reducing the rejection range to 22..25, IOW we would take anything in the range 1..21:\n\nint rand7()\n{\n int x = 22;\n while( x > 21)\n  x = rand5() + 5*rand5() - 5;\n int r = 1 + (x % 7);\n return r;\n}\n\n\n(or, further by going to 1…125 and rejecting 120..125).\n\nModulus of 7 can be “optimized” by hand, this is because 7 is a Mersenne prime. For the details, see what I wrote before on modulus with Mersenne prime. This looks useless and even obfuscates the code, but it’s harmless and you can tease your interviewer \n\nint rand7()\n{\n int x = 25;\n while( x > 21)\n  x = rand5() + 5*rand5() - 5;\n \n int r = (x >> 3) + (x & 7);\n r = (r >= 7) ? r - 6 : r + 1;\n return r;\n}\n\n\nCare to share your solutions?\n\n(`_|_`)Nov 9, 2007(`_|_`)ariya.io(`_|_`)random-number-1-5-to-1-7', 'random-number-1-5-to-1-7'),
(556, 'PictureFlow on another real device (or Cover Flow for HTC Touch)(`_|_`)\nUpdate: see also PictureFlow running on different mobile devices.\n\n\n\nHTC Touch is a touch-screen smartphone running Windows Mobile 6.0. It is armed with 200 MHz 32bit Texas Instruments OMAP 850 processor and 2.8 inch color transflective 240 x 320 screen. Like other Windows Mobile devices, HTC Touch is interesting because Qt runs also there, using Qt/WinCE.\n\nUpdate: see also PictureFlow running on different mobile devices.\n\n\n\nHTC Touch is a touch-screen smartphone running Windows Mobile 6.0. It is armed with 200 MHz 32bit Texas Instruments OMAP 850 processor and 2.8 inch color transflective 240 x 320 screen. Like other Windows Mobile devices, HTC Touch is interesting because Qt runs also there, using Qt/WinCE.\n\nAfter Chumby, HTC Touch is another real device that enjoys Apple-like Cover Flow effect, of course by using PictureFlow. Espen recently](http://labs.trolltech.com/blogs/2007/11/02/pictureflow-on-windows-mobile/) PictureFlow running on his HTC Touch, as can be seen in his YouTube video:\n\n\n\n“Awesome”, according to him.\n\nWe trust you, Espen \n\nNow I know that someone must have tried this on the Greenphone. Can anyone give a video or even a picture?\n\n(Picture from HTC Touch product page)\n\n(`_|_`)Nov 8, 2007(`_|_`)ariya.io(`_|_`)pictureflow-on-another-real-device-or-cover-flow-for-htc-touch', 'pictureflow-on-another-real-device-or-cover-flow-for-htc-touch'),
(557, 'deja vu(`_|_`)\n\n\n(`_|_`)Nov 7, 2007(`_|_`)ariya.io(`_|_`)deja-vu', 'deja-vu'),
(558, 'long weekend(`_|_`)\nDowntown is like a dead city.\n\nToday is Allerheiligen (All Saint’s day) and it’s public holiday in some states in Germany (Baden-Württemberg, Bayern, Nordrhein-Westfalen, Rheinland-Pfalz und Saarland).\n\nOf course, like many others, wisely I take vacation on Friday, thereby giving me a very nice and enjoyable long weekend.\n\n(`_|_`)Nov 1, 2007(`_|_`)ariya.io(`_|_`)long-weekend', 'long-weekend'),
(559, '10 signs that you aren’t cut out to be a developer(`_|_`)\nAs pointed out by Andry, Justin James’ 10 signs that you are not cut out to be a developer is an absolutely obligatory reading for anyone.\n\nHere is the checklist, go there for the details:\n\n\nYou’d rather be trained than self-teach\nYou like regular working hours\nYou prefer regular raises to job-hopping\nYou do not get along well with others\nYou are easily frustrated\nYou are close-minded to others’ ideas\nYou are not a “details person”\nYou do not take personal pride in your work\nYou prefer to shoot first and ask questions later\nYou do not like the geek type of person\n\n\nMy favorite is the close-mindness. Long time ago, I was told by someone that in order to be a great programmer (substitute this with other type of profession), you must unconditionally accept the fact that there are better ones than you. Only then you can reach the “enlightment”.\n\nWhich one is your favorite?\n\n(`_|_`)Oct 31, 2007(`_|_`)ariya.io(`_|_`)10-signs-that-you-arent-cut-out-to-be-a-developer', '10-signs-that-you-arent-cut-out-to-be-a-developer'),
(560, 'Motorola w205: some tips(`_|_`)\n After using Motorola w205 for some time, here I would like to share common tips which might be useful for others new w205 users:\n\nDoes it support key lock? Yes, of course. To lock the keypad, press menu button (middle button in the four-way pad) followed by * (star). If the screen becomes suddenly black, then the key locking is successful. To unlock, do the same step.\n\nHow to disable iTAP? iTAP is intelligent typing (or rather TAP-ping) technology from Motorola, used for writing text message (SMS). It’s claimed to be better than T9 (text-on-nine) which is used everywhere else (Nokia, SE, Siemens, …), but my personal experience shows that iTAP is inferior to T9.\n\nThere is no really menu item for disabling iTAP. The trick here is to switch the input method from iTAP to TAP . So iTAP means intelligent typing and TAP means non-intelligent typing. Yes, it’s very confusing and not usable at all.\n\nWhile you’re composing an SMS, just press the menu button so that Input IME Menu shows up. There you can move from iTAP English (or German, French, etc) to TAP English (or German, French, etc). Then press the soft-button for Select. Now, word autoguessing is inactive and you can enjoy normal typing thumbing again.\n\nIf you feel like using iTAP again, just change the input method to iTAP English (or German, French, etc).\n\nHow to switch between capital and lower-case letters? This is also not obvious. When typing an SMS, suppose now the display always shows capital letters for each button that you tap. When you press 2, A will show up and it is highlighted. Right away press __ and that A will be transformed to a. If you continue thumbing, only lower-case letters are produced. To switch to capital letters, just do it again (press a button, continue with __ while the character is highlighted).\n\nWhy right away? Because 3 seconds after you press a button, the displayed letter will not be highlighted anymore and thus you can’t change the case from lower-case to capital and vice versa.\n\nWhy __ button? If you see carefully, there is a symbol that resembles an up-pointing arrow that button. So, it is supposed to be a shift key like in a typewriter or a keyboard.\n\n(Picture from official Motorola w205 site)\n\n(`_|_`)Oct 30, 2007(`_|_`)ariya.io(`_|_`)motorola-w205-some-tips', 'motorola-w205-some-tips'),
(561, 'PictureFlow on real device (or CoverFlow on Chumby)(`_|_`)\nUpdate: see also PictureFlow running on different mobile devices, from Greenphone to HTC smartphones.\n\nChumby is a new hardware widget with open systems design. Jesper recently showed how to put Qt on Chumby, along with PictureFlow, as can be seen in his YouTube video:\n\n\n\nChumby is not even yet available on stores, you got it only if you’re an insider. And it’s like only a week after I placed the code of PictureFlow on the net. And with Jesper’s nice work, this cool little Chumby has already CoverFlow-like effect on par with iPod.\n\nIt is also a proof that PictureFlow’s performance is satisfactory even on portable device. Chumby has only a 300Mhz ARM9 processor, but the effect is quite smooth.\n\nSo, who’s next?\n\n(`_|_`)Oct 29, 2007(`_|_`)ariya.io(`_|_`)pictureflow-on-real-device-or-coverflow-on-chumby', 'pictureflow-on-real-device-or-coverflow-on-chumby'),
(562, 'Still PictureFlow: improving the rendering quality(`_|_`)\nStill about PictureFlow, my CoverFlow-effect clone, I did give some thoughts on improving its rendering quality without sacrificing the performance and still doing it in software (no help from graphics card).\n\nThe first that came to my mind is by using bilinear filtering in the texture mapper. As you might predict, the texture mapper itself needs only affine transformation, each cover/slide is rendered column-by-column. Since the z distance for all pixels in a column is constant, affine transformation is enough and can be implemented efficiently. Adding bilinear filter, however, means doing linear interpolation for each and every pixel. If it is done in one dimension only, i.e. vertically, that is still manageable. But since (to assure the quality), we need to perform it in both dimension, the whole stuff would become too slow.\n\nThen one morning I realized that I don’t really need to do the filtering on-the-fly. Just transform the cover image before it is rendered to screen, we can take advantage of Qt’s smooth pixmap scaling for this purpose. Won’t be as good as real interpolations, but everything up to now are dirty hacks anyway.\n\nHere is the result so far (clink to enlarge). Compare the filtered version against the original nearest-neighbor approach. Can you spot the improvement?\n\n\n\nFor starter, you can see that the jaggy lines between the cover images and the black background (obvious when the cover is white) become less noticeable in the filtered version, as shown below. Left is nearest neighbor, right is bilinear filter:\n\n\n\nThere is no impact at all on performance when doing the animation effect, everything is as smooth as before.\n\nThere are however disadvantages with my first approach. First, the cover image is enlarged four times in both dimension, thus making it consuming 16x more memory space. The surface cache becomes very large. Even for book covers (150×200, stored in ARGB32 format), each of them requires 1.8 MB. This is terrible for portable device, although still manageable on modern desktop machine. In addition, creating the surface cache is slower now due to the necessary image scaling.\n\nThe next steps would be more optimizations. First, the surface cache will still keep the original dimension (150×200 in the above example). The scaled version will be constructed only whenever necessary, i.e. right before it is texture-mapped. In addition, there is no need to perform filtering while the animation still takes place. The covers move so fast, a bit sacrifice in the quality won’t be noticeable to human eyes.\n\nLet’s see where this brings me further. Seems that software-rendered CoverFlow effect done in C++ with a quality that can match hardware-assisted version is quite feasible.\n\n(`_|_`)Oct 25, 2007(`_|_`)ariya.io(`_|_`)still-pictureflow-improving-the-rendering-quality', 'still-pictureflow-improving-the-rendering-quality'),
(563, 'PictureFlow, a clone of CoverFlow as a Qt widget(`_|_`)\nAnother no-time-yet-to-finish-it pet project of mine is a media player, something like for media center or portable device. I code it in SDL, in a hope that targeting platforms like GP2x and Nokia N800 are easy. But knowing that Qtopia (soon) runs also on N800, I am thinking of moving the code to pure Qt for ease of maintenance.\n\nUnless you live under the rocks, CoverFlow should sound familiar. For the said media player, I have an efficient implementation of CoverFlow effect, called PictureFlow. Last weekend I decided to port the code to sane C++ and Qt and here is what I get now:\n\n\n\nor, like the trend nowadays, in the following short screencast (if it is not visible, go to\n\nhttp://youtube.com/watch?v=uwE_UIHSWnY directly):\n\n\n\nYou can see that the typical “flowing” ala CoverFlow is implemented already. Even, the first and last covers always fades in and fades out during the animation (so a cover just doesn’t come in out of nowhere). Reflection is also there, done by crude-blending the cover with black (that’s why black background is so sweet!) and then placing it in the surface cache.\n\nThe important feature of PictureFlow is that it does not need 3-d accelerated graphics system. Everything is done in a software renderer. This is not so surprising, consider that I target the original media player for portable device(s). Even the latest sub-GHz iPod can have CoverFlow, so there is no reason to demand fast OpenGL implementation just to enjoy this little piece of eye candy. As long as blitting to screen is fast, you’re set. Moreover, no floating-point operation is carried out so that it’s fast enough even on ARM-like platforms.\n\nOn the other, using pure software renderer has a major drawback, namely the rather lower rendering quality (traded for optimal speed). As you witness from the screenshot, the edges of the tilted images are jaggy. However, with 225 dpi screen like in N800, these jaggy lines (hopefully) won’t be noticeable. This can’t be avoided without causing too much performance penalty. In fact, technically there is not even a perspective-correct texture mapper. It is just the same hack like the texture mapper done in raycasting-based game, e.g. the classic Wolfenstein 3-D ages ago. This is also the reason to bypass Qt own rasterizer, as we can do some sort of “cheating” and map the texture really fast. Texturing is done more like nearest neighbor approach rather than bilinear filtering, which gives less pleasant result if you stare at the rendering result too long.\n\nAlso, software renderer is much slower than hardware-assisted one. Thus, the trick is to keep the widget as small as possible, but not smaller. With reasonable size like 800×350 pixels, on fairly modern machines, you’d get something like 45 fps, which is quite satisfactory. I even tested on old 800Mhz box, it is not as smooth as in a dual-core system, but runs nevertheless well enough.\n\nOverall, this widget is still very basic though already functional. For example, there is no text nor fancy scrollbar which are typically superimposed on bottom side. I guess, in this case, you can subclass PictureFlow widget and add the extra gimmicks by yourself. In addition, as trade-off, covers with alpha channel and covers with non-uniform size won’t be supported, this is to minimize texture overdraw.\n\nAnyway, this widget is released as open-source (under MIT license), see http://pictureflow.googlecode.com. So, just grab it while it’s hot.\n\nSome ideas where it could be useful elsewhere:\n\n\nFor album browsing in Amarok. At the moment, Amarok for KDE4 has its own CoverFlow-like feature, but last time I check it requires OpenGL so it works well only when the graphics system is 3-d accelerated.\nChoosing a slide in a presentation (so maybe it could be integrated into KPresenter?). Imagine you’re running your presentation and one of your audience ask you to show some previous slides, wouldn’t be cool when you flip through the slides with this flowing effect?\nQuickly skim through photos, useful in Digikam, Gwenview, or similar imaging tools. Since it’s used as a chooser, not full-fledged slide show, the size could be kept small and thus the performance should be acceptable.\n\n\nAny more ideas?\n\n(`_|_`)Oct 22, 2007(`_|_`)ariya.io(`_|_`)pictureflow-a-clone-of-coverflow-as-a-qt-widget', 'pictureflow-a-clone-of-coverflow-as-a-qt-widget'),
(564, 'Thai Sambal Oelek?(`_|_`)\nStarting from Monday, for few days Lidl Germany will sell some Thai stuff, mostly food and spices. While reading the flyer and also its website, I stumbled upon this:\n\n\n\nI have no doubt that similar type of strong sambal is available elsewhere, and/or maybe the supplier of the said sambal oelek is indeed from Thailand. But at least let’s not claim it as Thailändische Würzpaste. It is even so obvious from the van Ophuijsen spelling of “oelek”. When speaking about sambal oelek, it is definitely typical Indonesian sambal.\n\nDas ist die Wahrheit.\n\n(`_|_`)Oct 21, 2007(`_|_`)ariya.io(`_|_`)thai-sambal-oelek', 'thai-sambal-oelek'),
(565, 'Eid Mubarak(`_|_`)\nHappy Eid Al-Fitr to all!\n\n(`_|_`)Oct 13, 2007(`_|_`)ariya.io(`_|_`)eid-mubarak-4', 'eid-mubarak-4'),
(566, 'back to basics: Motorola w205(`_|_`)\n During my adventure to find an ideal mobile phone, I often get arguments like: well, if you don’t need a particular feature, just don’t use it. The counter-argument is easy: if I don’t need a feature, why should it exist after all? Reducing the complexity of software and hardware in a mobile phone could simplify a lot of things, increase the battery life, ease the technical support, and possibly even as far as improve its environment-friendliness factor. However, normally it also means less profit for phone sellers.\n\nFortunately, for those who are old-fashioned and need simple and basic mobile phone without all the unnecessary gimmicks, nowadays there are already choices from Nokia (1110, 1600, 2610), Sony Ericsson (J110, J120, J220), Samsung (SGH-C300), Motorola (F3, w205, w208), and many others.\n\nSome time ago, I decided to bite the bullet and switch from the lovely black Motorola RAZR V3 to another phone: Motorola w205 (SAR head: 0.83 W/kg, body: 0.48 W/kg). It is considered one of the latest entry-level basic mobile phone as it is available only since Q1 this year. From Amazon.de, it costs only 46 euros including VAT and shipping. There are even cheaper offers, if you are willing to take SIM-locked phone in a prepaid bundle.\n\nThe phone is compact and light. It can do SMS but not MMS. I don’t really care for MMS, all these 6 years using mobile phone, I have sent like 2 or 3 (useless) MMS. As for typing SMS, instead the common T9, again Motorola’s own iTAP is used for intelligent/predictive typing. It is a minus point for me, for I always hate iTAP and disable it all time, but I guess I can live with that.\n\nIts 1 MB memory is enough for 500 address book entries or 750 SMS. With 850 mAh Li-Ion battery, it is claimed to have talk time up to 8 hours and stand-by time up to 12 days. For sure, I reach the charger less often than with RAZR. If this is not enough, more powerful 1700 mAh battery is available for less than 7 euros.\n\nThe phone has a decent color display, 128×128 pixels with 65 thousand colors. Actually, I’d prefer to get a sharp black-and-white display with e-ink technology (as in Motofone F3, but the dot-matrix version thereof) as I’m sure the battery life would even be improved. But again, this one is already good enough.\n\nThere is no camera in this phone. Also no infrared. No Bluetooth. No WAP. No GPRS. No MP3 player. No radio. No singing-and-dancing stuff. No extra bells-and-whistles.\n\nI am a happy man.\n\n(Picture from official Motorola w205 site)\n\n(`_|_`)Oct 10, 2007(`_|_`)ariya.io(`_|_`)back-to-basics-motorola-w205', 'back-to-basics-motorola-w205'),
(567, 'OpenSUSE 10.3: first look(`_|_`)\nI know I should be doing something “useful”, but the fresh-from-oven OpenSUSE 10.3 is just too good to skip. Thus, I decided to waste a weekend to try it. In short: it’s very solid and attractive, without doubt the best OpenSUSE release so far.\n\nInstallation (and upgrade) was easier than ever. Now we need only one CD. I choose KDE of course. For most users, this means getting openSUSE-10.3-GM-KDE-i386.iso through http/ftp/torrent, burning it, and using it to perform the installation.\n\nThe first boot after the installation (yes, it’s green again!) shows that boot time is needed really improved. My laptop needs 54 seconds until I get a fully functional KDE desktop, it takes at least 70 seconds with OpenSUSE 10.2, 90 seconds with Windows XP.\n\n\n\nPost installation, I had little problem trying to connect to Internet using my DSL modem, even after the usual steps of removing NetworkManager and installing KInternet. It turned out, somehow smpppd is not activated by default. If you experience the same problem, the solution is easy: run YaST, System, System Services (Runlevel) and then enable smpppd. While you’re there, try to tweak some services and turn off what you don’t need (e.g. for pure desktop, no need for postfix).\n\nAnd while doing software management, one quickly notices that package management is thousand times better compared to the previous versions. With OpenSUSE 10.1⁄10.2, doing things with packages is just unbearable without Smart, IMO zmd along with its Mono stuff are not for mere mortals. However, now zmd is gone, zypp is already greatly improved and thus making application installation in OpenSUSE 10.3 significantly faster than ever. Even better, if you are used to subscribe to alternative repositories (e.g. Guru, Packman, KDE:Backports, etc), there is a new Community Repositories module in YaST which allows you to add common non-official repositories with only few mouse clicks. This is extremely simple even for novices.\n\n\n\nBut the best is yet to come. Now OpenSUSE offers one-click application install. This is a new feature which will be appreciated by typical desktop users. Rather than using YaST to install new software, you just go to http://software.opensuse.org/search, search for the program, and then click on the 1-Click Install button to start the installer, which will download the packages (and handle the dependencies, if necessary) and install them for you. It couldn’t be easier, extremely useful for Linux newbies. It also resembles the way most applications are installed in Windows, a plus for those who switched or want to switch.\n\nOf course you can still use the familiar YaST to install and remove programs as usual. At first, maybe you’ll be a bit surprised because the icons in YaST have been changed. Looks like these new icons are designed to match Tango icon sets. If you prefer the good old Crystal style, just follow binner’s tips: remove package yast2-theme-openSUSE and install yast2-theme-openSUSE-Crystal instead.\n\nAs with any fresh Linux box nowadays, you need to perform the extra steps to install non open-sourced stuff so that you can enjoy e.g. your MP3 music. With the new click-and-install, this also couldn’t be easier. Just go to http://opensuse-community.org/Restricted_Formats/10.3 and click on codecs-kde.ymp link. The same installation wizard will pop-up, then just follow the step-by-step instructions. In addition to multimedia codecs, you can have the option to install Java (1.5 or 1.6) and Flash plug-in as well. All with few mouse clicks.\n\nThe same easy procedures apply also for installation of proprietary NVIDIA or ATI driver. For example, for ATI graphics card, just read the super-simple instructions, again a matter of clicking a link (even a child can do that!). You don’t even need to know the model of the graphics card.\n\nConclusion: with one CD install, faster boot, easier package management, single-click application install, OpenSUSE 10.3 is definitely worth to try. For 10.2 users: upgrade!\n\n(`_|_`)Oct 7, 2007(`_|_`)ariya.io(`_|_`)opensuse-10-3-first-look', 'opensuse-10-3-first-look'),
(568, 'just one chance, just one breath(`_|_`)\nIt is definitely interesting to know Oslo, one of the most beautiful and also most expensive city in the world.\n\nMy first touchdown wasn’t that smooth, however. Just a day before I left, I caught a terrible cold. This was likely because I was too tired after the 5-day conference in Berlin and had only few hours to rest. I travel very seldom, but just when I had these important flights, both were delayed and caused some incoveniences. I still managed to get the very last express train from the Oslo airport to the crowded downtown (this was weekend afterall) and found my hotel. So here I was cold, sick, hungry, with this bad fever, looking around trying to feed myself with some sensible food and hot drink at over midnight in a completely foreign land, at the same still trying to understand the Norwegian Kroner. Fortunately everyone here does understand English. And fortunately there is Deli de Luca everywhere. In the end I was finished with my business at 3 am and fell asleep almost immediately.\n\n\n\nI took the time on Sunday to take some needed rest. In the afternoon I met Helder, the current maintainer of SpeedCrunch, and he became my just-in-time guide and showed me some nice spots of Oslo, although the weather wasn’t so friendly. We had a nice dinner together. Of course we discussed a bit about SpeedCrunch. Unfortunately Johan did not manage to come here; otherwise we’re set for a SpeedCrunch Developer Conference \n\nI spent Monday mostly in Trolltech office. Some faces were already familiar to me and it’s good also to finally meet some others chaps I know only in names as well as few other famous Trolls. Simon gave me a tour of all the cool stuff they have. It was definitely very impressive.\n\nMy time in Oslo was obviously too short. And due to the weather, I still missed some beautiful sights Helder told me. For sure, I must go back again someday…\n\n(`_|_`)Oct 7, 2007(`_|_`)ariya.io(`_|_`)just-one-chance-just-one-breath', 'just-one-chance-just-one-breath'),
(569, 'with 8 seconds left in overtime(`_|_`)\n Within hours, I’ll be in a train to Berlin. This is my third trip to Berlin this year, the first was for KOffice weekend, the second was for LinuxTag. Unlike the first two, this time it’s not for “personal satisfaction” only because I’ll be attending this year’s ECOC (European Conference on Optical Communications). My last ECOC was in Glasgow, 2005. So it’s nice to have a chance again to look around, rebuild contacts, and find out what other researchers are doing.\n\nUpdate: I am already in Berlin. The conference started already, there are many exciting topics. We even get free WiFi so I’m not really fully isolated from the net, thanks to my N800.\n\n(`_|_`)Sep 15, 2007(`_|_`)ariya.io(`_|_`)with-8-seconds-left-in-overtime', 'with-8-seconds-left-in-overtime'),
(570, 'The Bourne Ultimatum(`_|_`)\n \n\nUltimatum is the last of the Bourne trilogy films. Here Jason was back, among others in Europe, on the search for his past. CIA tried to stop him by all means, but due to an internal conflict, some (including Nicky, again) tried to help him. You’ll be following his journey and his struggles with a couple of flying bullets, dangerous car chasing, intense hand combats, as well as puzzles solving.\n\nUltimatum is, without doubt, the best of Bourne ever. Recommended.\n\n(`_|_`)Sep 9, 2007(`_|_`)ariya.io(`_|_`)the-bourne-ultimatum', 'the-bourne-ultimatum'),
(571, 'Le Trote(`_|_`)\n \n\nThese are rainbow trouts, marinated with some drops of lemon, salt and pepper, vegetable oil, soy sauce, tomato ketchup, spicy sambal, covered in aluminum foil together with slices of vegetables (e.g. carrot and kohlrabi), and baked for 15 minutes at 200 C. Simply delicious.\n\n(`_|_`)Sep 2, 2007(`_|_`)ariya.io(`_|_`)le-trote', 'le-trote'),
(572, 'Legacy vs Lateral (3): Solution space isn\'t always in two dimensions(`_|_`)\nThis one also happens not so seldom.\n\nSupervisor: Hey, can you do Visual Basic?\n\nDeveloper: (surprised) Ahm, it depends….\n\nS: Look, I finally got the library that we need for our development. It comes with lots of VB examples, so please integrate a VB module with our app.\n\nD: Could you send me that stuff first?\n\nS: Sure.\n\nFew minutes later, the “stuff” has been received by the developer. After carefully examined it for few minutes, our hero found out that it’s just a normal dynamic library, it can be loaded by standard mechanism that every experienced programmer (worth his salt) is familiar with. The VB thing is just because examples are given for VB, presumably to show how easy it can be. But it is not necessary to restrict the solution space to VB.\n\nSetting aside VB & friends, what is important is the concern: often, you are already given a (very) limited set of solutions for a given problem. Long long time ago, that may work well. But nowadays, it won’t be that easy. Systems become exponentially more complex, our brain is bombarded with lots of useful information as well as useless junks, there are A to Z details that the brain cells won’t bother anymore. It becomes very challenging to be able to have an overview, let alone to always play the polymath rule all time. And the devil is always in the details.\n\nShare the problem descriptions, not always the proposed solutions. And thus, triggers creative thinking and discussions.\n\n(`_|_`)Aug 29, 2007(`_|_`)ariya.io(`_|_`)legacy-vs-lateral-3-solution-space-isnt-always-in-two-dimensions', 'legacy-vs-lateral-3-solution-space-isnt-always-in-two-dimensions'),
(573, 'Super Funny Mario(`_|_`)\n\n\n(Found via ogmaciel.com)\n\n(`_|_`)Aug 29, 2007(`_|_`)ariya.io(`_|_`)super-funny-mario', 'super-funny-mario'),
(574, 'Linus on git (again)(`_|_`)\n\n\n(No, this isn’t about the Linus’ Tech Talk  video on git).\n\nThe nice thing working on KDE project is because Linus likes KDE. Thus, it is not (so) surprising (he used to help with bugs, e.g. #27340) to see Linus himself writing something (read: sending some “enlightment”) to kde-core-devel, again on the topic of git:\n\n\nCentralized _works_. It’s just *inferior*.\n\n\nI’d like to see a ThinkGeek shirt with that quote.\n\n(`_|_`)Aug 21, 2007(`_|_`)ariya.io(`_|_`)linus-on-git-again', 'linus-on-git-again'),
(575, 'Transformers(`_|_`)\n\n\nOne word: it rocks!\n\n(Well, that’s more than one, but you get the idea…)\n\n(`_|_`)Aug 19, 2007(`_|_`)ariya.io(`_|_`)transformers', 'transformers'),
(576, 'c.o.t.d(`_|_`)\nWho is going to pay almost $500 for a phone?\n\nBrowser: Mozilla/5.0 (iPhone; U; CPU like Mac OS X; en) AppleWebKit/420+ (KHTML, like Gecko) Version/3.0 Mobile/1C25 Safari/419.3\n\n(A comment to the $491 Linux-based Motorola RAZR V8, posted from an iPhone).\n\n(`_|_`)Aug 18, 2007(`_|_`)ariya.io(`_|_`)c-o-t-d', 'c-o-t-d'),
(577, 'Dirgahayu(`_|_`)\nAug 17 is Indonesia’s independence day.\n\n(`_|_`)Aug 17, 2007(`_|_`)ariya.io(`_|_`)dirgahayu-2', 'dirgahayu-2'),
(578, 'Legacy vs Lateral (2): Design for the future, not for today(`_|_`)\nDid you ever try to assemble and create a great product but lately much more better, powerful and yet cheaper components are suddenly available, and were they available sooner, your life would have been significantly simplified? Setting aside first that nobody can really predict the future, it is important here to emphasize that often – but not always [1] – it makes more sense to design something for tomorrow or next year, rather than just for today.\n\nThe classic example for this is game development. Unless you’re coding a simple Pong clone, the whole process of game development (think the upcoming id’s Rage or Crytek’s Crysis – but certainly not Duke Nukem Forever) can take ages. By the time the game is finished, the whole digital world already makes a few leaps here and there. Thus, it is absolutely necessary to predict the trend and ride the curves so that the shipped game will match the available technology and cover the intended market as it may completely change many design decisions during the development phase.\n\nFor the sake of giving an example (I’m not saying this is what’s going to really happen), say you’re 1000% absolutely sure that Physics Processing Unit card ala Ageia would be ubiquitous in platforms you’re targeting, just like today’s accelerated graphics chip, then it will be less sensible [2] to use physics engine which won’t take advantage of the said unit, let alone optimize it to death, because right after you launch the game, it might have hard-time competing with other games which are e.g. specifically designed to exploit the physics processor.\n\nThe same goes for any non-trivial things that needs engineering love. We’re not in the 70’s anymore, a satisfactory achievement needs more than just a weekend, a copy of Popular Electronics, a bunch of vacuum tubes, plus a TV [3].\n\nBut the real challenge remains: how can you convince your superior that it’s the right thing to do?\n\nNotes:\n\n[1] For example, if your software is supposed to work well even on old systems\n\n[2] There are of course obvious exceptions to this, e.g. you don’t need fancy graphics nor physics\n\n[3] Like a project to show the actual time at the corner of the TV screen\n\nPostscript: To avoid misunderstanding, it does not mean that things like software bloatness is endorsed. Quite contrary, because bloatness is typically caused by careless uses of system resources and superfluous features while design for today implies imposing restrictions (which will not exist anymore in the future) unnecessarily. Between these two extremes we must stand.\n\n(`_|_`)Aug 16, 2007(`_|_`)ariya.io(`_|_`)legacy-vs-lateral-2-design-for-the-future-not-for-today', 'legacy-vs-lateral-2-design-for-the-future-not-for-today'),
(579, 'Tracing the diagonals(`_|_`)\nThis is a real-world problem, but could also serve well as an interview question. The task is to create two sequences of numbers which when plotted against each other (ala Lissajous curve) give the following (the knots are there to emphasize the points):\n\n\n\nHere was my quick hack to solve it (written for Qt 4.x). The important part is in the constructor, the rest is only to show the result. I’m sure there are way better and much more elegant solutions. Care to share yours?\n\n#define NSIZE 5 // must be odd\n#include <qapplication></qapplication>\n#include <qpainter></qpainter>\n#include <qpainterpath></qpainterpath>\n#include <qwidget></qwidget>\nclass W: public QWidget\n{\nprivate:\n int* x;\n int* y;\npublic:\n  W(): QWidget()\n  {\n    x = new int[NSIZE*NSIZE];\n    y = new int[NSIZE*NSIZE];\n    x[] = y[] = ;\n int xs = 1, ys = ;\n for(int i = 1; i < NSIZE*NSIZE; i++)\n    {\n      x[i] = x[i-1] + xs;\n      y[i] = y[i-1] + ys;\n      xs = (x[i]-x[i-1]+y[i]-y[i-1] == 1) ?\n           (xs) ? (y[i] ? 1 : -1) : (x[i] ? -1 : 1) :\n           (!x[i] || x[i]==NSIZE-1) ?  :\n           (y[i]==NSIZE-1) ? 1 : xs;\n      ys = (x[i]-x[i-1]+y[i]-y[i-1] == 1) ?\n           (ys) ? (x[i] ? 1 : -1) : (y[i] ? -1 : 1) :\n           (x[i]==NSIZE-1) ? 1 :\n           (!y[i] || y[i]==NSIZE-1) ?  : ys;\n    }\n  }\n  ~W()\n  {\n delete [] x;\n delete [] y;\n  }\n #define DD 0.05\n void paintEvent(QPaintEvent*)\n  {\n    QPainterPath d;\n    d.moveTo(x[],y[]);\n for(int i = ; i < NSIZE*NSIZE; i++)\n    {\n      d.lineTo(x[i], y[i]);\n      d.lineTo(x[i]+DD, y[i]+DD);\n      d.lineTo(x[i]+DD, y[i]-DD);\n      d.lineTo(x[i]-DD, y[i]-DD);\n      d.lineTo(x[i]-DD, y[i]+DD);\n      d.lineTo(x[i]+DD, y[i]+DD);\n      d.lineTo(x[i], y[i]);\n    }\n    QPainter p(this);\n    p.setRenderHint(QPainter::Antialiasing);\n    p.fillRect(rect(), Qt::white);\n    p.setPen(QPen(Qt::red, DD));\n    p.translate(10, 10);\n    p.scale((width()-20)/(NSIZE-1), (height()-20)/(NSIZE-1));\n    p.drawPath(d);\n  }\n};\nint main( int argc, char ** argv )\n{\n  QApplication a( argc, argv );\n  W* w = new W;\n  w->setWindowTitle(\"Diagonal Tracing\");\n  w->show();\n  a.connect( &a;, SIGNAL(lastWindowClosed()), &a;, SLOT(quit()) );\n return a.exec();\n}\n</span></span>\n\n(`_|_`)Aug 16, 2007(`_|_`)ariya.io(`_|_`)tracing-the-diagonals', 'tracing-the-diagonals'),
(580, 'Legacy vs Lateral (1): Google is here to help(`_|_`)\nDid you ever experience the typical scenario like this before?\n\nThe phone rings.\n\nEngineer 1: Yes?\n\nEngineer 2: Hi, it’s me. Look, I have a problem here with my . Can you help me?\n\nE1: Fine, I’ll come over.\n\nFew minutes later.\n\nE1: So, what kind of problem do you have?\n\nE2: I’m trying to run this-and-that. And out of sudden, what I’ve got is\n\nthe following error message: bla…bla..bla..\n\nE1: Hmm, that’s strange (thinking for a minute or two).\n\nE2: Yeah, that’s not supposed to happen, isn’t it?\n\nE1: Did you google already?\n\nE2: Google..what? Ah, I see. No, I didn’t try googling for that problem…\n\nE1: Well, let’s try it now.\n\nAnd after 5 minutes of googling and flipping web pages, the problem was easily solved. As a matter of fact, it could have been solved earlier.\n\nAlthough it looks simple, the above scene happens quite a lot. Those who grow up in the late nineties and take for granted that Internet exists for their conveniences often quickly open google.com whenever they find a problem (even as far as replacing the pocket calculator) and most of the time just mechanically and without too much thinking. Whether it’s about using Google or other search engines, searching for some support articles, or even reading discussion archives, the idea is the same: let’s tap into the vast amount of knowledge available out there. Given enough brains, likely one of them solved the problem already. However, the previous generations (granted, not all of them of course) sometimes struggle with this concept of “information at your fingertip”.\n\nEver witnessed something similar?\n\n(`_|_`)Aug 15, 2007(`_|_`)ariya.io(`_|_`)legacy-vs-lateral-1-google-is-here-to-help', 'legacy-vs-lateral-1-google-is-here-to-help'),
(581, 'Three Envelopes(`_|_`)\nA fellow had just been hired as the new CEO of a large high tech corporation. The CEO who was stepping down met with him privately and presented him with three numbered envelopes. “Open these if you run up against a problem you don’t think you can solve,” he said.\n\nWell, things went along pretty smoothly, but six months later, sales took a downturn and he was really catching a lot of heat. About at his wit’s end, he remembered the envelopes. He went to his drawer and took out the first envelope. The message read, “Blame your predecessor.”\n\nThe new CEO called a press conference and tactfully laid the blame at the feet of the previous CEO. Satisfied with his comments, the press — and Wall Street – responded positively, sales began to pick up and the problem was soon behind him.\n\nAbout a year later, the company was again experiencing a slight dip in sales, combined with serious product problems. Having learned from his previous experience, the CEO quickly opened the second envelope. The message read, “Reorganize.” This he did, and the company quickly rebounded.\n\nAfter several consecutive profitable quarters, the company once again fell on difficult times. The CEO went to his office, closed the door and opened the third envelope.\n\nThe message said, “Prepare three envelopes.”\n\n(From www.notboring.com/jokes/work/3.htm)\n\n(`_|_`)Aug 7, 2007(`_|_`)ariya.io(`_|_`)three-envelopes', 'three-envelopes'),
(582, 'deaf in the trenches(`_|_`)\nSoldier 1: Just go and let me die in peace… Soldier 2: Do you want any gravy, sir?\n\nThat brilliant line is enough to show that Catherine Tate and Little Britain are for me still miles away from the Two Ronnies.\n\n(`_|_`)Jul 16, 2007(`_|_`)ariya.io(`_|_`)deaf-in-the-trenches', 'deaf-in-the-trenches'),
(583, 'English breakfast (or Two Ronnies: Swedish Made Simple)(`_|_`)\nMan: L.O. Waiter: L.O. Man: R.U.B.C. Waiter: S.V.R.B.C. Waitress: L.O. Waiter: L.O. Man: L.O. Man: F.U.N.E.X. Waiter: S.V.F.X. Man: F.U.N.E.M. Waiter: 9. Man: I.F.C.D.M. Waiter: V.F.N.10.E.M. Waitress: A. V.F.M. Man: R. Waiter: O. Waitress: C. D.M. Waiter: O.S. V.F.M. Man: O.K. M.N.X. Waiter: M.N.X. Man: F.U.N.E.T. Waiter: 1 T. Man: 1 T. Waiter: O.K. M.X.N.T. M.X.N.T.4.1. Waitress: V.F.N.10.E.X. Man: U.Z.U.F.X. Waiter: Y.F.N.U.N.E.X. Waitress: I.F.E.10.M. Waiter: S.I.L.L.Y. C.O.W.\n\n(`_|_`)Jul 15, 2007(`_|_`)ariya.io(`_|_`)english-breakfast-or-two-ronnies-swedish-made-simple', 'english-breakfast-or-two-ronnies-swedish-made-simple');
INSERT INTO `ariyaio` (`id`, `content`, `url`) VALUES
(584, '11,000 downloads and a new alpha(`_|_`)\nIf the download counter is correct, we have already more than 11,000 downloads for SpeedCrunch 0.7, the latest stable release. And this of course doesn’t include installation via package manager (from apt to pirut). Not bad, considered it’s just released over 2 months ago.\n\nBut it’s all about “release early, relase often”, right? So now the SpeedCrunch team has just announced the first alpha for version 0.8. There is Win32 installer and the source code is known to build on Debian Etch, Gentoo and SUSE 10.2. Helder, the new maintainer, aims for a final release at the end of this month. So we have a month of bug fixing session.\n\nThere are couple of new features in this 0.8. Most of them are features suggested by you.\n\nAn important highlight is the support for other radix systems: hexadecimal, octal and binary (thanks to Thomas Lübking of Baghira and Oxygen fame). IIRC this is the most wanted feature. It is evidenced by the new radio button (Hex/Dec/Oct/Bin) on the main window:\n\n\n\nSince the documentation is not ready yet (will be for final release of course), I thought it’s worth mentioning here that the radio button only changes the formatting of the values shown in the display, not how you type in the expression. If you want to enter an expression containing hex number, you should prefix with 0x. For octal it’s 0o and for binary it’s 0b. So, you are allowed to do something like: 0xfe + 1, i.e. mixing between hex and decimal. The result will be shown as 255 or 0xff, depends on what you choose in that radix radio button.\n\nBeside that, there are also other new goodies, like tons of new functions, factorial operator, choices for decimal point (auto/comma/dot), engineering notation, case-sensitivity for variable names, and assorted bug fixes. You can also have non-modal, docked/floating lists to display built-in functions, variables, constants, and history.\n\nRemember, this is alpha, so there are rough edges here and there. But if you feel brave, just get it while it’s hot!\n\n(`_|_`)Jul 2, 2007(`_|_`)ariya.io(`_|_`)11000-downloads-and-a-new-alpha', '11000-downloads-and-a-new-alpha'),
(585, 'I must have done it half a dozen times(`_|_`)\nComing back from Berlin, I just realized that I got that stream of ideas again, of all things just now when my TODO list is unbelievably long, filled with all those backlog items for Real Life, KOffice, my PhD, and assorted fun projects. Granted, probably filling the TODO is still much better than having an empty one…\n\nMy time in Berlin was too short, I managed to have conversations with some, but unfortunately so little time to do everything.\n\n\n\n(Picture taken in Berlin Hauptbahnhof)\n\n(`_|_`)Jun 4, 2007(`_|_`)ariya.io(`_|_`)i-must-have-done-it-half-a-dozen-times', 'i-must-have-done-it-half-a-dozen-times'),
(586, 'Berlin (again)(`_|_`)\nYeah, it was only two weeks ago but soon I’ll be visiting Berlin again. This time is however only to have some fun in LinuxTag 2007, which, for the first time takes place in Berlin’s Messe. KDE will be there and there are lots of interesting talks.\n\n(`_|_`)Jun 1, 2007(`_|_`)ariya.io(`_|_`)berlin-again', 'berlin-again'),
(587, 'SpeedCrunch\'s tip of the day(`_|_`)\nTypically, “tip of the day” feature is not really loved. Often, the dialog for showing the tip blocks the main view of the application. Worse, this dialog is even modal, you have to click it to make it disappear.\n\nFor SpeedCrunch upcoming version 0.8, I play around with the idea of showing a short tip as a yellowish widget inside the main window. It will disappear automatically after couple of seconds (even with some smooth translucent and animation effect). I’m still thinking whether the tip should be displayed at start up, or only from a menu item.\n\n\n\nI hope this kind of tip is non-intrusive and yet allows the users to learn a thing or two about SpeedCrunch features.\n\nSo, what do you think?\n\n(Yes, I know there is typo in the screenshot \n\n(`_|_`)May 24, 2007(`_|_`)ariya.io(`_|_`)speedcrunchs-tip-of-the-day', 'speedcrunchs-tip-of-the-day'),
(588, 'digest the curves, honor the pixels(`_|_`)\nContinuing my last year’s GSOC, finally I managed to implement support for importing embedded raster images in libwpg. As with other graphics formats such as SVG, PDF, and ODG, WPG allows pixmaps or images to be combined with the vector graphics. It was a bit difficult because raster images are typically compressed using RLE (run-length encoding) and it was not too trivial to decode it. And I still do not code all possible depth/format yet. But finally, here is the mandatory click-to-enlarge screenshot:\n\n\n\nLeft is the original WPG which I made in Corel Presentations by placing this beautiful windmill in Bremen together with a windmill picture from the clip art. Right is the WPG file opened and showed in Perfectspot (the all-around WPG viewer and converter).\n\nNote that I’m waiting for Qt 4.3 before making a first stable release of Perfectspot (and also libwpg, provided that all image loading support is good enough). The reason is because it needs ObjectBoundingMode for QGradient which really simplifies the code. That’s why, in the above screenshot, the gradient is not yet properly rendered in Perfectspot.\n\nIn related story, thanks to our very own Master Fridrich, libwpg-based WPG importer is going into ooo-build. So at least the next version of Novell’s OpenOffice.org will be able handle those WPG files.\n\n(`_|_`)May 21, 2007(`_|_`)ariya.io(`_|_`)digest-the-curves-honor-the-pixels', 'digest-the-curves-honor-the-pixels'),
(589, 'Alternating row colors, in group(`_|_`)\nAlternating row colors is a very common user interface pattern, the most used example is the playlist in Apple iTunes. With different color every other row, the table or a long list looks more pleasant and easier to use.\n\nHowever, if your list is rather vertical than horizontal, i.e. it is not that wide, but rather quite tall, and only consists of one or two columns, sometimes it helps to color not every row but a group of row. The example is shown here. The leftmost list widget has the same white color for all rows, the middle one uses alternating row colors (which looks rather “busy”), and the last one colors every 3 rows. Which one do you think is better?\n\n\n\n\n\n\n\nIf your list is an instance of QListWidget, QListView or anything derived from QAbstractItemView, it is very easy to enable the alternating colors, just use alternatingRowColors property.\n\nAlas, for grouped alternating colors for QListWidget, you must do some additional work, e.g. (works well for rather static items):\n\nint group = 3;\n  list->setUpdatesEnabled( false );\n  for(int i = 0; i < list->count(); i++)\n  {\n    QListWidgetItem* item = list->item(i);\n    QBrush c = ((int)(i/group))&1 ? palette().base() : palette().alternateBase();\n    item->setBackground( c );\n  }\n  list->setUpdatesEnabled( true );\n\n\nMultiple column list is often made from QTreeWidget with only top level tree items. In this case, grouped alternating colors can be achieved using e.g. (for two columns, create a loop for more):\n\nint group = 3;\n    tree->setUpdatesEnabled( false );\n    for(int i = 0; i < tree->topLevelItemCount(); i++)\n    {\n      QTreeWidgetItem* item = tree->topLevelItem(i);\n      QBrush c = ((int)(i/group))&1 ? palette().base() : palette().alternateBase();\n      item->setBackground( 0, c );\n      item->setBackground( 1, c );\n    }\n    tree->setUpdatesEnabled( true );\n\n\nYou can of course save some microseconds if you cycle the background color while iterating the items.\n\nIn addition, you may want to put some logic to prevent coloring if the number is item is e.g. less that 2*group. Otherwise, 4-item list will look odd, as only the last item has different background color.\n\n(`_|_`)May 20, 2007(`_|_`)ariya.io(`_|_`)alternating-row-colors-in-group', 'alternating-row-colors-in-group'),
(590, 'QEMU 0.9 with acceleration on SUSE 10.2(`_|_`)\nQEMU version 0.9 is already out for some time, but AFAIK no official package is available for openSUSE Linux 10.2 yet. Here are some steps I did to have QEMU 0.9 with accelerator (kqemu) on SUSE 10.2. The motivation is simple: I’d like to have a faster system for filter development.\n\nQEMU 0.9 comes, among others, in binary package. I found out that this works well, so just download qemu-0.9.0-i386.tar.gz then unpack it to /. You’ll see some new stuff in /usr/local/.\n\nNext step is to install and use accelerator. This time I did compile it from source. First, get kqemu-1.3.0pre11.tar.gz, unpack it, then run the usual steps: ./configure follows by make and sudo make install. Don’t forget to have kernel sources (install kernel-source package from YaST if necessary) in your system before doing this.\n\nNow do the following:\n\nexport device=\"/dev/kqemu\"\nsudo rm -f $device\nsudo mknod --mode=0666 $device c 250 0\n\n\nAfter that, load the accelerator (kqemu) kernel module:\n\nsudo /sbin/modprobe kqemu major=250\n\nNow, run your virtual machine using the extra -kernel-kqemu option, e.g:\n\nqemu -hda vdisk.qcow -kernel-kqemu\n\nIf you forget to load the kqemu kernel module, you’ll get the following error message:\n\nCould not open \'/dev/kqemu\' - QEMU acceleration layer not activated\n\notherwise, nothing shows up and your virtual machine is executed as usual.\n\nTo verify that kqemu works, activate the monitor using Ctrl+Alt+2, then type in info kqemu followed by Enter. You should see:\n\nkqemu support: enabled for user and kernel code\n\n(Exit from the monitor using Ctrl+Alt+1)\n\nIf, for some reason, you don’t want to run the virtual machine with acceleration, use the option -no-kqemu, e.g.:\n\nqemu -hda vdisk.qcow -no-kqemu\n\nNow, info kqemu on the monitor would give:\n\nkqemu support: disabled\n\nI tested QEMU 0.9 with Windows NT 4.0 as the guest operating system. Even without acceleration, I’ve seen performance improvement compared to previous versions of QEMU. With acceleration (kqemu), it was even faster, although the kqemu documentation says only Windows 2000 and XP are supported. Benchmark done using CPUBench showed that the virtual machine runs roughly equal to a 300 Mhz and 1.3 GHz system without and with kqemu, respectively. Now, that’s an improvement!\n\nHappy virtualizing…\n\nSources:\n\nhttp://fabrice.bellard.free.fr/qemu/kqemu-doc.html\n\nhttp://fabrice.bellard.free.fr/qemu/kqemu-doc.html\n\nhttp://kidsquid.com/cgi-bin/moin.cgi/QemuOnLinux\n\n(`_|_`)May 19, 2007(`_|_`)ariya.io(`_|_`)qemu-0-9-with-acceleration-on-suse-10-2', 'qemu-0-9-with-acceleration-on-suse-10-2'),
(591, 'Newton and the apple(`_|_`)\nPhysics Teacher: “Isaac Newton was sitting under a tree when an apple fell on his head and he discovered gravity. Isn’t that wonderful?”\n\nStudent: “Yes sir, if he had been sitting in class looking at books like us, he wouldn’t have discovered anything.”\n\nfrom jokes4all.net\n\n(`_|_`)May 17, 2007(`_|_`)ariya.io(`_|_`)newton-and-the-apple', 'newton-and-the-apple'),
(592, 'On these hands and knees I\'m crawlin\'(`_|_`)\nTime flies. KOffice sprint weekend in Berlin was just over. I couldn’t believe I was on my bed again this morning. It was lots of fun, plenty of food, interesting talks, endless excitement, and most importantly, I got to see many great fellow KOffice hackers in real-life.\n\nIn terms of lines of code, I wasn’t that productive. But I did managed to fix the annoying column/row resizing tip in KSpread and cleaned up some stuff so that krazy score is going to the sane level again. I checked our list of bugs and already had plan for few of them. The unit test for some spreadsheet functions would hopefully get some love as well. Also, thanks to our filter framework, I could work on a Karbon filter even before Karbon 2.0 is 100% ready. And I promised jaham that I’ll help with the SVG to/from ODG stuff. There was also a buzz to finally start really using my latest work on KoXmlReader for all KOffice ODF loading code so that we won’t have problem with memory consumption again when working with big documents.\n\nFor more details, summary and pictures, see KOffice ODF Sprint Kickoff on the Dot™. Update: and also  KOffice ODF Sprint Report.\n\n(`_|_`)May 14, 2007(`_|_`)ariya.io(`_|_`)on-these-hands-and-knees-im-crawlin', 'on-these-hands-and-knees-im-crawlin'),
(593, 'berlin, berlin(`_|_`)\nSo it’ll be my n-th trip to Berlin. We’re going to have KOffice ODF Weekend, supported by KDE e.V and KDAB. 17 16 heads, lots of hacking, and rainy weather look like a great combination.\n\n(`_|_`)May 10, 2007(`_|_`)ariya.io(`_|_`)berlin-berlin', 'berlin-berlin'),
(594, 'point seven(`_|_`)\nFinally, SpeedCrunch version 0.7 has been released. Compared to the last beta, this final release has some fixes for potential crash (due to Q3TextEdit), which is also reported in Launchpad.\n\nSo, get it while it’s hot. Packages are already available for Windows, Mac OS X (universal binary), Fedora, OpenSUSE, Gentoo, and Debian. Or just compile it from source if you feel brave. See the download page for details.\n\nFor some stuff which will make it into the upcoming 0.8, I’m still preparing an interesting screencast. Stay tuned.\n\n(`_|_`)May 7, 2007(`_|_`)ariya.io(`_|_`)point-seven', 'point-seven'),
(595, 'Custom toggle action for QDockWidget(`_|_`)\nThanks to QDockWidget::toggleViewAction, if you want to create an action (and placed in in the menu, for example) to switch a dock widget on and off, it is very simple indeed. The text of the action will be the title of the dock. If you have more than dock widgets, this can be combined together in a sub menu “Show Docks”, just as illustrated below:\n\n\n\nWhen that menu item (and the corresponding action) is checked/unchecked by the user, magically the dock will show/disappear.\n\nBut what if you want to create your own toggle action? For example, you want to customize the text of the action to be a bit more descriptive, say “Show Function List”. Or perhaps you just want the total control.\n\nWell, you can create your own actions and get this result:\n\n\n\nwhich can be realized by the following code:\n\nm_actions->showHistory = new QAction( tr(\"Show Expression &History;\"), this );\n  m_actions->showFunctions = new QAction( tr(\"Show &Functions; List\"), this );\n  m_actions->showHistory->setToggleAction( true );\n  m_actions->showFunctions->setToggleAction( true );\n  connect( m_actions->showHistory, SIGNAL( toggled(bool) ), \n    m_historyDock, SLOT( setVisible(bool) ) );\n  connect( m_actions->showFunctions, SIGNAL( toggled(bool) ), \n    m_functionsDock, SLOT( setVisible(bool) ) );\n\n\nSo far so good. Everytime you toggle the menu item, the docks can disappear and reappear.\n\nHowever, it’s not completely foolproof. You can, infact, make the dock disappear by closing it manually, i.e. clicking on the X button on the dock title bar. But by doing that, the “checked” status of the action itself is not properly adjusted (i.e. it is still “checked” while the dock is long gone).\n\nWith Qt 4.3, the solution is easy: use visibilityChanged signal of QDockWidget:\n\nconnect( m_historyDock, SIGNAL( visibilityChanged(bool) ), \n    m_actions->showHistory, SLOT( setChecked(bool) ) );\n  connect( m_functionsDock, SIGNAL( visibilityChanged(bool) ), \n    m_actions->showFunctions, SLOT( setChecked(bool) ) );\n\n\nIf, for whatever reason, you’re stucked with Qt 4.2, then you have to find another remedy since visibilityChanged does not exist there. There are many ways to do this.\n\nA particularly complicated but looks-elegant solution is by hijacking trapping the show and hide event of the docks using eventFilter trick. So, hook the event filters during docks construction:\n\nm_historyDock->installEventFilter( this );\n  m_functionsDock->installEventFilter( this );\n\n\nand do something like this in the window’s event filter:\n\nbool MyWindow::eventFilter( QObject* object, QEvent* event )\n{\n  if( object == m_historyDock )\n    if( event->type() == QEvent::Hide || event->type() == QEvent::Show )\n      m_actions->showHistory->setChecked( event->type() == QEvent::Show );\n\n  if( object == m_functionsDock )\n    if( event->type() == QEvent::Hide || event->type() == QEvent::Show )\n      m_actions->showFunctions->setChecked( event->type() == QEvent::Show );\n\n  return false;\n}\n\n\nLooks good? Not really. Because for all this trouble, you can just do the same in these two lines of code (the simple and yet effective solution):\n\nconnect( m_historyDock->toggleViewAction(), SIGNAL( toggled( bool ) ),\n    m_actions->showHistory, SLOT( setChecked( bool ) ) );\n  connect( m_functionsDock->toggleViewAction(), SIGNAL( toggled( bool ) ),\n    m_actions->showFunctions, SLOT( setChecked( bool ) ) );\n\n\n\nAny other solution, perhaps?\n\n(`_|_`)Apr 20, 2007(`_|_`)ariya.io(`_|_`)custom-toggle-action-for-qdockwidget', 'custom-toggle-action-for-qdockwidget'),
(596, 'on winning in life(`_|_`)\n\nLife is a game, and if you aren\'t in it to win, what the heck are you still doing here?\n\n\n\n— Linus Torvalds\n\n\n(`_|_`)Apr 19, 2007(`_|_`)ariya.io(`_|_`)on-winning-in-life', 'on-winning-in-life'),
(597, 'Tab bar with RoundedNorth for tabbed dock widgets(`_|_`)\nWarning: don’t try this in real world’s application!\n\nUpdate: I found a trick to reduce the flicker, just read further on.\n\nOne advantage of dock widgets (using QDockWidget) is that the docks can be “stacked”, either programatically using tabifyDockWidget or when the user explicitly places one dock on top of another. Example is shown below (for future version of SpeedCrunch, more about this in another blog post). There are two dock widgets: History and Functions, and at the moment they are stacked.\n\n\n\nHowever, apparently the tab bar (QTabBar) which is used to choose the dock is always placed at the bottom. Or, using the Qt’s terminology, it has the shape of QTabBar::RoundedSouth. Since there are other possibilities for tab bar’s shape, e.g. RoundedNorth, would it be possible to make something like this, where the tab is place at the top?\n\n\n\nUnfortunately until Qt 4.2 this is not possible yet (issue 146772), although according to issue 145880, “vertical tab bar layout” will be possible in Qt 4.3.\n\nJust for fun, I found a very hackish way to make RoundedNorth for the tab bar (hence, the screenshot above). The trick is to find the tab bar using run-time introspection feature of Qt and then change the geometry manually. If I know in advance that there will be only one tab bar in my main window and there are only two dock widgets, this can be accomplished with a private slot like this:\n\nvoid MainWindow::hackTabbedDocks()\n{\n QDockWidget* topDock = d->historyDock;\n if( topDock->height() == 0)\n   topDock = d->functionsDock;\n\n QList<qtabbar> allTabs = findChildren</qtabbar><qtabbar>();\n for(int ii = 0; ii < allTabs.size(); ++ii)\n {\n   QTabBar* tab = allTabs[ii];\n   if(tab->parentWidget() == this)\n   {\n     if(tab->geometry().top() > topDock->geometry().top())\n     {\n       tab->setShape( QTabBar::RoundedNorth );\n       int h = tab->geometry().height();\n       tab->move(tab->geometry().left(), topDock->geometry().top());\n       topDock->move(topDock->geometry().left(), topDock->geometry().top()+h);\n     }\n     break;\n   }\n }\n}</qtabbar>\n\nI found out, I always need to call this slot twice so that it can work. To simplify, there two other slots which manage it:\n\nvoid MainWindow::handleTabChange()\n{\n  QTimer::singleShot(0, this, SLOT(hack1()));\n}\n\nvoid MainWindow::hack1()\n{\n  hackTabbedDocks();\n  QTimer::singleShot(100, this, SLOT(hackTabbedDocks()));\n}\n\n\nAnd I need to bind any signals which indicate that the tab bar has been relayouted, e.g. when a new tab is selected , when it is resized, etc, to handleTabChange slot above. For illustration purpose, let’s just do the first. Of course, this can be done only when tab bar already exists. So, time for another silly slot:\n\nvoid MainWindow::initHack()\n{\n  QList<qtabbar> allTabs = findChildren</qtabbar><qtabbar>();\n  for(int ii = 0; ii < allTabs.size(); ++ii)\n  {\n    QTabBar* tab = allTabs[ii];\n    if(tab->parentWidget() == this)\n    {\n      connect(tab, SIGNAL(currentChanged(int)), this, SLOT(handleTabChange()));\n      break;\n    }\n  }\n  handleTabChange();\n}</qtabbar>\n\nwhich will be called from MainWindow’s constructor by abusing QTimer once more:\n\ntabifyDockWidget( d->historyDock, d->functionsDock );\n  QTimer::singleShot(0, this, SLOT(initHack()));\n\n\nThat’s it!\n\nThe big disadvantage of this trick is obvious: flicker occurs everytime you do something with the docks, e.g. changing the tab. It will be quite annoying, but all of this is just a hack anyway. So was it fun? Yes. Useful? No.\n\n(I guess the real “solution” is only waiting for the Trolls to implement it)\n\nUPDATE. Here is the trick to reduce the flicker so that it becomes acceptable (even almost not noticeable). I need another private slot and some magic with setUpdatesEnabled as follows:\n\nvoid MainWindow::handleTabChange()\n{\n  setUpdatesEnabled(false);\n  QTimer::singleShot(0, this, SLOT(hack1()));\n}\n\nvoid MainWindow::hack1()\n{\n  hackTabbedDocks();\n  QTimer::singleShot(0, this, SLOT(hack2()));\n}\n\nvoid MainWindow::hack2()\n{\n  hackTabbedDocks();\n  setUpdatesEnabled(true);\n}\n\n\n(`_|_`)Apr 18, 2007(`_|_`)ariya.io(`_|_`)tab-bar-with-roundednorth-for-tabbed-dock-widgets', 'tab-bar-with-roundednorth-for-tabbed-dock-widgets'),
(598, 'N800(`_|_`)\nThanks to Nokia (and whoever has recommended me), I finally got the once-in-a-lifetime developer-discounted N800. After a little problem with payment and delivery, which fortunately were solved, I can enjoy this cute little gadget.\n\n\n\nUsing this N800 on and off for some weeks, I can only say that it’s a great experience. On the hardware side, everything works perfectly. The 4.1-inches display is sharp, touch screen works without glitch, control buttons are easy to use, my 2 GB SD-card is detected without hassle, FM radio shows no problem, the “hidden” web cam gives good image quality. Speaking of web cam, the direction is a bit strange because it is rather “tilted aways” from your face. When doing a video chat, your partner would see it as if you don’t face him directly.\n\nInternet connection with both Bluetooth/GPRS and WiFi works out of the box. For road warrior with e.g. GPRS flat-rate, N800 is better than small-screen smartphone and surely lighter than sub-notebook. The installed Opera browser is good enough for most surfing needs, even Flash is supported, although YouTube video playback will be sluggish. Fortunately, playing typical audio and video files are smooth enough (hardware decoding, I reckon). Text, voice and video chat are all easy to setup and they work right away.\n\nSince N800 is targeted as Internet Tablet, only few other applications are available preinstalled. This is a bit pity, as I guess this device could be a very good PDA. However, installing 3rd-party applications is not so difficult, e.g. browse to http://downloads.maemo.org and use the single-click install button. And there’s Pimlico project to bring PIM suite to N800.\n\nFor multimedia, the included media player is good enough, but nothing beats Canola (see it in action) if you want to impress your friends, it transforms N800 into a portable FrontRow-style media center. With N800’s speaker, Canola definitely boosts the “cool factor” easily.\n\nWhen finally I can have some more free time (read: after finishing the dissertation), I want to play around with it and probably try to port some of my personal programs to the platform.\n\n(`_|_`)Apr 15, 2007(`_|_`)ariya.io(`_|_`)n800', 'n800'),
(599, 'crispy catfish(`_|_`)\nWith the risk of being blacklisted by some PlanetKDE readers, here is yet another food post on pecel lele or fried catfish with raw vegetables.\n\nWhen you live in Java, for less than a dollar you can get this kind of food easily almost everywhere so the thought of cooking yourself catfish (ikan lele) hardly comes into mind (unless you’re the seller of course). But in Europe, it would be real hard to find a restaurant that offer this in the menu.\n\n\n\nHere is the rough recipe. The fish is basically fried until it becomes crispy. But before, rub the fish with lime juice and a bit of salt, pepper, garlic and wait some time until it absorbs everything. To prepare the dip, use a mix of chili sauce, tomatoes, shallots and shrimp taste. Add soy sauce to taste and then serve with fresh vegetables and warm rice.\n\n(`_|_`)Apr 15, 2007(`_|_`)ariya.io(`_|_`)crispy-catfish', 'crispy-catfish'),
(600, 'Obligatory Google bugs(`_|_`)\nThey are more dangerous than Seb’s \n\n\n\n(`_|_`)Apr 9, 2007(`_|_`)ariya.io(`_|_`)obligatory-google-bugs', 'obligatory-google-bugs'),
(601, 'Google as your assistant(`_|_`)\nSoon Google technologies would manage you life (almost) completely.\n\nJust recently I had short chat with someone I haven’t met for ages. I was doing this through chat feature of Google Mail. Cause we had not so much time to talk, we planned to have another chat session on Friday:\n\n\n\nLater on, I checked the chat log again. I wanted to put a reminder in my calendar (using Google Calendar), but then look what was offered to me right there:\n\n\n\nPutting privacy issues aside, apparently my chat log is automatically analyzed (no surprise here, messages in Google Mail is scanned to determine the content-targeted ads). Because seems that I and my friend have an appointment to chat again, that’s why I was given the link to add it to my calendar.\n\nIn another test, I chatted with someone and just typed “how about dinner on friday?”, and yes, Google Mail interface again displays the link to add “dinner” to my calendar. Pretty neat, isn’t it?\n\nI predict that soon it’s even completely normal that, if you plan a lunch with your business partner, perhaps somewhere downtown, Google technologies could place a call, make the reservation, confirm the menu, order the taxi at the right time (complete with printed optimal route for the driver), pull the right business documents, etc etc.\n\nWhat a digital life.\n\n(`_|_`)Apr 4, 2007(`_|_`)ariya.io(`_|_`)google-as-your-assistant', 'google-as-your-assistant'),
(602, 'CeBIT 2007(`_|_`)\n   \n\n(`_|_`)Mar 24, 2007(`_|_`)ariya.io(`_|_`)cebit-2007', 'cebit-2007'),
(603, 'the windmill(`_|_`)\n\n\nThis was taken in Bremen. Click on the picture to go to Flickr, if you want to get the larger version.\n\n(`_|_`)Mar 8, 2007(`_|_`)ariya.io(`_|_`)the-windmill', 'the-windmill'),
(604, 'the train station(`_|_`)\n\n\n(`_|_`)Mar 4, 2007(`_|_`)ariya.io(`_|_`)the-train-station', 'the-train-station'),
(605, 'strawberry couverture(`_|_`)\n\n\nThat’s a fantastic dessert. Inspiration is from Google, I mean of course literally, the first page of google.com today \n\n(In case you miss it, check this out)\n\n(`_|_`)Feb 14, 2007(`_|_`)ariya.io(`_|_`)strawberry-couverture', 'strawberry-couverture'),
(606, 'Modulus with Mersenne prime(`_|_`)\nConsider the following simple operation, where k is integer and p is prime:\n\nint i = k % p;\n\n\nTypically this will be assembled to (sorry, x86 only):\n\nmov  eax, k\n  cdq\n  idiv p\n\n\nwhere the result is available in register EDX.\n\nSuch IDIV instruction has a latency of more than 40 cycles on Intel Pentium or AMD64 processor family. Hence, for optimization purposes, it is best to avoid integer division.\n\nThe above division/modulus operation can be avoided if the prime number p is chosen to be the Mersenne primes only, i.e there is a positive integer s such as p = 2s-1. In 32-bit range, there are Mersenne primes: 3, 7, 31, 127, 8191, 131071, 524287, and 2147483647.\n\nThe modulus operator with Mersenne prime can be simplified as:\n\nint i = (k & p) + (k >> s);\n  return (i >= p) ? i - p : i;\n\n\nUpdate: This works only for k up to (1 < < (2 * s)) - 1, so careful with small Mersenne primes. Otherwise you need to call the function recursively.\n\nOne possible assembler implementation is as follows.\n\n; assume edx = k, ebx = p, ecx = s\n  ; result is in eax\n  mov     eax, edx\n  sar     edx, cl        ; k >> s\n  and     eax, ebx       ; k & p\n  add     eax, edx       ; eax is i = (k & p) + (k >> s)\n  mov     edx, eax       ; edx is also i\n  sub     edx, ebx       ; i - p\n  cmp     eax, ebx       ; only if (i >= p)\n  cmovge  eax, edx       ; then eax is (i-p)\n\n\nNote that with the help of CMOVGE (6 cycles latency on Pentium 4), there is no need for real branching (which is expensive). Although the code is longer compared to the IDIV version, it executes much faster. Still faster if the range k is limited so that only a decrement operator is needed. Even faster of course if p is constant.\n\nLast time I used this is for hash table (micro)optimization, because the number of stored items is known and I can live with a table whose size is a Mersenne prime. That’s indeed a very special case only.\n\nBTW this is off-topic, but thanks for those who mailed/texted me after this post. Nothing happened to me, I’m just fine. Those lines are from Keane’s latest single (guess which one?), picked for no particular reason other that it’s a good ballad.\n\n(`_|_`)Feb 12, 2007(`_|_`)ariya.io(`_|_`)modulus-with-mersenne-prime', 'modulus-with-mersenne-prime'),
(607, 'nightmarish(`_|_`)\nI wake up, it’s a bad dream No one on my side I was fighting But I just feel too tired To be fighting Guess I’m not the fighting kind\n\n(`_|_`)Feb 6, 2007(`_|_`)ariya.io(`_|_`)nightmarish', 'nightmarish'),
(608, 'Musselicious(`_|_`)\nIn order to keep polluting the Planets (the aggregators, not the heavenly bodies), here is yet another pasta dish: Spaghetti with Mussels. The tomate sauce, unfortunately not really visible in the picture, goes along very well with the mussels, especially – if you are not in hurry – when cooked slowly. 1 kg of mussels should be enough for 2 portions, unless you successfully make it extremely delicious \n\n\n\n(`_|_`)Feb 3, 2007(`_|_`)ariya.io(`_|_`)musselicious', 'musselicious'),
(609, 'Paccherimania(`_|_`)\nHere is another of my crime to Italian-style dish. Taste fresh and delicious (at least for me), suitable for vegetarians, and perfect for candle-light dinner.\n\n\n\nJust like before, here I mixed it with non-Italian ingredients. As the filling for paccheri (you can also use the bigger canneloni), just put vegetables of your choice, chopped to fit the tube size. For non-vegetarians, you may add e.g. tuna slices. The new thing here is that I stuffed also very tasty tempe, fried and cut into small pieces. As usual, make tomato sauce with fresh tomatoes. Cover the paccheri with the sauce and put it in the oven, heat up to 200 C for quarter an hour. For cheese-lovers, add some parmesan. In the mean time, cut eggplant (yes, eggplant!) in lengths, leave the skin, and then fry the pieces in hot oil (with onions, ginger, chili, and others). Add garlic and lots of pepper, it makes the taste really fantastic. When it’s ready, pour over some leftover of the tomate sauce, also add some olives and basil.\n\nFinally serve your paccheri with the eggplant. You’ll get different taste mixed together: sweet, hot, salty. Buon appetito!\n\n(`_|_`)Jan 28, 2007(`_|_`)ariya.io(`_|_`)paccherimania', 'paccherimania'),
(610, 'Kyrill, Lancelot(`_|_`)\nKyrill storm, with a wind gust record speed of 191 km/h and its catasthrophic effects, seems to be over. But now everyone is preparing for the successor: Lancelot.\n\nIn case you don’t know yet, these names are determined through sponsorship. If you are ready to shell out 199 euros, then you can decide the name of the next (alphabetically sorted) low and high-pressures. But you’d better be fast, many alphabets are taken already. And not to mention that there is no guarantee such pressures will ever become widely-known storms.\n\n“Ten thousand thundering typhoons…“\n\n(`_|_`)Jan 21, 2007(`_|_`)ariya.io(`_|_`)kyrill-lancelot', 'kyrill-lancelot'),
(611, 'wrap-up(`_|_`)\nOne of my failure until 2006 is this one:\n\n\n\nI did not managed to release it, so at least I post the screenshot \n\nThe full story/download/editor/code will be in 2007, or rather When It’s Done ™.\n\n(`_|_`)Dec 31, 2006(`_|_`)ariya.io(`_|_`)wrap-up', 'wrap-up'),
(612, 'unkrazification continues(`_|_`)\nLadies and gentlemen, please welcome KFormula, the third KOffice application (after KSpread and KPlato) that is not krazy anymore!\n\n\n\n(`_|_`)Dec 31, 2006(`_|_`)ariya.io(`_|_`)unkrazification-continues', 'unkrazification-continues'),
(613, 'Almond Cookies(`_|_`)\nWarsaw Almond Cookies: taste fantastic and need only eggs, sugar, almond and two hours of baking (see the recipe). Use couverture chocolate to decorate. Of course, you still live under the rock if you can’t find our beloved three letters in the picture.\n\n\n\nSurprisingly, Google does not give anything. Is there any official English name for that? I know only Warschauer Mandelgebäck.\n\n(`_|_`)Dec 29, 2006(`_|_`)ariya.io(`_|_`)almond-cookies', 'almond-cookies'),
(614, 'not krazy is cool(`_|_`)\nAfter KSpread, KPlato – KOffice’s project management tool – becomes the second non-krazy KOffice application:\n\n\n\n(`_|_`)Dec 29, 2006(`_|_`)ariya.io(`_|_`)not-krazy-is-cool', 'not-krazy-is-cool'),
(615, 'careful with your fortune(`_|_`)\nWhen Bob found out he was going to inherit a fortune when his sickly father died, he decided he needed a woman to enjoy it with. So one evening he went to a singles bar where he spotted the most beautiful woman he had ever seen.\n\nHer natural beauty took his breath away. “I may look like just an ordinary man,” he said as he walked up to her, “but in just a week or two my father will die, and I’ll inherit 20 million dollars.”\n\nImpressed, the woman went home with him that evening.\n\nThree days later, she became his stepmother.\n\n \n\n \n\n \n\n(always from jokes4all.net)\n\n(`_|_`)Dec 23, 2006(`_|_`)ariya.io(`_|_`)careful-with-your-fortune', 'careful-with-your-fortune'),
(616, 'One trained monkey to rule them all(`_|_`)\nHe did it again! Not satisfied with libwpd and libwpg, Fridrich “uberdedicated” Strba started libwps (that’s for Microsoft Works) integration with OpenOffice.org.\n\n(`_|_`)Dec 20, 2006(`_|_`)ariya.io(`_|_`)one-trained-monkey-to-rule-them-all', 'one-trained-monkey-to-rule-them-all'),
(617, '14 million bucks(`_|_`)\nThis metric is debatable, there are duplicated and imported code, the result is different to sloccount and KOffice 2.0 is still in heavy development, but what Ohloh at the moment says about KOffice: it’s worth USD 14,053,618 (256 Person Years) and its activity is still increasing:\n\n\n\nLooking at the detailed statistics, I’m somehow still at 11th position. However, I must be careful, this guy is right on my tail \n\nBTW, for comparisons, KDE itself is “only” $10,750,392, Amarok is $2,405,217, Firefox is $2,173,769 and OpenOffice is at $94,036,902.\n\n(`_|_`)Dec 17, 2006(`_|_`)ariya.io(`_|_`)14-million-bucks', '14-million-bucks'),
(618, 'Reverse and 64(`_|_`)\nNext time your candidate claims a deep knowledge of programming, ask him/her why the following line can reverse the bits in a 8-bit byte, along with an explanation why it needs 64-bit arithmetic:\n\nc = (c * 0x0202020202ULL & 0x010884422010ULL) % 1023;\n\nSolution: see the complete hacks.\n\n(`_|_`)Dec 4, 2006(`_|_`)ariya.io(`_|_`)reverse-and-64', 'reverse-and-64'),
(619, 'Memory efficient DOM (Part 2)(`_|_`)\nThis is the follow-up to the first part of my writing on memory efficient DOM implementation for KOffice. Now my intention is to find out whether real-time compression can help to further reduce the memory consumption.\n\nXML compression is a whole field of research. There are a bunch of compressor available, from XMill, XMLZip, XMLPPM, XGrind, XML-Xpress, Exalt, TREECHOP and many others. Since I’m not a scholar in this field (I already have my own graduate research to take care of), I have chosen a direct and brutal approach: just compress the packed nodes representation and decompress them on-the-fly. While iteration is very common, simple cache buffer for decompressed neighbouring nodes is implemented so there is no need to always decompress every single node. This method easily fulfills the requirements that I set: no need to load the whole XML (because it intercepts SAX events), allows queries and iteration (due to the QDom-like wrapper), and can be conveniently tested with the compression switched off.\n\nThere are many algorithms suitable for fast compression and decompression. Byte-aligned Lempel-Ziv is a logical and obvious choice. Again, I have very much zero knowledge about data compression. There are Ross Williams’s LZRW1, Herman Vogt’s LZV, Markus Oberhumer’s LZO, Marc Lehmann’s LZF and many others. LZRW1 is well-known although probably covered by patents. LZV has the poorest compression ratio so it goes out of the list. LZO’s compression is the best, at the price of a bit more complicated state-machine, but my own implementation (since the reference implementation is GPL only) is not so fast and well debugged. LZF, the successor to LZV, is a good contender and already used (among others) in suspend2 project. On fairly modern machine with large CPU cache and reasonable branch predictor, liblzf (the reference implementation of LZF) is much slower than LZRW1. So what I did is to recreate the compressor. Armed with Valgrind’s Cachegrind, my new implementation is finally faster than LZRW1.\n\nWhat I am really eager to try (but no time for that yet) is Wilson-Kaplan algorithm. At least the WK4x4 and WKdm variants have been implemented for Linux compressed caching project. And since the compression/decompression inside KoXmlReader is actually involving in-memory data, this fast and low-overhead WK algorithm should be a good candidate. There are assorted patent applications for such cache compression, but I wonder whether the algorithm per se is patented.\n\nNow on to the result, starting with the worst test document: Frequencies.ods. Just to remind you, loading and iterating this document (19 MB XML) takes 250 MB if we’re using QDom but only 40 MB with KoXmlReader. Here what Valgrind/Massif reported when the compact form of the DOM is compressed and decompressed on the fly. At most, this barely consumes 8 MB. Compared to 250 MB, 40 MB is good enough, but 8 MB is great, isn’t it?\n\n\n\nInteresting is, during the parsing phase, the heap allocation increases only (almost) linearly.\n\nThe full comparison with other documents is shown below. Amazing to see how short the violet bars are.\n\n(Update: this chart is not available anymore due to a data loss)\n\nAs for speed, regardless the lightning fast packing and unpacking, there’s some penalty. This graph below summarizes the timing required for parsing (light bars) and iterating (dark bars). Compare to what was shown in part 1, I only added the result for KoXmlReader with compression. Small documents are omitted because processing time is short anyway.\n\n\n\nOf course, all these graphs must be taken with a grain of salt. But my objective is only to find out whether this all makes sense, not to write a full-brown research paper. So far I’m quite happy with the result.\n\nIt can be seen that KoXmlReader is a feasible alternative for QDom (in KOffice) as it does not incur any significant performance penalty yet the memory footprint in the worst case (Frequencies.ods) can only be one sixth (40 MB) compared to that of QDom (250 MB). We also see the additional benefit of using real-time compression. Compared to plain KoXmlReader, although in the worst case it is 1⁄5 slower (and there is still room for further improvements here), the allocated heap is only one fifth (8 MB vs 40 MB). Or even 1⁄30 if you bravely compare it against QDom (8 MB vs 250 MB).\n\nI guess we should empirically find out how large the average documents that most people are working with. If these are less than the worst case that I tested, then enabling compression by default is a good thing because the performance penalty won’t be noticable. If not, even without compression it is already much more better than using QDom.\n\nOther than that, my aim now is to fully integrate KoXmlReader in KOffice. Hopefully someday bug #59510 can really be closed.\n\n(`_|_`)Nov 24, 2006(`_|_`)ariya.io(`_|_`)memory-efficient-dom-part-2', 'memory-efficient-dom-part-2'),
(620, 'unkraziness(`_|_`)\n\n\n(`_|_`)Nov 17, 2006(`_|_`)ariya.io(`_|_`)unkraziness', 'unkraziness'),
(621, 'KOffice in LinuxUser(`_|_`)\nThe November edition of LinuxUser features, among others, a review of six alternatives to OpenOffice: Applixware, Siag Office, Softmaker Office, Thinkfree Office, Gnome Office and of course our beloved KOffice.\n\nKOffice is praised for the perfect KDE integration, its resource friendliness, the comprehensive functionalities and the outlook of its future development.\n\nGranted, it was for KOffice 1.5.2 (although we already have 1.6 and even 1.6.1 soon), probably because KOffice 1.6 was not released yet at the time of the review. Nevertheless, that does not stop the good closing words:\n\n\nFür Privateanwender bietet einzig KOffice eine echte Alternative zu OpenOffice.\n\n\n(`_|_`)Nov 10, 2006(`_|_`)ariya.io(`_|_`)koffice-in-linuxuser', 'koffice-in-linuxuser');
INSERT INTO `ariyaio` (`id`, `content`, `url`) VALUES
(622, 'Memory efficient DOM(`_|_`)\nA known problem with KOffice applications is the inability to cope with very large data (e.g. bug #59510). This is often related to filters, e.g. when you are importing Excel documents (see bug #85372). Fortunately, as I wrote there, this has been solved already as the filter now can produce large documents without causing the machine to consume every single bytes of RAM.\n\nStill, a very large file can force the application to use hundred MB memory. One of the reason is because we use QDom to hold some DOMs associated with the document. Unfortunately, once the DOM gets very big, QDom would take too much memory space. And once some parts are paged out to swap, performance will degrade significantly. So when people claimed that opening 1 MB file (which is actually the compressed size, not the actual size of the XML document) consumes more than 300 MB memory, it is not exaggerated. After looking at some colorful charts below, you would hardly be astonished.\n\nWhen the document is loaded, we do not need the DOMs anymore and these can be destroyed. Thus, although loading takes quite some time, once the loading process is finished, the application won’t take so much memory anymore.\n\nThis topic has been discussed couple of times in the past. Last year, I started to work on a memory efficient implementation of DOM, designed to be used in KOffice. After some attempts, looks like it may after all work. And quite promising indeed.\n\nSo, how can this DOM thing be improved?\n\nFirst, it’s likely that we do not need to modify any elements once they are loaded from the file. The way it works is always like this: get the document, load some XML files from the storage (e.g. content.xml, settings.xml, styles.xml, …), parse them and construct the application-specific objects from those XML files. For example, for a spreadsheet this means that we create all the sheets, rows, columns, cells, and other objects. When the application saves the document, it creates the DOM from scratch and write it to the file. Thus, when opening a file, the corresponding DOMs are not modified at all.\n\nSecond, many namespace URIs, attribute names and element values are duplicated. That alone is already a very good reason to cache common strings. For example, in OpenDocument spreadsheet, almost every cell have attributes named table:style-name and office:value-type so we do not need to duplicate them for every single cells.\n\nThe replacement for QDom, dubbed as KoXmlReader, is using these tricks. The whole DOM tree is stored in a very compact form (where the overhead per node is minimized and all duplicated strings are stored efficiently), not using all instances of nodes, elements, texts, etc. However, there are KoXmlNode, KoXmlElement, KoXmlDocument classes which correspond to their QDom counterparts. The key is, those DOM nodes are created (from the compact representation) only when we need it and afterwards they can be destroyed again. In short: it’s constructed only on-demand.\n\nThis way, compatibility with QDom classes is preserved (otherwise we need to modify and test thousand lines of code) while the memory requirement can be kept to minimum.\n\n(Side note: yes, we considered using a SAX parser directly. But that means changing a lot of code and is prone to mistakes. And seems nobody is willing to do that. My personal feeling is that the gained performance is not worth the hassle, though but I’m not so sad if I’m wrong here).\n\nHow can this help? Say we’re dealing with a spreadsheet. When we parse the first sheet we need all the nodes and elements belong to this sheet, but we don’t care for nodes and elements associated for the other sheets. So we just load what we need (this loading even happens automagically). After we finish with it, we can move to the next sheet and at the same purge everything from the first sheet (cause we don’t bother with it anymore).\n\nI tried to make the API for node, element, text etc very much compatible to QDom. There is even a compiler define so that it just wraps all those QDom classes (to ease transition), which allowed Stefan to change all QDom references with KoXml in one amazing sweep. Unit tests – with more than 1000 checks – provide (hopefully) almost 100% coverage and should help catching bugs or incompatibilities as early as possible (also, I notice that I have one more example of what I wrote some time ago: the whole test suite is longer than code itself).\n\nSo how does it perform?\n\nObviously this is not a scientifically correct benchmark, but just to give some illustrations, here are few spreadsheet documents that I tested (actually I have tried many many documents, these are just some of them). The column Content specifies the size of the content.xml of each document. As you can see, once it’s uncompressed, the file can be very big. Other columns are self-explained, I hope.\n\n\n  \n    \n      Document\n    \n    \n    \n      File Size\n    \n    \n    \n      Content\n    \n    \n    \n      Sheets\n    \n    \n    \n      Cells\n    \n  \n  \n  \n    \n      permfall.ods\n    \n    \n    \n      18 KB\n    \n    \n    \n      92 KB\n    \n    \n    \n      4\n    \n    \n    \n      271\n    \n  \n  \n  \n    \n      test.ods\n    \n    \n    \n      18 KB\n    \n    \n    \n      144 KB\n    \n    \n    \n      13\n    \n    \n    \n      1138\n    \n  \n  \n  \n    \n      Customer_Solution.ods\n    \n    \n    \n      90 KB\n    \n    \n    \n      1478 KB\n    \n    \n    \n      18\n    \n    \n    \n      11735\n    \n  \n  \n  \n    \n      Financial_Report.ods\n    \n    \n    \n      143 KB\n    \n    \n    \n      2947 KB\n    \n    \n    \n      24\n    \n    \n    \n      8913\n    \n  \n  \n  \n    \n      bug85372.ods\n    \n    \n    \n      247 KB\n    \n    \n    \n      4754 KB\n    \n    \n    \n      81\n    \n    \n    \n      347193\n    \n  \n  \n  \n    \n      Frequencies.ods\n    \n    \n    \n      627 KB\n    \n    \n    \n      18952 KB\n    \n    \n    \n      3\n    \n    \n    \n      185334\n    \n  \n\n\nSo what happen if we load each of this document, give it to our XML parser, construct the DOM tree and iterate every single cell in the document? We won’t load it into KSpread, and we won’t create any data from that. We would just treat it like a plain DOM representation of a spreadsheet.\n\nUsing Valgrind’s Massif, here what I got when I processed one of them using all QDom classes (QDomDocument, QDomElement, etc). As you witness, the memory consumption skyrocketed to around 250 MB although the compressed ODS file is not even 1 MB. In reality (i.e. within KOffice), of course the situation is much worse because KOffice needs also some more megabytes for its own code and data.\n\n\n\nAnd this is how it looks like when I patch QDom so that the strings are cached (get the simple patch, if you’re curious). It does not seem to help too much in this case.\n\n\n\nHowever, using KoXmlReader stuff (KoXmlDocument, KoXmlElement, etc), at most we need only around 40 MB (see the vertical axis).\n\n\n\nAnd follows is the complete comparison chart for other documents. Note that I omit Frequencies.ods – which you can already enjoy from the graphs above – because the bars for that file would be very very long compared to the others.\n\n\n\n(There are perhaps better ways to instrument memory usage, so please take my lame attempt above with a grain of salt).\n\nSo we can see that the family of KoXml classes can be useful. But, what are the catches? For sure, we can’t change the DOM tree. That is quite clear. However, as I write in the beginning, this does not matter a lot for KOffice. In other words, you can’t just simply substitute your QDom with this KoXmlReader. It is designed and implemented for a very specific use case. It’s not even a fully compliant implementation.\n\nAnother disadvantage is that iterating over nodes is a bit slower than QDom. The good news: parsing is faster. This is because the whole process is likely memory bound. True, KoXmlReader has some processing overhead while packing and unpacking the nodes (i.e. constructing them on-the-fly). But it definitely also accesses only a fraction of RAM compared to QDom, and we all know how slow memory operation is.\n\nA few runs on P4 1.8 GHz gives the following chart. The light color is for parsing, the darker is for iterating. Looks like KoXmlReader does not really lag behind.\n\n\n\nThis also makes me rather excited, I wonder whether my next attempt (using additional real-time compression, wait for the Part II of this writing) would still give an acceptable performance in term of speed. Update: this part 2 is already available.\n\nThere are still few issues which must be solved before this stuff can be fully utilized in the upcoming KOffice 2.0. I’m working on that. But just for appetizer, here is the memory chart running KSpread and opening one of the test document (Customer_Solution.ods). Using QDom, the peak was about 110 MB before it settled down to around 80 MB when the loading is completed. I have no idea what caused the deep spike in the middle, this must be investigated (Is it really from KSpread? Or possibly Valgrind?).\n\n\n\nHowever, when KoXmlReader stuff is used instead of QDom, the heap allocation (during the parsing and iterating) touched just about 90 MB, as evidenced below:\n\n\n\nPlease do not assume that 80 MB is what KSpread 2.0 needs to work with such simple document. What I am using is a rather work-in-progress version, so it has lots of extra stuff. KOffice 2.0 is still very far from its release date and there are still lots of on-going work on optimizations.\n\nTo be continued…\n\nUpdate: see the follow-up”).\n\n(`_|_`)Nov 8, 2006(`_|_`)ariya.io(`_|_`)memory-efficient-dom', 'memory-efficient-dom'),
(623, 'fantastic home-made(`_|_`)\n\n\n(`_|_`)Oct 28, 2006(`_|_`)ariya.io(`_|_`)fantastic-home-made', 'fantastic-home-made'),
(624, 'evil bug(`_|_`)\nis Bug of the Month’s bug #666, which even prompts warning 666.\n\n(`_|_`)Oct 22, 2006(`_|_`)ariya.io(`_|_`)evil-bug', 'evil-bug'),
(625, 'hey, you! keep it clean!(`_|_`)\n\n\n(the beauty of configurable desktop environment)\n\n(`_|_`)Oct 18, 2006(`_|_`)ariya.io(`_|_`)hey-you-keep-it-clean', 'hey-you-keep-it-clean'),
(626, 'puzzle(`_|_`)\nJust for fun, I told one guy:\n\nYou know what? The number of CVS commits from KDE developers has dropped to zero since months.\n\nAnd surely he was surprised:\n\nAh, really? I thought they are working hard for KDE 4 or something like that…\n\nThis bloke apparently did not get it \n\n(`_|_`)Oct 18, 2006(`_|_`)ariya.io(`_|_`)puzzle', 'puzzle'),
(627, 'let\'s buzz it(`_|_`)\n\n\n\n\n\n\n(`_|_`)Oct 17, 2006(`_|_`)ariya.io(`_|_`)lets-buzz-it', 'lets-buzz-it'),
(628, 'the glassy nuance(`_|_`)\nAnother visually appealed style I would like to feature is Polyester from mart. It joins another interesting KDE styles with also interesting names (remember Liquid, Keramik, Plastik?). Polyester has a matching window decoration and some choices of color schemes.\n\nThe distinct look of this style is the glass rendering of push buttons, combo box, tab bar, menu bar, list view header, and even window titlebar. Nice, isn’t it?\n\n\n\n(`_|_`)Oct 16, 2006(`_|_`)ariya.io(`_|_`)the-glassy-nuance', 'the-glassy-nuance'),
(629, 'buon appetito(`_|_`)\nTagliatelle with Bolognese sauce and parmesan cheese? C’mon, that you can get easily in a ristorante next door. Let’s make something new. Here is tagliatelle with orak-arik or scrambled vegetables.\n\n\n\nThis dish can be prepared easily. Basically just stir fry chopped vegetables (use anything you can imagine) in medium heated oil with onions, shallots, garlic, chilli and quite amount of pepper. Then scramble the eggs (leave out for the pure vegetarian version). Add Italian-style tomato sauce and then serve everything together. For the European version, of course you can still have the parmesan cheese.\n\nAnd happy birthday KDE!\n\n(`_|_`)Oct 14, 2006(`_|_`)ariya.io(`_|_`)buon-appetito', 'buon-appetito'),
(630, 'soc 2006 t-shirt(`_|_`)\n\n\n(`_|_`)Oct 11, 2006(`_|_`)ariya.io(`_|_`)soc-2006-t-shirt', 'soc-2006-t-shirt'),
(631, 'too many lines will kill you(`_|_`)\nSerenity by Maxilys is a unique style in a sense that the widgets do not have the common bevels used to give the 3-d illusion. Instead, almost everything is painted with a kind of color gradient.\n\n\n\nAnother interesting point in this style is some different variants of the progress bar:\n\n\n\nIf you’re on SUSE, use Smart to install Serenity from standard Guru channel.\n\n(`_|_`)Oct 7, 2006(`_|_`)ariya.io(`_|_`)too-many-lines-will-kill-you', 'too-many-lines-will-kill-you'),
(632, 'take back the fish(`_|_`)\nNo doubt I love fish. Since many Europeans will eat fish on Friday, here is another one: ikan bumbu kecap or fish in soy sauce.\n\n\n\nThe irresistible sauce is an ancient secret. Long time ago it was revealed to me by my mother, who got it from her grandmother, who somehow (so I was told) got it from her ancestor. Basically you heat a little amount of oil, throw in lots of fresh garlic slices and after some time, add the sweet soy sauce until you get the unmistakable smell. Add some chili, chopped onions, and ginger to taste. Beware though (very much like coding), the algorithm looks ridiculously trivial but the implementation can be horrible.\n\nThe fish is simply fried. When it is ready, pour over the prepared sauce. Few additional drops of tomate sauce is also harmless. Make sure this makes your mouth water, and then serve!\n\n(`_|_`)Oct 5, 2006(`_|_`)ariya.io(`_|_`)take-back-the-fish', 'take-back-the-fish'),
(633, 'ubiquitous snack(`_|_`)\nStill not bored with my cuisine mumbo-jumbo? Here is another one: pisang goreng or banana fritters. This lovely snack can be found virtually anywhere in my country with virtually zero effort. But, it is also easy to make, probably with virtually no skill at all.\n\nNa, isst du noch oder kochst du schon? \n\n\n\n(`_|_`)Oct 4, 2006(`_|_`)ariya.io(`_|_`)ubiquitous-snack', 'ubiquitous-snack'),
(634, 'rediscover your dessert(`_|_`)\nAgar-agar – made from algae – is always good for dessert. For the European readers (from planetkde.org), in case you don’t know it yet, you can get this from most asian shops or order it online. A small package of 9 g agar powder should be enough for the whole family. Add slices of fruits, pour some milk and few drops of honey to taste. In hot days (like fews weeks ago in Germany), put some ice cubes. Enjoy!\n\n\n\n(`_|_`)Oct 4, 2006(`_|_`)ariya.io(`_|_`)rediscover-your-dessert', 'rediscover-your-dessert'),
(635, 'fish-n-tasty(`_|_`)\nPepes ikan is always tasty. The fish is wrapped in banana leaves (here in Europe, fall back to aluminium foil) and then steamed for some time (see the complete recipe). It is not difficult to prepare, and any fresh fish will do just fine. Delicious!\n\n\n\n\n(`_|_`)Oct 3, 2006(`_|_`)ariya.io(`_|_`)fish-n-tasty', 'fish-n-tasty'),
(636, 'yummy and fresh(`_|_`)\nStill have some vegetables in the fridge? Then prepare gado-gado (something you’d miss it quickly when you’re abroad), vegetable salad served with peanut sauce. It does not follow a strict recipe, so should be very easy. If you are really in hurry, peanut butter may even help. And for the vegetarian version, just leave out the boiled eggs.\n\n\n\n(`_|_`)Oct 3, 2006(`_|_`)ariya.io(`_|_`)yummy-and-fresh', 'yummy-and-fresh'),
(637, 'always yummy(`_|_`)\nSo here is another 80r1n6 c00k1n6: mi goreng spesial pakai tahu+ayam+telur, roughly means fried noodles with tofu, chicken and egg. So easy to prepare you can do it blindfolded \n\n\n\nThis is just like any other mi goreng recipes, except that I tend to add lots of garlic (vampires, if you read this, it is not recommended for you!) so that it smells fantastic, put few grated lemon peels, scramble the egg before frying the noodles, prepare the chicken with extra ginger and use melinjo crackers (instead of prawn ones). The sweet boiled corn perhaps does not belong to it, but since I like it, well there it is…\n\n(`_|_`)Sep 25, 2006(`_|_`)ariya.io(`_|_`)always-yummy', 'always-yummy'),
(638, 'yummy (again)(`_|_`)\nJust to show off my l4m3 c00k1n6 ski11z:\n\n\n\nFor the curious, it’s nasi lemak served with lemon chicken. It may look ugly, but it is very tasty \n\nAnd happy Ramadan!\n\n(`_|_`)Sep 24, 2006(`_|_`)ariya.io(`_|_`)yummy-again', 'yummy-again'),
(639, 'New LyX on the block(`_|_`)\nLyX 1.4.3 has been released. This is the third in 1.4 series and contains some bug fixes. I’ve been using 1.3 for some time but recently decided to jump to 1.4.\n\nOne of the interesting LyX 1.4’s new features is change tracking. This is very helpful if you collaborate with other people. You can easily merge (accept or reject) the changes. Deleted texts are marked in red, modified texts are in blue. For each change, who makes it and when it is made are also recorded:\n\n\n\nFor SUSE users, I found that the easiest way to install it is by using Smart, just follow this easy-to-follow step-by-step instructions if you don’t have Smart yet. From there, you just need to pick up lyx 1.4.3 from Guru’s RPM channel, available since yesterday. Couldn’t be easier.\n\nIf you compile from source and you are on AMD 64-bit processor, you may face a configure error. After fiddling around for hours, I found out that the solution is quite simple (and very obvious): run configure like this\n\n./configure --with-qt-libraries=/usr/lib/qt3/lib64 \n--with-qt-includes=/usr/lib/qt3/include --with-frontend=qt \n\nAlternatively you can try the CMake-based build system (yes, it’s CMake!). Use directory development/cmake/ in the source tree as the argument to cmake.\n\nStill stuck with Windows? Get the LyX installer. As I type this, version 1.4.3 is not available yet (hopefully soon, the latest is still 1.4.2). This installer will – surprisingly – install LyX and when necessary also MikTeX, aspell, ImageMagick and Ghostview. After few easy steps, you’ll have a ready to use LyX system.\n\nUpdate (9/28/2006): LyX 1.4.3 installer for Windows is already available.\n\nSo why are you still there? Grab it while it’s still fresh.\n\n(`_|_`)Sep 23, 2006(`_|_`)ariya.io(`_|_`)new-lyx-on-the-block', 'new-lyx-on-the-block'),
(640, 'Does not exist(`_|_`)\nA philosophy professor walks in to give his class their final. Placing his chair on his desk the professor instructs the class, “Using every applicable thing you’ve learned in this course, prove to me that this chair DOES NOT EXIST.”\n\nSo, pencils are writing and erasers are erasing, students are preparing to embark on novels proving that this chair doesn’t exist, except for one student. He spends thirty seconds writing his answer, then turns his final in to the astonishment of his peers.\n\nTime goes by, and the day comes when all the students get their final grades … and to the amazement of the class, the student who wrote for thirty seconds gets the highest grade in the class.\n\nHis answer to the question: “What chair?“\n\n(always from jokes4all.net)\n\n(`_|_`)Sep 22, 2006(`_|_`)ariya.io(`_|_`)does-not-exist', 'does-not-exist'),
(641, 'My dream mobile phone(`_|_`)\nUpdate: finally I settle with a Motorola w205, a simple mobile phone without any unnecessary gimmicks.\n\nI already have a black RAZR, but I don’t feel that it’s my dream phone. So here is a list of requirements for a mobile phone that someday I would like to own (oh, how old fashioned I am!):\n\n1. No camera. Not a single pixel. I don’t need such a built-in camera. I’m not a photographer anyway. And if I need to take pictures, I still have (and love) my digital camera. In case I forgot to bring my camera while witnessing a beautiful moment, I choose to let this moment lives in my mind.\n\n2. No ring tone. I don’t like customizable ring tones. And I prefer to have my phone just vibrates so that I wouldn’t accidentally shock and annoy somebody else due to an incoming call. For alarm purpose, I still have a cheap radio-synchronized clock (with a very annoying alarm, which is important) at my disposal.\n\n3. No music player. I hardly have time to listen to music from a normal MP3 player, let alone from a mobile phone. If I travel, I prefer to read books. Or to think about anything. If I really really need to have some music, the basic USB-memory player is usually sufficient. My music collection is very limited anyway.\n\n4. No radio. Same reason as above.\n\n5. No Bluetooth. At home, the only device which has Bluetooth support is this RAZR. So what’s the point of having it if I could not exchange anything with any other gadgets?\n\n6. No advanced connectivity, either hardware or software. No WAP, GPRS, UMTS or any other cryptic abbreviations that laymen hardly can understand. Except for trying WAP for the first time (back then in 2001) and just out of curiosity, I never touched it anymore. I have no urgent need to always have latest access to any web sites or my e-mails. I’m not a road warrior.\n\n7. No Java. No games. No entertainment stuff. If I really really need to kill time by playing something, I could still practise e.g. chess in my mind (I’m a very bad player, but you get the idea).\n\n8. No PIM applet. I am not a busy manager. My schedule is very simple and I seldom forget anything important. A simple clock and a normal monthly calendar could still be useful, but not more.\n\n9. No color display, if that reduces both the price and the current consumption.\n\nIn exchange for the above, I’d expect these:\n\n(a) Decent battery, and thus less often to be charged. Ideally even only once a month. In this modern world, we can have lots of different types of chargers. It would be too hassle to even deal with these chargers every now and then.\n\n(b) Usable interface. No endless items in the menu. No flashing but useless animations. No need to tap some buttons hundred times just to start writing an SMS. No automatic default to T9 or some other text prediction system that can’t be turned off.\n\n© Excellent form factor. Not too small and not a large as a brick. Something physically similar to RAZR is not too bad. I prefer clamshell model because I like it and I think it’s more practical to use.\n\n(d) Can be used to place and receive a call \n\nWith this no-music, no-web, no-fancy-stuff, no-singing-and-dancing requirements, I guess I have to go back to an old model. But which one then? What would you recommend?\n\n(`_|_`)Sep 20, 2006(`_|_`)ariya.io(`_|_`)my-dream-mobile-phone', 'my-dream-mobile-phone'),
(642, 'yummy(`_|_`)\n\n\n(`_|_`)Sep 19, 2006(`_|_`)ariya.io(`_|_`)yummy', 'yummy'),
(643, 'Details vs Knowledge(`_|_`)\nNormally we tend to admire those who can spot the small details that others will not even bother to notice. But sometimes it can be a different situation:\n\nA: So to prevent the copy, here I define a copy constructor but I place it in the private section of the class.\n\nB: (after carefully analyzing the implementation line by line) But you don’t implement this copy constructor at all. It’s in your class declaration but I can’t find it in your .cpp file.\n\nA: No need to do that. I don’t want to implement it. I just want\n\nto ensure that it won’t be called because it’s private.\n\nB: (again reading the implementation code) Is there a reason why you won’t implement it?\n\nA: (already slightly upset) No specific reason. You can implement an empty construct for that copy constructor in the .cpp file, if you want.\n\nB: Then you’d better write that empty construct. What’s so difficult about it? It’s better to do that rather than taking the easy way out not to implement the copy constructor.\n\nA: (decides that it is useless to argue) OK.\n\nA ends up being annoyed for the whole day. Not only he wastes his time with this unnecessary hyped drama, he is accused of taking “the easy way out”.\n\nThis case could also possibly explains why some untrained eyes file a compliant because you did optimize part X of the program but simply skipped part Y. The same eyes did not watch you as you spent few sleepless nights with the profiler.\n\n(`_|_`)Sep 19, 2006(`_|_`)ariya.io(`_|_`)details-vs-knowledge', 'details-vs-knowledge'),
(644, 'Underwater effect(`_|_`)\nUpdate: don’t fancy compiling/testing the code? See the short video clip.\n\n\n\nI found one piece of code which I wrote a very long long time ago.\n\nRemember the original Quake? When you submerge, the software renderer performs a simple but interesting effect. The view is somehow warped periodically. It turned out that you just need only few lines of code to achieve such effect. Just see the code if you’re curious.\n\nOf course, looking only at the above screenshot is not enough. You must see it in action.\n\n(`_|_`)Sep 13, 2006(`_|_`)ariya.io(`_|_`)underwater-effect', 'underwater-effect'),
(645, 'Semiobligatory cocktail(`_|_`)\n\n  \n    \n      How to make an ariya\n    \n  \n  \n  \n    \n       Ingredients: 1 part pride 5 parts crazyiness 5 parts beauty\n    \n  \n  \n  \n    \n      Method: Layer ingredientes in a shot glass. Top it off with a sprinkle of fitness and enjoy!\n    \n  \n\n\nPersonality cocktail\n\n(`_|_`)Sep 12, 2006(`_|_`)ariya.io(`_|_`)semiobligatory-cocktail', 'semiobligatory-cocktail'),
(646, 'Negative words and confusions(`_|_`)\nThis could be another example of bad usability.\n\nAn optical attenuator is – without doubt – a useful device in lab works. A variable one is suitable for many practical tasks. One of the variable optical attenuator from a well-known vendor has a front panel like this (I know, this sketch is lame):\n\n\n\nThe seven-segment display shows current attenuation level in dB. It can be changed using the three buttons next to the display (under the label VERNIER).\n\nThe INPUT and OUTPUT ports are very clear, they are where you plug the fiber connectors. The light coming out from the output port has less power (as it is attenuated) compared to when it enters the input port.\n\nThe POWER switch (it’s toggled switch BTW) has a red LED. The meaning of this LED is also quite clear. If it is on, then the device is powered on (which just makes sense).\n\nIt is the DISABLE switch that is quite of a question. This switch has also a red LED attached to it. However the meaning of this LED can’t be deduced easily, or you may need to consult the handbook to confirm your understanding. For example, if we take it that when the LED on the POWER switch is on than the unit is powered, does that also mean that if the LED on the DISABLE switch is on than the unit is disabled? Or is the other way around, an active indicator (like the LED) means that the unit is actually enabled?\n\nAnd what does disabled actually mean? Does it mean that no light is coming out from the OUTPUT port, i.e output is fully blocked? Or does it mean no attenuation takes place (i.e. the output power is the same as the input power?\n\nThis looks simple, but consider that the light might end up in a sensitive (and possibly also expensive) photo detector. Yes, people shall read the handbook first, but such simple matter should be straightforward anyway.\n\n(`_|_`)Sep 10, 2006(`_|_`)ariya.io(`_|_`)negative-words-and-confusions', 'negative-words-and-confusions'),
(647, 'Malware warning(`_|_`)\nIt’s been in the news since one month, but only recently I got that message when using Google:\n\n\n\nIf the API is made open, it will be interesting to integrate this into open-source browser (Konqueror and Firefox) so that the URLs which typed in by the users (not only the URLs given by Google) can be checked for badware as well. Of course, there’s a privacy issue here to be taken seriously.\n\n(`_|_`)Sep 9, 2006(`_|_`)ariya.io(`_|_`)malware-warning', 'malware-warning'),
(648, 'Patient and R6(`_|_`)\nTo spark again my interest on 3-d programming, I decided to buy some games. Since I know a bit about the Quake engine, I wanted then to try something not based on it. And it doesn’t need to be new. I am not a gamer, I just enjoy the technologies behind a game.\n\nSo when I looked around in a consumer electronic shop, I spotted Raven Shield, the third installment of Rainbow Six, that is using the Unreal engine. It was sold at a very cheap price. Looks perfect. Ghost Recon was also available at a special discount, but then I thought two might be too many. So I happily grabbed Raven Shield, went home and gave it a try. I found that it is very similar indeed to Counter-Strike, so no difficulty so far. The characters are also familiar, since for quite some time ago I finished almost all Tom Clancy’s novels.\n\nA few days later, while shopping in a big supermarket, I stumbled to a corner where old games were offered. The price was even more unbelievable, half of what I paid for Raven Shield. I doubt that it can even cover the CD and packaging cost. So I searched for something interesting and finally got Vietcong and Splinter Cell. Just before I left, (to my surprise) a box which looked very familiar caught my attention. It is nothing but that Raven Shield! So, if I can wait a few days, I’d get it cheaper. What a coincidence.\n\nBut it did not stop there. Last week when I searched for some reading, a game magazine looked quite interesting to me. I wanted to buy it until I realized that this magazine includes a full version of Raven Shield and Ghost Recon! These are exactly what I wanted the week before. It took couple of minutes until I could decide not to buy that magazine. I somehow believe that in few weeks, there will be another magazine which includes only Ghost Recon.\n\nAfter all, perhaps all I need is just a magazine subscription.\n\n(`_|_`)Sep 4, 2006(`_|_`)ariya.io(`_|_`)patient-and-r6', 'patient-and-r6'),
(649, 'More on the effect of language immersions(`_|_`)\nIf you learn enough German but then need to write or speak in English, you may often be tempted to use the following words (at least, in my case):\n\ntrainer. It looks like a perfect English word, except that it will confuse people. What is usually meant is actually coach.\n\nmother language, because the German word is die Müttersprache die Muttersprache, but it should be either native language or mother tongue.\n\nI read a roman, and yet difficult to catch because Roman is likely something or someone from Rome. It should be then a novel.\n\nmake a picture while the word make here should be take instead.\n\n(`_|_`)Sep 3, 2006(`_|_`)ariya.io(`_|_`)more-on-the-effect-of-language-immersions', 'more-on-the-effect-of-language-immersions'),
(650, 'Trick film(`_|_`)\nFor those who don’t know German, maybe you can still guess what Ellen meant in her last blog entry. Yes, it’s simply cartoon. I reckon it’s just a literal translation from the German word der Zeichentrickfilm (or der Trickfilm). Interesting, isn’t it?\n\n(`_|_`)Sep 2, 2006(`_|_`)ariya.io(`_|_`)trick-film', 'trick-film'),
(651, 'Be who you are(`_|_`)\nBe who you are and say what you feel, because those who mind don’t matter and those who matter don’t mind.\n\n— Theodor Seuss Geisel\n\n(`_|_`)Aug 24, 2006(`_|_`)ariya.io(`_|_`)be-who-you-are', 'be-who-you-are'),
(652, 'Turbo comeback(`_|_`)\nI was late to realize that the legendary Turbo products will be back in 13 days. So far Turbo Delphi, Turbo C++, Turbo Delphi .NET and Turbo C# will be offered, with the EXP edition that can be downloaded and used for free. Although this is surely interesting, especially for the hobbyists, I reckon many would be very happy if the Linux version is also available (either “pure” or through Wine). Even better when Borland/Devco can as well decide to create Turbo Python or Turbo Ruby \n\nIf you’re feeling nostalgic and can’t wait, even today you can already perfectly run the free downloadable  Turbo C++ 1.01 in a Dosbox session (try it in fullscreen!). Of course this version is considered ancient, but it works well and it is still useful to quickly try new stuff (or cross-compile for DOS).\n\nBTW, that Delphi Oktoberfest video is quite original. Try not to read the subtitle \n\n(`_|_`)Aug 22, 2006(`_|_`)ariya.io(`_|_`)turbo-comeback', 'turbo-comeback'),
(653, 'Dirgahayu(`_|_`)\nAugust 17th is Indonesia’s independence day.\n\n(`_|_`)Aug 16, 2006(`_|_`)ariya.io(`_|_`)dirgahayu-3', 'dirgahayu-3'),
(654, 'Stress testing(`_|_`)\nRecently I got WordPerfect 7 suite from ebay (which apparently can only be installed in Windows 95, but I don’t really bother to install it) which comes with over 5000 clip-arts in WordPerfect Graphics (WPG) format. The total size is over 200 MB. This is a ideal test for libwpg and its tools (wpg2svg and wpg2odg). So far, the conversion tools do not crash handling all of them. I let it run also under Valgrind, and it is still running as I write this…\n\nBTW, thanks to klik technology, the easiest way to check libwpg-based WPG support in Inkscape (what I wrote before) is by klik://inkscape-latest. Details can be found in http://inkscape-latest.klik.atekon.de. A very convenient way to check those old WPG collections.\n\n\n\nMeanwhile wpg2odg starts to reach the same support level as wpg2svg, except where some complex gradients which can’t be handled properly in OpenDocument Graphics format. It does not matter, as such uses of gradients are very rare anyway (from what I observed on those clip-art files).\n\nCompare what OpenOffice.org shows below against what Inkscape renders (ignore the different proportion as I resized the whole picture in OpenOffice.org already). I really hope that future version of OpenOffice.org supports anti-aliased painting.\n\n\n\nBack to those 5000 clip-arts. Now I have thousands of SVG and ODG files as well as a very long Valgrind log to analyze…\n\n(`_|_`)Aug 16, 2006(`_|_`)ariya.io(`_|_`)stress-testing', 'stress-testing'),
(655, 'no-install calculator(`_|_`)\nWant to try another type of desktop calculator? Just klik://speedcrunch.\n\nI just tried it on SUSE 10.1 and it works flawlessly. It is also reported to work on Kubuntu, Ubuntu and Kanotix. If you do not have klik yet, it’s very easy to prepare. For other details, check also http://speedcrunch.klik.atekon.de.\n\nHappy no-installing.\n\n(`_|_`)Aug 12, 2006(`_|_`)ariya.io(`_|_`)no-install-calculator', 'no-install-calculator'),
(656, 'Compact hooks(`_|_`)\nIn the old times, when a couple of KB can still be quite expensive, you have to play some tricks even with the OS services.\n\n(`_|_`)Aug 10, 2006(`_|_`)ariya.io(`_|_`)compact-hooks', 'compact-hooks'),
(657, 'juste avant toi(`_|_`)\nJust one verse of Juste Avant Toi and you can’t mistake it. I wouldn’t be surprised if this latest single from Anggun will be a hit. The video is also good, apparently shot in Indonesia.\n\nThe English version is I’ll Be Alright, but somehow Juste Avant Toi feels better.\n\n(`_|_`)Aug 8, 2006(`_|_`)ariya.io(`_|_`)juste-avant-toi', 'juste-avant-toi'),
(658, 'Swift: KDE trace on Win32(`_|_`)\nThe next KDE 4 is expected to be available also for Windows. But even now we can see already a trace of KDE technologies on this platform: Swift the web browser. It’s based on Webkit, which is based on KDE’s very own KHTML and KJS.\n\nThe alpha release itself is not ready yet for prime time. It has bugs and rough edges and many stuff necessary for modern web browsing are not yet fully functional. But it’s indeed a start.\n\nLike its name, it’s simply very fast.\n\n\n\n(`_|_`)Aug 7, 2006(`_|_`)ariya.io(`_|_`)swift-kde-trace-on-win32', 'swift-kde-trace-on-win32'),
(659, 'Winter, Bomber, Shogun, Tai-Pan(`_|_`)\nWinter is about seemingly complex conflicts around a family drama. With the background of Germany, in particular Berlin, in the first 50 years of the last century, the two central characters Paul and Peter Winter took a different route for their lives and yet they must once a while cross their paths, the last being the most tragic one. The story also involved many of their relatives, with quite some twists, intrigues and entanglements.\n\nAll in all, it’s just dark but fascinating, involves all things about love, hate, horror, pain and suffer. What I like most is that the characters are not simply “black” or “white”, almost everybody is portrayed as “grey”. The details are amazing, as with typical Len Deighton’s novels. It’s hard to put, it’s unforgettable and simply worth to read.\n\nBomber is, to put it mildly, Len Deighton’s narration of Murphy’s Law. A large RAF raid carefully planned to bomb Krefeld in the Ruhr area, mistakenly placed almost every single bomb in a (fictionalised) small country city named Altgarten. In this damned event in the last day (which was, 31st [sic]) of June 1943, both sides took big casualties. There is no single main characters, with lots of Britons and Germans both affected the main story.\n\nAgain everything is rich and super detailed, from the price of one RAF’s Lancaster to the operation of the German radar array. The storyline is pretty much linear albeit with many (but relevant) flashback. In the beginning perhaps it feels rather slow, but up to the vivid minutes in the dogfighting, it is just awesome. Don’t expect a happy end, though.\n\nShogun, set in Japan around 400 years ago, is the first of James Clavell’s Asian Saga. Blackthorne and the crew of Erasmus had to land in Japan and soon he was trapped in the conflict between two great daimyos Toranaga and Ishido. Blackthorne supported with Toranaga. He adopted Japanese culture and life style and was quick to learn the language. He was later known as his Japanese name Anjin and (quite predictably) he felt in love with a Japanese woman. There are surprises but the story is indeed touching.\n\nThe characters are strong and living. Obviously here Blackthorne is depicted as someone who is willing to see the new strange culture as the Japanese see it, not from the view of a westerner. It is fascinating to see the his transformation from “the barbarian”, a meat eater who seldom took a bath and did not appreciate cleanliness to someone who later on knew well and lived the style of a Japanese. Not Musashi, but as amazing as it could be.\n\nFast forward two and a half centuries: Tai-Pan. This second part is about Dirk Struan, a Scotsman which lead the Noble House during the years Hong Kong for the first time became a colony of England. He’s smart but ruthless, seem to have a full bag of tricks in order to save his life and protect those he cared. He manipulated almost every persons in the book, most critically Tyler Brock, his number one competitor and enemy.\n\nJust like in Shogun (one can see Clavell’s pattern here), Tai-Pan’s Dirk Struan moved away from a filthy barbarian and respected and enjoyed the local customs. He had a Chinese mistress which taught him many peculiar aspects of Chinese’s way of life. Dirk Struan’s life story is simply impressive. Page turner, without doubt. And although this book took many hours of my sleeping time, by the last page, I really hate that it must end.\n\n \n\nEpilog: still, many other novels from Len Deighton and James Clavell are still in my stack.\n\n(`_|_`)Aug 6, 2006(`_|_`)ariya.io(`_|_`)winter-bomber-shogun-tai-pan', 'winter-bomber-shogun-tai-pan'),
(660, 'Creativity(`_|_`)\n…is having fun with the (mime magic?) configuration.\n\n(`_|_`)Aug 2, 2006(`_|_`)ariya.io(`_|_`)creativity', 'creativity'),
(661, 'Inkscape WPG(`_|_`)\nTed Gould implements libwpg-based WPG extension for Inkscape. So it’s likely that the next 0.45 release can open WPG files directly. Very cool.\n\n\n\n(`_|_`)Aug 1, 2006(`_|_`)ariya.io(`_|_`)inkscape-wpg', 'inkscape-wpg'),
(662, 'English lesson(`_|_`)\nTeacher: Susie, make a sentence starting with the letter I.\n\nSusie: “I is …“\n\nTeacher: “No, no, no, don’t say I is, you say I am.\n\nSusie: OK, “I am the ninth letter of the alphabet.”\n\n(from jokes4all.net)\n\n(`_|_`)Jul 31, 2006(`_|_`)ariya.io(`_|_`)english-lesson', 'english-lesson'),
(663, 'wpg2odg, now with colors(`_|_`)\nAs I wrote before, finally I manage to correctly handle the stroke and fill in wpg2odg. The result can be witnessed in the following screenshot:\n\n\n\nThe two landscape pictures opened inside OpenOffice.org are in OpenDocument Graphics (ODG) format, converted from the corresponding WPGs (which are shown in Corel Presentation on the left side).\n\nThere are still bugs on some corner cases. When I clean this up, then I’ll commit everything so that it’s ready for public testing.\n\n(`_|_`)Jul 31, 2006(`_|_`)ariya.io(`_|_`)wpg2odg-now-with-colors', 'wpg2odg-now-with-colors'),
(664, 'The ultimate poll(`_|_`)\nThis pool poll at kde-look is very hilarious! As I write this, the result (from the most voted one) is like this:\n\n\nThe X11 Files\nDesperate Hackers\nLinux and the City\nThe 404 (not found)\n24⁄7 (and still running)\nThe Torvalds (reality soap)\nEmergency Root\nThe L Word (the one that really matters)\n6 Files Under\nScripts (Newbies learning shell script)\n\n\nInteresting suggestions from the comments are:\n\n\nEverybody Loves (Eric S.) Raymond\nGeek’s Anatomy\n\n\nSo, cast your vote!\n\n(`_|_`)Jul 28, 2006(`_|_`)ariya.io(`_|_`)the-ultimate-poll', 'the-ultimate-poll'),
(665, 'Jambi and Java(`_|_`)\nJambi is the next Qt technology for integrating Qt and Java. When I saw the name for the first time, I couldn’t stop wondering. Why is it Jambi? For those who do not know yet, it’s also the name of a province in Indonesia, but that province is in Sumatra, not Java.\n\nThere are still good places in Java which may make a good name (Jakarta is already taken by Apache), for example Jepara, Jogya (old spelling), Jombang, Jember and perhaps couple of more that I couldn’t remember.\n\nAt least, it’s not Jampi \n\n(`_|_`)Jul 28, 2006(`_|_`)ariya.io(`_|_`)jambi-and-java', 'jambi-and-java'),
(666, 'wpg2odg, wpg viewer, vs microsoft(`_|_`)\nI hope I don’t bore the readers with another Whiskey-Papa-Golf goodies.\n\nSo far, at least I make some steady progress with the wpg2odg. Yes, this is a command-line tool which will convert WordPerfect Graphics into OpenDocument Graphics. From perfection to openness, so to speak. The corresponding UNO service (for seamless import from within OpenOffice.org) is planned, but I can’t say when I could finish it.\n\nAs style handling in ODG is more complicated than SVG, my work with respect to stroke and fill properties of the objects isn’t very fast. However, at least the outlines/paths are already imported properly. Shown in the screenshot below is OpenOffice.org opening eiffel.odg, which is the result of running “wpg2odg eiffel.wpg eiffel.odg”. Compare it to the rendering in Corel Presentation and Inkscape as in my previous blog entry. So, it’s like Eiffel in wireframe mode.\n\n\n\nOf course, it’s rather boring. But given couple of more days, I hope all the wonderful colors will be there.\n\nSince libwpg is designed to be portable, I checked its status in non-Linux environment. So far I have tried to compile it on Win32 (not necessarily as dynamic library, lack of knowledge from my side) and it works well. At least with Microsoft, Borland, and GCC (Mingw) compilers. I am going to give it a try with Digital Mars and OpenWatcom later on, but I don’t foresee any serious problem with the code.\n\nI used the chance also to verify Perfectspot, another toy of mine which uses libwpg to show WPG files. So basically it’s a stand-alone WPG viewer. I’ll perhaps release it when it’s fully polished, not sure yet whether there is a demand for such tool. Perfectspot is Qt4-based and using Arthur to render the graphics onto the screen. Screenshot can be seen below. The beautiful Earth is drawn by Marcelo Staudt (available in from Open Clip Art library). I just imported his SVG file into Corel Presentation X3 and then save it as WPG. Perfectspot opens and displays the WPG file just fine. Note how smooth is Perfectspot’s rendering due to the antialiasing feature in Qt4, compared to that of Presentation’s.\n\n\n\nSince this blog got anothers hits from someone at microsoft.com with respect to WPG stuff, I decided to find out how good is the support for WPG in Microsoft Office. I inserted my favorite windmill picture (see the entry on gradient support) in PowerPoint 2002 and this is what I got:\n\n\n\nSeems that the importer and/or PowerPoint has problem with compound polygons or grouped objects. Look at the blade in the middle (which consists of some sub paths), it should be transparent just like the other blades. Compare it to what our wonderful Karbon14 renders:\n\n\n\nAlso notice the lack of antialiasing in PowerPoint. Strangely enough, this is only for imported pictures. When I clicked and converted the inserted picture into Office drawing, then it was smoothly painted.\n\nAlas, I saw another problem with the gradients. Instead of creating polygon with gradient fill, the import filter of PowerPoint splits the polygon into smaller polygon and fills it with solid color, as can be seen below (I select couple of those polygons to show that they are many many small objects indeed). You can quickly spot it if your eyes have native Sobel filter \n\n\n\nIs it only the case with Microsoft Office 2002? To verify it, I gave Office 2007 Beta a try. Despite its brand new user interface, it is just the same case: one blade is not transparent and gradient is converted to color bands:\n\n\n\nConclusion: when I am finally finished with all this endeavour, it is likely that applications like OpenOffice.org, Karbon14, and Inkscape can handle WPG files better than Microsoft Office. Or should we ask Microsoft to just use libwpg?\n\n(`_|_`)Jul 28, 2006(`_|_`)ariya.io(`_|_`)wpg2odg-wpg-viewer-vs-microsoft', 'wpg2odg-wpg-viewer-vs-microsoft'),
(667, 'Eiffel in perfection(`_|_`)\nAfter few failed attempts, finally I managed to implement full support of the so called compound polygon for libwpg (see also the previous progress). This is WordPerfect Graphics’ term for “grouped objects”. Without proper compound polygon support, often some objects are shifted, i.e. not placed in correct position due to the wrong transformation.\n\nAs always, the obligatory click-to-enlarge screenshot follows. And as usual, Corel Presentation is on the left side, opening a picture from the clip-art. On the right side, Inkscape (before I showed only Karbon14) is showing the converted SVG.\n\n\n\nComing soon: from WPG to ODG. Yes, that’s OpenDocument Graphics…\n\n(`_|_`)Jul 25, 2006(`_|_`)ariya.io(`_|_`)eiffel-in-perfection', 'eiffel-in-perfection'),
(668, 'q.o.t.n(`_|_`)\n the good old fanless 486 ……  I am a fan of it!  you’re really old fashion !  but I also really love that chap, always works like charm  and beyond it was a play on words  \n\n(`_|_`)Jul 25, 2006(`_|_`)ariya.io(`_|_`)q-o-t-n', 'q-o-t-n'),
(669, 'Blutorange(`_|_`)\nHelp! I can’t stop eating this chocolate…\n\n\n\n(`_|_`)Jul 16, 2006(`_|_`)ariya.io(`_|_`)blutorange', 'blutorange'),
(670, 'Beauty is in the smoothness of the colors(`_|_`)\nIn the recent days (see also the last progress), I have implemented support for two important things for libwpg: object transformation and gradient.\n\nObject transformation is necessary to have rotated or scaled objects. And most important is for translated objects. In Corel Presentations, when you copy an object and move the copy, the two still shares the same data but have different transformation matrix. Thus, in order to have all objects in proper location, transformation support is necessary.\n\nAnother interesting bit is gradient fill. This presents some challenge as the documentation does not say anything except the data structure, and the gradient concept in WPG does not actually fit into SVG model. After wasting many sheets of paper and scribbling lots of (mostly wrong) equations, I found the solution which may match WPG’s gradient with SVG. So far it works with linear gradient.\n\nIn the screenshot below (click for larger version), you can see the perfect conversion of the gradients. Left side: WordPerfect Office (inside emulator) shows windmill.wpg. Right side: Karbon14 opens windmill.svg, which is windmill.wpg converted to SVG using libwpg’s wpg2svg.\n\n\n\nNote 1: there are still rendering problem as I have not yet coded proper evenodd fill rule with grouped polygons.\n\nNote 2: Karbon here is just for illustration purpose. Inkscape (or other vector drawing programs which support SVG) works also flawlessly.\n\n(`_|_`)Jul 9, 2006(`_|_`)ariya.io(`_|_`)beauty-is-in-the-smoothness-of-the-colors', 'beauty-is-in-the-smoothness-of-the-colors'),
(671, 'Look ma, no extension!(`_|_`)\nUnlike Firefox which needs an extension (as mentioned by ThomasZ just now), KDE’s Konqueror users can happily and easily view OpenDocument files thanks to the integration between KOffice and the rest of KDE. A simple click on the ODF file is all that is needed.\n\n\n\nLeft side: Browse the document folder with Konqueror, and the click on the file.\n\nRight side: OO.o Calc is used to create the test file.\n\n(`_|_`)Jul 8, 2006(`_|_`)ariya.io(`_|_`)look-ma-no-extension', 'look-ma-no-extension'),
(672, 'Frequence Trois(`_|_`)\nLately I was asked about my favorite Internet radio. Well, without doubt it’s definitely Frequence3. I’m using it already for years and it really pleases me!\n\n(`_|_`)Jul 7, 2006(`_|_`)ariya.io(`_|_`)frequence-trois', 'frequence-trois'),
(673, 'Microsoft and WordPerfect(`_|_`)\nMicrosoft trying to improve support for WordPerfect graphics? (just like what I’m doing now for libwpg):\n\nReferring Link: http://www.google.com/search?hl=en&lr;=&q;=sample wpg files\n\n\nLooking at that log, at least their Google search had landed in this blog \n\n(`_|_`)Jul 6, 2006(`_|_`)ariya.io(`_|_`)microsoft-and-wordperfect', 'microsoft-and-wordperfect'),
(674, 'Talent vs patience(`_|_`)\nIf I have ever made any valuable discoveries, it has been owing more to patient attention, than to any other talent.\n\n— Isaac Newton\n\n(`_|_`)Jun 30, 2006(`_|_`)ariya.io(`_|_`)talent-vs-patience', 'talent-vs-patience');
INSERT INTO `ariyaio` (`id`, `content`, `url`) VALUES
(675, 'Summer of surprise?(`_|_`)\n\n\nThanks, Google!\n\n(`_|_`)Jun 30, 2006(`_|_`)ariya.io(`_|_`)summer-of-surprise', 'summer-of-surprise'),
(676, 'Courage is all that matters(`_|_`)\nA CEO throwing a party takes his executives on a tour of his opulent mansion. In the back of the property, the CEO has the largest swimming pool any of them has ever seen. The huge pool, however, is filled with hungry alligators.\n\nThe CEO says to his executives “I think an executive should be measured by courage. Courage is what made me CEO. So this is my challenge to each of you: if anyone has enough courage to dive into the pool, swim through those alligators, and make it to the other side, I will give that person anything they desire. My job, my money, my house, anything!”\n\nEveryone laughs at the outrageous offer and proceeds to follow the CEO on the tour of the estate.\n\nSuddenly, they hear a loud splash. Everyone turns around and sees the CFO (Chief Financial Officer) in the pool, swimming for his life. He dodges the alligators left and right and makes it to the edge of the pool with seconds to spare. He pulls himself out just as a huge alligator snaps at his shoes.\n\nThe flabbergasted CEO approaches the CFO and says, “You are amazing. I’ve never seen anything like it in my life. You are brave beyond measure and anything I own is yours. Tell me what I can do for you.”\n\nThe CFO, panting for breath, looks up and says, “You can tell me who the hell pushed me in the pool!!”\n\n(from jokes4all.net)\n\n(`_|_`)Jun 29, 2006(`_|_`)ariya.io(`_|_`)courage-is-all-that-matters', 'courage-is-all-that-matters'),
(677, 'The Office test drive(`_|_`)\nMicrosoft offers a free online test drive of its upcoming Microsoft Office 2007 (but seems you can only use Internet Explorer).\n\nOpenOffice.org offers similar test drive. It’s not only a test drive, as if you enjoy the test drive, you can keep the car. And without any other extra cost.\n\nOnline test drive is of course not a new idea. You can try – at no charge – online test drive of KOffice. You can also, when you don’t have fast Internet connection, try it\n\noffline. No installation is necessary, really no hassle. No harm will be done to your computer. And no ActiveX. You can even test drive it as long as you want, as if it is yours.\n\n(`_|_`)Jun 28, 2006(`_|_`)ariya.io(`_|_`)the-office-test-drive', 'the-office-test-drive'),
(678, 'Statistics(`_|_`)\nStatistically, when Germany hosts FIFA World Cup, it would win the trophy.\n\n(`_|_`)Jun 27, 2006(`_|_`)ariya.io(`_|_`)statistics', 'statistics'),
(679, 'Horizontal limit(`_|_`)\nSimilar problem, albeit in different direction.\n\n\n\n(`_|_`)Jun 18, 2006(`_|_`)ariya.io(`_|_`)horizontal-limit', 'horizontal-limit'),
(680, 'Curvey landscape(`_|_`)\nDecrypting Bezier curve in WordPerfect Graphics (WPG), for the libwpg project, turned out to be not so easy. First of all, the documentation is rather very brief. The curve is specified in some triplets, where each triplet consist of initial control point, anchor point and terminal control point. This hardly tells anything useful at all. In fact, first I thought this is about quadratic Bezier curve, which was of course wrong, as it is cubic Bezier instead.\n\nThe trick was finally quite simple, I should have though about it before. I just need to match each of those three points with the actual nodes and control points, this I got from within Corel Presentation by checking the cursor position when hovering over the corresponding points.\n\nAfter knowing the meaning of the triplet points, it is quite easy to adjust the WPG-to-SVG conversion tool. As the proof, shown here the screenshot of two wonderful landscape drawings. On the left side is the WPGs inside WordPerfect Office, on the right side is the converted SVGs shown in Karbon. Quite a perfect conversion so far.\n\n\n\n(`_|_`)Jun 10, 2006(`_|_`)ariya.io(`_|_`)curvey-landscape', 'curvey-landscape'),
(681, 'Emulator for filter development(`_|_`)\nMy hacking portfolio so far involves developing over a half dozen conversion filters for KOffice. It’s quite obvious that filter coding is not always fun. Sometimes the file format documentation does not exists at all, often it is also wrong. To certain point, it would bring you to reverse-engineering and trial-and-error steps.\n\nThe easiest way is of course to have an application that creates the document natively. If you have any doubt, you can always use it to create or modify the file in question. The problem is most of time these wonderful applications run only under non-Unix OS. Here where emulator solves the problem.\n\nWhat I used nowadays is QEMU. I’m sure you can as well use VMWare, especially since they now have the free VMWare Player, but when I started some time ago the Player did not surface yet. Pre-QEMU, I had to go through the difficulties of using Wine.\n\nMy latest endeavor is libwpg, a library which reads WPG (WordPerfect Graphics). It’s a vector graphics format (think SVG). WPG files can be created natively using Corel WordPerfect Office (more precisely, with its Presentation application). Here are the steps that I do, assuming I have QEMU installed and ready to use.\n\nFirst, create a disk image to be use as the “virtual disk”. Something like this:\n\nqemu-img create -f qcow vdisk.qcow 500M\n\nand I’d have a half GB of virtual disk. Do not worry that it would consume all the precious disk space. Using the qcow format, the disk grows automatically when necessary. In fact, right after creating it, the size is only 2 KB. Later on when something is installed there, then it will grow itself.\n\nNow since WordPerfect Office needs a Microsoft Windows, we need to install it on that fresh disk. The trick here is to choose an older version of WordPerfect Office (because WPG format is fairly backward and forward compatible) and an ancient version of Microsoft Windows. Both cost quite cheap on ebay. For example, I settled with Windows NT 4.0 SP6 and WordPerfect Office 10 as the guest operating-system and guest application. Bonus, that half GB will be more enough for these two.\n\nSo inserts the install CD and run:\n\nqemu -hda vdisk.qcow -cdrom /dev/cdrom -boot d\n\nthat will boot our virtual machine from the CD-ROM, thus allowing the installation of the guest operating system. When finished, continue with the guest application. Even without the accelerator module kqemu, everything should run pretty fast on a quite modern machine.\n\nSo now that I have WordPerfect Office running on that poor little virtual machine, the next step is to create, open and modify WPG files. The big problem is of course that I have to be able to access it also from my libwpg environment. QEMU’s virtual FAT feature nicely solves that. For example, by running it like this:\n\nqemu -hda vdisk.qcow -fda fat:floppy:rw:/home/ariya/vfloppy\n\nthen inside the virtualized machine, I’d have access to directory /home/ariya/vfloppy (on the host machine) as if it is a floppy disk (of the guest machine). Beautiful, isn’t it?\n\nIn old version of QEMU, I have to use the network by either setting up SMB or some file server. This often did not work smoothly. But the above virtual FAT is both painless and flawless.\n\nThe obligatory screenshot below – as usual, click to enlarge – shows a simple WPG file opened in Corel WordPerfect Office (its native application) running inside QEMU’ed machine and an SVG file converted from that WPG file opened in Karbon:\n\n\n\nNow back to coding.\n\n(`_|_`)Jun 6, 2006(`_|_`)ariya.io(`_|_`)emulator-for-filter-development', 'emulator-for-filter-development'),
(682, 'Profiling made fun(`_|_`)\nOne of the loudest complaint directed to KSpread is its inability to cope with large file. Worse, if you try to open large Microsoft Excel file with it, it just hangs there for minutes. Often it also consumes all your memory without mercy.\n\nThe solution which I introduced for the KOffice 1.5 was to create directly OpenDocument Spreadsheet file through David’s excellent  KoXmlWriter, thereby bypassing\n\nQDom all together. As you might probably know already, QDom is very inefficient to hold a large XML document. Writing XML directly avoids this QDom’s dramatic situation.\n\nThe filter is thus improved. But still the Excel import filter is slower than it should be. For the fresh-from-oven KOffice 1.5.1, I included so many little improvements that increase the speed of conversion and reduce the memory usage.\n\nYou can also test this yourself by running KoConverter, the underrated conversion tool built into each KOffice:\n\nkoconverter report.xls report.ods\n\nThat command above will convert report.xls (i.e. your Excel file) to OpenDocument Spreadsheet and save the result to into report.ods. Of course, our Excel filter is still very simple (read: it sucks), but the above trick works for simple Excel documents (and faster than launching OpenOffice.org).\n\nTake for example the test file in bug 85372 (folks, that why it’s important to file a bug report!), about 1.4 MB in size. It’s hopeless to run koconverter from KOffice 1.4 on this file. You can try it but don’t blame me if your computer burns.\n\nWith KOffice 1.5, the hope is there. You can have that file converted to OpenDocument in a reasonable time. In my test system (a fairly modern machine), it takes about 13 seconds.\n\nBut it could be improved indeed. Install KOffice 1.5.1 and try it again. Now it would only take less than 2 seconds. Nice, isn’t it?\n\nGraphically, comparing the speed (shorter is better) is like this:\n\n\n  \n    \n      Bug 85372 (1393 KB)\n    \n    \n    \n      1.5.0\n    \n    \n    \n      \n    \n  \n  \n  \n    \n      1.5.1\n    \n    \n    \n      \n    \n  \n\n\nwhere the blue bar is for KOffice 1.5.1 and red is for KOffice 1.5.0.\n\nOf course I didn’t only test with that particular file but with other large documents as well. Take Flows.xls, which I found via random googling and has 6 MB size. Conversion takes 28 seconds with 1.5.0 but only 4 seconds and with 1.5.1:\n\n\n  \n    \n      Flow.xls (6626 KB)\n    \n    \n    \n      1.5.0\n    \n    \n    \n      \n    \n  \n  \n  \n    \n      1.5.1\n    \n    \n    \n      \n    \n  \n\n\n(The fact that KSpread is still slow when loading the resulting ODS files is another issue which hopefully would be addressed in the upcoming KOffice 2.0).\n\nThe key to the boost here is the extensive use of profilers. Right after 1.5 release, I kept myself busy profiling the filter. Armed with Valgrind‘s Massif and cachegrind and also the excellent Sysprof, it was quite practical to find the bottlenecks though often not so easy to find workarounds. Sure, it’s basically a painful and boring job, but if LinuxFormat keeps giving low score to KSpread, then cool shiny Slashdotted hacks won’t matter much here, right?\n\nP.S: if your Excel files still crash KSpread, please please file bug report and attach the offending files.\n\n(`_|_`)May 25, 2006(`_|_`)ariya.io(`_|_`)profiling-made-fun', 'profiling-made-fun'),
(683, 'Vertical limit(`_|_`)\nSomeone please fix the ATI driver graphical installer. Yes, it can be solved using command-line option, but still a dropdown list would do the job better than a gazillion radio buttons.\n\n\n\n(`_|_`)May 25, 2006(`_|_`)ariya.io(`_|_`)vertical-limit', 'vertical-limit'),
(684, 'Try KOffice 1.5 with MCNLive Leuven(`_|_`)\n(Thanks to Anonymous, who gave a notice on my previous post).\n\nDo you want to give KOffice 1.5 a try but don’t fancy installing anything? Then use MCNLive, a Mandrive-based Live CD (can also be used as Live USB). The Leuven edition, released three weeks ago, has all KOffice 1.5 applications.\n\n\n\n(`_|_`)May 15, 2006(`_|_`)ariya.io(`_|_`)try-koffice-1-5-with-mcnlive-leuven', 'try-koffice-1-5-with-mcnlive-leuven'),
(685, 'Try KOffice 1.5 with SLAX(`_|_`)\nSLAX version 5.1.4, which was just released days ago, now has the latest and fresh KOffice 1.5. For those who do not know yet, SLAX is a Slackware-based Live CD. So download and try it if you want to see KOffice 1.5 in action without the need to install anything.\n\nNote that due to space constraint (typical ISO only as large as 200 MB), only KWord, KSpread, and KPresenter are available.\n\n\n\n(`_|_`)May 12, 2006(`_|_`)ariya.io(`_|_`)try-koffice-1-5-with-slax', 'try-koffice-1-5-with-slax'),
(686, 'FLSH GRDN(`_|_`)\nAfter launching Ming, which is Linux-based, expect Motorola to unveil FLSH and GRDN in the near future. These are again such funny names, just like previous Motorola RAZR (my favourite!), ROKR, and SLVR.\n\nBut FLSH GRDN is just simply old fashion. My take: why not sponsoring the potential most-discussed movies? Then an interesting set of names may pop up for recent ones, like\n\n\nMotorola ETHN (and HUNT)\n\nMotorola DVNC, or better (?) RBRT LGDN\n\nMotorola VNDT\n\nMotorola CAPT SPRW\n\n..and so on\n\n\nProbably also for (too late) names like:\n\n\nMotorola MILN FLCN\n\nMotorola DRTH VADR (with special edition IMYR FTHR)\n\nMotorola ANKN SKWL\n\nMotorola PADM AMDL\n\nMotorola OBWN KNBI\n\n\nAny other cool ideas?\n\n(`_|_`)May 11, 2006(`_|_`)ariya.io(`_|_`)flsh-grdn', 'flsh-grdn'),
(687, 'Accelarated OpenGL-based transition effects for KPresenter(`_|_`)\nI don’t think only Krita may get some OpenGL love. So I started to hack together a couple of transition effects for KPresenter, based on OpenGL:\n\n\n\n\n\n\n\n\n\nLater on when I’m finished I’ll prepare a patch set for KOffice 1.5, of course if there is demand for it. Otherwise, just wait for 1.6 or 2.0 then.\n\nSee you tomorrow in LinuxTag !\n\n(`_|_`)May 2, 2006(`_|_`)ariya.io(`_|_`)accelarated-opengl-based-transition-effects-for-kpresenter', 'accelarated-opengl-based-transition-effects-for-kpresenter'),
(688, 'Savin\' me: Part II(`_|_`)\nspoiler warning!\n\nSince the first time I liked Nickelback`s Savin’ me, I was wondering how the video would be. Yesterday for the first time I saw it on MTV (you can find it also in YouTube) and it was very good. That is a music video.\n\nA guy was almost hit by the bus when making a phone call. But he was saved, pulled from the street by someone. Right after that, he started to see countdown numbers on top of everybody’s head. As he experienced soon, this is actually the remaining life’s time. He could notice that (surprisingly) he did not have any numbers floating on his head.\n\nIn the final part of the video clip, this guy saved a woman who wanted to get in to her car but suddenly the car got crushed seconds after. From that point, the woman now started to see the countdown…\n\n(`_|_`)May 1, 2006(`_|_`)ariya.io(`_|_`)savin-me-part-ii', 'savin-me-part-ii'),
(689, 'KOffice in LinuxTag 2006(`_|_`)\nLinuxTag is a free software expo held every year in Germany. This year it will be in Wiesbaden, May 3-6. As usual, KDE will also have a booth, at Hall 9, Booth 938.\n\nI’ll give a talk about KOffice – mostly of course on the fresh KOffice 1.5 as well as some live demo – on Wednesday (May 3), right between Jacqueline’s OpenOffice.org and Kurt’s klik. Check the the summary and drop by if you are interested in.\n\nAny other KOffice developers will be there?\n\n(`_|_`)Apr 25, 2006(`_|_`)ariya.io(`_|_`)koffice-in-linuxtag-2006', 'koffice-in-linuxtag-2006'),
(690, 'Try KOffice 1.5, no-install(`_|_`)\n\n\nIf you have fast Internet connection, you can give the latest KOffice 1.5 a try, without the need to install Linux and/or download any other programs. You can even do it from normal Windows desktop. Just go to CosmoPOD, register (free) and launch your KDE with KOffice 1.5.\n\nThe speed may not be the fastest (e.g. compared to running it locally), but surely enough to check out those brand new features mentioned in KOffice 1.5 Tour.\n\nNote 1: I’m not affiliated with CosmoPOD.\n\nNote 2: “no-install” is a bit incorrect, since you may need NX client. But I hope you get the point.\n\n(`_|_`)Apr 14, 2006(`_|_`)ariya.io(`_|_`)try-koffice-1-5-no-install', 'try-koffice-1-5-no-install'),
(691, 'Why KOffice not using OpenOffice.org\'s converters?(`_|_`)\nEverytime a preview, alpha, beta, and final release of KOffice is announced, this question would arise: OpenOffice.org can handle Microsoft Office files pretty well. Why doesn’t KOffice reuse the code? Especially since default file format KOffice 1.5 is OpenDocument Format (ODF), just like OpenOffice.org 2.\n\nAnswer: the code for OO.o converters is tightly integrated with the rest of OO.o. It will take a lot of effort to pull the relevant part and place it in a library so that KOffice can also use it.\n\nIf somebody is willing to do it, of course we’ll happy to consider it.\n\nThat does not mean that there’s no cooperation. Look at libwpd, a library to read WordPerfect document (or WPD files). OpenOffice.org, Abiword and KOffice are all using this library already to import *.WPD, isn’t it great? In this case, it is easier because previous OpenOffice.org did not have support for WordPerfect import and thus a clean library could be designed with code-sharing objective in mind.\n\nNow, volunteer(s)?\n\n(`_|_`)Apr 12, 2006(`_|_`)ariya.io(`_|_`)why-koffice-not-using-openoffice-orgs-converters', 'why-koffice-not-using-openoffice-orgs-converters'),
(692, 'eotd(`_|_`)\nThere will be a sequel to Duke Nukem Forever.\n\n(eotd = enlightment of the day)\n\n(`_|_`)Apr 11, 2006(`_|_`)ariya.io(`_|_`)eotd', 'eotd'),
(693, 'iPod-wannabe(`_|_`)\nI don’t own an iPod or similar player, my music collection is not large and I prefer to listen to radio. But if I need to kill time with music (e.g. during a trip), then I just use Zaurus. With Opie, it can be quite interesting:\n\n\n\nIt is just the normal Opie Media Player, with the pod skin. No need for iTunes-like or special tool on the desktop side, I just use drag-and-drop within Konqueror.\n\nConsider that the four-way navigation buttons of the Zaurus SL 5500 serve also for the next/previous and increase/decrease volume, this nicely emulates an iPod-like player.\n\nIt can survive up to three hours. This is actually quite astonishing since the battery is already quite old. Even if it’s new, it’s just not up to iPod’s. All songs are in CF card, there is no aggressive buffering, MP3/Ogg decoding is done in software (not special DSP chip). So, not so bad.\n\n(`_|_`)Apr 8, 2006(`_|_`)ariya.io(`_|_`)ipod-wannabe', 'ipod-wannabe'),
(694, 'Z and kioslave(`_|_`)\nRight after upgrading to the latest Opie (I’m using OpenZaurus), it came to my mind to write this tip. Actually, it’s not new and I’m sure many know it already. Just in case you are not aware yet.\n\nTypically people use Qtopia Desktop to sync between the Zaurus and your main machine. I never however managed to make Qtopia Desktop looks good, i.e. using the antialiased font rendering. Beside, it is just much easier to use Kontact (with its Kitchensync) so that your PIM data is integrated with the rest of KDE.\n\nBut how to transfer documents? Well, just use the powerful kioslave of KDE. Since Opie is running an FTP server on port 4242 (forget first the security implications), you just need to type:\n\nftp://root@192.168.129.201:4242/media/cf\n\nin Konqueror, then you will (after got prompted for password and confirmed in the Z side) have access to the Compact Flash card (CF) content. Bookmark this, and you never have to type and memorize that long address again.\n\nSince my digital camera also uses CF, I also don’t need to search for that camera USB cable anymore (one less to care for). Just pull the CF from the camera, plug it into the Z, then copy my pictures conveniently. I still hope Krita runs on Z one day \n\nEven more interesting, you can work directly on that folder. For example, when I use Z to jot some notes and save it as a text file in CF, later on I just dock my Z on the cradle, click on my CF-on-Z bookmark, open the text file with KWrite, type some content, then save it again. No hassle.\n\nThe power of kioslave has been often demonstrated. In this particular use, it allows me to skip the download-edit-upload or sync-edit-sync steps. Nice, isn’t it?\n\n(`_|_`)Apr 7, 2006(`_|_`)ariya.io(`_|_`)z-and-kioslave', 'z-and-kioslave'),
(695, 'SpeedCrunch goes mobile(`_|_`)\nSpeedCrunch is now also available for pdaXrom (PDA distro, among others for Zaurus), compiled by 2or0.\n\n(Via tyrannozaurus)\n\n(`_|_`)Apr 4, 2006(`_|_`)ariya.io(`_|_`)speedcrunch-goes-mobile', 'speedcrunch-goes-mobile'),
(696, 'The Redemption of Mr. Payne(`_|_`)\nCan’t wait for 2007-planned Max Payne? Then keep an eye on Max Payne: Payne & Redemption (see also the interview). The trailer is so far very interesting! \n\n\n\n(`_|_`)Mar 22, 2006(`_|_`)ariya.io(`_|_`)the-redemption-of-mr-payne', 'the-redemption-of-mr-payne'),
(697, 'First Sign of Spring(`_|_`)\n\n\nThis week is going to be a bit sunny…\n\n(`_|_`)Mar 21, 2006(`_|_`)ariya.io(`_|_`)first-sign-of-spring', 'first-sign-of-spring'),
(698, 'K4B(`_|_`)\nThis is the most interesting thing I read today:\n\n\nAre there any plans to include K3B into KDE 4? Would it change to K4B, or maybe a more user-friendly name?\n\n\nSee if we can persuade Sebastian to rename it to K4B \n\n(`_|_`)Mar 20, 2006(`_|_`)ariya.io(`_|_`)k4b', 'k4b'),
(699, 'Resize Pop-up List of A Combo Box(`_|_`)\nYou want to be able to resize the pop-up list of a combo box. Normally, this pop-up list has always the same width as the combo box. However, in certain cases the width of the combo box needs to be fixed. But if the pop-up list does not expand itself, then only part of the items on the list is visible as illustrated here:\n\n\n\nIn this particular situation, the look of the pop-up list will be better if it can be resized independently from the combo box itself.\n\nQComboBox unfortunately does not provide public functions to access its pop-up list. Also, the pop-up list widget itself is not accessible. It is possible to create a subclass of QComboBox and reuse its private members (in header file qcombobox_p.h), but this would have required a quite amount of effort.\n\nBy looking at the source of QComboBox, we find out that the pop-up widget is QComboBoxPrivateContainer. It is also constructed as a child widget of the combo box. Using run-time introspection feature of Qt, it is very easy to find this widget and change its size:\n\nvoid resizeComboBoxPopup(QComboBox* comboBox, int width, int height)\n{\n  if(!comboBox) return;\n  \n  // force the construction of QComboBoxViewContainer\n  comboBox->view();  \n\n  // iterate to find QComboBoxPrivateContainer\n  QWidget* popup = 0;\n  QObjectList objects = comboBox->children();\n  for(int i = 0; i < objects.size(); ++i)\n  {\n      QObject* obj = objects.at(i);\n      if(obj->inherits(\"QComboBoxPrivateContainer\")) \n          popup = qobject_cast<qwidget>(obj);\n  }\n  \n  if(popup)\n    popup->resize(width, height);\n}    \n</qwidget>\n\nOf course, this cheap trick is only a workaround and only works as long as the implementation of QComboBox does not change too much. It can also be considered as a crime to Qt. So, kids, don’t try this at home…\n\n(`_|_`)Mar 15, 2006(`_|_`)ariya.io(`_|_`)resize-pop-up-list-of-a-combo-box', 'resize-pop-up-list-of-a-combo-box'),
(700, 'Numeric Entry with Pop-up Slider(`_|_`)\nAlthough typically I like slider, sometimes it is not practical to use because of space constraint. When a horizontal slider, for example becomes, narrow and narrower, it is difficult to get a fine tune movement.\n\nThe solution that I am still experimenting with is to use a pop-up slider. This is mostly seen in the volume applet, but, hey, let us try it somewhere else:\n\n\n\n\nSo by clicking on the down button (forget about the ugly pixmap), a slider will pop-up and let the user adjust the value by moving the slider handle. The slider will automagically disappear if the user clicks anywhere else, just like typical pop-up menu.\n\nI am not really surprised if usability-wise, this kind of pop-up slider is not usable at all. However, if there is interest, I’ll put the code online (it’s only couple of hundred lines anyway).\n\n(`_|_`)Mar 13, 2006(`_|_`)ariya.io(`_|_`)numeric-entry-with-pop-up-slider', 'numeric-entry-with-pop-up-slider'),
(701, 'Siegfried(`_|_`)\nSiegfried: every minute is just hilarious.\n\n(`_|_`)Mar 13, 2006(`_|_`)ariya.io(`_|_`)siegfried', 'siegfried'),
(702, 'Flying Pig(`_|_`)\nCareful next time you say when pigs fly! At least one was already flying yesterday…\n\n\n\n(Found via accuweather)\n\n(`_|_`)Mar 10, 2006(`_|_`)ariya.io(`_|_`)flying-pig', 'flying-pig'),
(703, 'XGL Live(`_|_`)\nI should have written all my wishes in this blog. Just hours after this, Koroora (Gentoo-based) Live CD for demonstrating XGL is available (thanks for Roman Khimov for pointing it out, thanks also for SlippJigg for mentioning PC LinuxOS).\n\nI quickly downloaded the ISO, burned into a CD, and gave it a try on\n\na GeForce4-armed desktop. It works out of the box. I even showed it to\n\ncouple of friends and they seem all like it so far. Kudos for\n\nthe Koroora team!\n\nNow, I still need to make some more copies…\n\n(`_|_`)Mar 8, 2006(`_|_`)ariya.io(`_|_`)xgl-live', 'xgl-live'),
(704, 'The Glass Experience(`_|_`)\nUsing Slackware-based Looking Glass Live CD, it was very interesting to watch the expression of some guys when I booted a fairly modern NVidia-equipped desktop with it. I even still considered burning some more CDs and give them to people that I know.\n\nNow came XLG XGL and AIGL. Wouldn’t be beautiful if we have a working Live CD which just can be handed to any average Joe Sixpack? I’m not the only one who is looking for it, and I’m sure there are many. Though there is possibility of using Dapper Flight (I still need to give it a try), a simple ready-to-burn-and-boot ISO file would really please me since I can as well point the URL to others.\n\n(`_|_`)Mar 7, 2006(`_|_`)ariya.io(`_|_`)the-glass-experience', 'the-glass-experience'),
(705, 'Commitment, Instinct, and Ability(`_|_`)\nCheck the inspiring insight from Brian Hook on why great products need commitment, instinct, and ability.\n\n(`_|_`)Mar 6, 2006(`_|_`)ariya.io(`_|_`)commitment-instinct-and-ability', 'commitment-instinct-and-ability'),
(706, 'Background and Backing Store(`_|_`)\nWhoever moved from Qt 4.0 to 4.1 typically realized that for some widgets, the background is not what it is supposed to be. In the latest Qt Quarterly article Transparent Backgrounds in Qt 4.1, Andreas Hanssen explained this feature in details. He also elaborated a bit about backing store, also a new thing in Qt 4.1 .\n\nStill related to backing store, Trenton Schulz showed how to create Fading Effects with Qt 4.1.\n\n(`_|_`)Mar 5, 2006(`_|_`)ariya.io(`_|_`)background-and-backing-store', 'background-and-backing-store'),
(707, 'Savin\' Me(`_|_`)\nIs it just me, or listening to the first few seconds of Savin’ Me also reminds you of How You Remind Me (yes, I’m aware of that Someday) ?\n\nIn all cases, I just like it.\n\n(`_|_`)Mar 3, 2006(`_|_`)ariya.io(`_|_`)savin-me', 'savin-me'),
(708, 'Euros vs Features(`_|_`)\nRecently I wanted a mini music centre. I tried to search for what I need, but still could not find the best compromise between the features and the amount of money I have to spend.\n\nFinally there was a special offer from a discount market. I carefully\n\nchecked the flyer to see whether it fulfills my requirement. For example,\n\nsleep mode and remote control are necessary because I just like listening\n\nto radio just when I am about to fall asleep. Auxiliary input is also a\n\nmust since I want to connect it to the DVD player.\n\nSeems everything is fine, so I showed up in the store minutes after\n\nit was opened and bought it.\n\nBecause the price is half of typical music centre found in electronic\n\nshops, I was ready to be surprised if there are some catches.\n\nFortunately, it is all just as good as I imagine. Sub woofer is included,\n\nwhich I did not really need but why not. There are even USB port\n\nand MMC slot, nice to plug-in the portable player or card containing music files.\n\nFew design decisions seem strange to me. The power supply is\n\ninside the sub woofer box, probably to reduce the space in the main unit.\n\nThat means I can’t use the system without sub woofer at all, but that’s not\n\nso bad. Speakers are small, yet the output is loud enough anyway for\n\nmy small apartment. I can’t judge the quality because my ears have\n\nclose to zero sensitivity to tones. As for the FM receiver, I doubt that it\n\ntunes to all stations but there are few good strong stations so I could not\n\ncare more. For playing CD, I must placed it from\n\nthe top which is not so interesting because I put everything in the shelf.\n\nA normal CD tray would have been better. Since I have limited music collection,\n\nthat’s not a big deal at all.\n\nI could say that I’m really happy with it. I would have spent twice\n\nthe amount of money if I want the common mini music centre, which has more\n\nfeatures that what I really need anyway. So why waste more euros.\n\nI wish we had such choice also for mobile phone. Unfortunately, I still can\n\nnot find a phone which fully fits my requirements: no camera at all,\n\nmaximum battery duration, sturdy case, easy-to-use menu, and good reception.\n\nI’m old fashioned, I’d like to use it only to make phone calls, so if possible\n\nI’d like to avoid extra euros, time, distraction, headache because\n\nthe phone has music player, camera, wireless connectivity, browser, and other\n\nextra baggage.\n\nBut I can see here that I’m dreaming. Or maybe I’m just the most\n\nselfish (potential) customer.\n\n(`_|_`)Mar 2, 2006(`_|_`)ariya.io(`_|_`)euros-vs-features', 'euros-vs-features'),
(709, 'Language, Another Take(`_|_`)\nStill about language, I feel that my language skill already starts to deteriorate.\n\nRegarding the issues like KDE vs GNOME (these days, XGL vs AIGL), once\n\nI explained to somebody:\n\n\n“Typically only the clueless ones, who do not contribute anything\n\n– let alone coding – are busy exaggerating the issues, thus fueling the flame\n\nwars”.\n\n“Hey! Just because you are a developer does not mean you can ignore\n\nthe feedback from a Joe User…“\n\n\nwhich surely prompted a big question mark in my head: _did I say that\n\nI hate normal users?_ This guy apparently framed an impression in his brain\n\nthat I did that, a total fallacy which either was entirely his imagination\n\nor possibly because I did not express my opinion clear enough.\n\nIn another occasion, with another guy we faced a circuit which needs\n\nexplanation. After spending few minutes scribbling some diagrams,\n\nthis guy was still confused:\n\n\n“I don’t understand this. The circuit should not behave like this.\n\nI expect it to be like this …bla bla bla “\n\n“Yeah fine, but how it works is not defined by you.”\n\n“Still, this kind of function is not what I need!”\n\n\nWell, even\n\nRDF\n\ncan not change the way hardware works,\n\notherwise your iPod has no button at all. And if it is that easy,\n\nMatthias Ettrich\n\nsurely already gave us focus-follows-mind a long time ago.\n\nForget about techie talk. Often in daily life this situation also\n\narises.\n\nSomebody shouted to me:\n\n\n“Dude, our  does\n\nnot work! It just keeps doing stupid thing like this!”\n\n“OK, let me see….(few minutes later). I see, I think it’s because\n\nbla bla bla… long explanation… ideas for workaround….”\n\n(still shouting)“But that’s not normal! It must not act like\n\nthat!”\n\n\nfollowed by a full lecture why it should not happen at all. Gee,\n\nhe thought that because I was trying to explain the possible culprit in that\n\nparticular madness, I also fully believed that the behavior is justified\n\n(and thus I need to be convinced about the annoyance). Good, except that it was all only in his mind.\n\nOr, in a discussion with guys from many different countries:\n\n\n“I’m not really impressed by my countrymen. There are few who\n\nsuccessfully pushed themselves very hard and later on became decision makers\n\nfor many big companies. But millions others are quite afraid to experience\n\neven just a simple change in their life.”\n\n“Maybe because they don’t need it. Maybe they’re already happy for\n\nwhat they have. Perhaps they don’t like to go abroad.\n\nOr they love simple life…“\n\n“But they deserve better! And we know that they are actually able\n\nto do it…“\n\n\nand so the continued discussion became less interesting to follow.\n\nI never said that his countrymen don’t deserve it, or are not capable\n\nto do such. I merely offered possible causes (OK, it’s stupid analysis but\n\nstill) and all of sudden, it was going on the wrong direction.\n\n/me sucks\n\nPostscript: Man, I started to write like\n\njwz.\n\n(`_|_`)Feb 28, 2006(`_|_`)ariya.io(`_|_`)language-another-take', 'language-another-take'),
(710, 'Codenames(`_|_`)\nCheck this interesting list of codenames of almost all known Microsoft products, from e.g. WfW (Snowball) to Dynamic HTML (Trident).\n\nNow I know why clee named his Windows-2000-pixel-per-pixel-copy style as Asteroid.\n\n(`_|_`)Feb 27, 2006(`_|_`)ariya.io(`_|_`)codenames', 'codenames'),
(711, 'Languages(`_|_`)\nSpeaking of languages, recently I found two interesting sites.\n\nPeribahasa Banjar lists (in alphabetical category) proverbs in Banjar. This is a language spoken in the southern part of Borneo. I do know how many millions people speak this language, but in all cases I am happy that I can still understand it (thought it starts to fade away with time). And proverbs are always interesting.\n\nOn the other hand, Guyonon Suroboyo collects funny (Warning: extremely funny) jokes, of course only if you can understand Suroboyoan, a strikingly marvelous dialect of Javanese (the human language, not that programming one) spoken mostly in West East Java. Pity that the site is not updated anymore. And I reckon that most of the jokes become less funny if they get translated \n\n(`_|_`)Feb 24, 2006(`_|_`)ariya.io(`_|_`)languages', 'languages'),
(712, 'Check traces with WordLeaker(`_|_`)\nMadelman has created WordLeaker, a tool which display hidden information as well as revision logs in Microsoft Word documents. Although seems that it is not compiled in, WordLeaker can also be found in as plug-in in libextractor, a library to extra metadata and similar information from various types of file.\n\nFor me, the interesting thing is because WordLeaker uses POLE , a portable and lightweight C++ library to read Microsoft OLE Compound Document (used also in some KOffice filters), which is one of my dirty hacks.\n\n(`_|_`)Feb 22, 2006(`_|_`)ariya.io(`_|_`)check-traces-with-wordleaker', 'check-traces-with-wordleaker'),
(713, 'How Cold(`_|_`)\n\n\nIt was (of course) a malfunction.\n\n(`_|_`)Feb 20, 2006(`_|_`)ariya.io(`_|_`)how-cold', 'how-cold'),
(714, 'Deutsche Telekom Drama: Part I(`_|_`)\nWarning: this is a terrible rant!\n\nExecutive summary: Suddenly one fine digit is gone from Deutsche Telekom database. This caused a chain of annoying events. In the end, I must pay for the incurred extra cost, and some amount of precious time is definitely lost.\n\nI have been a happy customer of Deutsche Telekom. For convenience, I let DT\n\nuses the debit entries (of my bank) for the telephone bill.\n\nOne time, I received a letter from DT saying that for that month, the bank rejected the request to cover my phone bill. In addition, since I also used the service from other providers (e.g. dial-up Internet etc), I also got some others invoices (with small amount of fine, because the payment is due). This is strange because for more than two years, automatically the bill is paid without problem and I always have enough amount of money to cover the bill.\n\nFrom the call to the bank representative, I was told that there was never error to be found for the transactions. So, I called the hotline service of DT and explained the problem. A man in the call center informed me that if the account has no problem, then I should wait and let the transaction be repeated. Because I’m not a native speaker, I was careful to confirm whether I should do anything about this, the answer was a clear no, just wait.\n\nIn two weeks, another letter came. Bad sign. This means that the problem wasn’t solved. So I called the hotline service again. This time, a woman checked the transaction and found that my account number was not correct. How this could be, I have no idea; but one initial digit was missing (if these digits are about money, I’ll be poor in a second). So, she corrected it and said everything should be fine now. Also, I told her that I got these invoices from other providers and asked whether these can be handled automatically. I wanted to avoid double payment. So carefully I asked again whether I should do anything, the answer was also no, do not worry, we’ll handle everything for you. Sounds good.\n\nAnother week passed by. I checked my balance and found out that DT has already taken some, so it looked good. But, then out of sudden I still received some letters from the service providers saying that I still do not pay the bill for them. Of course I did not pay it. Like I was informed, I believe that it should be handled by DT. Worse, my connection to the providers was blocked, means that in the mean time I could not use their particularly good services anymore.\n\nThe problem was now the bills came also with fine and extra cost for the lawyer. My goodness! I have done nothing wrong at all (who screw the payment for the first time), and then so easily I got letters from this lawyer. No wonder everybody goes to law school.\n\nI made another call. This time, another woman handled it. I explained again the story, and I didn’t forget to ask what I should actually do with those bills from other providers, to which she said that either I should pay it manually by myself or let DT process the payment (though they can’t handle the fines because they do not have the information from these providers). The latter was exactly what I demanded from the second call, and yet it was not carried out.\n\nStill in the third call to the hotline service, I asked whether she could checked what actually did happen which caused all this drama. Apparently, for whatever reason she had no full access to the system. I should call again later on. What a joy.\n\nIn the evening, I made my fourth call to DT hotline service (I started to remember my 10-digit customer id). A woman confirmed that all those extra bills not coming from DT better managed by myself manually, and they can’t do anything about it. I got a moment to ask what has caused the failed payment weeks ago. She didn’t give me anything new, it’s just that the transaction has been rejected by the bank. It’s not their fault and I should consult my bank.\n\nI came to the bank in the next morning and desperately asked for help. A man checked my account and found out that in fact, DT never tried to charge the bill from my account for that particular month. He also spotted the wrong account number in the invoice, this confirmed what the hotline service person (on my second call) noticed. Of course the requested transaction was rejected because the account number was invalid. So, it’s not the fault of the bank at all.\n\nThe madness did not just stop there.\n\nI went to T-Punkt shop in the city. Here I explained again the situation. A woman said that they can’t do anything about that, the best they can offer is only voucher/coupon. I was not interested in that, I wanted to find out how my bank information has been changed without my consent. Obviously, the shop can’t do anything regarding that but she was willing to write a notice to some DT representative about this problem. I left also my mobile number (fortunately – pun intended – my mobile provider is not DT). She said that I can also try to call a number, which is unsurprisingly the hotline service number.\n\nI called again and I was getting crazy. This call did not result in anything new. I was suggested to contact the invoice service department. Good, at least a new number. I made another call, but it was disconnected in the middle. I still repeated; a woman informed me that she can’t answer my question, she does not know how the bank account was unintentionally changed. I was recommended to contact the address which is written in the invoice, it was DT office in Bielefeld.\n\nNow, it’s getting out of control. I was foolish to try calling this office number, my call was simply redirected to (surprise, surprise) the hotline service. For the billion times, I retold again my story and this time the answer was slightly different. I should not use other providers because if I do that, then I have to prepare for this kind of situation, where they have nothing to do with these providers. I gave him the benefit of doubt and took it as a friendly advice. I found what he said is quite true, likely also legally correct, although I personally think that it is not a good thing to say to a customer. That simply scares people away. If a company agrees to process invoices from other providers, but only as as courtesy (they won’t be liable from any mistakes), then better not doing it at all. And I am completely dumb to believe in this. I’m sure some other competitors can do this kind of job better.\n\nAnd what about that stupid and fatal change in my bank account number? Well, it’s just a mistake. What a cool answer. This number is just an id, it is not a result from some scientific calculation. For more than two years, that wonderful number has been in their database and never been changed. Maybe this number is simply not mission-critical enough (it’s not going to send some astronauts to the Mars)?\n\nI went on to explain that I really really wanted to know what has caused this mistake, which costs me all these miserable hours. Some will think that I just exaggerate this. But for me, not knowing the cause of a bug is just scary. In fact, the bug itself might not be solved yet. And, who’s going to pay that lawyers?\n\n(If you have a pocket calculator which sometimes produce wrong last digit for simple operation like addition, are you going to rely on it? Who can ensure that later on the calculator would not falsify the most significant digit and causes you a big loss?)\n\nThis time one digit is gone. What’s next? Where is the corresponding bugzilla, please?\n\nSo finally I was suggested to call fault service department. I did it, but nobody there can do something about this. Obviously this place only deals with problem such as when telephone connection is out of service. They have no customer information, in fact they do not know anything about invoice, let alone my bank account. Then, from there I was suggested to call – which surely everybody could guess already – the hotline service.\n\n(I actually never expect that somebody will explain me the technical things in a hotline service. But at least, I hope, they can point me to someone, some manager, some big boss, or whoever, who knows what actually did happen)\n\nI placed another call and up front asked not to be redirected to any other number again because that was the way I have landed there. I gave the 10-digit customer id (piece of cake by then) and asked the woman to check the call history to show that I was indeed in a stressful ping-pong game. She notified that my problem has been registered and I do not need to call again, I should just wait for the call-back.\n\nThe next day I got the expected call. The first few minutes were again wasted to explain the problem (nobody, even DT people themselves, can believe that my bank account number has been magically changed), just to prove that I was not the one who made the stupid mistake. So, apparently they can manage the due payment to other providers, only if I transfer them the money because they are not allowed to take it from my bank account in this special case. Finally, it is quite relaxing to obtain the correct information, although until reaching this point I have to suffer more ten phone calls. As for other fines and such cost, the best they can offer is only (guess what?) a voucher. Ironically the nominal value of this voucher won’t even cover the lawyer’s cost. I was tired, angry, upset so I just accepted it. Apology? Not that I expected it, but still not even one time I heard that word.\n\nAs for the missing digit, it is still not clear how it did happen. Maybe it’s a software bug. Maybe someone just changed it, either mistakenly or only for the fun of it. Looks like nobody would be able to give me a satisfied answer at all. In fact, so far not even a dumb answer has been given. Heck, even if they said “it’s ancient black magic”, maybe I would have just accepted it.\n\nDeutsche Telekom, I’m punked!\n\n(`_|_`)Feb 15, 2006(`_|_`)ariya.io(`_|_`)deutsche-telekom-drama-part-i', 'deutsche-telekom-drama-part-i'),
(715, 'Computer vs Computer(`_|_`)\nI’m very bad at playing games. A high-school kid can beat me easily in almost any imaginable types of game. However, I’d like to enjoy the game itself, for the graphics, its gameplay, special effects, sound effects, etc. One way to do this is by watching the game while the player’s role is taken the computer. In some games, many players can even be played by the computer, e.g. really fun to do this with combat games.\n\nSo when I read about Microsoft Anti-Spyware prompts user to remove Norton AntiVirus, I could only smile. This is just not new (e.g. main task of an antivirus is typically to combat the viruses), but apparently elimination of a real product (one could also argue whether NAV is that really useful) by another one, in this particular case is more highlighted because it is official tool from Microsoft, may become common in the future.\n\nI would not be that surprised if this Anti-Spyware later on will also remove Internet Explorer \n\n(`_|_`)Feb 13, 2006(`_|_`)ariya.io(`_|_`)computer-vs-computer', 'computer-vs-computer'),
(716, 'Munich and Geisha(`_|_`)\nThese two movies did not really meet my expectations.\n\nIn Munich, Spielberg entered the controversial political foray with the adventure of Mossad agents taking revenge to what had happened in 1972 Olympic games. Due to its sensitive theme, I can imagine that in some countries (possibly also in my country, Indonesia), this Munich won’t be perhaps available in the cinema.\n\nDespite the good performance of Eric Bana, the characters did not seem to be portrayed “live” enough, which is sad because that was supposed to be the heart of the movie. In fact, this did not feel like typical Spielberg’s movie at all.\n\nAnd I also can’t really understand why Munich is chosen as the title, it feels like a cheap shot to that tragic event (same case for view of the New York’s twin towers in the final scene) as the whole thing is actually about Munich’s aftermath. Even Lucasian “The Agency Strikes Back” sounds better.\n\nThe visual in Memoirs of a Geisha is without doubt truly superb (and vivid). However, I did not really like the story adaptation. Sure, it can’t stick 100% to the book. But the book still reads like a memoirs while the movie feels like an expanded soap opera (you know, forbidden love thing). Some memorable and important moments are fast forwarded, while in other parts they are just long winded.\n\nI don’t know about other places, but here Geisha is not really well received. In the second running week, the cinema hall is unbelievably almost empty because so few people watched it. Maybe wrong place, wrong time.\n\nAs for Zhang Ziyi (I still believe if she’s doing modelling only, she’d be the Chinese answer to Kate Moss), I like her better in Flying Dagger.\n\nHopefully they won’t make a follow-up “Returns of a Geisha”.\n\n(`_|_`)Feb 1, 2006(`_|_`)ariya.io(`_|_`)munich-and-geisha', 'munich-and-geisha'),
(717, 'qotd(`_|_`)\n\nThe loudest zealots are usually the non-coders. To them, I am often tempted to ask: what was your contribution?\n\n\n\n(Shane’s comment in OSNews)\n\n(`_|_`)Jan 26, 2006(`_|_`)ariya.io(`_|_`)qotd', 'qotd');
INSERT INTO `ariyaio` (`id`, `content`, `url`) VALUES
(718, 'Translucency and Shadows Made Easy(`_|_`)\nWhen I show my desktop with real translucency and window shadows, I am often asked how to do that. It’s been ages since KDE is able doing this effect, yet not so many people are aware of it. So here I rehash the instructions in few steps (but remember: YMMV). In short: use KDE 3.4 or higher with the composite manager.\n\n[\n\n](http://ariya.pandu.org/blog/images/kde_translucent.png)\n\nTranslucency for the desktop, click to enlarge\n\nFirst step is to get accelerated driver for your X. This is not always necessary but often you get smoother performance. Beside, it’s good to install it even if you don’t need playing with eye candy anyway.\n\nNext is to get the composite manager. Somehow I manage to make translucency\n\nand drop shadows only using the X Composite Manager\n\nfrom X.Org. The easiest way is to install the binary package. This step is distribution-specific. On SUSE, just launch yast to install additional software, search for xcompmgr and finish it with few mouse clicks.\n\nUpdate (thanks to anonymous): you do not need this xcompmgr with KDE because KDE has its own composite manager already (kompmgr).\n\nNow you have enable the composite in X. For X.Org version (like what is used\n\nin major Linux distributions), edit /etc/X11/xorg.conf. Please make a backup first, in case you screw your system. In this config file, make sure you have these lines:\n\nSection \"Extensions\"\n    Option \"Composite\" \"true\"\nEndSection\n\n\nAfter this, check .xinitrc in your home directory, add this:\n\nxcompmgr -c\n\nLog out and then log in again, or just restart your X.\n\nOpen a window, right-click on the title bar and choose Configure Window Behavior (you can also use Control Center to reach the dialog but I always find this way faster). Click Translucency on the left pane and the rest is self-explained. You just need to enable the effect and customize the translucency and shadows as you like. For example, you can make the window translucent only when you move it. Or even make every single window translucent. Same goes for the shadow settings.\n\nCompare Konqueror’s window without (left) and with (right) shadows:\n\n\n\nand you certainly don’t want to look back.\n\n(`_|_`)Jan 24, 2006(`_|_`)ariya.io(`_|_`)translucency-and-shadows-made-easy', 'translucency-and-shadows-made-easy'),
(719, 'How to Avoid Number 13(`_|_`)\nCorel has shown it. The last WordPerfect version was 12, and now the new one is not 13, but rather X3. I think it’s awkward to make it as full-Roman XIII, so it’s shortened to X3. Perhaps, also not to be confused with X-Men 3 \n\nAnd BTW, the toolbar icons have been changed. After OpenOffice.org, now WordPerfect also has similar icon style to that of Office XP.\n\n\n\nAlthough now WordPerfect can import PDF, just like KWord, from what I observe, this new X3 edition still unfortunately has no support for OpenDocument.\n\n(`_|_`)Jan 19, 2006(`_|_`)ariya.io(`_|_`)how-to-avoid-number-13', 'how-to-avoid-number-13'),
(720, 'Magic Guide Lines(`_|_`)\nCasper Boemann and Thorsten Zachmann have worked together to implement a nice feature: automatic guide lines. This is available in KPresenter and Kivio. The idea is, when you e.g. drag an object to move it, then vertical and horizontal guide lines should appear magically when necessary, thereby making it easier to align the object with other objects:\n\n\n\nIn the above screenshot, the circle is being moved (by dragging)\n\nand at certain position, the dashed guide lines (in light green) show up.\n\nIf the circle is moved away, the guide lines are placed in another position\n\ne.g. close to the object that the circle is approaching.\n\nThis is much better than using the manual guide lines. Very cool, isn’t it?\n\n(`_|_`)Jan 17, 2006(`_|_`)ariya.io(`_|_`)magic-guide-lines', 'magic-guide-lines'),
(721, 'Last Minute Function Tip(`_|_`)\nSince everyone seems to have last minute feature for KOffice, I also want to have one. So, here it is:\n\n\n\nWhen autocompletion pop-up appears, choosing one of the item will also shows the description of function. I’m still playing around regarding the tip position, though. Where is the best place to put it?\n\nThis is just the next logical step after that function autocomplete.\n\n(`_|_`)Jan 15, 2006(`_|_`)ariya.io(`_|_`)last-minute-function-tip', 'last-minute-function-tip'),
(722, 'qotd(`_|_`)\n<cyrilleb> ariya: real man doesn’t live ;p\n</cyrilleb></ariya>\n\n(`_|_`)Jan 15, 2006(`_|_`)ariya.io(`_|_`)qotd-2', 'qotd-2'),
(723, 'Music for Coding(`_|_`)\nduring commits: Coldplay – Speed of Sound Audioslave – Be Yourself U2 – City Of Blinding Lights Green Day – Holiday Thousand Foot Krutch – Move Nickelback – Photograph\n\nwhile bugfixing:\n\nSystem of A down – Lonely Day\n\nNickelback – Animals\n\nOasis – Let There Be Love\n\nLifehouse – You And Me\n\nColdplay – Talk\n\nDaniel Powter – Bad Day\n\nBon Jovi – Have a Nice Day\n\n(`_|_`)Jan 14, 2006(`_|_`)ariya.io(`_|_`)music-for-coding', 'music-for-coding'),
(724, 'What is your Perfect Major?(`_|_`)\nExactly subjects that I like!\n\n\n  \n    \n    \n    \n    \n      \n        \n          \n            \n              Engineering\n            \n          \n          \n          \n            \n              \n                \n                \n              \n            \n          \n          \n          \n            100%\n          \n        \n        \n        \n          \n            \n              English\n            \n          \n          \n          \n            \n              \n                \n                \n              \n            \n          \n          \n          \n            100%\n          \n        \n        \n        \n          \n            \n              Mathematics\n            \n          \n          \n          \n            \n              \n                \n                \n              \n            \n          \n          \n          \n            92%\n          \n        \n        \n        \n          \n            \n              Linguistics\n            \n          \n          \n          \n            \n              \n                \n                \n              \n            \n          \n          \n          \n            83%\n          \n        \n        \n        \n          \n            \n              Philosophy\n            \n          \n          \n          \n            \n              \n                \n                \n              \n            \n          \n          \n          \n            83%\n          \n        \n        \n        \n          \n            \n              Journalism\n            \n          \n          \n          \n            \n              \n                \n                \n              \n            \n          \n          \n          \n            83%\n          \n        \n        \n        \n          \n            \n              Art\n            \n          \n          \n          \n            \n              \n                \n                \n              \n            \n          \n          \n          \n            83%\n          \n        \n        \n        \n          \n            \n              Theater\n            \n          \n          \n          \n            \n              \n                \n                \n              \n            \n          \n          \n          \n            67%\n          \n        \n        \n        \n          \n            \n              Chemistry\n            \n          \n          \n          \n            \n              \n                \n                \n              \n            \n          \n          \n          \n            58%\n          \n        \n        \n        \n          \n            \n              Sociology\n            \n          \n          \n          \n            \n              \n                \n                \n              \n            \n          \n          \n          \n            50%\n          \n        \n        \n        \n          \n            \n              Dance\n            \n          \n          \n          \n            \n              \n                \n                \n              \n            \n          \n          \n          \n            42%\n          \n        \n        \n        \n          \n            \n              Anthropology\n            \n          \n          \n          \n            \n              \n                \n                \n              \n            \n          \n          \n          \n            42%\n          \n        \n        \n        \n          \n            \n              Biology\n            \n          \n          \n          \n            \n              \n                \n                \n              \n            \n          \n          \n          \n            33%\n          \n        \n        \n        \n          \n            \n              Psychology\n            \n          \n          \n          \n            \n              \n                \n                \n              \n            \n          \n          \n          \n            33%\n          \n        \n      \n    \n  \n\n\nWhat is your Perfect Major? (PLEASE RATE ME!!<3)\ncreated with QuizFarm.com\n\n(via Jamin)\n\n(`_|_`)Jan 13, 2006(`_|_`)ariya.io(`_|_`)what-is-your-perfect-major', 'what-is-your-perfect-major'),
(725, 'Percent Featurelet(`_|_`)\nThis is long overdue, but finally with the new formula engine (recently integrated and completed by Tomas Mecir as his SoC), the percent operator is supported in KSpread:\n\n\n\n(`_|_`)Jan 12, 2006(`_|_`)ariya.io(`_|_`)percent-featurelet', 'percent-featurelet'),
(726, '1600 Gb/s(`_|_`)\nThe latest December edition of IEEE Photonics Technology Letters includes our publication entitled 1.6-Tb/s (40×40 Gb/s) Transmission Over 44..94 km of SSMF With Adaptive Chromatic Dispersion Compensation.\n\nIn short, it is summarized as follows. We transmitted 40 channels, each can carry 40 Gb/s data, in a distance up to 94 km. That’s indeed not really new. But, in our experiment, at the receiver we needed ony one multichannel dispersion compensator that is able to compensate the different dispersion of all channels. The said compensator is even adjustable (thermally tunable), that’s why the transmission distance could be easily varied (e.g. as short as 44 km). Interestingly, the compensator did have just enough bandwidth because it was initially designed for 10 Gb/s transmission. Both amplitude and phase modulation gave satisfactory performance.\n\nTo imagine the capacity, this is equivalent to transporting approximately 45 standard DVDs in just one second.\n\nAnd actually this experiment is a bit outdated. In last year’s European Conference on Optical Communication (whereby I had the chance to visit Glasgow), I have presented the follow-up experiment in which the rate is further pushed to reach approximately 6000 Gb/s.\n\n(`_|_`)Jan 11, 2006(`_|_`)ariya.io(`_|_`)1600-gbs', '1600-gbs'),
(727, 'Arthuring Gnash(`_|_`)\nNow that Gnash is actively developed, making a Qt 4 binding and let it render using Arthur will be a wonderful addition to KDE 4’s Konqueror. Or, perhaps even Plasma. Of course, Konqueror can use the Netscape plug-in version, but accelerated rendering as well as making it available to other apps (yes, yes, I know Flash is proprietary and there is SVG) should be cooler, right?\n\n(`_|_`)Jan 10, 2006(`_|_`)ariya.io(`_|_`)arthuring-gnash', 'arthuring-gnash'),
(728, 'One Word to Rule Them All(`_|_`)\nFrom OSNews: Blastware.org stated that Polaris, OpenSolaris kernel ported to the PowerPC has been built.\n\nAnd then, Slashdot linked recent Hubble’s telescope observation on Polaris – the North Star – system.\n\nHowever, Windows Media Player 11 codenamed Polaris is still not available yet. It was slated for first months of 2006, though.\n\n(`_|_`)Jan 9, 2006(`_|_`)ariya.io(`_|_`)one-word-to-rule-them-all', 'one-word-to-rule-them-all'),
(729, 'Compiler Talk (Again)(`_|_`)\nTalking to compiler is just like to human being, if you do not understand the dialect then you keep wondering what the other side is trying to say:\n\nerror C2663:  \'QWidget::move\': 1 overloads have no legal conversion for \n\'this\' pointer\n\nThat is from Microsoft VC++ compiler. If you are new, this message hardly tells you anything useful. So, open up MSDN help or fire Google.\n\nBut time is money:\n\nerror: passing `const Foo\' as `this\' argument of `void QWidget::move(int, int)\' \ndiscards qualifiers\n\nand the way how GCC spots the same mistakes easily sparks your brain cells and in matter of milliseconds, you know what you’ve done wrong.\n\n(`_|_`)Jan 9, 2006(`_|_`)ariya.io(`_|_`)compiler-talk-again', 'compiler-talk-again'),
(730, 'Prototype in Office(`_|_`)\nJensen Harris has revealed how the initial design of Microsoft Office 12 user interface has something to do with paper prototyping. Interesting to notice, because creating mock-up using paper prototype has been covered before by Ellen. Perhaps we should do it for the next generation of KOffice?\n\n(`_|_`)Jan 6, 2006(`_|_`)ariya.io(`_|_`)prototype-in-office', 'prototype-in-office'),
(731, 'Be Yourself(`_|_`)\n\neven when you\'ve paid enough been pulled apart or been held up ’cause every single memory of  the good or bad faces of luck don\'t lose any sleep tonight I\'m sure everything will end up alright you may win or lose \n\n\n\n\n\n\n(`_|_`)Jan 3, 2006(`_|_`)ariya.io(`_|_`)be-yourself', 'be-yourself'),
(732, 'speedcrunch: the madness continues(`_|_`)\nWhat was intended to be a proof-of-concept has become the calculator of choice in the latest Kubuntu Breezy Badger. The next logical step is to let users of other platforms also have a chance to enjoy it.\n\nMany have asked why I do not offer (and encourage) Windows version, as it is written in the website. This is a not technical matter as the code itself is as portable as I can make (sans compiler quirkness) and it does not depend on anything. But for once, the situation has changed since Trolltech released Qt 4 because now official GPL-ed Win32 edition of Qt is available. Johan Thelin has taken the task of porting it to Qt 4 and thus makes SpeedCrunch runs in Win32.\n\nThe next 0.7 series will hopefully feature Linux, Windows and Mac OS X version, essentially all platform where Qt is supported. So Window and Mac OS X users soon can also enjoy the keyboard-friendly calculator with 50 digits precision, variables support,\n\ncolor syntax highlight, functions autocomplete and calc-as-you-type (or on-the-fly calculation) convenience. Thanks to Johan, it will also sport the long-awaited optional keypad:\n\n\n\nUntil KDE 4 ready, SpeedCrunch will be Qt only. If you can’t wait, then I highly recommend Michael Pyne’s abakus. It is well integrated with KDE. Some goodies – among others the high-precision feature – are also in abakus as we share plenty of code.\n\nAnd with the new year comes also the new maintainer. From the very long development time of version 0.6 (I still need to upload the final version, but Berlios seems to be down all time), I realized that I was doing it harm if I keep it that way. So finally, I passed the torch of SpeedCrunch to Johan and surely he would steward the development better than what I did. For the users, translators and contributors, I sincerely thank you and appreciate all your patches and feedback.\n\nThere are still tons of interesting ideas for this calculator: RPN support, user-defined function, more built-in functions, external plug-in, higher precision, common scientific constants, just-in-time compile, etc. So do not expect the madness to stop …\n\n(`_|_`)Jan 2, 2006(`_|_`)ariya.io(`_|_`)speedcrunch-the-madness-continues', 'speedcrunch-the-madness-continues'),
(733, '1136073600(`_|_`)\nGood bye, 2005. Welcome to 2006!\n\nGuess what the number means… \n\n(`_|_`)Dec 31, 2005(`_|_`)ariya.io(`_|_`)1136073600', '1136073600'),
(734, 'qPrintable(`_|_`)\nIn Qt application, outputting printf-like formatted debug message involving QString means using latin1 or utf8 such as:\n\nQString name = \"Willy Wonka\";\nint num = 5;\nqDebug(\"My name is %s, I invite %d children\", name.latin1(), num);\n\n\nBut in Qt 4.x, you can use qPrintable function:\n\nQString str = \"a chocolate factory\";\nqDebug(\"I have %s\", qPrintable(str));\n\n\nFor non-formatted output, just use qDebug() as an output stream.\n\n(`_|_`)Dec 30, 2005(`_|_`)ariya.io(`_|_`)qprintable', 'qprintable'),
(735, 'Front Pages(`_|_`)\nFind your newspapers in Today’s Front Pages.\n\n(`_|_`)Dec 28, 2005(`_|_`)ariya.io(`_|_`)front-pages', 'front-pages'),
(736, 'OpenMortal Combat(`_|_`)\nRemember the old good time with Mortal Kombat? Well, look no more! Why don’t you try OpenMortal?\n\n\n\nInstallation is supereasy. In a standard box with SDL, that would only mean typical extract, configure, make and make install steps. Few minutes are all that you need. Mac OS X and Windows packages are also available.\n\nOpenMortal is practically meant to be a parody, but nevertheless it is a good one and quite joyful to play. Don’t expect the same touches and completeness as the original Mortal Kombat. Looking at what has been achieved so far, then it’s simply amazing! The characters are for real, at least real persons whose movements are digitized and imported to the game. If you are willing to undertake the tedious steps, the you can also become a character. However, it’s safe to say we would not see someone like Goro in the near future \n\nNetwork play is supported, but no AI means you can not play against the computer. Since that old Mortal Kombat could have such a simple (and dumb) AI in a ridiculously prehistoric machine by today’s standard, I bet it’s only a question of lack of contribution rather that difficulties. If you’re a programmer looking for something for fun, this could be a nice holiday project indeed.\n\nOh, how I miss Fatality…\n\n(`_|_`)Dec 23, 2005(`_|_`)ariya.io(`_|_`)openmortal-combat', 'openmortal-combat'),
(737, 'The Famous Cat(`_|_`)\nOK, finally I got my Schrödinger’s Cat T-shirt (has nothing to do with this guy’s encyclopedia). Unless you live under the rock, you would know what this shirt has different statement (about the life of the cat) on its front and back side. And if you don’t live under the rock, you might want to know that this shirt can boost your charm, at least that what happened to Wil Wheaton.\n\nNow I’m awaiting someone to make the Heisenberg version of the shirt, saying that “Schrödinger’s Cat May Have Been There”. That would be funny \n\n(`_|_`)Dec 23, 2005(`_|_`)ariya.io(`_|_`)the-famous-cat', 'the-famous-cat'),
(738, 'Language Autodetect(`_|_`)\nIf you often compose mails with different languages and use spell checker quite often, GMail cleverly does not ask you in which language the mail is written, nor you need to specify one. You write in English, then English spell checker is used. You write in German, then German spell checker is used. Seems trivial, still I was happy when I realized this for the first time.\n\nOn related thing, GMail seems to use Sophos for its antivirus.\n\n(`_|_`)Dec 21, 2005(`_|_`)ariya.io(`_|_`)language-autodetect', 'language-autodetect'),
(739, 'Pulsating Effect for QToolTip(`_|_`)\nAbout ten months ago, I played around with the idea of pulsating effect in QToolTip. Basically, the background color is changed quickly to series of some colors. See this Flash animation. The actual effect is of course much smoother than what is shown in this Flash demo.\n\nUnfortunately that trick does not work anymore with the new Qt 4 as you can’t change QToolTip’s palette. However, I am able to get the solution: find the QTipLabel and then apply the same crime.\n\nvoid MyWindow::beat()\n{\n  static QPointer<qlabel> tipLabel;\n  static int index = ;\n \n  if(!tipLabel)\n    foreach(QWidget *widget, QApplication::allWidgets())\n      if(widget->inherits(\"QTipLabel\"))\n        tipLabel = qobject_cast</qlabel><qlabel>(widget);\n \n  if(tipLabel)\n  {\n    int k = (index>7) ? 14-index : index;\n    index += (index&lt;14) ? 1 : -14;\n \n    QColor c = QColor( 255, 128+k*16, k*20 );\n    QPalette pal = tipLabel->palette();\n    pal.setColor( QPalette::Background, c );\n    tipLabel->setPalette( pal );\n  }\n \n  QTimer::singleShot(tipLabel? 100 : 1000, this, SLOT(beat()));\n}\n</qlabel>\n\n\nThis is again a dirty hack, but it works as long as your program does not create its own QTipLabel and QToolTip implementation won’t be radically changed.\n\n(`_|_`)Dec 19, 2005(`_|_`)ariya.io(`_|_`)pulsating-effect-for-qtooltip', 'pulsating-effect-for-qtooltip'),
(740, 'if (party) CEO = false(`_|_`)\nI haven’t read How to Become CEO yet, but looking at the excerpt, something is very interesting indeed:\n\n\n_\n\nThere is no such thing as a business or office party. It is not a social gathering. It is business. Never party at an office party. It won’t hurt you not to go at all. Don’t offend people by criticizing the party or by publicly announcing your intentions. Simply don’t go. Give polite excuses.\n\n_\n\n\n(`_|_`)Dec 19, 2005(`_|_`)ariya.io(`_|_`)if-party-ceo-false', 'if-party-ceo-false'),
(741, 'Mission Impossible 3.0(`_|_`)\nYes, Tom Cruise wants to catch up with the (amazing) 3.x series of KDE \n\nMission: Impossible III will be out next summer. The teaser is already available, unfortunately nothing else has been revealed so far. Judging from the teaser, quite likely it will be the same like the last two: full of action and with boring plot. Frankly, I was quite disappointed that Ethan Hunt became more a 007-style agent, rather than one belongs to a group with astonishing teamwork skills. Let see what will happen to Ethan this time.\n\n\n\n(`_|_`)Dec 18, 2005(`_|_`)ariya.io(`_|_`)mission-impossible-3-0', 'mission-impossible-3-0'),
(742, '27.831(`_|_`)\nOK, Roberto, you also let me waste my time…\n\n(`_|_`)Dec 16, 2005(`_|_`)ariya.io(`_|_`)27-831', '27-831'),
(743, 'Google Summer of Code: The T-Shirt(`_|_`)\nI got my Summer-of-Code‘s mentor version of the long-awaited T-shirt. Thanks, Google!\n\n\n\n(`_|_`)Dec 16, 2005(`_|_`)ariya.io(`_|_`)google-summer-of-code-the-t-shirt', 'google-summer-of-code-the-t-shirt'),
(744, 'Buzz, or Shake My Window(`_|_`)\nCtrl+G is a very well-known shortcut by Yahoo! Messenger users. It means buzz your contact. Essentially, the other side will get “Buzz!” message, along with sound effect (if enabled) and the shaking of the chat window. The last part is very interesting and obviously used to steal the attention. It is difficult to explain if you never have experienced it \n\nTo buzz-enabling your Qt application, here is the code snippet taken from what I have implemented for KYIM long time ago:\n\nvoid Mainwin::buzz()\n{\n  int xp = x();\n  int yp = y();\n  QTime t;\n \n  t.start();\n  for ( int i = 32; i > ; )\n  {\n    QApplication::processEvents();\n    if ( t.elapsed() >= 1 )\n    {\n      int delta = i >> 2;\n      int dir = i & 3;\n      int dx = ((dir==1)||(dir==2)) ? delta : -delta;\n      int dy = (dir&lt;2) ? delta : -delta;\n      move( xp+dx, yp+dy );\n      t.restart();\n      i--;\n    }\n  }\n  move( xp, yp );\n}\n\n\nHappy buzzing !\n\n(`_|_`)Dec 15, 2005(`_|_`)ariya.io(`_|_`)buzz-or-shake-my-window', 'buzz-or-shake-my-window'),
(745, 'Arrow in Plastique QComboBox(`_|_`)\nIf you try to find the dimension and position of the combobox arrow button, one of your chance is by using subControlRect of the style in use. Unfortunately, this can not work in Plastique style because this style does not return a correct QRect associated with the arrow’s geometry, as evidence from the source code:\n\ncase CC_ComboBox:\n        switch (subControl) {\n        case SC_ComboBoxArrow:\n            rect = option->rect;\n            break;\n\n\nIt simply gives back option->rect which is likely the widget’s own rect(). Your program might believe that the arrow occupies the whole combobox.\n\nFortunately, thanks to the Trolls, this problem is gone with the upcoming Qt 4.1.\n\nBut just in case you still want to work with Qt 4.0 (and 4.0.1), then you have to implement hackish fix like this:\n\nQRect arrowRect = style()->subControlRect(QStyle::CC_ComboBox, \n        &opt;, QStyle::SC_ComboBoxArrow, this);\n    if( arrowRect == opt.rect )\n    {\n        // workaround for broken subControlRect\n        int fw = style()->pixelMetric(QStyle::PM_DefaultFrameWidth);\n        arrowRect = QRect(width()-16-fw, height()-2*fw);\n    }\n\n\n(`_|_`)Dec 14, 2005(`_|_`)ariya.io(`_|_`)arrow-in-plastique-qcombobox', 'arrow-in-plastique-qcombobox'),
(746, 'Mostly Europe(`_|_`)\nAccording to Google Analytics, visitors to my blog are mostly from Europe:\n\n\n\nCould it be because the majority of Planet KDE readers are KDE users? Will be interesting to see the result from Planet GNOME.\n\n(`_|_`)Dec 13, 2005(`_|_`)ariya.io(`_|_`)mostly-europe', 'mostly-europe'),
(747, 'Practical Qt(`_|_`)\nYay! I’ve got my copy of Practical Qt.\n\n(`_|_`)Dec 9, 2005(`_|_`)ariya.io(`_|_`)practical-qt', 'practical-qt'),
(748, 'Virus from Aliens(`_|_`)\n Beware of the aliens, as they may send viruses: “…scientists searching the heavens for signals from extra-terrestrial civilisations are putting Earth’s security at risk…“\n\nMan, did these aliens watch Independence Day?\n\n(`_|_`)Dec 5, 2005(`_|_`)ariya.io(`_|_`)virus-from-aliens', 'virus-from-aliens'),
(749, 'Scientific Example(`_|_`)\nA young English professor opened his first lecture for freshmen with a question, “Could anyone give an example of a sentence using the word learn, please?”\n\nA student raised his hand and said, “I learn physics”.\n\n“Good”, continued the professor, “but since you are now not in high school anymore, could you rather give a more interesting example? A more scientific one perhaps?”\n\nThe student thought for a few seconds. Then he came up with another example, “Albert Einstein learned physics”.\n\n(`_|_`)Dec 2, 2005(`_|_`)ariya.io(`_|_`)scientific-example', 'scientific-example'),
(750, 'Tenerife(`_|_`)\nN24 aired an interesting documentary film on Tenerife accident between two 747s, considered one of the biggest pre-9⁄11 aircraft disaster. Detailed information, including released reports and reconstructed illustrations are also available from Project Tenerife website.\n\n\n\nThis accident happened long time ago (when I was few days old), the lessons learned from it proved be to useful for improvements in the regulations. Even for people outside airline industry, it shows how good communication is indeed very very important.\n\n(`_|_`)Nov 28, 2005(`_|_`)ariya.io(`_|_`)tenerife', 'tenerife'),
(751, 'The Danger of Spamming(`_|_`)\nRick Downes is against spamming. Yet he was arrested because the police suspected that he spams people with advertisement of pharmaceutical products.\n\n(`_|_`)Nov 28, 2005(`_|_`)ariya.io(`_|_`)the-danger-of-spamming', 'the-danger-of-spamming'),
(752, 'Seven-Segment Problem(`_|_`)\nAfter too long working on a prototype board, I had an idea to invent this question.\n\n\n\n\nYou have a 7-segment display. A byte is sent to the display, 7 bits are used to switch on (if the bit is set) or switch off (if the bit is reset) the segments. One bit in this byte is not used and always zero.\n\nValues in the byte which correspond to decimal number (0 to 9) shown in the display are summarized as follows:\n\n\"0\"    0xE7 \n  \"1\"    0x22 \n  \"2\"    0xAD \n  \"3\"    0xAB \n  \"4\"    0x6A \n  \"5\"    0xCB \n  \"6\"    0xCF \n  \"7\"    0xA2 \n  \"8\"    0xEF \n  \"9\"    0xEB \n\n\nFind out what value you must send so that the display shows “E”.\n\n\nIn an interview, see how fast your candidate can get the answer (of course, you can replace “E” with another letter). Also, if he or she spends too much time studying number “8”, time to try another candidate…\n\n(`_|_`)Nov 25, 2005(`_|_`)ariya.io(`_|_`)seven-segment-problem', 'seven-segment-problem'),
(753, 'Pronounciation of \'char\'(`_|_`)\nFrom Bjarne Stroustrup’s C++ FAQ:\n\n\nHow do you pronounce “char”?\n\n“char” is usually pronounced “tchar”, not “kar”. This may seem illogical because “character” is pronounced “ka-rak-ter”, but nobody ever accused English pronounciation and spelling of being logical.\n\n\nAll these years, I’ve pronounced it incorrectly…\n\n(`_|_`)Nov 24, 2005(`_|_`)ariya.io(`_|_`)pronounciation-of-char', 'pronounciation-of-char'),
(754, 'Ladies Mouse(`_|_`)\nDo they have it in pink?\n\n\n\n(From thatwasfunny.com)\n\n(`_|_`)Nov 22, 2005(`_|_`)ariya.io(`_|_`)ladies-mouse', 'ladies-mouse'),
(755, 'RealTime vs Live(`_|_`)\nWordPerfect Office, since version 9, has a very nice timesaving feature called RealTime Preview. When choosing specific font from the dropdown list, the selected text is already reformatted and displayed using that font. This applies also with other types of formatting. And because the update is instant, you can scroll throughout the font list and see the text “morphs” into different look and finally choose what suits you best. This is not like in other office suite, where you need that many repetitive clicks because every time you change the font, the text just looks ugly and you have to repeat and repeat it again.\n\nHalf a decade later, Office 12 has Live Preview, which is basically the same thing.\n\n(`_|_`)Nov 21, 2005(`_|_`)ariya.io(`_|_`)realtime-vs-live', 'realtime-vs-live'),
(756, 'Unzipping in C(`_|_`)\nIf your C program needs to extract files from a ZIP-compressed package, using minizip (and zlib) is a fast and easy solution. Not to pollute planetkde (no pun intended here :-), a simple function to extract one file from a ZIP and write it to the specified output file is shown in this simple unzip example instead.\n\n(`_|_`)Nov 21, 2005(`_|_`)ariya.io(`_|_`)unzipping-in-c', 'unzipping-in-c'),
(757, 'rand(): font, Qt 4.1, Superman, beauty(`_|_`)\nSome random goodies, welcoming the weekend.\n\nAmusing history of Verdana and Georgia fonts. Got this link when reading\n\nOffice UI blog.\n\nChangelog for Qt 4.1 is quietly available.\n\nSuperman Returns will be out in Summer 2006. The released teaser so far contains almost nothing. Do not waste your time downloading it.\n\nBeauty? Per definition, beauty is in the eye of the beer holder.\n\n(`_|_`)Nov 18, 2005(`_|_`)ariya.io(`_|_`)rand-font-qt-4-1-superman-beauty', 'rand-font-qt-4-1-superman-beauty'),
(758, 'Unoptimize OpenOffice.org\'s content.xml(`_|_`)\nThis is probably not of much interest for normal users.\n\nIf you work with OpenDocument and OpenOffice.org, you know that XML file produced by OpenOffice.org is not quite human-friendly as it contains no CR/LF and no indentation because it is (so to speak) “optimized” for size. The XML file of course looks ugly in normal text editor. To change this, open menu Tools, Option to bring the Options dialog. Choose Load/Save, General from the list of the left and uncheck the option Size optimization for XML format.\n\n(`_|_`)Nov 18, 2005(`_|_`)ariya.io(`_|_`)unoptimize-openoffice-orgs-content-xml', 'unoptimize-openoffice-orgs-content-xml'),
(759, 'No Test? It\'s Broken!(`_|_`)\nI’d like to add one important point to Aaron’s list to good practices in open source software: extensive tests. Sure, manually testing the program is good, but since open-source software is done mostly by volunteers, tests that run by themselves are of great help. In the past, I have witnessed so many bugs in KOffice, including mine of course, that surely would be earlier exposed, had we an automated test suite for that.\n\nThis taught me first hand the importance of testing (unit test is the obvious choice, but even a bunch of plain assert()s is better than nothing), until I finally adopt the “if no test exists for this module, assume it’s broken” philosophy. For my personal projects, now I am very careful to make the corresponding tester for all modules/classes. That will save my days and reduce the headache later. It is funny to observe that the code which does the testing is sometimes longer than the code under test (though this fact definitely plays little role here).\n\nTest suite is also very useful on stuff being developed by many people. Some day in the future, maybe the maintenanceship of your code is transferred to another person and when s/he wants to further develop it (implement feature, fix the bug, add workaround, you name it), the test suite will give early hints whether the new code breaks the regression or not. “But the code looks good (and I am a great hacker!)” just does not guarantee anything and completely antipodal to that broken philosophy I’ve mentioned.\n\nSpeaking about test, I can as well mentioned that it is a good idea to valgrindify the program from time to time. Ideally, after a feature is correctly implemented and does not break any tests, Valgrind should be used to point any possibilities of memory leaks and other similar mistakes.\n\nProgramming is 1% coding, and 99% debugging. You surely would appreciate any extra help for that 99% part, wouldn’t you?\n\nSo, happy testing.\n\n(`_|_`)Nov 17, 2005(`_|_`)ariya.io(`_|_`)no-test-its-broken', 'no-test-its-broken'),
(760, 'Browser\'s Blue Screen(`_|_`)\nI wonder whether novice Windows users would get panic if you give them this link: http://www.acme.com/notexist. Can possibly some Ajax guru make it more scary?\n\n“Related” HAL 9000 Technorati link: notexist :-))\n\n(`_|_`)Nov 16, 2005(`_|_`)ariya.io(`_|_`)browsers-blue-screen', 'browsers-blue-screen'),
(761, 'Compiler Talk(`_|_`)\nWhen for the first time I learned C++, I used to practise guessing what goes wrong when the compiler issues errors. Basically, I jumped to the line where the error is spotted and, without reading further error message, tried to deduce the mistake just by looking at the code. I found that this is quite effective (but not efficient, do not do this for in real-world because you will waste lots of your time) to understand many advanced programming caveats. I even always recommend it to C/C++ newbie who has the guts to do so. Up to certain points, you can even start to understand the distinct behaviors of different type of compilers.\n\nOften, time does not permit me to do this kind of exercises anymore. So instead of “talking” to the compiler directly, now from time to time I just drop Gimpel Software’s bug of the month a visit. Some of them can be quite inspiring, and it is always fascinating to try to get the bug in matter of seconds. Try it yourself.\n\n(`_|_`)Nov 16, 2005(`_|_`)ariya.io(`_|_`)compiler-talk', 'compiler-talk'),
(762, 'Who Let The Bugs Out?(`_|_`)\nWhoever behind it, this kdebugs.blogspot.com is cool.\n\n(`_|_`)Nov 14, 2005(`_|_`)ariya.io(`_|_`)who-let-the-bugs-out', 'who-let-the-bugs-out'),
(763, 'Unleashed(`_|_`)\nNormally, amazing fighting scenes are what you expect from Jet Li’s movies. That also what I had mind when I inserted Unleashed into my DVD player. But I was wrong. This European-produced movie offered a good and strong (and believable) story, and most important is that it was not packed with unnecessary fights (except perhaps one in the pool, but that’s acceptable considering this is Jet Li’s). The story was a bit slow and probably disappoint those who favor thriller, but all in all it is very much enjoyable. The performance of Morgan Freeman playing a fatherly figure was fairly decent as well.\n\nExcluding his Chinese movies, in my opinion until now this is the best from Jet Li.\n\n(`_|_`)Nov 14, 2005(`_|_`)ariya.io(`_|_`)unleashed', 'unleashed'),
(764, 'Afraid or Not?(`_|_`)\nThis is another joke.\n\nAt a company picnic, the CEO wanted to hold a little game. After asked for attention, he started his speech, “People, it is often said that we, the men in the family, are afraid of our spouses. Is that really true? Or is it only a myth? Well, let us now experience the moment of truth.”\n\n“For all the women, please let go your husbands for a while. Come on guys, come forward! For those who are afraid of your wives, just stand up next to me, on my left side. For those who aren’t, on my right side.”\n\nIt took a while until all the married men lined themselves. After some chaotic movements, in the end only one cool-looking guy stood to the right of the CEO. This stunned everybody.\n\nThe CEO approached him. “So, you are the best among us. You are the only who dare to stand here, while others had chosen another path. How come?”\n\n“No idea”, the guy gave a calm answer, “my wife told me I must stand here”.\n\n(`_|_`)Nov 13, 2005(`_|_`)ariya.io(`_|_`)afraid-or-not', 'afraid-or-not'),
(765, 'Autumn Again(`_|_`)\n\n\nMy fourth autumn so far…\n\n(`_|_`)Nov 11, 2005(`_|_`)ariya.io(`_|_`)autumn-again', 'autumn-again'),
(766, 'Property in C++(`_|_`)\nAlmost ten years ago a friend of mine showed that he was happy to use Visual Basic’s (and also later on Delphi’s, with Borland’s extensions to Pascal) feature of object property, which allows one to set a property of an object and have the object respond to the change. For example, this code:\n\nButton1.Left = 43\n\nwill automagically also move that button to a new position, not only\n\nchanging Left to a new value. In C++, this is not achievable\n\nbecause no function call is involved. Instead, the code must be\n\nmodified to something like:\n\nButton1.SetLeft(43);\n\n\nAnd we need to have another (getter) method to obtain the property’s\n\nvalue:\n\nint posx = Button1.Left();\n\n\nwhile in VB and Delphi’s Pascal, one Left is enough.\n\nPersonally, I believe this is only syntax stuff. It doesn’t matter so much,\n\nit even improves nothing. But just to make a rebuttal, I crafted a simple\n\nexample to show that it is also possible to implement such feature in C++.\n\nThe key here is that each property is an object. To cover all basic\n\ndata type, obviously template-based is a good choice:\n\ntemplate<class t=\"T\">\nclass Property\n{\npublic:\n Property(){ owner = ; };\n operator T(){ return data; }\n Property( T dat ){ data = dat; }\n void setup( Object* obj, std::string n ){ owner = obj; name = n; }\n Property& operator=( T dat ){ \n  bool changed = dat!=data; data = dat; \n  if(owner && changed) owner->propertyChanged(name);return *this; }\nprivate:\n T data;\n Object* owner;\n std::string name;\n};\n</class>\n\n\nLater on, to wrap that setup() method, a simple macro magic is employed:\n\n#define INIT_PROPERTY(x)  (x).setup( this, #x )\n\nThe basic object system needs to have method to be called when its\n\nproperties are modified:\n\nclass Object\n{\npublic:\n  virtual void propertyChanged( std::string name ) = ;\n};\n\n\nAs you can guess already, propertyChanged is invoked\n\nwhen a new value is assigned to the property. So the secret is here\n\nis the overloaded assignment operator.\n\nA hypotetical widget named Slider can be implemented as follows:\n\nclass Slider: public Object\n{\npublic:\n  Slider();\n  virtual void propertyChanged( std::string name );\n  Property<int> min;\n  Property</int><int> max;\n  Property<double> value;\n};\n</double></int>\n\n\nProperties of this Slider must be initialized in the constructor. This is\n\nso that each will get a unique name and assigned to an object (simply\n\nthis) to which it will report when its value is changed.\n\nWith the INIT_PROPERTY macro, this is as convenient as:\n\nSlider::Slider()\n{\n  std::cout < < \"Creating slider\" << std::endl;\n  INIT_PROPERTY( min );\n  INIT_PROPERTY( max );\n  INIT_PROPERTY( value );\n}\n\n\nThe job of propertyChanged is then to handle the situation when\n\none of the property has been changed:\n\nvoid Slider::propertyChanged( std::string name )\n{\n  if( name == \"min\" )\n     {\n     std::cout < < \"Slider.min has been changed\" << std::endl;\n     // do something\n     }\n \n  if( name == \"max\" )\n     {\n     std::cout << \"Slider.max has been changed\" << std::endl;\n     // do something\n     }\n \n  if( name == \"value\" )\n     {\n     std::cout << \"Slider.value has been changed\" << std::endl;\n     // do something\n     }\n}\n\n\nAlmost nothing else is needed. Then, the code snippet shown below is\n\nalready comparable to how it is done in VB:\n\n&nbsp; Slider slider;\n&nbsp; slider.min = 1;\n&nbsp; slider.max = 42;\n&nbsp; slider.value = 8.3;\n\n\nAlthought is a “fake implementation”, at least I have convinced\n\nmy friend that C++ can have property.\n\nOf course, this trick has some disadvantages. Properties needs to be\n\ninitialized in the class constructor, so more boilerplate code compared\n\nto the case where this kind of feature is supported in the language itself.\n\nNo checking when setting a value means corner cases must be well taken care of.\n\nAlso, properties are object instances which are not so cheap. Comparing\n\nthe property using string is also not fast.\n\nInfinite loop is even possible when it is not handled well.\n\nI believe that some functors in combination with more template and macro\n\nmagic will even allow the redirection of reading and writing property to\n\nthe corresponding getter and setter methods. Left as an\n\nexercise for the reader \n\n(`_|_`)Nov 10, 2005(`_|_`)ariya.io(`_|_`)property-in-c', 'property-in-c'),
(767, 'Reading the Memoirs(`_|_`)\nLooking forward to seeing Zhang Ziyi‘s performance in Memoirs of a Geisha, I started to read the book from which the film is adapted. So the new few days will be hopefully quite exciting.\n\n(`_|_`)Nov 10, 2005(`_|_`)ariya.io(`_|_`)reading-the-memoirs', 'reading-the-memoirs'),
(768, 'Qt 4.2: one tenth of...(`_|_`)\nAs I write before, Qt 4.1 will be cool.\n\nBUT, the next Qt 4.2 would be much more awesome because it is one tenth of the ultimate answer to life, the universe, and everything !\n\n(`_|_`)Nov 9, 2005(`_|_`)ariya.io(`_|_`)qt-4-2-one-tenth-of', 'qt-4-2-one-tenth-of'),
(769, 'Reaper 3-D: Flight Combat(`_|_`)\nThis Reaper 3-D, an open-source spaceship combat game seems to be underrated. It is of the same style as Terminal Velocity, but with better goodies such as improved 3-D ground objects (instead of flat, sprite-based ones like in TV). The OpenGL-based graphics is amazing, though it lacks the fast-paced background music which – in TV – pumps the adrenalin faster and faster. And granted, it has not been updated anymore since few years ago although the last release was still fun enough to play.\n\n\n\nGive it a try!\n\n(`_|_`)Nov 8, 2005(`_|_`)ariya.io(`_|_`)reaper-3-d-flight-combat', 'reaper-3-d-flight-combat'),
(770, 'Engineers (Again)(`_|_`)\nFollowing Aaron Krill, here is another engineer joke:\n\nIt was decided to build a bridge between heaven and hell. Half of the bridge should be made from hell and another half from heaven and these two shall meet in the middle. People from hell worked hard for this, as if the bridge is finished they could also once a while visit the heaven (who wouldn’t?).\n\nUp to a point where the two parts of the bridge should be connected, there wasn’t any structure or whatsoever from the heaven’s side. It was just empty space. Even after waiting for some time, there seems no activity at all from heaven regarding this bridge thing.\n\nA call was made from hell to heaven, asking for explanation on what had happenned. “Well”, expressed a representative from heaven, “we don’t have engineers.”\n\n(`_|_`)Nov 7, 2005(`_|_`)ariya.io(`_|_`)engineers-again', 'engineers-again'),
(771, 'DOOM and KPresenter(`_|_`)\nDOOM is an FPS game. KPresenter is our lovely presentation tool. What do they have in common?\n\n\n\nWell, long time ago I implemented lots of slide transition effects to KPresenter. Later on, just for fun I have added one effect called melting that IIRC has no equivalent in other presentation program. If you play the classic DOOM many times, you know how this effect looks like…\n\n(`_|_`)Nov 4, 2005(`_|_`)ariya.io(`_|_`)doom-and-kpresenter', 'doom-and-kpresenter'),
(772, 'Pocket Dragon(`_|_`)\nIn Germany, a youngster might bump to you in and ask “Hey Alter, hast du Taschendrachen?” which is translated literally as “Hi dude, have you got pocket dragon?”. Quite easily, one can guess that pocket dragon in this context means the lighter.\n\nAnd there are still more phrases like this, such as Lungenbrötchen (bread for the lung, means cigarette), Fünf-Finger-Rabatt (five-finger discount or thief) and Tretferrari (Ferrari with pedal, definitely a bike).What a wonderful imagination, isnt it? IIRC there is even a special slang dictionary for that!\n\n(`_|_`)Nov 3, 2005(`_|_`)ariya.io(`_|_`)pocket-dragon', 'pocket-dragon'),
(773, 'I-D-D-Q-D(`_|_`)\nAs I expected before, DOOM: The Movie was quite awesome. OK, as in the game, the story was rather weak. Often, it was quite predictable as well, e.g. that additional extra chromosome pair would apparently lead to something (although thumbs-up for mentioning Lucy).\n\n[\n\n](http://www.imdb.com/title/tt0419706/photogallery)\n\n[\n\n](http://www.imdb.com/title/tt0419706/photogallery)\n\nThe film is definitely more enjoyable for those who had experienced the game.\n\nThe appearance of typical-scientist Dr. Carmack was a nod to John Carmack, this trivia would be hardly known if you are never exposed to iD Software. And Dr. Willits – for the famous DOOM levels designer Tim Willits – was also there (one may wonder though, where is Dr. Romero? :-P). Few minutes scene which was entirely in first-person perspective surely would be appreciated by the DOOM lovers. And of course, everybody has been waiting for that BFG show.\n\nSo, are we going to see Quake: The Movie soon?\n\n(`_|_`)Nov 2, 2005(`_|_`)ariya.io(`_|_`)i-d-d-q-d', 'i-d-d-q-d'),
(774, 'Kung Fu Hustle(`_|_`)\nKung Fu Hustle is entertaining and hilarious! Recommended.\n\n(`_|_`)Oct 27, 2005(`_|_`)ariya.io(`_|_`)kung-fu-hustle', 'kung-fu-hustle');

--
-- Indexes for dumped tables
--

--
-- Indexes for table `ariyaio`
--
ALTER TABLE `ariyaio`
  ADD PRIMARY KEY (`id`);

--
-- AUTO_INCREMENT for dumped tables
--

--
-- AUTO_INCREMENT for table `ariyaio`
--
ALTER TABLE `ariyaio`
  MODIFY `id` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=775;COMMIT;

/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;
/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;
/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;
